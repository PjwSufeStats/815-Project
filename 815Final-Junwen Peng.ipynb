{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/pjw22/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/pjw22/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/pjw22/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from math import ceil\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import collections\n",
    "import random\n",
    "import time\n",
    "import string\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_curve, auc, f1_score, accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Dense, Convolution1D, MaxPooling1D, GlobalMaxPooling1D, Flatten, Dropout, LSTM, GRU,Bidirectional"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Processing and Train-Validation-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label = pd.read_csv('/Users/pjw22/Desktop/BU Course/815/NLP_app/MutualFundLabels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>fund_name</th>\n",
       "      <th>Performance fee?</th>\n",
       "      <th>Ivestment Strategy</th>\n",
       "      <th>Leverage?</th>\n",
       "      <th>Portfolio composition</th>\n",
       "      <th>Concentration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000051931-18-000151</td>\n",
       "      <td>American Funds College 2018 Fund</td>\n",
       "      <td>None</td>\n",
       "      <td>Balanced Fund (Low Risk)</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Investment grade securities</td>\n",
       "      <td>Diversified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000051931-18-000151</td>\n",
       "      <td>American Funds College 2021 Fund</td>\n",
       "      <td>None</td>\n",
       "      <td>Balanced Fund (Low Risk)</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Investment grade securities</td>\n",
       "      <td>Diversified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000051931-18-000151</td>\n",
       "      <td>American Funds College 2024 Fund</td>\n",
       "      <td>None</td>\n",
       "      <td>Balanced Fund (Low Risk)</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Investment grade securities</td>\n",
       "      <td>Diversified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000051931-18-000151</td>\n",
       "      <td>American Funds College 2027 Fund</td>\n",
       "      <td>None</td>\n",
       "      <td>Balanced Fund (Low Risk)</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Investment grade securities</td>\n",
       "      <td>Diversified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000051931-18-000151</td>\n",
       "      <td>American Funds College 2030 Fund</td>\n",
       "      <td>None</td>\n",
       "      <td>Balanced Fund (Low Risk)</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Investment grade securities</td>\n",
       "      <td>Diversified</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id                         fund_name Performance fee?  \\\n",
       "0  0000051931-18-000151  American Funds College 2018 Fund             None   \n",
       "1  0000051931-18-000151  American Funds College 2021 Fund             None   \n",
       "2  0000051931-18-000151  American Funds College 2024 Fund             None   \n",
       "3  0000051931-18-000151  American Funds College 2027 Fund             None   \n",
       "4  0000051931-18-000151  American Funds College 2030 Fund             None   \n",
       "\n",
       "         Ivestment Strategy Leverage?        Portfolio composition  \\\n",
       "0  Balanced Fund (Low Risk)       Yes  Investment grade securities   \n",
       "1  Balanced Fund (Low Risk)       Yes  Investment grade securities   \n",
       "2  Balanced Fund (Low Risk)       Yes  Investment grade securities   \n",
       "3  Balanced Fund (Low Risk)       Yes  Investment grade securities   \n",
       "4  Balanced Fund (Low Risk)       Yes  Investment grade securities   \n",
       "\n",
       "   Concentration  \n",
       "0    Diversified  \n",
       "1    Diversified  \n",
       "2    Diversified  \n",
       "3    Diversified  \n",
       "4    Diversified  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_label.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Equity Long Only (Low Risk)          248\n",
       "Fixed Income Long Only (Low Risk)    130\n",
       "Balanced Fund (Low Risk)              84\n",
       "Long Short Funds (High Risk)           4\n",
       "Commodities Fund (Low Risk)            1\n",
       "Name: Ivestment Strategy, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_label['Ivestment Strategy'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label = df_label[df_label['Ivestment Strategy'] != 'Commodities Fund (Low Risk)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Equity Long Only (Low Risk)          248\n",
       "Fixed Income Long Only (Low Risk)    130\n",
       "Balanced Fund (Low Risk)              84\n",
       "Long Short Funds (High Risk)           4\n",
       "Name: Ivestment Strategy, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_label['Ivestment Strategy'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Progress bar\n",
    "def progress(value, max=100):\n",
    "    return HTML(\"\"\"\n",
    "        <progress\n",
    "            value='{value}'\n",
    "            max='{max}',\n",
    "            style='width: 100%'\n",
    "        >\n",
    "            {value}\n",
    "        </progress>\n",
    "    \"\"\".format(value=value, max=max))\n",
    "\n",
    "\n",
    "# read the repo in PATH and append the texts in a list\n",
    "def get_data(PATH):\n",
    "    list_dir = os.listdir(PATH)\n",
    "    texts = []\n",
    "    fund_names = []\n",
    "    out = display(progress(0, len(list_dir)-1), display_id=True)\n",
    "    for ii, filename in enumerate(list_dir) :\n",
    "        with open(PATH+'/'+filename, 'r', encoding=\"utf8\") as f :\n",
    "            txt = f.read()\n",
    "            try :\n",
    "                txt_split = txt.split('<head_breaker>')\n",
    "                summary = txt_split[1].strip()\n",
    "                fund_name = txt_split[0].strip()\n",
    "            except :\n",
    "                summary = txt\n",
    "                fund_name = ''\n",
    "        texts.append(summary)\n",
    "        fund_names.append(fund_name)\n",
    "        out.update(progress(ii, len(list_dir)-1))\n",
    "    return fund_names, texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the summaries\n",
    "fund_names, summaries = get_data('/Users/pjw22/Desktop/BU Course/815/NLP_app/MutualFundSummary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Investment Objective\\nThrivent Partner Healthcare Portfolio (the \"Portfolio\") seeks long-term capital growth.\\nFees and Expenses\\nThis table describes the fees and expenses that you may pay if you buy and hold shares of the Portfolio. If you own a variable annuity contract or variable life insurance contract, you will have additional expenses including mortality and expense risk charges. Please refer to the prospectus for your variable contract for additional information about charges for those contracts.\\nSHAREHOLDER FEES\\n(fees paid directly from your investment)\\nMaximum Sales Charge (load) Imposed On Purchases (as a percentage of offering price)\\tN/A\\nMaximum Deferred Sales Charge (load) (as a percentage of the net asset value at time of purchase or redemption, whichever is lower)\\tN/A\\nANNUAL PORTFOLIO OPERATING EXPENSES\\n(expenses that you pay each year as a percentage of\\nthe value of your investment)\\nManagement Fees\\t0.83%\\nOther Expenses\\t0.10%\\nTotal Annual Portfolio Operating Expenses\\t0.93%\\nLess Fee Waivers and/or Expense Reimbursements1\\t0.05%\\nTotal Annual Portfolio Operating Expenses After Fee Waivers and/or Expense Reimbursements\\t0.88%\\n1\\tThe Adviser has contractually agreed, through at least April 30, 2019, to waive a portion of the management fees associated with the shares of the Thrivent Partner Healthcare Portfolio equal in the aggregate to 0.05% of the average daily net assets. This contractual provision, however, may be terminated before the indicated termination date upon the mutual agreement between the Independent Directors of the Portfolio and the Adviser.\\nEXAMPLE This example is intended to help you compare the cost of investing in the Portfolio with the cost of investing in other mutual funds. The Portfolio is an investment option for variable contracts, and the example does not include charges imposed by variable contracts. If variable contract charges were imposed, your expenses would be higher than those shown. The example assumes that you invest $10,000 in the Portfolio for the time periods indicated and then redeem all of your shares at the end of those periods. In addition, the example for the 1 Year period reflects the effect of the contractual fee waiver and/or expense reimbursement. The example also assumes that your investment has a 5% return each year, and that the\\nPortfolio’s operating expenses remain the same. Although your actual cost may be higher or lower, based on the foregoing assumptions, your cost would be:\\n \\t1 Year\\t3 Years\\t5 Years\\t10 Years\\nThrivent Partner Healthcare Portfolio\\t$90\\t$291\\t$510\\t$1,138\\nPortfolio Turnover\\nThe Portfolio pays transaction costs, such as commissions, when it buys and sells securities (or “turns over” its portfolio). A higher portfolio turnover rate may indicate higher transaction costs and may result in higher taxes when Portfolio shares are held in a taxable account. These costs, which are not reflected in annual fund operating expenses or in the example, affect the Portfolio’s performance. During the most recent fiscal year, the Portfolio’s portfolio turnover rate was 212% of the average value of its portfolio.\\nPrincipal Strategies\\nUnder normal circumstances, the Portfolio will invest at least 80% of its net assets (plus the amount of any borrowing for investment purposes) in the securities of companies that are engaged in the development, production or distribution of pharmaceutical, generic, biotechnology and medical technology products or services (“healthcare companies”). Healthcare companies are those that derive at least 50% of their annual revenues from the production of such products and provision of such services or have at least 50% of their assets in such products or services. The Portfolio invests primarily in equity securities of both U.S. and non-U.S. companies (including American Depositary Receipts and issuers in emerging markets) and, as a non-diversified fund under the Investment Company Act of 1940 (the “1940 Act”), focuses its investments in the securities of a relatively few number of issuers. In addition, the Portfolio concentrates its investments in the securities of companies in the healthcare industry, some of which may be small- and medium-sized companies. Should the Adviser determine that the Portfolio would benefit from reducing the percentage of its assets invested in the securities of healthcare companies from 80% to a lesser amount, it will notify you at least 60 days prior to the change.\\nBlackRock Investment Management, LLC, the Portfolio’s subadviser, considers a variety of factors when choosing investments for the Portfolio, including (i) identifying companies and industries that appear to have the potential for above-average returns; and (ii) identifying companies that are expected to show above-average growth over the long-term, as well as those that appear\\n \\n \\n101\\n \\n\\nTable of Contents\\nto be trading below their true worth. The Portfolio will generally sell a stock when, in the opinion of the subadviser, the stock reaches its price target or if there is deterioration in the company’s fundamentals, a change in macroeconomic outlook, technical deterioration, valuation issues, a need to rebalance the Portfolio or a better opportunity elsewhere.\\nPrincipal Risks\\nThe Portfolio is subject to the following principal investment risks. Shares of the Portfolio will rise and fall in value and there is a risk that you could lose money by investing in the Portfolio. The Portfolio cannot be certain that it will achieve its investment objective.\\nEmerging Markets Risk. The economic and political structures of developing countries, in most cases, do not compare favorably with the U.S. or other developed countries in terms of wealth and stability, and their financial markets often lack liquidity. Portfolio performance will likely be negatively affected by portfolio exposure to countries in the midst of, among other things, hyperinflation, currency devaluation, trade disagreements, sudden political upheaval, or interventionist government policies. Significant buying or selling actions by a few major investors may also heighten the volatility of emerging markets. These factors make investing in emerging market countries significantly riskier than in other countries, and events in any one country could cause the Portfolio’s share price to decline.\\nForeign Securities Risk. Foreign securities are generally more volatile than their domestic counterparts, in part because of higher political and economic risks, lack of reliable information and fluctuations in currency exchange rates. Foreign securities may also be more difficult to resell than comparable U.S. securities because the markets for foreign securities are often less liquid. Even when a foreign security increases in price in its local currency, the appreciation may be diluted by adverse changes in exchange rates when the security’s value is converted to U.S. dollars. Foreign withholding taxes also may apply and errors and delays may occur in the settlement process for foreign securities. All of these risks may be heightened for securities of issuers located in, or with significant operations in, emerging market countries.\\nGrowth Investing Risk. Growth style investing includes the risk of investing in securities whose prices historically have been more volatile than other securities, especially over the short term. Growth stock prices reflect projections of future earnings or revenues and, if a company’s earnings or revenues fall short of expectations, its stock price may fall dramatically.\\nHealthcare Industry Risk. As a sector fund that invests primarily in the healthcare industry, the Portfolio is subject to the risk that the companies in that\\nindustry are likely to react similarly to legislative or regulatory changes, adverse market conditions and/or increased competition affecting their market segment. Due to the rapid pace of technological development, there is the risk that the products and services developed by these companies may become rapidly obsolete or have relatively short product cycles. There is also the risk that the products and services offered by these companies will not meet expectations or even reach the marketplace.\\nInvestment Adviser Risk. The Portfolio is actively managed and the success of its investment strategy depends significantly on the skills of the Adviser or subadviser in assessing the potential of the investments in which the Portfolio invests. This assessment of investments may prove incorrect, resulting in losses or poor performance, even in rising markets.\\nIssuer Risk. Issuer risk is the possibility that factors specific to a company to which the Portfolio is exposed will affect the market prices of the company’s securities and therefore the value of the Portfolio. Some factors affecting the performance of a company include demand for the company\\'s products or services, the quality of management of the company and brand recognition and loyalty. Common stock of a company is subordinate to other securities issued by the company. If a company becomes insolvent, interests of investors owning common stock will be subordinated to the interests of other investors in, and general creditors of, the company.\\nMarket Risk. Over time, securities markets generally tend to move in cycles with periods when security prices rise and periods when security prices decline. The value of the Portfolio’s investments may move with these cycles and, in some instances, increase or decrease more than the applicable market(s) as measured by the Portfolio’s benchmark index(es). The securities markets may also decline because of factors that affect a particular industry.\\nNon-Diversified Risk. The Portfolio is not “diversified” within the meaning of the 1940 Act. That means the Portfolio may invest a greater percentage of its assets in the securities of any single issuer compared to other funds. A non-diversified portfolio is generally more susceptible than a diversified portfolio to the risk that events or developments affecting a particular issuer or industry will significantly affect the Portfolio’s performance.\\nSmall and Mid Cap Risk. Small- and medium-sized companies often have greater price volatility, lower trading volumes, and less liquidity than larger, more established companies. These companies tend to have smaller revenues, narrower product lines, less management depth and experience, smaller shares of their product or service markets, fewer financial\\n102\\n \\n\\nTable of Contents\\nresources, and less competitive strength than larger companies.\\nValue Investing Risk. Value style investing includes the risk that stocks of undervalued companies may not rise as quickly as anticipated if the market doesn’t recognize their intrinsic value or if value stocks are out of favor.\\nVolatility Risk. Volatility risk is the risk that certain types of securities shift in and out of favor depending on market and economic conditions as well as investor sentiment. Stocks of growth companies historically have been more volatile than other securities, especially over the short term. Growth stock prices reflect projections of future earnings or revenues and if a company’s earnings or revenues fall short of expectations its stock price may fall dramatically.\\nPerformance\\nThe following bar chart and table provide an indication of the risks of investing in the Portfolio by showing changes in the Portfolio’s performance from year to year and by showing how the Portfolio’s average annual returns for one- and five-year periods and since inception compared to a broad-based securities market index. The index is the S&P Composite 1500® Index, which measures the performance of stocks in the S&P 1500® Index that are classified as members of the GICS® health care sector. The Portfolio no longer uses the MSCI World Healthcare Index, which is a capitalization-weighted index of selected health care stocks from around the world, because BlackRock Investment Management, LLC replaced Sectoral Asset Management Inc. (“Sectoral”) as the subadviser of the Portfolio on September 11, 2017. Performance information presented below with respect to periods prior to September 11, 2017 reflects the Portfolio’s performance when managed by Sectoral. Call 800-847-4836 or visit Thrivent.com for performance results current to the most recent month-end.\\nThe bar chart includes the effects of Portfolio expenses, but not charges or deductions against your variable contract, and assumes that you sold your investment at the end of the period. Because shares of the Portfolio are offered through variable life insurance and variable annuity contracts, you should carefully review the variable contract prospectus for information on applicable charges and expenses. If the charges and deductions against your variable contract were included, returns would be lower than those shown.\\nHow a Portfolio has performed in the past is not necessarily an indication of how it will perform in the future. Performance information provides some indication of the risks of investing in the Portfolio by showing changes in the Portfolio’s performance over time.\\nYEAR-BY-YEAR TOTAL RETURN\\n\\nBest Quarter:\\tQ1 \\'17\\t+11.60%\\nWorst Quarter:\\tQ3 \\'11\\t(15.79)%\\n    \\nAVERAGE ANNUAL TOTAL RETURNS\\n(PERIODS ENDING DECEMBER 29, 2017)\\nThrivent Partner Healthcare Portfolio\\t1 Year\\t5 Years\\tSince\\nInception\\n(4/30/08)\\n \\t19.42%\\t11.31%\\t9.68%\\nS&P Composite 1500 Health Care Index\\n(reflects no deduction for fees, expenses or taxes)\\t22.47%\\t17.98%\\t12.98%\\nMSCI World Healthcare Index - USD Net Returns\\n(reflects no deduction for fees, expenses or taxes)\\t19.80%\\t13.88%\\t10.57%\\nManagement\\nInvestment Adviser(s)\\nThe Portfolio is managed by Thrivent Financial for Lutherans (“Thrivent Financial” or the “Adviser”), which has engaged BlackRock Investment Management, LLC. (“BIM”) to subadvise the Portfolio.\\nPortfolio Manager(s)\\nErin Xie, Managing Director of BlackRock, Inc.(“BlackRock”), is primarily responsible for the day-to-day management of the Portfolio. Dr. Xie has served as the portfolio manager of the Portfolio since September 2017. Dr. Xie has been a Managing Director of BlackRock since 2006 and joined BlackRock as a Director in 2005. Prior to joining BlackRock, Dr. Xie was a Senior Vice President of State Street Research & Management from 2001 to 2005.\\nPurchase and Sale of Shares\\nShares of each series of Thrivent Series Fund, Inc. (the “Fund”) may be sold, without any minimum initial or subsequent investment requirements, only to:\\n103\\n \\n\\nTable of Contents\\n•\\tSeparate accounts of Thrivent Financial and Thrivent Life Insurance Company;\\n•\\tSeparate accounts of other insurance companies not affiliated with Thrivent Financial; and\\n•\\tOther Portfolios of the Fund.\\nTax Information\\nFor information about certain tax-related aspects of investing in the Portfolio through a variable contract, please see the variable product prospectus.\\nPayments to Broker-Dealers and Other Financial Intermediaries\\nIf you purchase the Portfolio through a broker-dealer or other financial intermediary (such as an insurance company), the Portfolio and its related companies may pay the intermediary for the sale of Portfolio shares and related services. These payments may create a conflict of interest by influencing the broker-dealer or other intermediary and your salesperson to recommend the Portfolio over another investment. Ask your salesperson or visit your financial intermediary’s website for more information.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summaries[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>fund_name</th>\n",
       "      <th>Performance fee?</th>\n",
       "      <th>Ivestment Strategy</th>\n",
       "      <th>Leverage?</th>\n",
       "      <th>Portfolio composition</th>\n",
       "      <th>Concentration</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000051931-18-000151</td>\n",
       "      <td>American Funds College 2018 Fund</td>\n",
       "      <td>None</td>\n",
       "      <td>Balanced Fund (Low Risk)</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Investment grade securities</td>\n",
       "      <td>Diversified</td>\n",
       "      <td>American Funds College 2018 Fund\\n\\nInvestment...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000051931-18-000151</td>\n",
       "      <td>American Funds College 2021 Fund</td>\n",
       "      <td>None</td>\n",
       "      <td>Balanced Fund (Low Risk)</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Investment grade securities</td>\n",
       "      <td>Diversified</td>\n",
       "      <td>American Funds College 2021 Fund\\n\\nInvestment...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000051931-18-000151</td>\n",
       "      <td>American Funds College 2024 Fund</td>\n",
       "      <td>None</td>\n",
       "      <td>Balanced Fund (Low Risk)</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Investment grade securities</td>\n",
       "      <td>Diversified</td>\n",
       "      <td>American Funds College 2024 Fund\\n\\nInvestment...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000051931-18-000151</td>\n",
       "      <td>American Funds College 2027 Fund</td>\n",
       "      <td>None</td>\n",
       "      <td>Balanced Fund (Low Risk)</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Investment grade securities</td>\n",
       "      <td>Diversified</td>\n",
       "      <td>American Funds College 2027 Fund\\n\\nInvestment...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000051931-18-000151</td>\n",
       "      <td>American Funds College 2030 Fund</td>\n",
       "      <td>None</td>\n",
       "      <td>Balanced Fund (Low Risk)</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Investment grade securities</td>\n",
       "      <td>Diversified</td>\n",
       "      <td>American Funds College 2030 Fund\\n\\nInvestment...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id                         fund_name Performance fee?  \\\n",
       "0  0000051931-18-000151  American Funds College 2018 Fund             None   \n",
       "1  0000051931-18-000151  American Funds College 2021 Fund             None   \n",
       "2  0000051931-18-000151  American Funds College 2024 Fund             None   \n",
       "3  0000051931-18-000151  American Funds College 2027 Fund             None   \n",
       "4  0000051931-18-000151  American Funds College 2030 Fund             None   \n",
       "\n",
       "         Ivestment Strategy Leverage?        Portfolio composition  \\\n",
       "0  Balanced Fund (Low Risk)       Yes  Investment grade securities   \n",
       "1  Balanced Fund (Low Risk)       Yes  Investment grade securities   \n",
       "2  Balanced Fund (Low Risk)       Yes  Investment grade securities   \n",
       "3  Balanced Fund (Low Risk)       Yes  Investment grade securities   \n",
       "4  Balanced Fund (Low Risk)       Yes  Investment grade securities   \n",
       "\n",
       "   Concentration                                            summary  \n",
       "0    Diversified  American Funds College 2018 Fund\\n\\nInvestment...  \n",
       "1    Diversified  American Funds College 2021 Fund\\n\\nInvestment...  \n",
       "2    Diversified  American Funds College 2024 Fund\\n\\nInvestment...  \n",
       "3    Diversified  American Funds College 2027 Fund\\n\\nInvestment...  \n",
       "4    Diversified  American Funds College 2030 Fund\\n\\nInvestment...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We create here the dataframe that contains the summaries along with their labels\n",
    "df_extraction = pd.DataFrame({'fund_name' : fund_names, 'summary':summaries})\n",
    "#df_label = pd.read_csv(SUMMARY_LABELS_PATH)\n",
    "df = df_label.merge(df_extraction, on='fund_name', how='left').dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test validation split, adjust the random state to make sure every set contains a long short sample\n",
    "\n",
    "df_train, df_test = train_test_split(df, test_size = 0.2, random_state=48)\n",
    "df_train, df_val = train_test_split(df_train, test_size=0.2, random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_summaries = list(df_train['summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Equity Long Only (Low Risk)          153\n",
       "Fixed Income Long Only (Low Risk)     89\n",
       "Balanced Fund (Low Risk)              53\n",
       "Long Short Funds (High Risk)           2\n",
       "Name: Ivestment Strategy, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['Ivestment Strategy'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Equity Long Only (Low Risk)          44\n",
       "Fixed Income Long Only (Low Risk)    18\n",
       "Balanced Fund (Low Risk)             12\n",
       "Long Short Funds (High Risk)          1\n",
       "Name: Ivestment Strategy, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val['Ivestment Strategy'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Equity Long Only (Low Risk)          50\n",
       "Fixed Income Long Only (Low Risk)    23\n",
       "Balanced Fund (Low Risk)             19\n",
       "Long Short Funds (High Risk)          1\n",
       "Name: Ivestment Strategy, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['Ivestment Strategy'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Train the Skip-Gram Model and Build Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"english\")+list(string.punctuation)+['``',\"''\"]+[\"]\",\"[\",\"*\"]+['doe', 'ha', 'wa'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean and tokenize the text -> we don't want to lemmatize\n",
    "def tokenizer(txt):\n",
    "    txt = txt.replace('\\n', ' ').replace('\\t', ' ').lower()\n",
    "    word_tokens = word_tokenize(txt)\n",
    "    filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
    "    filtered_sentence = [w for w in filtered_sentence if re.sub(\"[^A-Za-z ]+\",'',w) != ''] \n",
    "    return filtered_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_words = np.concatenate([tokenizer(summary) for summary in train_summaries])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Parameters\n",
    "batch_size = 128 # The model will be trained batch per batch and one batch contains 128 rows\n",
    "num_epochs = 2 # The model will go through all the data twice\n",
    "\n",
    "\n",
    "# Word2Vec Parameters\n",
    "embedding_size = 50 # Dimension of the embedding vector\n",
    "max_vocabulary_size = 5000 # Total number of different words in the vocabulary\n",
    "min_occurrence = 10 # Remove all words that does not appears at least n times\n",
    "skip_window = 3 # How many words to consider left and right\n",
    "num_skips = 4 # How many times to reuse an input to generate a label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the dictionary and replace rare words with UNK token\n",
    "count = [('UNK', -1)]\n",
    "# Retrieve the most common words\n",
    "count.extend(collections.Counter(text_words).most_common(max_vocabulary_size - 1))\n",
    "# Remove samples with less than 'min_occurrence' occurrences\n",
    "for i in range(len(count) - 1, -1, -1):\n",
    "    if count[i][1] < min_occurrence:\n",
    "        count.pop(i)\n",
    "    else:\n",
    "        # The collection is ordered, so stop when 'min_occurrence' is reached\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2id = dict()\n",
    "for i, (word, _)in enumerate(count):\n",
    "    word2id[word] = i\n",
    "id2word = dict(zip(word2id.values(), word2id.keys()))\n",
    "vocab_size = len(id2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data\n",
    "data = list()\n",
    "unk_count = 0\n",
    "for word in text_words:\n",
    "    # Retrieve a word id, or assign it index 0 ('UNK') if not in dictionary\n",
    "    index = word2id.get(word, 0)\n",
    "    if index == 0:\n",
    "        unk_count += 1\n",
    "    data.append(index)\n",
    "count[0] = ('UNK', unk_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build OneHot vector from index\n",
    "def to_one_hot(data_point_index, vocab_size):\n",
    "    temp = np.zeros(vocab_size)\n",
    "    temp[data_point_index] = 1\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate training batch for the skip-gram model\n",
    "def batch_generator(batch_size, num_skips, skip_window, vocab_size):\n",
    "    data_index = 0\n",
    "    while True :\n",
    "        assert batch_size % num_skips == 0\n",
    "        assert num_skips <= 2 * skip_window\n",
    "        # batch is filled with 128 inputs\n",
    "        batch = np.ndarray(shape=(batch_size), dtype=np.int32)\n",
    "        # labels is filled with 128 outputs \n",
    "        labels = np.ndarray(shape=(batch_size), dtype=np.int32)\n",
    "        span = 2 * skip_window + 1\n",
    "        # buffer keep track of the visited indexes visited\n",
    "        buffer = collections.deque(maxlen=span)\n",
    "        if data_index + span > len(data):\n",
    "            data_index = 0\n",
    "            # We stop the loop when we went through all the corpus\n",
    "            break\n",
    "        buffer.extend(data[data_index:data_index + span])\n",
    "        data_index += span\n",
    "        for i in range(batch_size // num_skips):  \n",
    "            # Take the context current word\n",
    "            context_words = [w for w in range(span) if w != skip_window]\n",
    "            # Randomly select num_skips words in the context\n",
    "            words_to_use = random.sample(context_words, num_skips)\n",
    "            for j, context_word in enumerate(words_to_use):\n",
    "                # Creates one raw data\n",
    "                batch[i * num_skips + j] = buffer[skip_window]\n",
    "                labels[i * num_skips + j] = buffer[context_word]\n",
    "            if data_index == len(data):\n",
    "                buffer.extend(data[0:span])\n",
    "                data_index = span\n",
    "            else:\n",
    "                buffer.append(data[data_index])\n",
    "                data_index += 1\n",
    "        # Backtrack a little bit to avoid skipping words in the end of a batch\n",
    "        data_index = (data_index + len(data) - span) % len(data)\n",
    "\n",
    "        # translate word index to on-hot representation\n",
    "        batch_one_hot = np.array([to_one_hot(b, vocab_size) for b in batch])\n",
    "        labels_one_hot = np.array([to_one_hot(l, vocab_size) for l in labels])\n",
    "\n",
    "        # output one batch\n",
    "        yield batch_one_hot, labels_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create en compile the Autoencoder\n",
    "def creat_word2vec_model():\n",
    "    input_word = Input(shape=(vocab_size,))\n",
    "\n",
    "    encoded = Dense(embedding_size, activation='linear')(input_word)\n",
    "    decoded = Dense(vocab_size, activation='softmax')(encoded)\n",
    "\n",
    "    # The autoencoder is the whole model with hidden layer contected to the output layer.\n",
    "    autoencoder = Model(input_word, decoded)\n",
    "    # The encoder is just the input layer connected to the hidden layer. One the Autoencoder will be trained we will use\n",
    "    # the encoder to create our word vectors \n",
    "    encoder = Model(input_word, encoded)\n",
    "    \n",
    "    #autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    autoencoder.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "    return encoder, autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create the model\n",
    "encoder, autoencoder = creat_word2vec_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l_/7bxj1ry51hbcvpybp93hdq4w0000gn/T/ipykernel_46970/486976267.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  autoencoder.fit_generator(batch_generator(batch_size, num_skips, skip_window, vocab_size), steps_per_epoch=ceil(len(data) / batch_size), epochs=num_epochs)\n",
      "2023-05-05 10:43:14.271464: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4124/4124 [==============================] - 13s 3ms/step - loss: 6.5602\n",
      "Epoch 2/2\n",
      "4124/4124 [==============================] - 12s 3ms/step - loss: 6.0103\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17338ed60>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit_generator(batch_generator(batch_size, num_skips, skip_window, vocab_size), steps_per_epoch=ceil(len(data) / batch_size), epochs=num_epochs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_path= '/Users/pjw22/Desktop/BU Course/815/NLP_app'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a word2vec dictionary.\n",
    "def save_word2vec(filename):\n",
    "    with open(os.path.join(my_path, filename),'a' , encoding='utf-8') as f :\n",
    "    #with open(os.path.join('/Users/haoxing/Documents/Work/Teaching/Machine learning for Finance/Codes/NLP/NLP_app', filename),'a' , encoding='utf-8') as f :\n",
    "        for k, v in word2vec.items():\n",
    "            line = k+' '+str(list(v)).strip('[]').replace(',','')+'\\n'\n",
    "            f.write(line)\n",
    "\n",
    "# Load a word2vec dictionary.\n",
    "def load_word2vec(filename):\n",
    "    word2vec = {}\n",
    "    with open(os.path.join(my_path, filename), encoding='utf8') as f:\n",
    "    #with open(os.path.join('/Users/haoxing/Documents/Work/Teaching/Machine learning for Finance/Codes/NLP/NLP_app', filename), encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            try :\n",
    "                values = line.split()\n",
    "                word = values[0]\n",
    "                vec = np.asarray(values[1:], dtype='float32')\n",
    "                word2vec[word] = vec\n",
    "            except :\n",
    "                None\n",
    "    return word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n"
     ]
    }
   ],
   "source": [
    "# Create the Vectorizer function (prediciton of the encoder)\n",
    "def vecotrize(word):\n",
    "    word_one_hot = to_one_hot(word2id[word], vocab_size)\n",
    "    return encoder.predict(np.array([word_one_hot]))[0]\n",
    "\n",
    "\n",
    "# Create the word2vec dictionary\n",
    "word2vec = {w : vecotrize(w) for w in word2id.keys()}\n",
    "\n",
    "# This dictionary gives for all words it's vectorial representation.\n",
    "\n",
    "\n",
    "our_word2vec = 'word2vec_perso.txt'\n",
    "\n",
    "# We can save the word2vec dictionary to reuse it later.\n",
    "save_word2vec(our_word2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a given word, output the n closer words in the word2vec maping.\n",
    "def get_n_closer(w, n, word2vec):\n",
    "    vect = word2vec[w]\n",
    "    distances_dict = {k: cosine(v, vect) for k, v in word2vec.items()}\n",
    "    \n",
    "    closer_words = []\n",
    "    for _ in range(n):\n",
    "        min_key = min(distances_dict.keys(), key=lambda k: distances_dict[k])\n",
    "        closer_words.append(min_key)\n",
    "        del distances_dict[min_key]\n",
    "    return closer_words"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Design Knowledge Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keywords for “Balanced Fund (Low Risk)”\n",
    "key_words1 = ['portfolio', 'balanced', 'asset', 'diversification', 'risk', 'low', 'investment', 'strategy', 'fixed', 'income', 'equity', 'return', 'fund', 'conservative', 'market']\n",
    "\n",
    "# keywords for “Fixed Income Long Only (Low Risk)”\n",
    "key_words2 = ['portfolio', 'risk', 'low', 'investment', 'strategy', 'cash', 'fixed', 'income', 'bond', 'yield', 'credit', 'maturity', 'duration', 'treasury', 'interest', 'rate', 'corporate', 'inflation', 'economic']\n",
    "\n",
    "# keywords for “Equity Long Only (Low Risk)”\n",
    "key_words3 = ['equity', 'stocks', 'securities', 'earnings', 'dividend', 'financial', 'statement', 'revenue', 'price', 'volatility', 'fund', 'company', 'industry', 'economic', 'growth', 'sector', 'strategy', 'risk', 'portfolio', 'factor']\n",
    "\n",
    "# keywords for “Long Short Funds (High Risk)”\n",
    "key_words4 = ['stock', 'derivatives', 'short', 'long', 'leverage', 'risk', 'option', 'future', 'loan', 'margin', 'volatility', 'selling', 'stock', 'fixed', 'income', 'exchange', 'rate', 'currency']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates the knwoledge base by taking the num_neighbors closes neighbors of each key_words in word2vec\n",
    "def create_knowledge_base(num_neighbors, word2vec, key_words):\n",
    "    knowledge_base = set()\n",
    "    out = display(progress(0, len(key_words)-1), display_id=True)\n",
    "    for ii, key_word in enumerate(key_words) :\n",
    "        knowledge_base.add(key_word)\n",
    "        neighbors = []\n",
    "        try :\n",
    "            neighbors = get_n_closer(key_word, num_neighbors, word2vec)\n",
    "        except :\n",
    "            print(key_word + ' not in word2vec')\n",
    "\n",
    "        knowledge_base.update(neighbors)\n",
    "        \n",
    "        out.update(progress(ii, len(key_words)-1))\n",
    "    return knowledge_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <progress\n",
       "            value='12'\n",
       "            max='14',\n",
       "            style='width: 100%'\n",
       "        >\n",
       "            12\n",
       "        </progress>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <progress\n",
       "            value='16'\n",
       "            max='18',\n",
       "            style='width: 100%'\n",
       "        >\n",
       "            16\n",
       "        </progress>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <progress\n",
       "            value='5'\n",
       "            max='19',\n",
       "            style='width: 100%'\n",
       "        >\n",
       "            5\n",
       "        </progress>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <progress\n",
       "            value='9'\n",
       "            max='17',\n",
       "            style='width: 100%'\n",
       "        >\n",
       "            9\n",
       "        </progress>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#word2vec = load_word2vec(our_word2vec)\n",
    "knowledge_base1 = create_knowledge_base(5, word2vec, key_words1)\n",
    "knowledge_base2 = create_knowledge_base(5, word2vec, key_words2)\n",
    "knowledge_base3 = create_knowledge_base(5, word2vec, key_words3)\n",
    "knowledge_base4 = create_knowledge_base(5, word2vec, key_words4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "knowledge_base = knowledge_base1.union(knowledge_base2).union(knowledge_base3).union(knowledge_base4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'stocks', 'flow', 'behalf', 'avoid', 'projects', 'things', 'investment', 'advisers', 'corporate', 'bbb-', 'sai', 'june', 'advisor', 'declining', 'managers', 'jpmorgan', 'managed', 'prevailing', 'economic', 'means', 'debt', 'weightings', 'decisions', 'earlier', 'movements', 'short', 'factor', 'page', 'maturity', 'duration', 'revenue', 'selected', 'iico', 'underperform', 'intermediary', 'terms', 'gross', 'attractively', 'company', 'manages', 'entails', 'section', 'summary', 'treasury', 'loss', 'currency', 'increases', 'loan', 'year-to-date', 'statement', 'commodity', 'conservative', 'parent', 'hypothetically', 'prepayment', 'fluctuations', 'serves', 'force', 'backed', 'bond', 'equity', 'monitor', 'financing', 'managing', 'reason', 'multi-manager', 'derivatives', 'conduct', 'mortgage', 'electronic', 'linked', 'performs', 'credit', 'turnover', 'low', 'dollar', 'developments', 'governing', 'potentially', 'risk', 'reward', 'preferred', 'designed', 'interconnected', 'particularly', 'imi', 'erratic', 'margin', 'rise', 'general', 'equity-type', 'enterprises', 'individuals', 'convertible', 'realized', 'unmanaged', 'expire', 'gain', 'forth', 'extension', 'nav', 'selling', 'instruments', 'unexpected', 'etf', 'california', 'portion', 'lose', 'durations', 'technology', 'long', 'index℠', 'volatility', 'conversely', 'perceived', 'march', 'asset', 'actively', 'additional', 'sector', 'marginal', 'use', 'includes', 'magnify', 'affect', 'opinion', 'manager', 'repay', 'inflation', 'specific', 'title', 'income', 'considered', 'balanced', 'floating', 'assigned', 'losing', 'industries', 'bottom-up', 'growth', 'updated', 'earnings', 'dividend', 'option', 'falling', 'sponsoring', 'usually', 'blockage', 'longer', 'future', 'cash', 'indication', 'others', 'treatment', 'key', 'subadviser', 'values', 'thereafter', 'affecting', 'stock', 'u.s.', 'defaults', 'possibility', 'precious', 'web', 'strategy', 'return', 'stabilize', 'proceeds', 'portfolio', 'ivy', 'rising', 'pay', 'inc.', 'fixed', 'sharply', 'security', 'fund', 'characteristics', 'social', 'interest', 'exchanging', 'events', 'agree', 'supply', 'liquidity', 'mortgage-backed', 'realize', 'financial', 'intermediaries', 'determinations', 'factors', 'heightened', 'highly', 'description', 'finance', 'property', 'drop', 'additionally', 'gains', 'provided', 'borrowers', 'yield', 'rate', 'regulatory', 'exchange', 'yields', 'securities', 'industry', 'communications', 'tariffs', 'exempt', 'lipper', 'market', 'original', 'price', 'decreased', 'smaller', 'counterparty', 'instability', 'common', 'prepayments', 'extremely', 'junk', 'necessarily', 'process', 'illiquidity', 'differing', 'diversification', 'leverage', 'sensitive', 'ability', 'typically'}\n"
     ]
    }
   ],
   "source": [
    "print(knowledge_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes a summary, the knowledge base and some hyper parameters and returns the \"num_sent\" sentences\n",
    "# of the summary that are closer to the the knowledge base in term of spacial distances.\n",
    "def extract_sentence_distance(summary, knowledge, n_closer, n_reject, num_sent):\n",
    "    # Split the summary into sentences.\n",
    "    sentences = sent_tokenize(summary)\n",
    "    sentence_scores = []\n",
    "    # Loop over the sentences.\n",
    "    for j, sentence in enumerate(sentences):\n",
    "        # we tokenize and clean the sentence\n",
    "        tokens = tokenizer(sentence)\n",
    "\n",
    "        sentence_barycentre = np.zeros(embedding_size)\n",
    "        effective_len = 0\n",
    "        # Compute the barycentre of the sentence\n",
    "        for token in tokens :\n",
    "            try :\n",
    "                sentence_barycentre += np.array(word2vec[token])\n",
    "                effective_len += 1\n",
    "            except KeyError :\n",
    "                pass\n",
    "            except :\n",
    "                raise\n",
    "        \n",
    "        # Reject sentences with less than n_reject words in our word2vec map\n",
    "        if effective_len <= n_reject :\n",
    "            sentence_scores.append(1)    \n",
    "\n",
    "        else :\n",
    "            sentence_barycentre = sentence_barycentre/effective_len\n",
    "            # Compute the distance sentece_barycentre -> words in our knowledge base\n",
    "            barycentre_distance = [cosine(sentence_barycentre, word2vec[key_word]) for key_word in knowledge]\n",
    "            barycentre_distance.sort()\n",
    "            # Create the score of the sentence by averaging the \"n_closer\" smallest distances\n",
    "            score = np.mean(barycentre_distance[:n_closer])\n",
    "            sentence_scores.append(score)\n",
    "    # Select the \"num_sent\" sentences that have the smallest score (smallest distance score with the knowledge base)\n",
    "    sentence_scores, sentences = zip(*sorted(zip(sentence_scores, sentences)))\n",
    "    top_sentences = sentences[:num_sent]\n",
    "    return ' '.join(top_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It takes several minutes (5-10 minutes)\n",
    "df_train['sentences_distance'] = df_train.apply(lambda x : extract_sentence_distance(x['summary'], knowledge_base, n_closer=10, n_reject=5, num_sent=5), axis=1)\n",
    "\n",
    "df_val['sentences_distance'] = df_val.apply(lambda x : extract_sentence_distance(x['summary'], knowledge_base, n_closer=10, n_reject=5, num_sent=5), axis=1)\n",
    "\n",
    "df_test['sentences_distance'] = df_test.apply(lambda x : extract_sentence_distance(x['summary'], knowledge_base, n_closer=10, n_reject=5, num_sent=5), axis=1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Construct Prediction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'inflation rapid fluctuations inflation interest rates may continue negative effects economy securiti'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = df_train['sentences_distance'].values\n",
    "X_val = df_val['sentences_distance'].values\n",
    "X_test = df_test['sentences_distance'].values\n",
    "\n",
    "# X = df['deriv_sentences_distance'].values # uncomment to use the first sentence extraction method.\n",
    "# Clean the texts\n",
    "X_train = [' '.join(tokenizer(txt)) for txt in X_train]\n",
    "X_val = [' '.join(tokenizer(txt)) for txt in X_val]\n",
    "X_test = [' '.join(tokenizer(txt)) for txt in X_test]\n",
    "\n",
    "X_train[0][:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# one-hot for labels\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "\n",
    "y_train = encoder.fit_transform(np.array(df_train['Ivestment Strategy']).reshape(-1,1))\n",
    "y_val = encoder.fit_transform(np.array(df_val['Ivestment Strategy']).reshape(-1,1))\n",
    "y_test = encoder.fit_transform(np.array(df_test['Ivestment Strategy']).reshape(-1,1))\n",
    "\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = 2500 # Size of the vocabulary used. we only consider the 2500 most common words. The other words are removed from the texts.\n",
    "maxlen = 150 # Number of word considered for each document. we cut or lengthen the texts to have texts of 150 words.\n",
    "word_dimension = 50 # dimension of our word vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_word2vec = '/Users/pjw22/Desktop/BU Course/815/NLP_app/glove.6B.50d.txt'\n",
    "our_word2vec = '/Users/pjw22/Desktop/BU Course/815/NLP_app/word2vec_perso.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_g = load_word2vec(glove_word2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Tokenizer provided by the Keras library allows to perform such transformation.\n",
    "keras_tokenizer = Tokenizer(num_words=num_words)\n",
    "keras_tokenizer.fit_on_texts(X_train)\n",
    "# word_index is the dictionary that contains the index of each words in our 2500 long vocabulary.\n",
    "word_index = keras_tokenizer.word_index\n",
    "sequences_train = keras_tokenizer.texts_to_sequences(X_train)\n",
    "sequences_test = keras_tokenizer.texts_to_sequences(X_test)\n",
    "sequences_val = keras_tokenizer.texts_to_sequences(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_train = pad_sequences(sequences_train, maxlen=maxlen, dtype=float, padding='post', truncating='post')\n",
    "feature_test = pad_sequences(sequences_test, maxlen=maxlen, dtype=float, padding='post', truncating='post')\n",
    "feature_val = pad_sequences(sequences_val, maxlen=maxlen, dtype=float, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(word_index) + 1, word_dimension))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = word2vec_g.get(word)\n",
    "    #embedding_vector = word2vec.get(word)   # uncomment to use our own word2vec\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_CNN_model():\n",
    "    CNN = Sequential()\n",
    "    # The Embedding layer takes the embedding matrix as an argument and transform the inputed the sequences of index to sequences of vectors.\n",
    "    CNN.add(Embedding(len(word_index) + 1, word_dimension, weights=[embedding_matrix], input_length = maxlen, trainable=False))\n",
    "\n",
    "\n",
    "    CNN.add(Convolution1D(64, 5, activation = 'relu'))\n",
    "    CNN.add(MaxPooling1D(pool_size = 5))\n",
    "\n",
    "    CNN.add(Convolution1D(32, 5, activation = 'relu'))\n",
    "    CNN.add(MaxPooling1D(pool_size = 5))\n",
    "\n",
    "    CNN.add(Flatten())\n",
    "    CNN.add(Dense(units = 128 , activation = 'relu'))\n",
    "    CNN.add(Dropout(0.5))\n",
    "\n",
    "    #CNN.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "    CNN.add(Dense(units = 4, activation = 'sigmoid'))\n",
    "\n",
    "    #CNN.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    CNN.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    return CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_model = create_CNN_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 1.0807 - accuracy: 0.5421 - val_loss: 0.9315 - val_accuracy: 0.5867\n",
      "Epoch 2/50\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.8864 - accuracy: 0.6397 - val_loss: 0.7926 - val_accuracy: 0.7200\n",
      "Epoch 3/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.6594 - accuracy: 0.7744 - val_loss: 0.6591 - val_accuracy: 0.7467\n",
      "Epoch 4/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4598 - accuracy: 0.8451 - val_loss: 0.6269 - val_accuracy: 0.8267\n",
      "Epoch 5/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.3604 - accuracy: 0.8990 - val_loss: 0.5544 - val_accuracy: 0.8133\n",
      "Epoch 6/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.3354 - accuracy: 0.8889 - val_loss: 0.5238 - val_accuracy: 0.8267\n",
      "Epoch 7/50\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.2419 - accuracy: 0.9394 - val_loss: 0.5004 - val_accuracy: 0.8400\n",
      "Epoch 8/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.1584 - accuracy: 0.9630 - val_loss: 0.5331 - val_accuracy: 0.8400\n",
      "Epoch 9/50\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.1194 - accuracy: 0.9697 - val_loss: 0.5626 - val_accuracy: 0.8533\n",
      "Epoch 10/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0916 - accuracy: 0.9697 - val_loss: 0.5113 - val_accuracy: 0.8667\n",
      "Epoch 11/50\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.1048 - accuracy: 0.9663 - val_loss: 0.4875 - val_accuracy: 0.8667\n",
      "Epoch 12/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0800 - accuracy: 0.9832 - val_loss: 0.5318 - val_accuracy: 0.8667\n",
      "Epoch 13/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0899 - accuracy: 0.9697 - val_loss: 0.5719 - val_accuracy: 0.8667\n",
      "Epoch 14/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0852 - accuracy: 0.9832 - val_loss: 0.5221 - val_accuracy: 0.8533\n",
      "Epoch 15/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0457 - accuracy: 0.9899 - val_loss: 0.5662 - val_accuracy: 0.8667\n",
      "Epoch 16/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0611 - accuracy: 0.9798 - val_loss: 0.5756 - val_accuracy: 0.8267\n",
      "Epoch 17/50\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.0419 - accuracy: 0.9933 - val_loss: 0.6032 - val_accuracy: 0.8667\n",
      "Epoch 18/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0411 - accuracy: 0.9899 - val_loss: 0.6227 - val_accuracy: 0.8400\n",
      "Epoch 19/50\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0779 - accuracy: 0.9798 - val_loss: 0.5450 - val_accuracy: 0.8533\n",
      "Epoch 20/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0638 - accuracy: 0.9899 - val_loss: 0.5444 - val_accuracy: 0.8667\n",
      "Epoch 21/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0626 - accuracy: 0.9865 - val_loss: 0.5250 - val_accuracy: 0.8533\n",
      "Epoch 22/50\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0350 - accuracy: 0.9933 - val_loss: 0.6653 - val_accuracy: 0.8133\n",
      "Epoch 23/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0641 - accuracy: 0.9899 - val_loss: 0.5120 - val_accuracy: 0.8800\n",
      "Epoch 24/50\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0454 - accuracy: 0.9865 - val_loss: 0.5477 - val_accuracy: 0.8667\n",
      "Epoch 25/50\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0379 - accuracy: 0.9933 - val_loss: 0.5692 - val_accuracy: 0.8667\n",
      "Epoch 26/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0434 - accuracy: 0.9899 - val_loss: 0.5386 - val_accuracy: 0.8533\n",
      "Epoch 27/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0245 - accuracy: 0.9933 - val_loss: 0.5770 - val_accuracy: 0.8800\n",
      "Epoch 28/50\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0366 - accuracy: 0.9899 - val_loss: 0.5976 - val_accuracy: 0.8800\n",
      "Epoch 29/50\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0465 - accuracy: 0.9798 - val_loss: 0.5142 - val_accuracy: 0.8533\n",
      "Epoch 30/50\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0390 - accuracy: 0.9966 - val_loss: 0.7610 - val_accuracy: 0.8667\n",
      "Epoch 31/50\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0274 - accuracy: 0.9966 - val_loss: 0.6438 - val_accuracy: 0.8533\n",
      "Epoch 32/50\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0317 - accuracy: 0.9933 - val_loss: 0.6584 - val_accuracy: 0.8400\n",
      "Epoch 33/50\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0325 - accuracy: 0.9933 - val_loss: 0.8160 - val_accuracy: 0.8533\n",
      "Epoch 34/50\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.0300 - accuracy: 0.9899 - val_loss: 0.6799 - val_accuracy: 0.8133\n",
      "Epoch 35/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0335 - accuracy: 0.9933 - val_loss: 0.7541 - val_accuracy: 0.8533\n",
      "Epoch 36/50\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0338 - accuracy: 0.9899 - val_loss: 0.6006 - val_accuracy: 0.8667\n",
      "Epoch 37/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0329 - accuracy: 0.9933 - val_loss: 0.6565 - val_accuracy: 0.8667\n",
      "Epoch 38/50\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0228 - accuracy: 0.9933 - val_loss: 0.6454 - val_accuracy: 0.8667\n",
      "Epoch 39/50\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0207 - accuracy: 0.9933 - val_loss: 0.6757 - val_accuracy: 0.8667\n",
      "Epoch 40/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0156 - accuracy: 0.9933 - val_loss: 0.6759 - val_accuracy: 0.8667\n",
      "Epoch 41/50\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0216 - accuracy: 0.9933 - val_loss: 0.6942 - val_accuracy: 0.8400\n",
      "Epoch 42/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0220 - accuracy: 0.9933 - val_loss: 0.7119 - val_accuracy: 0.8667\n",
      "Epoch 43/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0112 - accuracy: 0.9966 - val_loss: 0.7267 - val_accuracy: 0.8667\n",
      "Epoch 44/50\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0397 - accuracy: 0.9933 - val_loss: 0.8522 - val_accuracy: 0.8133\n",
      "Epoch 45/50\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0298 - accuracy: 0.9933 - val_loss: 0.7596 - val_accuracy: 0.8400\n",
      "Epoch 46/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0283 - accuracy: 0.9933 - val_loss: 0.6603 - val_accuracy: 0.8533\n",
      "Epoch 47/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0301 - accuracy: 0.9899 - val_loss: 0.6318 - val_accuracy: 0.8533\n",
      "Epoch 48/50\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0175 - accuracy: 0.9933 - val_loss: 0.6500 - val_accuracy: 0.8800\n",
      "Epoch 49/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0368 - accuracy: 0.9933 - val_loss: 0.8142 - val_accuracy: 0.8533\n",
      "Epoch 50/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0199 - accuracy: 0.9966 - val_loss: 0.7466 - val_accuracy: 0.8400\n"
     ]
    }
   ],
   "source": [
    "CNN_history = CNN_model.fit(feature_train, y_train, epochs=50, batch_size=16, validation_data=(feature_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training & validation accuracy\n",
    "plt.figure(figsize=(9,6))\n",
    "plt.plot(CNN_history.history['accuracy'])\n",
    "plt.plot(CNN_history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training & validation loss values\n",
    "plt.figure(figsize=(9,6))\n",
    "plt.plot(CNN_history.history['loss'])\n",
    "plt.plot(CNN_history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_CNN = CNN_model.predict(feature_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_CNN_class = np.argmax(y_pred_CNN, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 1, 1, 2, 2, 0, 1, 1, 2, 2, 1, 2, 2, 1, 1, 2, 1, 1, 0, 2,\n",
       "       0, 1, 0, 1, 0, 2, 1, 2, 0, 2, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1,\n",
       "       1, 0, 1, 2, 2, 2, 0, 0, 1, 1, 1, 2, 0, 1, 2, 1, 1, 2, 1, 2, 1, 2,\n",
       "       2, 2, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 2, 2, 1, 2, 1, 1, 1, 1, 2, 0,\n",
       "       1, 2, 1, 1, 1])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_CNN_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_class = np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8817204301075269"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test_class, y_pred_CNN_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.68      0.76        19\n",
      "           1       0.94      0.92      0.93        50\n",
      "           2       0.79      1.00      0.88        23\n",
      "           3       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.88        93\n",
      "   macro avg       0.65      0.65      0.64        93\n",
      "weighted avg       0.88      0.88      0.87        93\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_class, y_pred_CNN_class))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Hyperparameters Tuning on validation Data "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, we tune the hyperparameters by Bayesian Optimization Tunning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "from keras.optimizers import Adam, SGD, RMSprop, Adagrad\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we set the parameters list that we would like to optimize\n",
    "\n",
    "optimizers_list = ['SGD', 'RMSprop', 'Adam', 'Adagrad']\n",
    "\n",
    "activations_list = ['relu', 'elu', 'tanh', 'softplus']\n",
    "\n",
    "learning_rates = (0.01, 1)\n",
    "\n",
    "epochs = (20, 100)\n",
    "\n",
    "batch_sizes = (5, 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_func1(optimizer_index, activation_index, learning_rate, epoch, batch_size):\n",
    "\n",
    "    optimizers_dict = {'SGD':SGD(lr=learning_rate), 'RMSprop':RMSprop(lr=learning_rate), 'Adam':Adam(lr=learning_rate), 'Adagrad':Adagrad(lr=learning_rate)}\n",
    "\n",
    "    optimizer = optimizers_dict[optimizers_list[round(optimizer_index)]]\n",
    "    activation = activations_list[round(activation_index)]\n",
    "\n",
    "    def create_CNN_model():\n",
    "\n",
    "        CNN = Sequential()\n",
    "        # The Embedding layer takes the embedding matrix as an argument and transform the inputed the sequences of index to sequences of vectors.\n",
    "        CNN.add(Embedding(len(word_index) + 1, word_dimension, weights=[embedding_matrix], input_length = maxlen, trainable=False))\n",
    "\n",
    "\n",
    "        CNN.add(Convolution1D(64, 5, activation = activation))\n",
    "        CNN.add(MaxPooling1D(pool_size = 5))\n",
    "\n",
    "        CNN.add(Convolution1D(32, 5, activation = activation))\n",
    "        CNN.add(MaxPooling1D(pool_size = 5))\n",
    "\n",
    "        CNN.add(Flatten())\n",
    "        CNN.add(Dense(units = 128 , activation = activation))\n",
    "        CNN.add(Dropout(0.5))\n",
    "\n",
    "        CNN.add(Dense(units = 4, activation = 'sigmoid'))\n",
    "\n",
    "        CNN.compile(optimizer = optimizer, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "        \n",
    "        return CNN\n",
    "    \n",
    "    CNN_model = create_CNN_model()\n",
    "\n",
    "    CNN_model.fit(feature_train, y_train, epochs=round(epoch), batch_size=round(batch_size), validation_data=(feature_val, y_val))\n",
    "    \n",
    "    #cnn = KerasClassifier(build_fn=CNN_model, epochs=epoch, batch_size=batch_size, verbose=0)\n",
    "\n",
    "    y_pred_CNN = CNN_model.predict(feature_test)\n",
    "    y_pred_CNN_class = np.argmax(y_pred_CNN, axis=1)\n",
    "\n",
    "    return accuracy_score(y_test_class, y_pred_CNN_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | activa... | batch_... |   epoch   | learni... | optimi... |\n",
      "-------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/rmsprop.py:140: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adagrad.py:81: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3/3 [==============================] - 3s 239ms/step - loss: 267333.8125 - accuracy: 0.2559 - val_loss: 7.0912 - val_accuracy: 0.2400\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 26.8142 - accuracy: 0.3434 - val_loss: 441.0152 - val_accuracy: 0.5867\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 258.3643 - accuracy: 0.4882 - val_loss: 1.1480 - val_accuracy: 0.6000\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 17.8773 - accuracy: 0.5084 - val_loss: 8.9715 - val_accuracy: 0.5867\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 15.6616 - accuracy: 0.4882 - val_loss: 109.1707 - val_accuracy: 0.2933\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 22.4117 - accuracy: 0.3603 - val_loss: 81.4631 - val_accuracy: 0.2800\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 9.2630 - accuracy: 0.3805 - val_loss: 4.3139 - val_accuracy: 0.2800\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 78.6775 - accuracy: 0.4108 - val_loss: 0.9880 - val_accuracy: 0.6000\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 34.7778 - accuracy: 0.5084 - val_loss: 0.9842 - val_accuracy: 0.6000\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 1.0855 - accuracy: 0.5219 - val_loss: 0.9809 - val_accuracy: 0.6000\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 53.2983 - accuracy: 0.5152 - val_loss: 0.9938 - val_accuracy: 0.6000\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 27.3632 - accuracy: 0.5185 - val_loss: 1.0512 - val_accuracy: 0.6000\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 56.9811 - accuracy: 0.5185 - val_loss: 1.0541 - val_accuracy: 0.6000\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 1.1690 - accuracy: 0.5219 - val_loss: 1.0084 - val_accuracy: 0.6000\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 3.1192 - accuracy: 0.5185 - val_loss: 0.9811 - val_accuracy: 0.6000\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.0155 - accuracy: 0.5152 - val_loss: 0.9984 - val_accuracy: 0.5867\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 1.0313 - accuracy: 0.4916 - val_loss: 1.0025 - val_accuracy: 0.5867\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 1.0111 - accuracy: 0.5152 - val_loss: 1.0116 - val_accuracy: 0.5867\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.0098 - accuracy: 0.5152 - val_loss: 1.0151 - val_accuracy: 0.5867\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 1.8237 - accuracy: 0.5118 - val_loss: 1.0175 - val_accuracy: 0.5867\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 1.0012 - accuracy: 0.5152 - val_loss: 1.0116 - val_accuracy: 0.5867\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 33.2158 - accuracy: 0.5051 - val_loss: 1.0259 - val_accuracy: 0.5867\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.0211 - accuracy: 0.5118 - val_loss: 1.0304 - val_accuracy: 0.5867\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 1.0160 - accuracy: 0.5152 - val_loss: 1.0177 - val_accuracy: 0.5867\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 61.1483 - accuracy: 0.5084 - val_loss: 1.0453 - val_accuracy: 0.5867\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 163ms/step - loss: 34.5775 - accuracy: 0.5084 - val_loss: 1.0931 - val_accuracy: 0.5867\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 1.0461 - accuracy: 0.5152 - val_loss: 1.0487 - val_accuracy: 0.5867\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 1.0329 - accuracy: 0.5152 - val_loss: 1.0033 - val_accuracy: 0.5867\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.1034 - accuracy: 0.5118 - val_loss: 1.0078 - val_accuracy: 0.5867\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 24.0122 - accuracy: 0.5118 - val_loss: 1.0186 - val_accuracy: 0.5867\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.0230 - accuracy: 0.5152 - val_loss: 1.0272 - val_accuracy: 0.5867\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.0249 - accuracy: 0.5152 - val_loss: 51.5762 - val_accuracy: 0.5867\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.0368 - accuracy: 0.5152 - val_loss: 117.9563 - val_accuracy: 0.5867\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.8661 - accuracy: 0.5118 - val_loss: 171.3585 - val_accuracy: 0.5867\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 1.0242 - accuracy: 0.5152 - val_loss: 212.2637 - val_accuracy: 0.5867\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 1.0211 - accuracy: 0.5152 - val_loss: 243.2049 - val_accuracy: 0.5867\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.0211 - accuracy: 0.5152 - val_loss: 266.4648 - val_accuracy: 0.5867\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 38.3161 - accuracy: 0.5118 - val_loss: 515.7744 - val_accuracy: 0.5867\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.0231 - accuracy: 0.5152 - val_loss: 895.5646 - val_accuracy: 0.5867\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.0215 - accuracy: 0.5152 - val_loss: 1277.9985 - val_accuracy: 0.5867\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.0184 - accuracy: 0.5152 - val_loss: 1602.6400 - val_accuracy: 0.5867\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.0206 - accuracy: 0.5152 - val_loss: 1862.5729 - val_accuracy: 0.5867\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.0225 - accuracy: 0.5152 - val_loss: 2067.8501 - val_accuracy: 0.5867\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.0199 - accuracy: 0.5152 - val_loss: 2234.9099 - val_accuracy: 0.5867\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.0205 - accuracy: 0.5152 - val_loss: 2367.6973 - val_accuracy: 0.5867\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.0204 - accuracy: 0.5152 - val_loss: 2468.4343 - val_accuracy: 0.5867\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.0241 - accuracy: 0.5152 - val_loss: 2543.8103 - val_accuracy: 0.5867\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.0216 - accuracy: 0.5152 - val_loss: 2599.9907 - val_accuracy: 0.5867\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 1.0197 - accuracy: 0.5152 - val_loss: 2641.7336 - val_accuracy: 0.5867\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 1.0199 - accuracy: 0.5152 - val_loss: 2672.6736 - val_accuracy: 0.5867\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m0.5376   \u001b[0m | \u001b[0m0.3482   \u001b[0m | \u001b[0m100.5    \u001b[0m | \u001b[0m50.05    \u001b[0m | \u001b[0m0.6167   \u001b[0m | \u001b[0m2.038    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/rmsprop.py:140: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adagrad.py:81: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/71\n",
      "3/3 [==============================] - 1s 160ms/step - loss: 1.9148 - accuracy: 0.3165 - val_loss: 8.7443 - val_accuracy: 0.2400\n",
      "Epoch 2/71\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 13.1502 - accuracy: 0.3805 - val_loss: 13.6191 - val_accuracy: 0.2400\n",
      "Epoch 3/71\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 15.4896 - accuracy: 0.4040 - val_loss: 19.2587 - val_accuracy: 0.5867\n",
      "Epoch 4/71\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 16.1977 - accuracy: 0.3468 - val_loss: 18.9282 - val_accuracy: 0.1600\n",
      "Epoch 5/71\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 15.5290 - accuracy: 0.2929 - val_loss: 9.2128 - val_accuracy: 0.2400\n",
      "Epoch 6/71\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 16.6089 - accuracy: 0.3670 - val_loss: 9.2768 - val_accuracy: 0.5867\n",
      "Epoch 7/71\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 17.6547 - accuracy: 0.4175 - val_loss: 10.2185 - val_accuracy: 0.1600\n",
      "Epoch 8/71\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 13.4367 - accuracy: 0.3569 - val_loss: 25.1521 - val_accuracy: 0.5867\n",
      "Epoch 9/71\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 17.8156 - accuracy: 0.5118 - val_loss: 4.7058 - val_accuracy: 0.5867\n",
      "Epoch 10/71\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 8.3686 - accuracy: 0.3872 - val_loss: 41.1491 - val_accuracy: 0.1600\n",
      "Epoch 11/71\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 25.0447 - accuracy: 0.3805 - val_loss: 15.7262 - val_accuracy: 0.5867\n",
      "Epoch 12/71\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 17.5151 - accuracy: 0.3300 - val_loss: 18.1134 - val_accuracy: 0.2400\n",
      "Epoch 13/71\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 22.7176 - accuracy: 0.3670 - val_loss: 14.6069 - val_accuracy: 0.5867\n",
      "Epoch 14/71\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 22.3461 - accuracy: 0.4108 - val_loss: 17.7321 - val_accuracy: 0.2400\n",
      "Epoch 15/71\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 20.5465 - accuracy: 0.3771 - val_loss: 13.3085 - val_accuracy: 0.2400\n",
      "Epoch 16/71\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 19.0007 - accuracy: 0.4411 - val_loss: 5.2300 - val_accuracy: 0.5867\n",
      "Epoch 17/71\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 9.9048 - accuracy: 0.4411 - val_loss: 6.5946 - val_accuracy: 0.1600\n",
      "Epoch 18/71\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 13.2892 - accuracy: 0.3434 - val_loss: 16.6762 - val_accuracy: 0.5867\n",
      "Epoch 19/71\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 18.3762 - accuracy: 0.3636 - val_loss: 42.6483 - val_accuracy: 0.2400\n",
      "Epoch 20/71\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 29.3472 - accuracy: 0.3838 - val_loss: 18.2304 - val_accuracy: 0.5867\n",
      "Epoch 21/71\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 20.8292 - accuracy: 0.3535 - val_loss: 34.5503 - val_accuracy: 0.2400\n",
      "Epoch 22/71\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 27.5185 - accuracy: 0.3737 - val_loss: 26.2481 - val_accuracy: 0.5867\n",
      "Epoch 23/71\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 19.9524 - accuracy: 0.4848 - val_loss: 9.4460 - val_accuracy: 0.5867\n",
      "Epoch 24/71\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 16.9243 - accuracy: 0.3838 - val_loss: 5.0948 - val_accuracy: 0.1600\n",
      "Epoch 25/71\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 12.2097 - accuracy: 0.3872 - val_loss: 17.6342 - val_accuracy: 0.5867\n",
      "Epoch 26/71\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 19.2682 - accuracy: 0.3670 - val_loss: 31.7192 - val_accuracy: 0.2400\n",
      "Epoch 27/71\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 22.4870 - accuracy: 0.4343 - val_loss: 19.2774 - val_accuracy: 0.5867\n",
      "Epoch 28/71\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 24.9281 - accuracy: 0.3232 - val_loss: 15.3099 - val_accuracy: 0.2400\n",
      "Epoch 29/71\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 19.9547 - accuracy: 0.3939 - val_loss: 15.7243 - val_accuracy: 0.5867\n",
      "Epoch 30/71\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 19.2723 - accuracy: 0.4074 - val_loss: 23.8897 - val_accuracy: 0.1600\n",
      "Epoch 31/71\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 17.7185 - accuracy: 0.3535 - val_loss: 21.3385 - val_accuracy: 0.5867\n",
      "Epoch 32/71\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 15.1188 - accuracy: 0.3704 - val_loss: 8.4460 - val_accuracy: 0.5867\n",
      "Epoch 33/71\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 12.0595 - accuracy: 0.4074 - val_loss: 18.4615 - val_accuracy: 0.2400\n",
      "Epoch 34/71\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 13.9703 - accuracy: 0.4007 - val_loss: 18.4196 - val_accuracy: 0.5867\n",
      "Epoch 35/71\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 16.3481 - accuracy: 0.3906 - val_loss: 21.3586 - val_accuracy: 0.1600\n",
      "Epoch 36/71\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 22.6541 - accuracy: 0.3737 - val_loss: 31.8573 - val_accuracy: 0.5867\n",
      "Epoch 37/71\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 25.8802 - accuracy: 0.4848 - val_loss: 17.1116 - val_accuracy: 0.5867\n",
      "Epoch 38/71\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 14.0531 - accuracy: 0.4343 - val_loss: 19.1969 - val_accuracy: 0.1600\n",
      "Epoch 39/71\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 16.9600 - accuracy: 0.3771 - val_loss: 21.3285 - val_accuracy: 0.5867\n",
      "Epoch 40/71\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 16.1658 - accuracy: 0.4343 - val_loss: 14.8790 - val_accuracy: 0.1600\n",
      "Epoch 41/71\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 18.4633 - accuracy: 0.3199 - val_loss: 13.0165 - val_accuracy: 0.5867\n",
      "Epoch 42/71\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 13.8616 - accuracy: 0.4310 - val_loss: 42.2605 - val_accuracy: 0.1600\n",
      "Epoch 43/71\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 28.4429 - accuracy: 0.2593 - val_loss: 8.1608 - val_accuracy: 0.2400\n",
      "Epoch 44/71\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 13.6182 - accuracy: 0.4343 - val_loss: 11.5907 - val_accuracy: 0.2400\n",
      "Epoch 45/71\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 16.4083 - accuracy: 0.4276 - val_loss: 16.2588 - val_accuracy: 0.5867\n",
      "Epoch 46/71\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 19.5942 - accuracy: 0.3704 - val_loss: 29.8103 - val_accuracy: 0.2400\n",
      "Epoch 47/71\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 21.6724 - accuracy: 0.4007 - val_loss: 12.7336 - val_accuracy: 0.5867\n",
      "Epoch 48/71\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 19.4420 - accuracy: 0.3737 - val_loss: 2.6498 - val_accuracy: 0.5867\n",
      "Epoch 49/71\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 7.8755 - accuracy: 0.3434 - val_loss: 13.9219 - val_accuracy: 0.5867\n",
      "Epoch 50/71\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 12.6018 - accuracy: 0.4377 - val_loss: 5.5829 - val_accuracy: 0.5867\n",
      "Epoch 51/71\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 11.4037 - accuracy: 0.3771 - val_loss: 34.1318 - val_accuracy: 0.2400\n",
      "Epoch 52/71\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 23.4903 - accuracy: 0.3098 - val_loss: 26.0037 - val_accuracy: 0.5867\n",
      "Epoch 53/71\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 20.1487 - accuracy: 0.4276 - val_loss: 2.7695 - val_accuracy: 0.5867\n",
      "Epoch 54/71\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 7.6138 - accuracy: 0.3569 - val_loss: 13.7264 - val_accuracy: 0.5867\n",
      "Epoch 55/71\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 18.1634 - accuracy: 0.3401 - val_loss: 35.4022 - val_accuracy: 0.2400\n",
      "Epoch 56/71\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 25.4311 - accuracy: 0.4040 - val_loss: 28.7208 - val_accuracy: 0.5867\n",
      "Epoch 57/71\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 24.6515 - accuracy: 0.3939 - val_loss: 19.0848 - val_accuracy: 0.2400\n",
      "Epoch 58/71\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 15.7353 - accuracy: 0.4512 - val_loss: 13.4129 - val_accuracy: 0.5867\n",
      "Epoch 59/71\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 18.6561 - accuracy: 0.4141 - val_loss: 7.6625 - val_accuracy: 0.2400\n",
      "Epoch 60/71\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 15.9833 - accuracy: 0.3300 - val_loss: 22.2689 - val_accuracy: 0.5867\n",
      "Epoch 61/71\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 20.2562 - accuracy: 0.4444 - val_loss: 11.0209 - val_accuracy: 0.2400\n",
      "Epoch 62/71\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 17.2267 - accuracy: 0.3973 - val_loss: 24.0348 - val_accuracy: 0.2400\n",
      "Epoch 63/71\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 26.0869 - accuracy: 0.4377 - val_loss: 3.8839 - val_accuracy: 0.5867\n",
      "Epoch 64/71\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 7.0906 - accuracy: 0.3771 - val_loss: 10.7399 - val_accuracy: 0.2400\n",
      "Epoch 65/71\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 17.8432 - accuracy: 0.3973 - val_loss: 20.1785 - val_accuracy: 0.5867\n",
      "Epoch 66/71\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 28.6692 - accuracy: 0.3737 - val_loss: 10.3410 - val_accuracy: 0.2400\n",
      "Epoch 67/71\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 13.5695 - accuracy: 0.4343 - val_loss: 21.3156 - val_accuracy: 0.2400\n",
      "Epoch 68/71\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 23.2720 - accuracy: 0.4310 - val_loss: 14.1457 - val_accuracy: 0.2400\n",
      "Epoch 69/71\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 17.1343 - accuracy: 0.3838 - val_loss: 21.7324 - val_accuracy: 0.5867\n",
      "Epoch 70/71\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 21.2011 - accuracy: 0.4108 - val_loss: 11.6451 - val_accuracy: 0.2400\n",
      "Epoch 71/71\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 14.8408 - accuracy: 0.4040 - val_loss: 9.5998 - val_accuracy: 0.2400\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "| \u001b[0m2        \u001b[0m | \u001b[0m0.2473   \u001b[0m | \u001b[0m2.047    \u001b[0m | \u001b[0m143.5    \u001b[0m | \u001b[0m70.98    \u001b[0m | \u001b[0m0.5178   \u001b[0m | \u001b[0m0.2585   \u001b[0m |\n",
      "Epoch 1/31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/rmsprop.py:140: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adagrad.py:81: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 1s 47ms/step - loss: 163.2249 - accuracy: 0.2694 - val_loss: 65.6634 - val_accuracy: 0.2400\n",
      "Epoch 2/31\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 24.2296 - accuracy: 0.3569 - val_loss: 2.4184 - val_accuracy: 0.2533\n",
      "Epoch 3/31\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 4.7168 - accuracy: 0.3569 - val_loss: 4.0795 - val_accuracy: 0.5867\n",
      "Epoch 4/31\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 3.4782 - accuracy: 0.3838 - val_loss: 1.4364 - val_accuracy: 0.2533\n",
      "Epoch 5/31\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 1.8423 - accuracy: 0.3636 - val_loss: 1.2650 - val_accuracy: 0.5867\n",
      "Epoch 6/31\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 1.4613 - accuracy: 0.4579 - val_loss: 2.5397 - val_accuracy: 0.5867\n",
      "Epoch 7/31\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 2.7899 - accuracy: 0.4613 - val_loss: 1.9883 - val_accuracy: 0.2400\n",
      "Epoch 8/31\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.3850 - accuracy: 0.3401 - val_loss: 1.9011 - val_accuracy: 0.5867\n",
      "Epoch 9/31\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 1.4338 - accuracy: 0.4512 - val_loss: 1.8332 - val_accuracy: 0.1600\n",
      "Epoch 10/31\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 1.4824 - accuracy: 0.3771 - val_loss: 1.0243 - val_accuracy: 0.6533\n",
      "Epoch 11/31\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 1.3418 - accuracy: 0.4444 - val_loss: 1.3098 - val_accuracy: 0.2400\n",
      "Epoch 12/31\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 2.2705 - accuracy: 0.3670 - val_loss: 3.0910 - val_accuracy: 0.2400\n",
      "Epoch 13/31\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 1.9482 - accuracy: 0.4983 - val_loss: 3.6696 - val_accuracy: 0.2400\n",
      "Epoch 14/31\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 1.9485 - accuracy: 0.4175 - val_loss: 1.1922 - val_accuracy: 0.2400\n",
      "Epoch 15/31\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 2.2452 - accuracy: 0.3670 - val_loss: 61.6704 - val_accuracy: 0.0133\n",
      "Epoch 16/31\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 11.6929 - accuracy: 0.3030 - val_loss: 1.7728 - val_accuracy: 0.2400\n",
      "Epoch 17/31\n",
      "7/7 [==============================] - 0s 29ms/step - loss: 1.6938 - accuracy: 0.3434 - val_loss: 1.0384 - val_accuracy: 0.6133\n",
      "Epoch 18/31\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 1.1394 - accuracy: 0.5152 - val_loss: 1.7195 - val_accuracy: 0.2533\n",
      "Epoch 19/31\n",
      "7/7 [==============================] - 0s 37ms/step - loss: 1.9041 - accuracy: 0.4007 - val_loss: 1.6770 - val_accuracy: 0.4933\n",
      "Epoch 20/31\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 1.4693 - accuracy: 0.4478 - val_loss: 1.9875 - val_accuracy: 0.5867\n",
      "Epoch 21/31\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 29.4941 - accuracy: 0.3535 - val_loss: 1.3612 - val_accuracy: 0.2400\n",
      "Epoch 22/31\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 1.7705 - accuracy: 0.3367 - val_loss: 1.2192 - val_accuracy: 0.3867\n",
      "Epoch 23/31\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 1.3926 - accuracy: 0.4175 - val_loss: 1.0479 - val_accuracy: 0.6133\n",
      "Epoch 24/31\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 1.4196 - accuracy: 0.4579 - val_loss: 1.5922 - val_accuracy: 0.5867\n",
      "Epoch 25/31\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 1.4800 - accuracy: 0.4175 - val_loss: 1.6266 - val_accuracy: 0.2400\n",
      "Epoch 26/31\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 1.8302 - accuracy: 0.3737 - val_loss: 1.3481 - val_accuracy: 0.5867\n",
      "Epoch 27/31\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 1.5710 - accuracy: 0.4141 - val_loss: 2.2573 - val_accuracy: 0.2400\n",
      "Epoch 28/31\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 1.8352 - accuracy: 0.4141 - val_loss: 2.4922 - val_accuracy: 0.5867\n",
      "Epoch 29/31\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 2.3226 - accuracy: 0.3872 - val_loss: 1.3346 - val_accuracy: 0.5867\n",
      "Epoch 30/31\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 1.7054 - accuracy: 0.4175 - val_loss: 1.4404 - val_accuracy: 0.6000\n",
      "Epoch 31/31\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 1.5539 - accuracy: 0.4040 - val_loss: 1.8511 - val_accuracy: 0.2400\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "| \u001b[0m3        \u001b[0m | \u001b[0m0.2366   \u001b[0m | \u001b[0m1.162    \u001b[0m | \u001b[0m47.11    \u001b[0m | \u001b[0m30.83    \u001b[0m | \u001b[0m0.02     \u001b[0m | \u001b[0m1.238    \u001b[0m |\n",
      "Epoch 1/65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/rmsprop.py:140: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adagrad.py:81: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 1s 7ms/step - loss: 7237.7500 - accuracy: 0.4040 - val_loss: 6.6351 - val_accuracy: 0.4400\n",
      "Epoch 2/65\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 12.2921 - accuracy: 0.3300 - val_loss: 193.0733 - val_accuracy: 0.5867\n",
      "Epoch 3/65\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 271.1498 - accuracy: 0.2963 - val_loss: 12.2442 - val_accuracy: 0.2400\n",
      "Epoch 4/65\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 6.2438 - accuracy: 0.3199 - val_loss: 14.9262 - val_accuracy: 0.2400\n",
      "Epoch 5/65\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 10.9490 - accuracy: 0.3838 - val_loss: 2.5963 - val_accuracy: 0.5867\n",
      "Epoch 6/65\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 6.2435 - accuracy: 0.3805 - val_loss: 15.9068 - val_accuracy: 0.2400\n",
      "Epoch 7/65\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 9.5816 - accuracy: 0.3535 - val_loss: 7.7194 - val_accuracy: 0.5867\n",
      "Epoch 8/65\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 7.1624 - accuracy: 0.3771 - val_loss: 9.7885 - val_accuracy: 0.5867\n",
      "Epoch 9/65\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 9.2539 - accuracy: 0.4478 - val_loss: 1146.6035 - val_accuracy: 0.0133\n",
      "Epoch 10/65\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 576.4876 - accuracy: 0.3603 - val_loss: 18.0765 - val_accuracy: 0.2400\n",
      "Epoch 11/65\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 12.0893 - accuracy: 0.3468 - val_loss: 15.4072 - val_accuracy: 0.2400\n",
      "Epoch 12/65\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 6.8918 - accuracy: 0.3704 - val_loss: 13.4302 - val_accuracy: 0.1600\n",
      "Epoch 13/65\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 7.3372 - accuracy: 0.3805 - val_loss: 7.6970 - val_accuracy: 0.5867\n",
      "Epoch 14/65\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 7.9252 - accuracy: 0.3266 - val_loss: 18.5230 - val_accuracy: 0.2400\n",
      "Epoch 15/65\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 140.0037 - accuracy: 0.3535 - val_loss: 8.9006 - val_accuracy: 0.5867\n",
      "Epoch 16/65\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 135.7735 - accuracy: 0.3805 - val_loss: 11.0107 - val_accuracy: 0.2400\n",
      "Epoch 17/65\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 147.1615 - accuracy: 0.3771 - val_loss: 26.4896 - val_accuracy: 0.2400\n",
      "Epoch 18/65\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 9.3111 - accuracy: 0.3030 - val_loss: 4.8606 - val_accuracy: 0.5867\n",
      "Epoch 19/65\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.9855 - accuracy: 0.4007 - val_loss: 7.1170 - val_accuracy: 0.5867\n",
      "Epoch 20/65\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 6.7684 - accuracy: 0.3939 - val_loss: 16.3116 - val_accuracy: 0.2400\n",
      "Epoch 21/65\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 6.9598 - accuracy: 0.3805 - val_loss: 7.8615 - val_accuracy: 0.5867\n",
      "Epoch 22/65\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 8.3995 - accuracy: 0.3333 - val_loss: 11.4047 - val_accuracy: 0.2400\n",
      "Epoch 23/65\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 7.7856 - accuracy: 0.3939 - val_loss: 10.0494 - val_accuracy: 0.5867\n",
      "Epoch 24/65\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 7.0174 - accuracy: 0.4141 - val_loss: 14.2158 - val_accuracy: 0.2400\n",
      "Epoch 25/65\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 7.1300 - accuracy: 0.3906 - val_loss: 17.3719 - val_accuracy: 0.2400\n",
      "Epoch 26/65\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 7.5306 - accuracy: 0.4007 - val_loss: 5.6095 - val_accuracy: 0.5867\n",
      "Epoch 27/65\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 7.0400 - accuracy: 0.3973 - val_loss: 8.6378 - val_accuracy: 0.1600\n",
      "Epoch 28/65\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 6.9625 - accuracy: 0.3973 - val_loss: 7.3544 - val_accuracy: 0.2400\n",
      "Epoch 29/65\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 7.6419 - accuracy: 0.3636 - val_loss: 3.9188 - val_accuracy: 0.5867\n",
      "Epoch 30/65\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 7.0164 - accuracy: 0.3737 - val_loss: 14.4944 - val_accuracy: 0.1600\n",
      "Epoch 31/65\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 7.0895 - accuracy: 0.3872 - val_loss: 19.0242 - val_accuracy: 0.1600\n",
      "Epoch 32/65\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 7.8467 - accuracy: 0.3973 - val_loss: 11.7748 - val_accuracy: 0.2400\n",
      "Epoch 33/65\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 6.5037 - accuracy: 0.4074 - val_loss: 8.4266 - val_accuracy: 0.2400\n",
      "Epoch 34/65\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 7.0397 - accuracy: 0.3939 - val_loss: 3.0188 - val_accuracy: 0.5867\n",
      "Epoch 35/65\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 7.8654 - accuracy: 0.4074 - val_loss: 6.8378 - val_accuracy: 0.2400\n",
      "Epoch 36/65\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 7.8252 - accuracy: 0.3502 - val_loss: 11.9727 - val_accuracy: 0.5867\n",
      "Epoch 37/65\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 6.4209 - accuracy: 0.4377 - val_loss: 2.7558 - val_accuracy: 0.5867\n",
      "Epoch 38/65\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 7.8833 - accuracy: 0.4074 - val_loss: 6.2113 - val_accuracy: 0.5867\n",
      "Epoch 39/65\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 7.3521 - accuracy: 0.3906 - val_loss: 2.8358 - val_accuracy: 0.5867\n",
      "Epoch 40/65\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 6.1311 - accuracy: 0.4007 - val_loss: 2.6428 - val_accuracy: 0.5867\n",
      "Epoch 41/65\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 8.0755 - accuracy: 0.3401 - val_loss: 6.7005 - val_accuracy: 0.5867\n",
      "Epoch 42/65\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 7.0548 - accuracy: 0.3704 - val_loss: 3.4851 - val_accuracy: 0.5867\n",
      "Epoch 43/65\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 8.5163 - accuracy: 0.3603 - val_loss: 7.2415 - val_accuracy: 0.5867\n",
      "Epoch 44/65\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 6.9483 - accuracy: 0.3805 - val_loss: 10.1995 - val_accuracy: 0.5867\n",
      "Epoch 45/65\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 7.1483 - accuracy: 0.3636 - val_loss: 10.6655 - val_accuracy: 0.5867\n",
      "Epoch 46/65\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 7.1407 - accuracy: 0.3468 - val_loss: 12.0155 - val_accuracy: 0.5867\n",
      "Epoch 47/65\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 7.6864 - accuracy: 0.3906 - val_loss: 5.4453 - val_accuracy: 0.5867\n",
      "Epoch 48/65\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 7.6046 - accuracy: 0.3737 - val_loss: 2.0136 - val_accuracy: 0.2400\n",
      "Epoch 49/65\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 6.6716 - accuracy: 0.3704 - val_loss: 16.1231 - val_accuracy: 0.1600\n",
      "Epoch 50/65\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 7.3380 - accuracy: 0.3872 - val_loss: 13.0812 - val_accuracy: 0.2400\n",
      "Epoch 51/65\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 7.2113 - accuracy: 0.3704 - val_loss: 9.1363 - val_accuracy: 0.2400\n",
      "Epoch 52/65\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 7.2970 - accuracy: 0.3805 - val_loss: 5.7239 - val_accuracy: 0.5867\n",
      "Epoch 53/65\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 7.3368 - accuracy: 0.3973 - val_loss: 4.3720 - val_accuracy: 0.2400\n",
      "Epoch 54/65\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 7.4548 - accuracy: 0.3401 - val_loss: 7.5983 - val_accuracy: 0.5867\n",
      "Epoch 55/65\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 6.6327 - accuracy: 0.4209 - val_loss: 6.4849 - val_accuracy: 0.5867\n",
      "Epoch 56/65\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 7.2740 - accuracy: 0.4141 - val_loss: 11.0368 - val_accuracy: 0.5867\n",
      "Epoch 57/65\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 7.2614 - accuracy: 0.3670 - val_loss: 4.6566 - val_accuracy: 0.5867\n",
      "Epoch 58/65\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 6.9648 - accuracy: 0.3737 - val_loss: 4.1837 - val_accuracy: 0.5867\n",
      "Epoch 59/65\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 6.9706 - accuracy: 0.3872 - val_loss: 14.2318 - val_accuracy: 0.1600\n",
      "Epoch 60/65\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 7.5351 - accuracy: 0.3838 - val_loss: 9.5069 - val_accuracy: 0.2400\n",
      "Epoch 61/65\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 7.1247 - accuracy: 0.3434 - val_loss: 2.7399 - val_accuracy: 0.2400\n",
      "Epoch 62/65\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 6.4132 - accuracy: 0.4175 - val_loss: 6.1050 - val_accuracy: 0.5867\n",
      "Epoch 63/65\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 7.0006 - accuracy: 0.4074 - val_loss: 4.8351 - val_accuracy: 0.5867\n",
      "Epoch 64/65\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 7.2730 - accuracy: 0.3838 - val_loss: 10.7069 - val_accuracy: 0.5867\n",
      "Epoch 65/65\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 7.1034 - accuracy: 0.3603 - val_loss: 5.9066 - val_accuracy: 0.5867\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "| \u001b[0m4        \u001b[0m | \u001b[0m0.2043   \u001b[0m | \u001b[0m1.478    \u001b[0m | \u001b[0m8.103    \u001b[0m | \u001b[0m64.76    \u001b[0m | \u001b[0m0.08684  \u001b[0m | \u001b[0m1.223    \u001b[0m |\n",
      "Epoch 1/68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/rmsprop.py:140: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adagrad.py:81: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 114ms/step - loss: 1113815.7500 - accuracy: 0.2256 - val_loss: 29940300.0000 - val_accuracy: 0.5867\n",
      "Epoch 2/68\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 18083972.0000 - accuracy: 0.3300 - val_loss: 2485983.2500 - val_accuracy: 0.5867\n",
      "Epoch 3/68\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1516880.0000 - accuracy: 0.3502 - val_loss: 16844.4219 - val_accuracy: 0.2667\n",
      "Epoch 4/68\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 21592.0312 - accuracy: 0.3973 - val_loss: 7200.9199 - val_accuracy: 0.4933\n",
      "Epoch 5/68\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 10243.9248 - accuracy: 0.4343 - val_loss: 3927.9907 - val_accuracy: 0.4800\n",
      "Epoch 6/68\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 5916.2393 - accuracy: 0.4646 - val_loss: 3538.5212 - val_accuracy: 0.4000\n",
      "Epoch 7/68\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 5856.1357 - accuracy: 0.4411 - val_loss: 2881.0281 - val_accuracy: 0.5333\n",
      "Epoch 8/68\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 3740.1191 - accuracy: 0.4848 - val_loss: 2279.5603 - val_accuracy: 0.4533\n",
      "Epoch 9/68\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 2737.7122 - accuracy: 0.4680 - val_loss: 1100.7296 - val_accuracy: 0.4800\n",
      "Epoch 10/68\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 2237.9458 - accuracy: 0.4242 - val_loss: 913.5665 - val_accuracy: 0.5467\n",
      "Epoch 11/68\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 1272.9052 - accuracy: 0.4781 - val_loss: 617.0377 - val_accuracy: 0.6000\n",
      "Epoch 12/68\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 1127.7289 - accuracy: 0.4949 - val_loss: 671.1845 - val_accuracy: 0.5733\n",
      "Epoch 13/68\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 870.3130 - accuracy: 0.4512 - val_loss: 489.9995 - val_accuracy: 0.5333\n",
      "Epoch 14/68\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 664.6157 - accuracy: 0.4983 - val_loss: 378.2507 - val_accuracy: 0.5600\n",
      "Epoch 15/68\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 405.5768 - accuracy: 0.4646 - val_loss: 358.7423 - val_accuracy: 0.5333\n",
      "Epoch 16/68\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 498.1020 - accuracy: 0.4343 - val_loss: 263.7387 - val_accuracy: 0.5333\n",
      "Epoch 17/68\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 365.8516 - accuracy: 0.4377 - val_loss: 202.2126 - val_accuracy: 0.4533\n",
      "Epoch 18/68\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 351.2537 - accuracy: 0.3939 - val_loss: 361.4587 - val_accuracy: 0.5200\n",
      "Epoch 19/68\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 329.2810 - accuracy: 0.4882 - val_loss: 838.6683 - val_accuracy: 0.4133\n",
      "Epoch 20/68\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 1245.5499 - accuracy: 0.4040 - val_loss: 491.7323 - val_accuracy: 0.4667\n",
      "Epoch 21/68\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 637.5580 - accuracy: 0.4579 - val_loss: 128.9250 - val_accuracy: 0.6000\n",
      "Epoch 22/68\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 187.1932 - accuracy: 0.3771 - val_loss: 146.2193 - val_accuracy: 0.6267\n",
      "Epoch 23/68\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 162.3839 - accuracy: 0.4444 - val_loss: 73.0491 - val_accuracy: 0.6000\n",
      "Epoch 24/68\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 161.4599 - accuracy: 0.4579 - val_loss: 88.1034 - val_accuracy: 0.5867\n",
      "Epoch 25/68\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 122.1556 - accuracy: 0.3704 - val_loss: 84.4756 - val_accuracy: 0.5733\n",
      "Epoch 26/68\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 122.4994 - accuracy: 0.4209 - val_loss: 59.6727 - val_accuracy: 0.3867\n",
      "Epoch 27/68\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 132.7026 - accuracy: 0.4343 - val_loss: 139.6421 - val_accuracy: 0.4000\n",
      "Epoch 28/68\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 196.7848 - accuracy: 0.4007 - val_loss: 329.2938 - val_accuracy: 0.3867\n",
      "Epoch 29/68\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 2201.5259 - accuracy: 0.3367 - val_loss: 11667.4971 - val_accuracy: 0.2133\n",
      "Epoch 30/68\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 829098.3750 - accuracy: 0.3064 - val_loss: 28941.0605 - val_accuracy: 0.2800\n",
      "Epoch 31/68\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 26185.7168 - accuracy: 0.3973 - val_loss: 2798.1587 - val_accuracy: 0.6133\n",
      "Epoch 32/68\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 2942.7507 - accuracy: 0.4276 - val_loss: 690.2859 - val_accuracy: 0.4133\n",
      "Epoch 33/68\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 1130.8875 - accuracy: 0.3939 - val_loss: 811.4434 - val_accuracy: 0.5200\n",
      "Epoch 34/68\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 815.5154 - accuracy: 0.4040 - val_loss: 453.9782 - val_accuracy: 0.3600\n",
      "Epoch 35/68\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 447.7701 - accuracy: 0.3704 - val_loss: 255.3745 - val_accuracy: 0.3600\n",
      "Epoch 36/68\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 264.3146 - accuracy: 0.3906 - val_loss: 117.5798 - val_accuracy: 0.3333\n",
      "Epoch 37/68\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 143.8280 - accuracy: 0.3266 - val_loss: 303.2357 - val_accuracy: 0.4800\n",
      "Epoch 38/68\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 188.0645 - accuracy: 0.3502 - val_loss: 140.4230 - val_accuracy: 0.2933\n",
      "Epoch 39/68\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 131.6523 - accuracy: 0.2862 - val_loss: 130.8432 - val_accuracy: 0.4667\n",
      "Epoch 40/68\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 108.8220 - accuracy: 0.3367 - val_loss: 954.5688 - val_accuracy: 0.4133\n",
      "Epoch 41/68\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 441.0792 - accuracy: 0.2593 - val_loss: 59.3220 - val_accuracy: 0.4133\n",
      "Epoch 42/68\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 160.8890 - accuracy: 0.3434 - val_loss: 138.2624 - val_accuracy: 0.1733\n",
      "Epoch 43/68\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 114.1422 - accuracy: 0.2559 - val_loss: 58.5023 - val_accuracy: 0.4133\n",
      "Epoch 44/68\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 74.7250 - accuracy: 0.3468 - val_loss: 30.5937 - val_accuracy: 0.4000\n",
      "Epoch 45/68\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 53.9608 - accuracy: 0.2828 - val_loss: 20.5712 - val_accuracy: 0.3867\n",
      "Epoch 46/68\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 53.3862 - accuracy: 0.3199 - val_loss: 32.8681 - val_accuracy: 0.3867\n",
      "Epoch 47/68\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 50.3709 - accuracy: 0.3333 - val_loss: 21.5645 - val_accuracy: 0.6133\n",
      "Epoch 48/68\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 45.7274 - accuracy: 0.2997 - val_loss: 11.3468 - val_accuracy: 0.6133\n",
      "Epoch 49/68\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 42.3268 - accuracy: 0.3434 - val_loss: 14.2861 - val_accuracy: 0.6267\n",
      "Epoch 50/68\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 37.9074 - accuracy: 0.3737 - val_loss: 54.3240 - val_accuracy: 0.5867\n",
      "Epoch 51/68\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 1410.2188 - accuracy: 0.3468 - val_loss: 10886.6211 - val_accuracy: 0.0800\n",
      "Epoch 52/68\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 25453.6289 - accuracy: 0.3064 - val_loss: 11509.7695 - val_accuracy: 0.6000\n",
      "Epoch 53/68\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 10717.5557 - accuracy: 0.4074 - val_loss: 239.8320 - val_accuracy: 0.6400\n",
      "Epoch 54/68\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 182.2059 - accuracy: 0.4175 - val_loss: 144.0871 - val_accuracy: 0.5733\n",
      "Epoch 55/68\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 52.5521 - accuracy: 0.4646 - val_loss: 123.2564 - val_accuracy: 0.5867\n",
      "Epoch 56/68\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 68.5447 - accuracy: 0.4141 - val_loss: 83.3391 - val_accuracy: 0.5733\n",
      "Epoch 57/68\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 32.5146 - accuracy: 0.4108 - val_loss: 64.2588 - val_accuracy: 0.5867\n",
      "Epoch 58/68\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 27.3786 - accuracy: 0.3973 - val_loss: 67.7033 - val_accuracy: 0.5733\n",
      "Epoch 59/68\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 29.2992 - accuracy: 0.3973 - val_loss: 64.9396 - val_accuracy: 0.5867\n",
      "Epoch 60/68\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 27.4311 - accuracy: 0.4276 - val_loss: 66.4025 - val_accuracy: 0.5733\n",
      "Epoch 61/68\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 18.3668 - accuracy: 0.3973 - val_loss: 62.3224 - val_accuracy: 0.5733\n",
      "Epoch 62/68\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 16.1558 - accuracy: 0.4141 - val_loss: 64.7732 - val_accuracy: 0.6133\n",
      "Epoch 63/68\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 15.5136 - accuracy: 0.3939 - val_loss: 63.7534 - val_accuracy: 0.5733\n",
      "Epoch 64/68\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 21.4666 - accuracy: 0.4276 - val_loss: 66.0409 - val_accuracy: 0.5733\n",
      "Epoch 65/68\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 20.1895 - accuracy: 0.3266 - val_loss: 84.5908 - val_accuracy: 0.5600\n",
      "Epoch 66/68\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 38.4248 - accuracy: 0.4108 - val_loss: 63.3183 - val_accuracy: 0.5733\n",
      "Epoch 67/68\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 14.6888 - accuracy: 0.4040 - val_loss: 62.4108 - val_accuracy: 0.5467\n",
      "Epoch 68/68\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 15.7630 - accuracy: 0.4040 - val_loss: 80.0840 - val_accuracy: 0.5733\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "| \u001b[0m5        \u001b[0m | \u001b[0m0.3441   \u001b[0m | \u001b[0m0.9423   \u001b[0m | \u001b[0m116.7    \u001b[0m | \u001b[0m68.08    \u001b[0m | \u001b[0m0.4232   \u001b[0m | \u001b[0m1.005    \u001b[0m |\n",
      "Epoch 1/88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/rmsprop.py:140: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adagrad.py:81: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 1s 27ms/step - loss: 1306793.7500 - accuracy: 0.3973 - val_loss: 67.8356 - val_accuracy: 0.5733\n",
      "Epoch 2/88\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 35.1323 - accuracy: 0.4478 - val_loss: 1.0644 - val_accuracy: 0.5867\n",
      "Epoch 3/88\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1.6020 - accuracy: 0.4848 - val_loss: 1.1251 - val_accuracy: 0.5867\n",
      "Epoch 4/88\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.1151 - accuracy: 0.4646 - val_loss: 1.3911 - val_accuracy: 0.2400\n",
      "Epoch 5/88\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1.1221 - accuracy: 0.4714 - val_loss: 1.1151 - val_accuracy: 0.2400\n",
      "Epoch 6/88\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1.0995 - accuracy: 0.4680 - val_loss: 1.1956 - val_accuracy: 0.2400\n",
      "Epoch 7/88\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 1.0993 - accuracy: 0.4545 - val_loss: 1.1132 - val_accuracy: 0.5867\n",
      "Epoch 8/88\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1.1016 - accuracy: 0.5152 - val_loss: 1.3837 - val_accuracy: 0.2400\n",
      "Epoch 9/88\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1.1170 - accuracy: 0.4141 - val_loss: 1.0469 - val_accuracy: 0.5867\n",
      "Epoch 10/88\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 1.1209 - accuracy: 0.4377 - val_loss: 1.0630 - val_accuracy: 0.5867\n",
      "Epoch 11/88\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 1.1203 - accuracy: 0.4613 - val_loss: 1.1719 - val_accuracy: 0.2400\n",
      "Epoch 12/88\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 1.0885 - accuracy: 0.4512 - val_loss: 1.1265 - val_accuracy: 0.5867\n",
      "Epoch 13/88\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 1.1335 - accuracy: 0.4680 - val_loss: 1.0375 - val_accuracy: 0.5867\n",
      "Epoch 14/88\n",
      "17/17 [==============================] - 0s 14ms/step - loss: 1.0667 - accuracy: 0.4848 - val_loss: 1.0793 - val_accuracy: 0.5867\n",
      "Epoch 15/88\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 1.1018 - accuracy: 0.4848 - val_loss: 1.0662 - val_accuracy: 0.5867\n",
      "Epoch 16/88\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 1.0811 - accuracy: 0.4983 - val_loss: 1.0645 - val_accuracy: 0.5867\n",
      "Epoch 17/88\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 1.1180 - accuracy: 0.4310 - val_loss: 1.1452 - val_accuracy: 0.5867\n",
      "Epoch 18/88\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 1.1382 - accuracy: 0.4411 - val_loss: 1.0249 - val_accuracy: 0.5867\n",
      "Epoch 19/88\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 1.1276 - accuracy: 0.4209 - val_loss: 1.0283 - val_accuracy: 0.5867\n",
      "Epoch 20/88\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 1.1030 - accuracy: 0.4815 - val_loss: 1.0488 - val_accuracy: 0.5867\n",
      "Epoch 21/88\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 1.1068 - accuracy: 0.4747 - val_loss: 1.0370 - val_accuracy: 0.5867\n",
      "Epoch 22/88\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 1.1196 - accuracy: 0.4680 - val_loss: 1.2055 - val_accuracy: 0.2400\n",
      "Epoch 23/88\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 1.1080 - accuracy: 0.4343 - val_loss: 1.0615 - val_accuracy: 0.5867\n",
      "Epoch 24/88\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 1.0948 - accuracy: 0.4882 - val_loss: 1.0322 - val_accuracy: 0.5867\n",
      "Epoch 25/88\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 1.0961 - accuracy: 0.4983 - val_loss: 1.1306 - val_accuracy: 0.5867\n",
      "Epoch 26/88\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 1.1214 - accuracy: 0.4916 - val_loss: 1.1602 - val_accuracy: 0.2400\n",
      "Epoch 27/88\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 1.1331 - accuracy: 0.4579 - val_loss: 1.0256 - val_accuracy: 0.5867\n",
      "Epoch 28/88\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 1.0838 - accuracy: 0.4680 - val_loss: 1.3481 - val_accuracy: 0.1600\n",
      "Epoch 29/88\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 1.1191 - accuracy: 0.4141 - val_loss: 1.1664 - val_accuracy: 0.1600\n",
      "Epoch 30/88\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 1.1248 - accuracy: 0.4646 - val_loss: 1.1862 - val_accuracy: 0.2400\n",
      "Epoch 31/88\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 1.1249 - accuracy: 0.4343 - val_loss: 1.0223 - val_accuracy: 0.5867\n",
      "Epoch 32/88\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 1.0939 - accuracy: 0.4916 - val_loss: 1.1653 - val_accuracy: 0.2400\n",
      "Epoch 33/88\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 1.0744 - accuracy: 0.4916 - val_loss: 1.1471 - val_accuracy: 0.5867\n",
      "Epoch 34/88\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 1.0961 - accuracy: 0.4882 - val_loss: 1.3036 - val_accuracy: 0.2400\n",
      "Epoch 35/88\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 1.1218 - accuracy: 0.4916 - val_loss: 1.1115 - val_accuracy: 0.2400\n",
      "Epoch 36/88\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 1.0961 - accuracy: 0.4747 - val_loss: 1.1735 - val_accuracy: 0.5867\n",
      "Epoch 37/88\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 1.1136 - accuracy: 0.4815 - val_loss: 1.0967 - val_accuracy: 0.2400\n",
      "Epoch 38/88\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 1.0981 - accuracy: 0.4747 - val_loss: 1.0671 - val_accuracy: 0.5867\n",
      "Epoch 39/88\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 1.1319 - accuracy: 0.4141 - val_loss: 1.0227 - val_accuracy: 0.5867\n",
      "Epoch 40/88\n",
      "17/17 [==============================] - 0s 14ms/step - loss: 1.1115 - accuracy: 0.4444 - val_loss: 1.0319 - val_accuracy: 0.5867\n",
      "Epoch 41/88\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 1.1282 - accuracy: 0.4478 - val_loss: 1.0928 - val_accuracy: 0.5867\n",
      "Epoch 42/88\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 1.0959 - accuracy: 0.4613 - val_loss: 1.0355 - val_accuracy: 0.5867\n",
      "Epoch 43/88\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 1.0901 - accuracy: 0.4545 - val_loss: 1.3472 - val_accuracy: 0.2400\n",
      "Epoch 44/88\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 1.0898 - accuracy: 0.4512 - val_loss: 1.0276 - val_accuracy: 0.5867\n",
      "Epoch 45/88\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 1.1124 - accuracy: 0.4545 - val_loss: 1.3863 - val_accuracy: 0.2400\n",
      "Epoch 46/88\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 1.1130 - accuracy: 0.4276 - val_loss: 1.0245 - val_accuracy: 0.5867\n",
      "Epoch 47/88\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 1.1035 - accuracy: 0.5084 - val_loss: 1.1029 - val_accuracy: 0.5867\n",
      "Epoch 48/88\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1.1004 - accuracy: 0.5118 - val_loss: 1.1200 - val_accuracy: 0.5867\n",
      "Epoch 49/88\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 1.0893 - accuracy: 0.4848 - val_loss: 1.1056 - val_accuracy: 0.2400\n",
      "Epoch 50/88\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 1.1038 - accuracy: 0.4646 - val_loss: 1.2023 - val_accuracy: 0.2400\n",
      "Epoch 51/88\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 1.1391 - accuracy: 0.4444 - val_loss: 1.0460 - val_accuracy: 0.5867\n",
      "Epoch 52/88\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 1.1094 - accuracy: 0.4512 - val_loss: 1.0982 - val_accuracy: 0.5867\n",
      "Epoch 53/88\n",
      "17/17 [==============================] - 0s 14ms/step - loss: 1.0862 - accuracy: 0.4949 - val_loss: 1.1911 - val_accuracy: 0.2400\n",
      "Epoch 54/88\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 1.0591 - accuracy: 0.4848 - val_loss: 1.2044 - val_accuracy: 0.2400\n",
      "Epoch 55/88\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 1.1216 - accuracy: 0.4714 - val_loss: 1.1260 - val_accuracy: 0.5867\n",
      "Epoch 56/88\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 1.1214 - accuracy: 0.4209 - val_loss: 1.0258 - val_accuracy: 0.5867\n",
      "Epoch 57/88\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 1.0988 - accuracy: 0.4983 - val_loss: 1.0768 - val_accuracy: 0.5867\n",
      "Epoch 58/88\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 1.0882 - accuracy: 0.4848 - val_loss: 1.0956 - val_accuracy: 0.2400\n",
      "Epoch 59/88\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 1.1262 - accuracy: 0.4007 - val_loss: 1.1141 - val_accuracy: 0.2400\n",
      "Epoch 60/88\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 1.1279 - accuracy: 0.4276 - val_loss: 1.0274 - val_accuracy: 0.5867\n",
      "Epoch 61/88\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1.0869 - accuracy: 0.4680 - val_loss: 1.0261 - val_accuracy: 0.5867\n",
      "Epoch 62/88\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 1.1076 - accuracy: 0.4411 - val_loss: 1.0146 - val_accuracy: 0.5867\n",
      "Epoch 63/88\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 1.0996 - accuracy: 0.4646 - val_loss: 1.1428 - val_accuracy: 0.5867\n",
      "Epoch 64/88\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 1.1146 - accuracy: 0.4411 - val_loss: 1.0260 - val_accuracy: 0.5867\n",
      "Epoch 65/88\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 1.1107 - accuracy: 0.4747 - val_loss: 1.0800 - val_accuracy: 0.5867\n",
      "Epoch 66/88\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 1.1398 - accuracy: 0.4377 - val_loss: 1.0317 - val_accuracy: 0.5867\n",
      "Epoch 67/88\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1.0999 - accuracy: 0.4781 - val_loss: 1.0646 - val_accuracy: 0.5867\n",
      "Epoch 68/88\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 1.1170 - accuracy: 0.4411 - val_loss: 1.0301 - val_accuracy: 0.5867\n",
      "Epoch 69/88\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1.1000 - accuracy: 0.4613 - val_loss: 1.1075 - val_accuracy: 0.2400\n",
      "Epoch 70/88\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1.1268 - accuracy: 0.4545 - val_loss: 1.0180 - val_accuracy: 0.5867\n",
      "Epoch 71/88\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1.1238 - accuracy: 0.4411 - val_loss: 1.1190 - val_accuracy: 0.5867\n",
      "Epoch 72/88\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 1.1237 - accuracy: 0.4983 - val_loss: 1.0293 - val_accuracy: 0.5867\n",
      "Epoch 73/88\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 1.0775 - accuracy: 0.4983 - val_loss: 1.0476 - val_accuracy: 0.5867\n",
      "Epoch 74/88\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1.1039 - accuracy: 0.5185 - val_loss: 1.3653 - val_accuracy: 0.2400\n",
      "Epoch 75/88\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 1.1342 - accuracy: 0.4579 - val_loss: 1.0628 - val_accuracy: 0.5867\n",
      "Epoch 76/88\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 1.1106 - accuracy: 0.4882 - val_loss: 1.1640 - val_accuracy: 0.2400\n",
      "Epoch 77/88\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 1.0921 - accuracy: 0.4310 - val_loss: 1.2440 - val_accuracy: 0.5867\n",
      "Epoch 78/88\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 1.1487 - accuracy: 0.4646 - val_loss: 1.0910 - val_accuracy: 0.5867\n",
      "Epoch 79/88\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 1.0865 - accuracy: 0.5084 - val_loss: 1.0761 - val_accuracy: 0.5867\n",
      "Epoch 80/88\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 1.0957 - accuracy: 0.4579 - val_loss: 1.1317 - val_accuracy: 0.2400\n",
      "Epoch 81/88\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 1.0953 - accuracy: 0.4882 - val_loss: 1.1050 - val_accuracy: 0.5867\n",
      "Epoch 82/88\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1.1234 - accuracy: 0.4613 - val_loss: 1.2407 - val_accuracy: 0.1600\n",
      "Epoch 83/88\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 1.1170 - accuracy: 0.4444 - val_loss: 1.0877 - val_accuracy: 0.5867\n",
      "Epoch 84/88\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 1.1224 - accuracy: 0.4613 - val_loss: 1.3955 - val_accuracy: 0.1600\n",
      "Epoch 85/88\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 1.1102 - accuracy: 0.4848 - val_loss: 1.0211 - val_accuracy: 0.5867\n",
      "Epoch 86/88\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 1.1008 - accuracy: 0.4848 - val_loss: 1.0589 - val_accuracy: 0.5867\n",
      "Epoch 87/88\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 1.1112 - accuracy: 0.4815 - val_loss: 1.0825 - val_accuracy: 0.5867\n",
      "Epoch 88/88\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 1.1069 - accuracy: 0.4579 - val_loss: 1.0491 - val_accuracy: 0.5867\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "| \u001b[95m6        \u001b[0m | \u001b[95m0.5484   \u001b[0m | \u001b[95m0.07513  \u001b[0m | \u001b[95m17.98    \u001b[0m | \u001b[95m88.33    \u001b[0m | \u001b[95m0.4962   \u001b[0m | \u001b[95m0.7488   \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/rmsprop.py:140: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adagrad.py:81: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/51\n",
      "4/4 [==============================] - 1s 102ms/step - loss: 80.7352 - accuracy: 0.3401 - val_loss: 171.3937 - val_accuracy: 0.2400\n",
      "Epoch 2/51\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 92.2457 - accuracy: 0.3872 - val_loss: 61.9239 - val_accuracy: 0.1600\n",
      "Epoch 3/51\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 83.6454 - accuracy: 0.3434 - val_loss: 13.9425 - val_accuracy: 0.2400\n",
      "Epoch 4/51\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 47.1469 - accuracy: 0.3569 - val_loss: 82.7551 - val_accuracy: 0.2400\n",
      "Epoch 5/51\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 62.8084 - accuracy: 0.3401 - val_loss: 54.3777 - val_accuracy: 0.2400\n",
      "Epoch 6/51\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 51.2051 - accuracy: 0.4141 - val_loss: 17.6210 - val_accuracy: 0.2400\n",
      "Epoch 7/51\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 35.8600 - accuracy: 0.3872 - val_loss: 90.4581 - val_accuracy: 0.2400\n",
      "Epoch 8/51\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 57.5784 - accuracy: 0.4007 - val_loss: 36.0645 - val_accuracy: 0.2400\n",
      "Epoch 9/51\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 55.2988 - accuracy: 0.3367 - val_loss: 89.1448 - val_accuracy: 0.2400\n",
      "Epoch 10/51\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 62.2862 - accuracy: 0.3872 - val_loss: 39.0860 - val_accuracy: 0.2400\n",
      "Epoch 11/51\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 49.7019 - accuracy: 0.3636 - val_loss: 90.8653 - val_accuracy: 0.2400\n",
      "Epoch 12/51\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 57.1238 - accuracy: 0.3973 - val_loss: 27.2046 - val_accuracy: 0.2400\n",
      "Epoch 13/51\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 36.2573 - accuracy: 0.3939 - val_loss: 90.7070 - val_accuracy: 0.2400\n",
      "Epoch 14/51\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 45.7920 - accuracy: 0.3704 - val_loss: 79.4328 - val_accuracy: 0.2400\n",
      "Epoch 15/51\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 58.7171 - accuracy: 0.3603 - val_loss: 102.5615 - val_accuracy: 0.2400\n",
      "Epoch 16/51\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 61.3724 - accuracy: 0.3939 - val_loss: 53.2904 - val_accuracy: 0.1600\n",
      "Epoch 17/51\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 55.2002 - accuracy: 0.3704 - val_loss: 36.8112 - val_accuracy: 0.5867\n",
      "Epoch 18/51\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 44.4514 - accuracy: 0.3468 - val_loss: 42.9151 - val_accuracy: 0.2400\n",
      "Epoch 19/51\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 58.6405 - accuracy: 0.3468 - val_loss: 83.0587 - val_accuracy: 0.2400\n",
      "Epoch 20/51\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 56.4696 - accuracy: 0.3603 - val_loss: 25.3236 - val_accuracy: 0.5867\n",
      "Epoch 21/51\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 27.3001 - accuracy: 0.3737 - val_loss: 38.1959 - val_accuracy: 0.2400\n",
      "Epoch 22/51\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 44.4821 - accuracy: 0.3535 - val_loss: 84.4127 - val_accuracy: 0.2400\n",
      "Epoch 23/51\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 60.4098 - accuracy: 0.3502 - val_loss: 53.0816 - val_accuracy: 0.1600\n",
      "Epoch 24/51\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 43.5435 - accuracy: 0.3805 - val_loss: 69.2229 - val_accuracy: 0.5867\n",
      "Epoch 25/51\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 37.7509 - accuracy: 0.4545 - val_loss: 47.4099 - val_accuracy: 0.2400\n",
      "Epoch 26/51\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 53.8595 - accuracy: 0.3300 - val_loss: 49.4062 - val_accuracy: 0.5867\n",
      "Epoch 27/51\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 59.8960 - accuracy: 0.4040 - val_loss: 39.1041 - val_accuracy: 0.5867\n",
      "Epoch 28/51\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 57.8661 - accuracy: 0.4444 - val_loss: 99.5324 - val_accuracy: 0.2400\n",
      "Epoch 29/51\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 79.3211 - accuracy: 0.2997 - val_loss: 56.7630 - val_accuracy: 0.5867\n",
      "Epoch 30/51\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 45.5905 - accuracy: 0.3737 - val_loss: 44.9441 - val_accuracy: 0.5867\n",
      "Epoch 31/51\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 60.3008 - accuracy: 0.3805 - val_loss: 49.7729 - val_accuracy: 0.5867\n",
      "Epoch 32/51\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 39.8457 - accuracy: 0.4175 - val_loss: 57.6608 - val_accuracy: 0.5867\n",
      "Epoch 33/51\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 59.3305 - accuracy: 0.3737 - val_loss: 44.6254 - val_accuracy: 0.5867\n",
      "Epoch 34/51\n",
      "4/4 [==============================] - 0s 91ms/step - loss: 42.0156 - accuracy: 0.3737 - val_loss: 18.5005 - val_accuracy: 0.5867\n",
      "Epoch 35/51\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 42.0537 - accuracy: 0.4209 - val_loss: 43.2094 - val_accuracy: 0.2400\n",
      "Epoch 36/51\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 46.8515 - accuracy: 0.3939 - val_loss: 63.5947 - val_accuracy: 0.2400\n",
      "Epoch 37/51\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 53.1260 - accuracy: 0.3569 - val_loss: 100.5048 - val_accuracy: 0.2400\n",
      "Epoch 38/51\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 54.3283 - accuracy: 0.3838 - val_loss: 55.1067 - val_accuracy: 0.1600\n",
      "Epoch 39/51\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 57.7108 - accuracy: 0.3603 - val_loss: 60.4226 - val_accuracy: 0.1600\n",
      "Epoch 40/51\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 39.2779 - accuracy: 0.3535 - val_loss: 79.8843 - val_accuracy: 0.2400\n",
      "Epoch 41/51\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 60.7549 - accuracy: 0.3434 - val_loss: 35.9309 - val_accuracy: 0.5867\n",
      "Epoch 42/51\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 58.9964 - accuracy: 0.3502 - val_loss: 25.8129 - val_accuracy: 0.5867\n",
      "Epoch 43/51\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 37.3172 - accuracy: 0.3670 - val_loss: 36.3736 - val_accuracy: 0.5867\n",
      "Epoch 44/51\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 52.6998 - accuracy: 0.4074 - val_loss: 17.1215 - val_accuracy: 0.5867\n",
      "Epoch 45/51\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 37.3404 - accuracy: 0.3670 - val_loss: 46.2183 - val_accuracy: 0.5867\n",
      "Epoch 46/51\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 62.6629 - accuracy: 0.4343 - val_loss: 45.8004 - val_accuracy: 0.5867\n",
      "Epoch 47/51\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 39.3114 - accuracy: 0.3704 - val_loss: 57.1228 - val_accuracy: 0.2400\n",
      "Epoch 48/51\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 41.2038 - accuracy: 0.3704 - val_loss: 54.1844 - val_accuracy: 0.5867\n",
      "Epoch 49/51\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 60.1449 - accuracy: 0.4074 - val_loss: 50.4409 - val_accuracy: 0.5867\n",
      "Epoch 50/51\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 57.3433 - accuracy: 0.4242 - val_loss: 39.1942 - val_accuracy: 0.5867\n",
      "Epoch 51/51\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 54.3258 - accuracy: 0.4108 - val_loss: 33.4298 - val_accuracy: 0.5867\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m0.2043   \u001b[0m | \u001b[0m2.284    \u001b[0m | \u001b[0m83.33    \u001b[0m | \u001b[0m50.85    \u001b[0m | \u001b[0m0.6476   \u001b[0m | \u001b[0m0.515    \u001b[0m |\n",
      "Epoch 1/68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/rmsprop.py:140: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adagrad.py:81: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 1s 10ms/step - loss: 20.9359 - accuracy: 0.3737 - val_loss: 17.7224 - val_accuracy: 0.1600\n",
      "Epoch 2/68\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 17.0012 - accuracy: 0.3603 - val_loss: 4.8868 - val_accuracy: 0.5867\n",
      "Epoch 3/68\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 18.9972 - accuracy: 0.3535 - val_loss: 6.8331 - val_accuracy: 0.2400\n",
      "Epoch 4/68\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 15.6899 - accuracy: 0.3737 - val_loss: 13.2102 - val_accuracy: 0.5867\n",
      "Epoch 5/68\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 18.0459 - accuracy: 0.3502 - val_loss: 11.9852 - val_accuracy: 0.5867\n",
      "Epoch 6/68\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 16.3507 - accuracy: 0.4040 - val_loss: 16.6587 - val_accuracy: 0.5867\n",
      "Epoch 7/68\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 15.9446 - accuracy: 0.3670 - val_loss: 20.5592 - val_accuracy: 0.5867\n",
      "Epoch 8/68\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 17.8364 - accuracy: 0.3872 - val_loss: 14.7579 - val_accuracy: 0.5867\n",
      "Epoch 9/68\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 18.8659 - accuracy: 0.3401 - val_loss: 5.3650 - val_accuracy: 0.5867\n",
      "Epoch 10/68\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 18.0571 - accuracy: 0.3805 - val_loss: 3.6624 - val_accuracy: 0.5867\n",
      "Epoch 11/68\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 16.5986 - accuracy: 0.3636 - val_loss: 18.5224 - val_accuracy: 0.2400\n",
      "Epoch 12/68\n",
      "27/27 [==============================] - 0s 8ms/step - loss: 16.7096 - accuracy: 0.3569 - val_loss: 8.4695 - val_accuracy: 0.5867\n",
      "Epoch 13/68\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 16.1125 - accuracy: 0.3569 - val_loss: 17.4322 - val_accuracy: 0.2400\n",
      "Epoch 14/68\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 16.4256 - accuracy: 0.3603 - val_loss: 8.5755 - val_accuracy: 0.5867\n",
      "Epoch 15/68\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 13.2523 - accuracy: 0.4377 - val_loss: 3.4275 - val_accuracy: 0.5867\n",
      "Epoch 16/68\n",
      "27/27 [==============================] - 0s 8ms/step - loss: 14.6649 - accuracy: 0.4209 - val_loss: 10.0409 - val_accuracy: 0.5867\n",
      "Epoch 17/68\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 18.4632 - accuracy: 0.3670 - val_loss: 2.7344 - val_accuracy: 0.5333\n",
      "Epoch 18/68\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 14.5813 - accuracy: 0.4242 - val_loss: 28.6842 - val_accuracy: 0.2400\n",
      "Epoch 19/68\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 18.4011 - accuracy: 0.3939 - val_loss: 14.6079 - val_accuracy: 0.5867\n",
      "Epoch 20/68\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 17.9177 - accuracy: 0.3704 - val_loss: 14.6720 - val_accuracy: 0.5867\n",
      "Epoch 21/68\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 16.5637 - accuracy: 0.4007 - val_loss: 21.6484 - val_accuracy: 0.2400\n",
      "Epoch 22/68\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 16.7503 - accuracy: 0.4074 - val_loss: 6.3524 - val_accuracy: 0.6000\n",
      "Epoch 23/68\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 16.1804 - accuracy: 0.3805 - val_loss: 22.3529 - val_accuracy: 0.5867\n",
      "Epoch 24/68\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 17.3245 - accuracy: 0.3737 - val_loss: 29.0440 - val_accuracy: 0.2400\n",
      "Epoch 25/68\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 17.5536 - accuracy: 0.3300 - val_loss: 20.4286 - val_accuracy: 0.5867\n",
      "Epoch 26/68\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 17.1521 - accuracy: 0.3906 - val_loss: 17.7341 - val_accuracy: 0.2400\n",
      "Epoch 27/68\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 15.9911 - accuracy: 0.3771 - val_loss: 10.4142 - val_accuracy: 0.5733\n",
      "Epoch 28/68\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 14.1963 - accuracy: 0.3973 - val_loss: 11.2747 - val_accuracy: 0.6133\n",
      "Epoch 29/68\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 14.1722 - accuracy: 0.4579 - val_loss: 7.8514 - val_accuracy: 0.2400\n",
      "Epoch 30/68\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 15.4084 - accuracy: 0.3569 - val_loss: 29.0610 - val_accuracy: 0.2400\n",
      "Epoch 31/68\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 15.8584 - accuracy: 0.3670 - val_loss: 10.0124 - val_accuracy: 0.2400\n",
      "Epoch 32/68\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 15.7493 - accuracy: 0.3872 - val_loss: 9.0414 - val_accuracy: 0.4133\n",
      "Epoch 33/68\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 16.2625 - accuracy: 0.3737 - val_loss: 7.2169 - val_accuracy: 0.5733\n",
      "Epoch 34/68\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 13.7993 - accuracy: 0.4108 - val_loss: 11.3595 - val_accuracy: 0.5867\n",
      "Epoch 35/68\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 14.9207 - accuracy: 0.4209 - val_loss: 6.1688 - val_accuracy: 0.5867\n",
      "Epoch 36/68\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 15.3576 - accuracy: 0.3771 - val_loss: 8.8984 - val_accuracy: 0.5600\n",
      "Epoch 37/68\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 14.0661 - accuracy: 0.3872 - val_loss: 13.7262 - val_accuracy: 0.2133\n",
      "Epoch 38/68\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 15.5637 - accuracy: 0.3973 - val_loss: 12.6386 - val_accuracy: 0.5867\n",
      "Epoch 39/68\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 15.3815 - accuracy: 0.3569 - val_loss: 12.5785 - val_accuracy: 0.4267\n",
      "Epoch 40/68\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 14.5639 - accuracy: 0.4141 - val_loss: 12.1559 - val_accuracy: 0.5867\n",
      "Epoch 41/68\n",
      "27/27 [==============================] - 0s 8ms/step - loss: 16.5833 - accuracy: 0.3737 - val_loss: 9.5066 - val_accuracy: 0.5600\n",
      "Epoch 42/68\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 15.7177 - accuracy: 0.3670 - val_loss: 10.3050 - val_accuracy: 0.2667\n",
      "Epoch 43/68\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 14.7608 - accuracy: 0.3838 - val_loss: 18.7205 - val_accuracy: 0.1867\n",
      "Epoch 44/68\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 15.0359 - accuracy: 0.4209 - val_loss: 19.2385 - val_accuracy: 0.2400\n",
      "Epoch 45/68\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 14.7386 - accuracy: 0.4074 - val_loss: 14.2469 - val_accuracy: 0.5867\n",
      "Epoch 46/68\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 17.2381 - accuracy: 0.3771 - val_loss: 6.4408 - val_accuracy: 0.5867\n",
      "Epoch 47/68\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 16.6113 - accuracy: 0.3771 - val_loss: 21.8721 - val_accuracy: 0.5867\n",
      "Epoch 48/68\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 19.0864 - accuracy: 0.3670 - val_loss: 22.6364 - val_accuracy: 0.1600\n",
      "Epoch 49/68\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 15.0632 - accuracy: 0.4074 - val_loss: 26.2976 - val_accuracy: 0.5867\n",
      "Epoch 50/68\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 15.9167 - accuracy: 0.4175 - val_loss: 8.6598 - val_accuracy: 0.5867\n",
      "Epoch 51/68\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 15.0458 - accuracy: 0.3973 - val_loss: 9.5923 - val_accuracy: 0.5867\n",
      "Epoch 52/68\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 14.6205 - accuracy: 0.3906 - val_loss: 5.8928 - val_accuracy: 0.3867\n",
      "Epoch 53/68\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 15.1212 - accuracy: 0.4242 - val_loss: 23.4705 - val_accuracy: 0.5867\n",
      "Epoch 54/68\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 14.5893 - accuracy: 0.4040 - val_loss: 6.2073 - val_accuracy: 0.4133\n",
      "Epoch 55/68\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 15.9038 - accuracy: 0.3468 - val_loss: 8.9460 - val_accuracy: 0.2400\n",
      "Epoch 56/68\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 14.7159 - accuracy: 0.3906 - val_loss: 25.5922 - val_accuracy: 0.2400\n",
      "Epoch 57/68\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 15.8257 - accuracy: 0.3636 - val_loss: 21.2186 - val_accuracy: 0.5867\n",
      "Epoch 58/68\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 16.3350 - accuracy: 0.3838 - val_loss: 9.7135 - val_accuracy: 0.2400\n",
      "Epoch 59/68\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 15.7754 - accuracy: 0.3805 - val_loss: 9.3117 - val_accuracy: 0.3333\n",
      "Epoch 60/68\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 14.4213 - accuracy: 0.3973 - val_loss: 6.7420 - val_accuracy: 0.5867\n",
      "Epoch 61/68\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 13.9911 - accuracy: 0.3939 - val_loss: 9.8876 - val_accuracy: 0.3733\n",
      "Epoch 62/68\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 17.6048 - accuracy: 0.3502 - val_loss: 4.5084 - val_accuracy: 0.6000\n",
      "Epoch 63/68\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 13.4478 - accuracy: 0.3805 - val_loss: 3.1766 - val_accuracy: 0.6000\n",
      "Epoch 64/68\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 15.0355 - accuracy: 0.3737 - val_loss: 8.9873 - val_accuracy: 0.5733\n",
      "Epoch 65/68\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 16.3990 - accuracy: 0.4175 - val_loss: 17.0937 - val_accuracy: 0.5867\n",
      "Epoch 66/68\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 15.9601 - accuracy: 0.3535 - val_loss: 7.1315 - val_accuracy: 0.5733\n",
      "Epoch 67/68\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 14.3614 - accuracy: 0.3906 - val_loss: 3.1062 - val_accuracy: 0.1733\n",
      "Epoch 68/68\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 17.6490 - accuracy: 0.3636 - val_loss: 6.9156 - val_accuracy: 0.5867\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "| \u001b[0m8        \u001b[0m | \u001b[0m0.2043   \u001b[0m | \u001b[0m2.128    \u001b[0m | \u001b[0m10.83    \u001b[0m | \u001b[0m67.99    \u001b[0m | \u001b[0m0.2113   \u001b[0m | \u001b[0m0.7468   \u001b[0m |\n",
      "Epoch 1/83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/rmsprop.py:140: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adagrad.py:81: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 148ms/step - loss: 63360444.0000 - accuracy: 0.2492 - val_loss: 852335488.0000 - val_accuracy: 0.0133\n",
      "Epoch 2/83\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 367712320.0000 - accuracy: 0.2626 - val_loss: 3301561.2500 - val_accuracy: 0.1867\n",
      "Epoch 3/83\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 2515113.5000 - accuracy: 0.2525 - val_loss: 155103.7969 - val_accuracy: 0.2800\n",
      "Epoch 4/83\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 259424.4062 - accuracy: 0.3333 - val_loss: 50051.8711 - val_accuracy: 0.6000\n",
      "Epoch 5/83\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 112705.5859 - accuracy: 0.4074 - val_loss: 29937.4141 - val_accuracy: 0.5733\n",
      "Epoch 6/83\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 44901.8398 - accuracy: 0.4175 - val_loss: 17895.4590 - val_accuracy: 0.4533\n",
      "Epoch 7/83\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 20332.7070 - accuracy: 0.4646 - val_loss: 12358.1963 - val_accuracy: 0.5067\n",
      "Epoch 8/83\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 6049.2930 - accuracy: 0.4815 - val_loss: 15312.1934 - val_accuracy: 0.2400\n",
      "Epoch 9/83\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 6210.8950 - accuracy: 0.3872 - val_loss: 3960.2280 - val_accuracy: 0.5733\n",
      "Epoch 10/83\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 30578.3945 - accuracy: 0.4411 - val_loss: 181.3371 - val_accuracy: 0.6000\n",
      "Epoch 11/83\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 4692.2627 - accuracy: 0.4242 - val_loss: 150.5432 - val_accuracy: 0.2533\n",
      "Epoch 12/83\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 976.7397 - accuracy: 0.4040 - val_loss: 145.7363 - val_accuracy: 0.6000\n",
      "Epoch 13/83\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 334.4981 - accuracy: 0.4242 - val_loss: 131.5922 - val_accuracy: 0.5867\n",
      "Epoch 14/83\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 1035.3311 - accuracy: 0.4175 - val_loss: 112.0898 - val_accuracy: 0.5867\n",
      "Epoch 15/83\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 949.9424 - accuracy: 0.4007 - val_loss: 124.7075 - val_accuracy: 0.6000\n",
      "Epoch 16/83\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 1060.4038 - accuracy: 0.3704 - val_loss: 96.7803 - val_accuracy: 0.5867\n",
      "Epoch 17/83\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 187.3493 - accuracy: 0.4040 - val_loss: 91.5724 - val_accuracy: 0.5733\n",
      "Epoch 18/83\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 263.1134 - accuracy: 0.4074 - val_loss: 184.6016 - val_accuracy: 0.2533\n",
      "Epoch 19/83\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 269.8036 - accuracy: 0.4040 - val_loss: 70.6628 - val_accuracy: 0.5867\n",
      "Epoch 20/83\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 779.4189 - accuracy: 0.3906 - val_loss: 65.8520 - val_accuracy: 0.5867\n",
      "Epoch 21/83\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 174.8825 - accuracy: 0.3603 - val_loss: 60.9920 - val_accuracy: 0.5867\n",
      "Epoch 22/83\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 296.2196 - accuracy: 0.3502 - val_loss: 58.8129 - val_accuracy: 0.5867\n",
      "Epoch 23/83\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 168.5323 - accuracy: 0.3704 - val_loss: 50.4378 - val_accuracy: 0.5867\n",
      "Epoch 24/83\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 132.2718 - accuracy: 0.3300 - val_loss: 61.9308 - val_accuracy: 0.5867\n",
      "Epoch 25/83\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 91.2882 - accuracy: 0.3670 - val_loss: 54.2568 - val_accuracy: 0.5867\n",
      "Epoch 26/83\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 86.7105 - accuracy: 0.3805 - val_loss: 47.2358 - val_accuracy: 0.5867\n",
      "Epoch 27/83\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 82.6937 - accuracy: 0.3771 - val_loss: 44.9813 - val_accuracy: 0.5867\n",
      "Epoch 28/83\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 67.3848 - accuracy: 0.4141 - val_loss: 42.6353 - val_accuracy: 0.5867\n",
      "Epoch 29/83\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 63.8224 - accuracy: 0.3872 - val_loss: 43.3010 - val_accuracy: 0.5867\n",
      "Epoch 30/83\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 68.5412 - accuracy: 0.3737 - val_loss: 41.8604 - val_accuracy: 0.5867\n",
      "Epoch 31/83\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 58.5443 - accuracy: 0.4108 - val_loss: 34.7038 - val_accuracy: 0.5867\n",
      "Epoch 32/83\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 54.0142 - accuracy: 0.4007 - val_loss: 34.3901 - val_accuracy: 0.2400\n",
      "Epoch 33/83\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 66.5142 - accuracy: 0.4108 - val_loss: 40.7178 - val_accuracy: 0.5867\n",
      "Epoch 34/83\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 56.5216 - accuracy: 0.4613 - val_loss: 36.0274 - val_accuracy: 0.5867\n",
      "Epoch 35/83\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 54.8805 - accuracy: 0.3939 - val_loss: 29.6641 - val_accuracy: 0.5867\n",
      "Epoch 36/83\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 55.0340 - accuracy: 0.4007 - val_loss: 29.1435 - val_accuracy: 0.5867\n",
      "Epoch 37/83\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 44.9799 - accuracy: 0.4444 - val_loss: 24.4522 - val_accuracy: 0.5867\n",
      "Epoch 38/83\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 105.4226 - accuracy: 0.3232 - val_loss: 19.5288 - val_accuracy: 0.5867\n",
      "Epoch 39/83\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 64.1474 - accuracy: 0.3401 - val_loss: 21.1714 - val_accuracy: 0.5867\n",
      "Epoch 40/83\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 52.9186 - accuracy: 0.3502 - val_loss: 28.1650 - val_accuracy: 0.5867\n",
      "Epoch 41/83\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 108.3192 - accuracy: 0.4209 - val_loss: 25.4886 - val_accuracy: 0.5867\n",
      "Epoch 42/83\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 66.7719 - accuracy: 0.3232 - val_loss: 27.8141 - val_accuracy: 0.5867\n",
      "Epoch 43/83\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 59.8455 - accuracy: 0.3737 - val_loss: 28.0103 - val_accuracy: 0.5867\n",
      "Epoch 44/83\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 65.6664 - accuracy: 0.3401 - val_loss: 31.1938 - val_accuracy: 0.5867\n",
      "Epoch 45/83\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 77.7944 - accuracy: 0.3333 - val_loss: 24.6255 - val_accuracy: 0.5867\n",
      "Epoch 46/83\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 56.1501 - accuracy: 0.3872 - val_loss: 32.1753 - val_accuracy: 0.5867\n",
      "Epoch 47/83\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 72.6225 - accuracy: 0.3569 - val_loss: 23.4670 - val_accuracy: 0.5867\n",
      "Epoch 48/83\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 77.1571 - accuracy: 0.3030 - val_loss: 25.9250 - val_accuracy: 0.5867\n",
      "Epoch 49/83\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 78.7698 - accuracy: 0.2694 - val_loss: 37.6853 - val_accuracy: 0.5867\n",
      "Epoch 50/83\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 112.9132 - accuracy: 0.3131 - val_loss: 42.0674 - val_accuracy: 0.5867\n",
      "Epoch 51/83\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 112.1049 - accuracy: 0.3603 - val_loss: 40.6911 - val_accuracy: 0.5867\n",
      "Epoch 52/83\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 64.1750 - accuracy: 0.3603 - val_loss: 34.4812 - val_accuracy: 0.5867\n",
      "Epoch 53/83\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 58.2650 - accuracy: 0.3636 - val_loss: 242.3137 - val_accuracy: 0.5867\n",
      "Epoch 54/83\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 159.0842 - accuracy: 0.3502 - val_loss: 39.9842 - val_accuracy: 0.2400\n",
      "Epoch 55/83\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 76.9693 - accuracy: 0.3401 - val_loss: 33.7610 - val_accuracy: 0.5867\n",
      "Epoch 56/83\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 156.6603 - accuracy: 0.3098 - val_loss: 32.5114 - val_accuracy: 0.5867\n",
      "Epoch 57/83\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 61.7518 - accuracy: 0.3569 - val_loss: 36.4175 - val_accuracy: 0.5867\n",
      "Epoch 58/83\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 56.2306 - accuracy: 0.3165 - val_loss: 34.5657 - val_accuracy: 0.5867\n",
      "Epoch 59/83\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 64.9981 - accuracy: 0.3232 - val_loss: 23.4289 - val_accuracy: 0.5867\n",
      "Epoch 60/83\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 76.3073 - accuracy: 0.3064 - val_loss: 31.9197 - val_accuracy: 0.5867\n",
      "Epoch 61/83\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 93.4451 - accuracy: 0.2256 - val_loss: 53.1148 - val_accuracy: 0.0133\n",
      "Epoch 62/83\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 99.9060 - accuracy: 0.2088 - val_loss: 36.1782 - val_accuracy: 0.5867\n",
      "Epoch 63/83\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 86.1259 - accuracy: 0.2525 - val_loss: 427.7449 - val_accuracy: 0.2400\n",
      "Epoch 64/83\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 283.4295 - accuracy: 0.3300 - val_loss: 33.0825 - val_accuracy: 0.5867\n",
      "Epoch 65/83\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 71.1305 - accuracy: 0.2896 - val_loss: 29.6302 - val_accuracy: 0.5867\n",
      "Epoch 66/83\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 73.0538 - accuracy: 0.2795 - val_loss: 26.0081 - val_accuracy: 0.5867\n",
      "Epoch 67/83\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 62.3075 - accuracy: 0.2828 - val_loss: 23.0764 - val_accuracy: 0.5867\n",
      "Epoch 68/83\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 47.7543 - accuracy: 0.3131 - val_loss: 18.7282 - val_accuracy: 0.5867\n",
      "Epoch 69/83\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 44.2878 - accuracy: 0.3300 - val_loss: 14.7531 - val_accuracy: 0.5867\n",
      "Epoch 70/83\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 44.4532 - accuracy: 0.3064 - val_loss: 13.0904 - val_accuracy: 0.5867\n",
      "Epoch 71/83\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 43.4241 - accuracy: 0.3030 - val_loss: 12.2211 - val_accuracy: 0.5867\n",
      "Epoch 72/83\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 33.1553 - accuracy: 0.3670 - val_loss: 12.1252 - val_accuracy: 0.5867\n",
      "Epoch 73/83\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 35.4331 - accuracy: 0.3030 - val_loss: 14.8084 - val_accuracy: 0.5867\n",
      "Epoch 74/83\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 34.5281 - accuracy: 0.3333 - val_loss: 11.0726 - val_accuracy: 0.5867\n",
      "Epoch 75/83\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 32.5107 - accuracy: 0.3603 - val_loss: 8.3017 - val_accuracy: 0.5867\n",
      "Epoch 76/83\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 30.2018 - accuracy: 0.3569 - val_loss: 6.5015 - val_accuracy: 0.5867\n",
      "Epoch 77/83\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 31.0606 - accuracy: 0.3603 - val_loss: 11.4797 - val_accuracy: 0.5867\n",
      "Epoch 78/83\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 24.6469 - accuracy: 0.3838 - val_loss: 3.5077 - val_accuracy: 0.5867\n",
      "Epoch 79/83\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 29.6039 - accuracy: 0.3569 - val_loss: 10.5172 - val_accuracy: 0.5867\n",
      "Epoch 80/83\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 27.9186 - accuracy: 0.3704 - val_loss: 19.9752 - val_accuracy: 0.5867\n",
      "Epoch 81/83\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 24.7867 - accuracy: 0.3973 - val_loss: 23.4735 - val_accuracy: 0.1600\n",
      "Epoch 82/83\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 34.0622 - accuracy: 0.3939 - val_loss: 12.5538 - val_accuracy: 0.1600\n",
      "Epoch 83/83\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 26.0579 - accuracy: 0.3906 - val_loss: 9.6049 - val_accuracy: 0.5867\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m0.5161   \u001b[0m | \u001b[0m1.197    \u001b[0m | \u001b[0m108.5    \u001b[0m | \u001b[0m83.4     \u001b[0m | \u001b[0m0.8959   \u001b[0m | \u001b[0m0.6616   \u001b[0m |\n",
      "Epoch 1/35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/rmsprop.py:140: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adagrad.py:81: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 97ms/step - loss: 179.2894 - accuracy: 0.3704 - val_loss: 4587.3765 - val_accuracy: 0.5867\n",
      "Epoch 2/35\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 10923.2773 - accuracy: 0.3064 - val_loss: 127.8634 - val_accuracy: 0.1733\n",
      "Epoch 3/35\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 159.6419 - accuracy: 0.3367 - val_loss: 2.6494 - val_accuracy: 0.5867\n",
      "Epoch 4/35\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 7.6654 - accuracy: 0.4074 - val_loss: 2.8278 - val_accuracy: 0.5333\n",
      "Epoch 5/35\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 4.4580 - accuracy: 0.4411 - val_loss: 2.4428 - val_accuracy: 0.5867\n",
      "Epoch 6/35\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.5248 - accuracy: 0.5320 - val_loss: 1.6967 - val_accuracy: 0.6000\n",
      "Epoch 7/35\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.1185 - accuracy: 0.5354 - val_loss: 1.7087 - val_accuracy: 0.6133\n",
      "Epoch 8/35\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 1.0875 - accuracy: 0.5488 - val_loss: 1.7360 - val_accuracy: 0.5867\n",
      "Epoch 9/35\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 1.0474 - accuracy: 0.5488 - val_loss: 1.7492 - val_accuracy: 0.6133\n",
      "Epoch 10/35\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 1.0357 - accuracy: 0.5455 - val_loss: 1.7319 - val_accuracy: 0.6133\n",
      "Epoch 11/35\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 1.0196 - accuracy: 0.5522 - val_loss: 1.7522 - val_accuracy: 0.6133\n",
      "Epoch 12/35\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 1.0276 - accuracy: 0.5589 - val_loss: 1.7354 - val_accuracy: 0.5867\n",
      "Epoch 13/35\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.9861 - accuracy: 0.5522 - val_loss: 1.7482 - val_accuracy: 0.6000\n",
      "Epoch 14/35\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.9853 - accuracy: 0.5657 - val_loss: 1.7400 - val_accuracy: 0.6000\n",
      "Epoch 15/35\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.9932 - accuracy: 0.5455 - val_loss: 1.7471 - val_accuracy: 0.6000\n",
      "Epoch 16/35\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.9627 - accuracy: 0.5589 - val_loss: 1.7724 - val_accuracy: 0.6133\n",
      "Epoch 17/35\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 1.0035 - accuracy: 0.5488 - val_loss: 1.6882 - val_accuracy: 0.6000\n",
      "Epoch 18/35\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.9895 - accuracy: 0.5421 - val_loss: 1.6953 - val_accuracy: 0.6000\n",
      "Epoch 19/35\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.9760 - accuracy: 0.5488 - val_loss: 1.6725 - val_accuracy: 0.5733\n",
      "Epoch 20/35\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.9686 - accuracy: 0.5589 - val_loss: 1.6704 - val_accuracy: 0.5733\n",
      "Epoch 21/35\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.9730 - accuracy: 0.5623 - val_loss: 1.6924 - val_accuracy: 0.5733\n",
      "Epoch 22/35\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 1.4752 - accuracy: 0.5657 - val_loss: 1.7106 - val_accuracy: 0.6000\n",
      "Epoch 23/35\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.9723 - accuracy: 0.5589 - val_loss: 1.7236 - val_accuracy: 0.6133\n",
      "Epoch 24/35\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.9785 - accuracy: 0.5320 - val_loss: 1.6670 - val_accuracy: 0.5733\n",
      "Epoch 25/35\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.9793 - accuracy: 0.5455 - val_loss: 1.6536 - val_accuracy: 0.5733\n",
      "Epoch 26/35\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.9686 - accuracy: 0.5690 - val_loss: 1.6613 - val_accuracy: 0.5733\n",
      "Epoch 27/35\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.9666 - accuracy: 0.5589 - val_loss: 1.6887 - val_accuracy: 0.6000\n",
      "Epoch 28/35\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.9503 - accuracy: 0.5690 - val_loss: 1.6825 - val_accuracy: 0.6133\n",
      "Epoch 29/35\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.9585 - accuracy: 0.5623 - val_loss: 1.6699 - val_accuracy: 0.6000\n",
      "Epoch 30/35\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.9576 - accuracy: 0.5589 - val_loss: 1.6799 - val_accuracy: 0.6133\n",
      "Epoch 31/35\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.9505 - accuracy: 0.5657 - val_loss: 1.6791 - val_accuracy: 0.6133\n",
      "Epoch 32/35\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.9797 - accuracy: 0.5589 - val_loss: 1.6798 - val_accuracy: 0.6000\n",
      "Epoch 33/35\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.9800 - accuracy: 0.5455 - val_loss: 1.7088 - val_accuracy: 0.5733\n",
      "Epoch 34/35\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.9714 - accuracy: 0.5455 - val_loss: 1.7180 - val_accuracy: 0.5733\n",
      "Epoch 35/35\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.9634 - accuracy: 0.5387 - val_loss: 1.6216 - val_accuracy: 0.5733\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "| \u001b[0m10       \u001b[0m | \u001b[0m0.5161   \u001b[0m | \u001b[0m0.03892  \u001b[0m | \u001b[0m115.3    \u001b[0m | \u001b[0m34.61    \u001b[0m | \u001b[0m0.7956   \u001b[0m | \u001b[0m2.852    \u001b[0m |\n",
      "Epoch 1/91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/rmsprop.py:140: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adagrad.py:81: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 98ms/step - loss: 1399.7009 - accuracy: 0.3333 - val_loss: 49.2325 - val_accuracy: 0.1600\n",
      "Epoch 2/91\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 85.0642 - accuracy: 0.2391 - val_loss: 26.6017 - val_accuracy: 0.5867\n",
      "Epoch 3/91\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 19.8041 - accuracy: 0.4343 - val_loss: 1.0968 - val_accuracy: 0.5867\n",
      "Epoch 4/91\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.1581 - accuracy: 0.5152 - val_loss: 1.0434 - val_accuracy: 0.5867\n",
      "Epoch 5/91\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 1.4355 - accuracy: 0.5084 - val_loss: 1.0515 - val_accuracy: 0.5867\n",
      "Epoch 6/91\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 1.0659 - accuracy: 0.5152 - val_loss: 1.0389 - val_accuracy: 0.5867\n",
      "Epoch 7/91\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 1.0593 - accuracy: 0.5152 - val_loss: 1.0384 - val_accuracy: 0.5867\n",
      "Epoch 8/91\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 1.0488 - accuracy: 0.5152 - val_loss: 1.0221 - val_accuracy: 0.5867\n",
      "Epoch 9/91\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 1.0428 - accuracy: 0.5152 - val_loss: 1.0175 - val_accuracy: 0.5867\n",
      "Epoch 10/91\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 1.0420 - accuracy: 0.5152 - val_loss: 1.0142 - val_accuracy: 0.5867\n",
      "Epoch 11/91\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 1.2729 - accuracy: 0.5118 - val_loss: 1.0731 - val_accuracy: 0.5867\n",
      "Epoch 12/91\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 1.0517 - accuracy: 0.5152 - val_loss: 1.0160 - val_accuracy: 0.5867\n",
      "Epoch 13/91\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 1.0844 - accuracy: 0.5118 - val_loss: 1.0294 - val_accuracy: 0.5867\n",
      "Epoch 14/91\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 1.0399 - accuracy: 0.5152 - val_loss: 1.0298 - val_accuracy: 0.5867\n",
      "Epoch 15/91\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 1.0379 - accuracy: 0.5152 - val_loss: 1.0285 - val_accuracy: 0.5867\n",
      "Epoch 16/91\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 1.0379 - accuracy: 0.5152 - val_loss: 1.0317 - val_accuracy: 0.5867\n",
      "Epoch 17/91\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 1.0379 - accuracy: 0.5152 - val_loss: 1.0324 - val_accuracy: 0.5867\n",
      "Epoch 18/91\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 1.0368 - accuracy: 0.5152 - val_loss: 1.0161 - val_accuracy: 0.5867\n",
      "Epoch 19/91\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 1.0356 - accuracy: 0.5152 - val_loss: 1.0147 - val_accuracy: 0.5867\n",
      "Epoch 20/91\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 1.0360 - accuracy: 0.5152 - val_loss: 1.0107 - val_accuracy: 0.5867\n",
      "Epoch 21/91\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 1.0355 - accuracy: 0.5152 - val_loss: 1.0142 - val_accuracy: 0.5867\n",
      "Epoch 22/91\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 1.0349 - accuracy: 0.5152 - val_loss: 1.0205 - val_accuracy: 0.5867\n",
      "Epoch 23/91\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 1.0346 - accuracy: 0.5152 - val_loss: 1.0229 - val_accuracy: 0.5867\n",
      "Epoch 24/91\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 1.0343 - accuracy: 0.5152 - val_loss: 1.0171 - val_accuracy: 0.5867\n",
      "Epoch 25/91\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 1.0346 - accuracy: 0.5152 - val_loss: 1.0228 - val_accuracy: 0.5867\n",
      "Epoch 26/91\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 1.0345 - accuracy: 0.5152 - val_loss: 1.0255 - val_accuracy: 0.5867\n",
      "Epoch 27/91\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 1.0345 - accuracy: 0.5152 - val_loss: 1.0319 - val_accuracy: 0.5867\n",
      "Epoch 28/91\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 1.0364 - accuracy: 0.5152 - val_loss: 1.0253 - val_accuracy: 0.5867\n",
      "Epoch 29/91\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 1.0341 - accuracy: 0.5152 - val_loss: 1.0272 - val_accuracy: 0.5867\n",
      "Epoch 30/91\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 1.0340 - accuracy: 0.5152 - val_loss: 1.0232 - val_accuracy: 0.5867\n",
      "Epoch 31/91\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 1.0347 - accuracy: 0.5152 - val_loss: 1.0210 - val_accuracy: 0.5867\n",
      "Epoch 32/91\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 1.0344 - accuracy: 0.5152 - val_loss: 1.0143 - val_accuracy: 0.5867\n",
      "Epoch 33/91\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 1.0340 - accuracy: 0.5152 - val_loss: 1.0229 - val_accuracy: 0.5867\n",
      "Epoch 34/91\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 1.0345 - accuracy: 0.5152 - val_loss: 1.0152 - val_accuracy: 0.5867\n",
      "Epoch 35/91\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 1.0348 - accuracy: 0.5152 - val_loss: 1.0121 - val_accuracy: 0.5867\n",
      "Epoch 36/91\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 1.0342 - accuracy: 0.5152 - val_loss: 1.0280 - val_accuracy: 0.5867\n",
      "Epoch 37/91\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 1.0341 - accuracy: 0.5152 - val_loss: 1.0272 - val_accuracy: 0.5867\n",
      "Epoch 38/91\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 1.0367 - accuracy: 0.5152 - val_loss: 1.0160 - val_accuracy: 0.5867\n",
      "Epoch 39/91\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 1.0335 - accuracy: 0.5152 - val_loss: 1.0214 - val_accuracy: 0.5867\n",
      "Epoch 40/91\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 1.0336 - accuracy: 0.5152 - val_loss: 1.0175 - val_accuracy: 0.5867\n",
      "Epoch 41/91\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 1.0353 - accuracy: 0.5152 - val_loss: 1.0294 - val_accuracy: 0.5867\n",
      "Epoch 42/91\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 1.0353 - accuracy: 0.5152 - val_loss: 1.0394 - val_accuracy: 0.5867\n",
      "Epoch 43/91\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 1.0372 - accuracy: 0.5152 - val_loss: 1.0216 - val_accuracy: 0.5867\n",
      "Epoch 44/91\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 1.0330 - accuracy: 0.5152 - val_loss: 1.0286 - val_accuracy: 0.5867\n",
      "Epoch 45/91\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 1.0344 - accuracy: 0.5152 - val_loss: 1.0111 - val_accuracy: 0.5867\n",
      "Epoch 46/91\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 1.0350 - accuracy: 0.5152 - val_loss: 1.0155 - val_accuracy: 0.5867\n",
      "Epoch 47/91\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 1.0361 - accuracy: 0.5152 - val_loss: 1.0291 - val_accuracy: 0.5867\n",
      "Epoch 48/91\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 1.0363 - accuracy: 0.5152 - val_loss: 1.0324 - val_accuracy: 0.5867\n",
      "Epoch 49/91\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 1.0357 - accuracy: 0.5152 - val_loss: 1.0223 - val_accuracy: 0.5867\n",
      "Epoch 50/91\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 1.0339 - accuracy: 0.5152 - val_loss: 1.0254 - val_accuracy: 0.5867\n",
      "Epoch 51/91\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 1.0354 - accuracy: 0.5152 - val_loss: 1.0172 - val_accuracy: 0.5867\n",
      "Epoch 52/91\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 1.0344 - accuracy: 0.5152 - val_loss: 1.0149 - val_accuracy: 0.5867\n",
      "Epoch 53/91\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 1.0338 - accuracy: 0.5152 - val_loss: 1.0212 - val_accuracy: 0.5867\n",
      "Epoch 54/91\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.0332 - accuracy: 0.5152 - val_loss: 1.0209 - val_accuracy: 0.5867\n",
      "Epoch 55/91\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 1.0334 - accuracy: 0.5152 - val_loss: 1.0211 - val_accuracy: 0.5867\n",
      "Epoch 56/91\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 1.0349 - accuracy: 0.5152 - val_loss: 1.0342 - val_accuracy: 0.5867\n",
      "Epoch 57/91\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 1.0359 - accuracy: 0.5152 - val_loss: 1.0325 - val_accuracy: 0.5867\n",
      "Epoch 58/91\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 1.0355 - accuracy: 0.5152 - val_loss: 1.0319 - val_accuracy: 0.5867\n",
      "Epoch 59/91\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 1.0345 - accuracy: 0.5152 - val_loss: 1.0233 - val_accuracy: 0.5867\n",
      "Epoch 60/91\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 1.0336 - accuracy: 0.5152 - val_loss: 1.0272 - val_accuracy: 0.5867\n",
      "Epoch 61/91\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 1.0350 - accuracy: 0.5152 - val_loss: 1.0201 - val_accuracy: 0.5867\n",
      "Epoch 62/91\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 1.0337 - accuracy: 0.5152 - val_loss: 1.0317 - val_accuracy: 0.5867\n",
      "Epoch 63/91\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 1.0350 - accuracy: 0.5152 - val_loss: 1.0167 - val_accuracy: 0.5867\n",
      "Epoch 64/91\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 1.0349 - accuracy: 0.5152 - val_loss: 1.0098 - val_accuracy: 0.5867\n",
      "Epoch 65/91\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 1.0369 - accuracy: 0.5152 - val_loss: 1.0121 - val_accuracy: 0.5867\n",
      "Epoch 66/91\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 1.0370 - accuracy: 0.5152 - val_loss: 1.0147 - val_accuracy: 0.5867\n",
      "Epoch 67/91\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 1.0406 - accuracy: 0.5152 - val_loss: 1.0180 - val_accuracy: 0.5867\n",
      "Epoch 68/91\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 1.0343 - accuracy: 0.5152 - val_loss: 1.0212 - val_accuracy: 0.5867\n",
      "Epoch 69/91\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 1.0337 - accuracy: 0.5152 - val_loss: 1.0186 - val_accuracy: 0.5867\n",
      "Epoch 70/91\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 1.0331 - accuracy: 0.5152 - val_loss: 1.0298 - val_accuracy: 0.5867\n",
      "Epoch 71/91\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 1.0339 - accuracy: 0.5152 - val_loss: 1.0201 - val_accuracy: 0.5867\n",
      "Epoch 72/91\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 1.0344 - accuracy: 0.5152 - val_loss: 1.0258 - val_accuracy: 0.5867\n",
      "Epoch 73/91\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 1.0339 - accuracy: 0.5152 - val_loss: 1.0237 - val_accuracy: 0.5867\n",
      "Epoch 74/91\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 1.0343 - accuracy: 0.5152 - val_loss: 1.0273 - val_accuracy: 0.5867\n",
      "Epoch 75/91\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 1.0343 - accuracy: 0.5152 - val_loss: 1.0260 - val_accuracy: 0.5867\n",
      "Epoch 76/91\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 1.0333 - accuracy: 0.5152 - val_loss: 1.0167 - val_accuracy: 0.5867\n",
      "Epoch 77/91\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 1.0377 - accuracy: 0.5152 - val_loss: 1.0247 - val_accuracy: 0.5867\n",
      "Epoch 78/91\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 1.0330 - accuracy: 0.5152 - val_loss: 1.0185 - val_accuracy: 0.5867\n",
      "Epoch 79/91\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 1.0337 - accuracy: 0.5152 - val_loss: 1.0172 - val_accuracy: 0.5867\n",
      "Epoch 80/91\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 1.0336 - accuracy: 0.5152 - val_loss: 1.0263 - val_accuracy: 0.5867\n",
      "Epoch 81/91\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 1.0336 - accuracy: 0.5152 - val_loss: 1.0177 - val_accuracy: 0.5867\n",
      "Epoch 82/91\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 1.0335 - accuracy: 0.5152 - val_loss: 1.0209 - val_accuracy: 0.5867\n",
      "Epoch 83/91\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 1.0336 - accuracy: 0.5152 - val_loss: 1.0187 - val_accuracy: 0.5867\n",
      "Epoch 84/91\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 1.0351 - accuracy: 0.5152 - val_loss: 1.0144 - val_accuracy: 0.5867\n",
      "Epoch 85/91\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 1.0360 - accuracy: 0.5152 - val_loss: 1.0208 - val_accuracy: 0.5867\n",
      "Epoch 86/91\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 1.0332 - accuracy: 0.5152 - val_loss: 1.0209 - val_accuracy: 0.5867\n",
      "Epoch 87/91\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 1.0338 - accuracy: 0.5152 - val_loss: 1.0144 - val_accuracy: 0.5867\n",
      "Epoch 88/91\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 1.0351 - accuracy: 0.5152 - val_loss: 1.0231 - val_accuracy: 0.5867\n",
      "Epoch 89/91\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 1.0347 - accuracy: 0.5152 - val_loss: 1.0344 - val_accuracy: 0.5867\n",
      "Epoch 90/91\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 1.0361 - accuracy: 0.5152 - val_loss: 1.0232 - val_accuracy: 0.5867\n",
      "Epoch 91/91\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 1.0359 - accuracy: 0.5152 - val_loss: 1.0217 - val_accuracy: 0.5867\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "| \u001b[0m11       \u001b[0m | \u001b[0m0.5376   \u001b[0m | \u001b[0m0.01165  \u001b[0m | \u001b[0m135.3    \u001b[0m | \u001b[0m90.91    \u001b[0m | \u001b[0m0.9871   \u001b[0m | \u001b[0m2.577    \u001b[0m |\n",
      "Epoch 1/59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/rmsprop.py:140: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adagrad.py:81: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 94ms/step - loss: 1932.0995 - accuracy: 0.2054 - val_loss: 27344.8594 - val_accuracy: 0.4800\n",
      "Epoch 2/59\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 42270.6289 - accuracy: 0.3535 - val_loss: 3280.3694 - val_accuracy: 0.3867\n",
      "Epoch 3/59\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 2713.7949 - accuracy: 0.2189 - val_loss: 492.0898 - val_accuracy: 0.4000\n",
      "Epoch 4/59\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 363.8551 - accuracy: 0.4108 - val_loss: 133.6006 - val_accuracy: 0.5733\n",
      "Epoch 5/59\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 163.2567 - accuracy: 0.3771 - val_loss: 109.3128 - val_accuracy: 0.5867\n",
      "Epoch 6/59\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 127.5403 - accuracy: 0.4040 - val_loss: 82.4886 - val_accuracy: 0.5867\n",
      "Epoch 7/59\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 113.9780 - accuracy: 0.3737 - val_loss: 43.1954 - val_accuracy: 0.4267\n",
      "Epoch 8/59\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 102.6704 - accuracy: 0.3468 - val_loss: 53.5717 - val_accuracy: 0.5600\n",
      "Epoch 9/59\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 102.7534 - accuracy: 0.4141 - val_loss: 30.1419 - val_accuracy: 0.5067\n",
      "Epoch 10/59\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 81.7146 - accuracy: 0.3771 - val_loss: 45.3467 - val_accuracy: 0.5867\n",
      "Epoch 11/59\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 76.1718 - accuracy: 0.4108 - val_loss: 38.7249 - val_accuracy: 0.5867\n",
      "Epoch 12/59\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 65.1349 - accuracy: 0.4074 - val_loss: 31.4727 - val_accuracy: 0.5867\n",
      "Epoch 13/59\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 56.5073 - accuracy: 0.4310 - val_loss: 18.3467 - val_accuracy: 0.5067\n",
      "Epoch 14/59\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 47.3716 - accuracy: 0.4209 - val_loss: 44.6426 - val_accuracy: 0.6000\n",
      "Epoch 15/59\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 68.0472 - accuracy: 0.3805 - val_loss: 37.4565 - val_accuracy: 0.5600\n",
      "Epoch 16/59\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 59.8510 - accuracy: 0.4411 - val_loss: 21.4492 - val_accuracy: 0.3200\n",
      "Epoch 17/59\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 44.8833 - accuracy: 0.4141 - val_loss: 28.4317 - val_accuracy: 0.5867\n",
      "Epoch 18/59\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 45.0736 - accuracy: 0.4175 - val_loss: 16.7041 - val_accuracy: 0.1600\n",
      "Epoch 19/59\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 47.2292 - accuracy: 0.3805 - val_loss: 17.7229 - val_accuracy: 0.5067\n",
      "Epoch 20/59\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 41.5320 - accuracy: 0.3737 - val_loss: 19.1459 - val_accuracy: 0.5867\n",
      "Epoch 21/59\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 38.7803 - accuracy: 0.4007 - val_loss: 29.3504 - val_accuracy: 0.5867\n",
      "Epoch 22/59\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 40.8532 - accuracy: 0.4074 - val_loss: 14.4999 - val_accuracy: 0.5067\n",
      "Epoch 23/59\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 30.4055 - accuracy: 0.4040 - val_loss: 24.6662 - val_accuracy: 0.2267\n",
      "Epoch 24/59\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 42.6715 - accuracy: 0.3502 - val_loss: 16.2660 - val_accuracy: 0.2267\n",
      "Epoch 25/59\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 36.2546 - accuracy: 0.3973 - val_loss: 11.2727 - val_accuracy: 0.5067\n",
      "Epoch 26/59\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 28.2832 - accuracy: 0.4310 - val_loss: 16.8863 - val_accuracy: 0.5867\n",
      "Epoch 27/59\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 27.7681 - accuracy: 0.4579 - val_loss: 12.5045 - val_accuracy: 0.5867\n",
      "Epoch 28/59\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 27.1770 - accuracy: 0.3805 - val_loss: 17.1467 - val_accuracy: 0.5867\n",
      "Epoch 29/59\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 26.2644 - accuracy: 0.3939 - val_loss: 11.9195 - val_accuracy: 0.4000\n",
      "Epoch 30/59\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 26.9191 - accuracy: 0.4007 - val_loss: 15.7669 - val_accuracy: 0.2267\n",
      "Epoch 31/59\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 26.5866 - accuracy: 0.3502 - val_loss: 21.8536 - val_accuracy: 0.6000\n",
      "Epoch 32/59\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 24.9719 - accuracy: 0.4276 - val_loss: 11.7068 - val_accuracy: 0.5200\n",
      "Epoch 33/59\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 22.8673 - accuracy: 0.3939 - val_loss: 22.4673 - val_accuracy: 0.2400\n",
      "Epoch 34/59\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 29.2505 - accuracy: 0.3232 - val_loss: 16.1513 - val_accuracy: 0.6000\n",
      "Epoch 35/59\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 22.6331 - accuracy: 0.4141 - val_loss: 13.5499 - val_accuracy: 0.5867\n",
      "Epoch 36/59\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 17.3002 - accuracy: 0.4108 - val_loss: 10.0827 - val_accuracy: 0.5867\n",
      "Epoch 37/59\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 18.6598 - accuracy: 0.4141 - val_loss: 10.5126 - val_accuracy: 0.6000\n",
      "Epoch 38/59\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 19.3518 - accuracy: 0.4276 - val_loss: 15.2179 - val_accuracy: 0.6000\n",
      "Epoch 39/59\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 20.7597 - accuracy: 0.4007 - val_loss: 9.0290 - val_accuracy: 0.4933\n",
      "Epoch 40/59\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 18.8032 - accuracy: 0.4310 - val_loss: 19.2255 - val_accuracy: 0.3333\n",
      "Epoch 41/59\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 24.9306 - accuracy: 0.3737 - val_loss: 15.3898 - val_accuracy: 0.6000\n",
      "Epoch 42/59\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 16.3829 - accuracy: 0.4545 - val_loss: 9.2079 - val_accuracy: 0.4133\n",
      "Epoch 43/59\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 17.6349 - accuracy: 0.3805 - val_loss: 12.4041 - val_accuracy: 0.6000\n",
      "Epoch 44/59\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 17.4682 - accuracy: 0.4040 - val_loss: 13.2079 - val_accuracy: 0.5867\n",
      "Epoch 45/59\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 18.6115 - accuracy: 0.3670 - val_loss: 11.2266 - val_accuracy: 0.5867\n",
      "Epoch 46/59\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 15.7894 - accuracy: 0.4108 - val_loss: 9.3411 - val_accuracy: 0.5867\n",
      "Epoch 47/59\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 11.8501 - accuracy: 0.4209 - val_loss: 10.5581 - val_accuracy: 0.4800\n",
      "Epoch 48/59\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 15.7045 - accuracy: 0.4141 - val_loss: 9.4717 - val_accuracy: 0.4000\n",
      "Epoch 49/59\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 16.5318 - accuracy: 0.3232 - val_loss: 14.7091 - val_accuracy: 0.5867\n",
      "Epoch 50/59\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 13.9391 - accuracy: 0.4411 - val_loss: 10.8534 - val_accuracy: 0.5867\n",
      "Epoch 51/59\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 13.9011 - accuracy: 0.4377 - val_loss: 8.8116 - val_accuracy: 0.5867\n",
      "Epoch 52/59\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 12.0637 - accuracy: 0.4276 - val_loss: 6.6173 - val_accuracy: 0.4000\n",
      "Epoch 53/59\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 12.9515 - accuracy: 0.3805 - val_loss: 8.6083 - val_accuracy: 0.5867\n",
      "Epoch 54/59\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 15.4649 - accuracy: 0.3737 - val_loss: 12.6796 - val_accuracy: 0.2267\n",
      "Epoch 55/59\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 15.0870 - accuracy: 0.4040 - val_loss: 10.6345 - val_accuracy: 0.5867\n",
      "Epoch 56/59\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 13.2569 - accuracy: 0.4074 - val_loss: 9.8888 - val_accuracy: 0.3200\n",
      "Epoch 57/59\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 13.3650 - accuracy: 0.3737 - val_loss: 10.5102 - val_accuracy: 0.5867\n",
      "Epoch 58/59\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 13.1067 - accuracy: 0.4343 - val_loss: 7.5783 - val_accuracy: 0.5867\n",
      "Epoch 59/59\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 12.6596 - accuracy: 0.4377 - val_loss: 8.7320 - val_accuracy: 0.4800\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "| \u001b[0m12       \u001b[0m | \u001b[0m0.2258   \u001b[0m | \u001b[0m0.8706   \u001b[0m | \u001b[0m134.4    \u001b[0m | \u001b[0m58.96    \u001b[0m | \u001b[0m0.4965   \u001b[0m | \u001b[0m2.719    \u001b[0m |\n",
      "Epoch 1/52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/rmsprop.py:140: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adagrad.py:81: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 91ms/step - loss: 47.2986 - accuracy: 0.3434 - val_loss: 124.9566 - val_accuracy: 0.5867\n",
      "Epoch 2/52\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 189.1100 - accuracy: 0.2694 - val_loss: 149.8959 - val_accuracy: 0.5867\n",
      "Epoch 3/52\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 107.7749 - accuracy: 0.4444 - val_loss: 62.1756 - val_accuracy: 0.5867\n",
      "Epoch 4/52\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 46.7733 - accuracy: 0.3636 - val_loss: 41.9878 - val_accuracy: 0.5867\n",
      "Epoch 5/52\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 36.1172 - accuracy: 0.3805 - val_loss: 78.7464 - val_accuracy: 0.5867\n",
      "Epoch 6/52\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 108.2520 - accuracy: 0.4545 - val_loss: 47.5395 - val_accuracy: 0.2400\n",
      "Epoch 7/52\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 54.3886 - accuracy: 0.3704 - val_loss: 58.9083 - val_accuracy: 0.5867\n",
      "Epoch 8/52\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 81.8744 - accuracy: 0.4882 - val_loss: 33.0129 - val_accuracy: 0.1600\n",
      "Epoch 9/52\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 70.4656 - accuracy: 0.3232 - val_loss: 75.5255 - val_accuracy: 0.5867\n",
      "Epoch 10/52\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 89.6181 - accuracy: 0.3906 - val_loss: 106.2228 - val_accuracy: 0.2400\n",
      "Epoch 11/52\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 67.8091 - accuracy: 0.4141 - val_loss: 17.5382 - val_accuracy: 0.5867\n",
      "Epoch 12/52\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 38.7111 - accuracy: 0.4141 - val_loss: 81.1953 - val_accuracy: 0.2400\n",
      "Epoch 13/52\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 88.3470 - accuracy: 0.3300 - val_loss: 57.8779 - val_accuracy: 0.5867\n",
      "Epoch 14/52\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 98.0526 - accuracy: 0.3906 - val_loss: 17.1141 - val_accuracy: 0.2400\n",
      "Epoch 15/52\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 39.0959 - accuracy: 0.3603 - val_loss: 57.8610 - val_accuracy: 0.5867\n",
      "Epoch 16/52\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 64.0302 - accuracy: 0.4074 - val_loss: 39.4940 - val_accuracy: 0.1600\n",
      "Epoch 17/52\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 62.5463 - accuracy: 0.3535 - val_loss: 64.7631 - val_accuracy: 0.5867\n",
      "Epoch 18/52\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 67.2224 - accuracy: 0.3973 - val_loss: 134.6360 - val_accuracy: 0.2400\n",
      "Epoch 19/52\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 74.7482 - accuracy: 0.3906 - val_loss: 61.9084 - val_accuracy: 0.5867\n",
      "Epoch 20/52\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 71.4068 - accuracy: 0.3636 - val_loss: 84.6488 - val_accuracy: 0.2400\n",
      "Epoch 21/52\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 63.5534 - accuracy: 0.4074 - val_loss: 52.9982 - val_accuracy: 0.2400\n",
      "Epoch 22/52\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 69.5056 - accuracy: 0.3737 - val_loss: 46.6384 - val_accuracy: 0.5867\n",
      "Epoch 23/52\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 83.6096 - accuracy: 0.4074 - val_loss: 53.7672 - val_accuracy: 0.1600\n",
      "Epoch 24/52\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 60.6381 - accuracy: 0.3704 - val_loss: 67.8540 - val_accuracy: 0.2400\n",
      "Epoch 25/52\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 70.1074 - accuracy: 0.3401 - val_loss: 57.4135 - val_accuracy: 0.5867\n",
      "Epoch 26/52\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 80.5113 - accuracy: 0.4579 - val_loss: 26.4308 - val_accuracy: 0.2400\n",
      "Epoch 27/52\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 45.2271 - accuracy: 0.2929 - val_loss: 55.5983 - val_accuracy: 0.5867\n",
      "Epoch 28/52\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 63.7125 - accuracy: 0.4747 - val_loss: 67.3978 - val_accuracy: 0.1600\n",
      "Epoch 29/52\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 55.1101 - accuracy: 0.3401 - val_loss: 88.6114 - val_accuracy: 0.5867\n",
      "Epoch 30/52\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 73.5126 - accuracy: 0.3670 - val_loss: 26.3864 - val_accuracy: 0.2400\n",
      "Epoch 31/52\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 54.6818 - accuracy: 0.3670 - val_loss: 53.0410 - val_accuracy: 0.5867\n",
      "Epoch 32/52\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 91.1179 - accuracy: 0.4209 - val_loss: 24.0878 - val_accuracy: 0.2400\n",
      "Epoch 33/52\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 67.3362 - accuracy: 0.2929 - val_loss: 56.4309 - val_accuracy: 0.5867\n",
      "Epoch 34/52\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 93.1408 - accuracy: 0.3939 - val_loss: 22.1993 - val_accuracy: 0.2400\n",
      "Epoch 35/52\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 66.4156 - accuracy: 0.3300 - val_loss: 212.4370 - val_accuracy: 0.0133\n",
      "Epoch 36/52\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 102.3232 - accuracy: 0.2761 - val_loss: 77.2945 - val_accuracy: 0.1600\n",
      "Epoch 37/52\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 81.4346 - accuracy: 0.3098 - val_loss: 66.9819 - val_accuracy: 0.5867\n",
      "Epoch 38/52\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 36.6996 - accuracy: 0.4209 - val_loss: 68.9695 - val_accuracy: 0.2400\n",
      "Epoch 39/52\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 48.2050 - accuracy: 0.3704 - val_loss: 40.1523 - val_accuracy: 0.5867\n",
      "Epoch 40/52\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 77.9480 - accuracy: 0.4242 - val_loss: 87.1800 - val_accuracy: 0.1600\n",
      "Epoch 41/52\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 84.7753 - accuracy: 0.3266 - val_loss: 27.3095 - val_accuracy: 0.5867\n",
      "Epoch 42/52\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 64.2469 - accuracy: 0.4108 - val_loss: 107.9560 - val_accuracy: 0.1600\n",
      "Epoch 43/52\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 58.4315 - accuracy: 0.3872 - val_loss: 121.3027 - val_accuracy: 0.2400\n",
      "Epoch 44/52\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 62.3047 - accuracy: 0.4108 - val_loss: 93.7081 - val_accuracy: 0.2400\n",
      "Epoch 45/52\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 86.6906 - accuracy: 0.3064 - val_loss: 36.2088 - val_accuracy: 0.5867\n",
      "Epoch 46/52\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 69.4132 - accuracy: 0.3603 - val_loss: 55.0250 - val_accuracy: 0.5867\n",
      "Epoch 47/52\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 57.2161 - accuracy: 0.4175 - val_loss: 110.2227 - val_accuracy: 0.2400\n",
      "Epoch 48/52\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 79.8280 - accuracy: 0.3266 - val_loss: 60.5894 - val_accuracy: 0.5867\n",
      "Epoch 49/52\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 58.2470 - accuracy: 0.3805 - val_loss: 84.5089 - val_accuracy: 0.2400\n",
      "Epoch 50/52\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 70.8992 - accuracy: 0.3098 - val_loss: 45.3356 - val_accuracy: 0.5867\n",
      "Epoch 51/52\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 58.0146 - accuracy: 0.4007 - val_loss: 48.9725 - val_accuracy: 0.2400\n",
      "Epoch 52/52\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 58.3294 - accuracy: 0.3401 - val_loss: 54.4477 - val_accuracy: 0.5867\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "| \u001b[0m13       \u001b[0m | \u001b[0m0.2043   \u001b[0m | \u001b[0m2.319    \u001b[0m | \u001b[0m101.0    \u001b[0m | \u001b[0m52.06    \u001b[0m | \u001b[0m0.8403   \u001b[0m | \u001b[0m1.216    \u001b[0m |\n",
      "Epoch 1/34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/rmsprop.py:140: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adagrad.py:81: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 61ms/step - loss: 153692688.0000 - accuracy: 0.3131 - val_loss: 1707.8953 - val_accuracy: 0.2933\n",
      "Epoch 2/34\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 19099.0332 - accuracy: 0.3805 - val_loss: 629.5252 - val_accuracy: 0.5200\n",
      "Epoch 3/34\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 236.9534 - accuracy: 0.4714 - val_loss: 136.4186 - val_accuracy: 0.6267\n",
      "Epoch 4/34\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 61.1194 - accuracy: 0.5387 - val_loss: 54.7888 - val_accuracy: 0.6267\n",
      "Epoch 5/34\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 70.6979 - accuracy: 0.4848 - val_loss: 22.3273 - val_accuracy: 0.1333\n",
      "Epoch 6/34\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 5.8366 - accuracy: 0.4310 - val_loss: 20.6508 - val_accuracy: 0.5467\n",
      "Epoch 7/34\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 3.9108 - accuracy: 0.5455 - val_loss: 20.5197 - val_accuracy: 0.2800\n",
      "Epoch 8/34\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 3.2998 - accuracy: 0.3434 - val_loss: 17.5802 - val_accuracy: 0.5467\n",
      "Epoch 9/34\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 2.3475 - accuracy: 0.5421 - val_loss: 17.3020 - val_accuracy: 0.2800\n",
      "Epoch 10/34\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 2.2769 - accuracy: 0.5051 - val_loss: 14.8789 - val_accuracy: 0.6267\n",
      "Epoch 11/34\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 2.2018 - accuracy: 0.5421 - val_loss: 13.2065 - val_accuracy: 0.6267\n",
      "Epoch 12/34\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1.6935 - accuracy: 0.5354 - val_loss: 11.8199 - val_accuracy: 0.6267\n",
      "Epoch 13/34\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 1.3861 - accuracy: 0.5488 - val_loss: 10.6400 - val_accuracy: 0.3733\n",
      "Epoch 14/34\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 1.5281 - accuracy: 0.4646 - val_loss: 10.5756 - val_accuracy: 0.2800\n",
      "Epoch 15/34\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1.3560 - accuracy: 0.4848 - val_loss: 9.6372 - val_accuracy: 0.5733\n",
      "Epoch 16/34\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.2872 - accuracy: 0.5320 - val_loss: 9.0930 - val_accuracy: 0.2267\n",
      "Epoch 17/34\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.1807 - accuracy: 0.3300 - val_loss: 9.1253 - val_accuracy: 0.2267\n",
      "Epoch 18/34\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1.2399 - accuracy: 0.4478 - val_loss: 9.0759 - val_accuracy: 0.2000\n",
      "Epoch 19/34\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1.1361 - accuracy: 0.3367 - val_loss: 8.3986 - val_accuracy: 0.2000\n",
      "Epoch 20/34\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.1630 - accuracy: 0.3232 - val_loss: 9.1710 - val_accuracy: 0.2000\n",
      "Epoch 21/34\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1.3560 - accuracy: 0.4209 - val_loss: 8.2868 - val_accuracy: 0.5467\n",
      "Epoch 22/34\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1.1341 - accuracy: 0.4545 - val_loss: 8.3913 - val_accuracy: 0.5467\n",
      "Epoch 23/34\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1.1825 - accuracy: 0.5286 - val_loss: 8.3706 - val_accuracy: 0.5467\n",
      "Epoch 24/34\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.1617 - accuracy: 0.4916 - val_loss: 7.3091 - val_accuracy: 0.5467\n",
      "Epoch 25/34\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 1.2684 - accuracy: 0.5286 - val_loss: 7.3538 - val_accuracy: 0.5467\n",
      "Epoch 26/34\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1.1925 - accuracy: 0.5286 - val_loss: 7.3001 - val_accuracy: 0.1733\n",
      "Epoch 27/34\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 1.1126 - accuracy: 0.4074 - val_loss: 7.9995 - val_accuracy: 0.2533\n",
      "Epoch 28/34\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1.3128 - accuracy: 0.4343 - val_loss: 7.1869 - val_accuracy: 0.5467\n",
      "Epoch 29/34\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.1430 - accuracy: 0.4377 - val_loss: 7.1792 - val_accuracy: 0.5467\n",
      "Epoch 30/34\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1.1261 - accuracy: 0.5286 - val_loss: 7.3000 - val_accuracy: 0.5467\n",
      "Epoch 31/34\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1.0940 - accuracy: 0.5286 - val_loss: 7.0990 - val_accuracy: 0.5467\n",
      "Epoch 32/34\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.1203 - accuracy: 0.4209 - val_loss: 7.4737 - val_accuracy: 0.5467\n",
      "Epoch 33/34\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1.2996 - accuracy: 0.5286 - val_loss: 8.1022 - val_accuracy: 0.2533\n",
      "Epoch 34/34\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1.3054 - accuracy: 0.4680 - val_loss: 7.1719 - val_accuracy: 0.5467\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "| \u001b[0m14       \u001b[0m | \u001b[0m0.5376   \u001b[0m | \u001b[0m0.2      \u001b[0m | \u001b[0m96.99    \u001b[0m | \u001b[0m33.59    \u001b[0m | \u001b[0m0.8808   \u001b[0m | \u001b[0m0.6819   \u001b[0m |\n",
      "Epoch 1/88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/rmsprop.py:140: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adagrad.py:81: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 64ms/step - loss: 12.1539 - accuracy: 0.3232 - val_loss: 1.0839 - val_accuracy: 0.4667\n",
      "Epoch 2/88\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.0949 - accuracy: 0.4377 - val_loss: 0.9588 - val_accuracy: 0.5867\n",
      "Epoch 3/88\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.0442 - accuracy: 0.5185 - val_loss: 0.9984 - val_accuracy: 0.5867\n",
      "Epoch 4/88\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.0298 - accuracy: 0.5354 - val_loss: 0.9566 - val_accuracy: 0.5867\n",
      "Epoch 5/88\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.9860 - accuracy: 0.4781 - val_loss: 0.9509 - val_accuracy: 0.5867\n",
      "Epoch 6/88\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.9187 - accuracy: 0.5690 - val_loss: 0.9706 - val_accuracy: 0.5067\n",
      "Epoch 7/88\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.8626 - accuracy: 0.6195 - val_loss: 0.8545 - val_accuracy: 0.6267\n",
      "Epoch 8/88\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 0.8285 - accuracy: 0.6263 - val_loss: 0.8290 - val_accuracy: 0.5867\n",
      "Epoch 9/88\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.8247 - accuracy: 0.6027 - val_loss: 0.8410 - val_accuracy: 0.6267\n",
      "Epoch 10/88\n",
      "4/4 [==============================] - 1s 170ms/step - loss: 0.7749 - accuracy: 0.6734 - val_loss: 0.8985 - val_accuracy: 0.6400\n",
      "Epoch 11/88\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.7508 - accuracy: 0.6801 - val_loss: 0.8607 - val_accuracy: 0.6133\n",
      "Epoch 12/88\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7696 - accuracy: 0.7475 - val_loss: 0.8063 - val_accuracy: 0.6400\n",
      "Epoch 13/88\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.5954 - accuracy: 0.7340 - val_loss: 0.8676 - val_accuracy: 0.6267\n",
      "Epoch 14/88\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.5881 - accuracy: 0.7374 - val_loss: 0.9299 - val_accuracy: 0.6267\n",
      "Epoch 15/88\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.5435 - accuracy: 0.7441 - val_loss: 1.0573 - val_accuracy: 0.6267\n",
      "Epoch 16/88\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.5696 - accuracy: 0.7609 - val_loss: 1.1111 - val_accuracy: 0.6533\n",
      "Epoch 17/88\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 0.5126 - accuracy: 0.7744 - val_loss: 1.1576 - val_accuracy: 0.6800\n",
      "Epoch 18/88\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.5275 - accuracy: 0.7643 - val_loss: 1.1140 - val_accuracy: 0.6533\n",
      "Epoch 19/88\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.5177 - accuracy: 0.7744 - val_loss: 1.1200 - val_accuracy: 0.6533\n",
      "Epoch 20/88\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.5122 - accuracy: 0.7677 - val_loss: 1.1731 - val_accuracy: 0.6533\n",
      "Epoch 21/88\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.5215 - accuracy: 0.7677 - val_loss: 1.0660 - val_accuracy: 0.6267\n",
      "Epoch 22/88\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.4811 - accuracy: 0.7475 - val_loss: 1.1331 - val_accuracy: 0.6133\n",
      "Epoch 23/88\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.4591 - accuracy: 0.8013 - val_loss: 1.4916 - val_accuracy: 0.6000\n",
      "Epoch 24/88\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.4560 - accuracy: 0.7912 - val_loss: 1.4978 - val_accuracy: 0.6267\n",
      "Epoch 25/88\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.4738 - accuracy: 0.7912 - val_loss: 1.2869 - val_accuracy: 0.6533\n",
      "Epoch 26/88\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.5195 - accuracy: 0.7576 - val_loss: 1.4744 - val_accuracy: 0.6400\n",
      "Epoch 27/88\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.5504 - accuracy: 0.7441 - val_loss: 1.4308 - val_accuracy: 0.6000\n",
      "Epoch 28/88\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.5336 - accuracy: 0.7508 - val_loss: 1.3470 - val_accuracy: 0.6267\n",
      "Epoch 29/88\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.5037 - accuracy: 0.7744 - val_loss: 1.8547 - val_accuracy: 0.6133\n",
      "Epoch 30/88\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.4771 - accuracy: 0.7845 - val_loss: 1.8038 - val_accuracy: 0.6000\n",
      "Epoch 31/88\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.4506 - accuracy: 0.7710 - val_loss: 1.7696 - val_accuracy: 0.5867\n",
      "Epoch 32/88\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.5472 - accuracy: 0.7576 - val_loss: 2.1214 - val_accuracy: 0.5067\n",
      "Epoch 33/88\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.7636 - accuracy: 0.6667 - val_loss: 2.8053 - val_accuracy: 0.6400\n",
      "Epoch 34/88\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.6062 - accuracy: 0.7407 - val_loss: 2.4318 - val_accuracy: 0.6400\n",
      "Epoch 35/88\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.5827 - accuracy: 0.7542 - val_loss: 1.9108 - val_accuracy: 0.5733\n",
      "Epoch 36/88\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.5247 - accuracy: 0.7643 - val_loss: 2.0932 - val_accuracy: 0.6400\n",
      "Epoch 37/88\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.5247 - accuracy: 0.7677 - val_loss: 2.0965 - val_accuracy: 0.6267\n",
      "Epoch 38/88\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.7094 - accuracy: 0.7677 - val_loss: 1.5313 - val_accuracy: 0.6400\n",
      "Epoch 39/88\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.4566 - accuracy: 0.7845 - val_loss: 1.8472 - val_accuracy: 0.6133\n",
      "Epoch 40/88\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.4491 - accuracy: 0.7980 - val_loss: 1.9277 - val_accuracy: 0.6267\n",
      "Epoch 41/88\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.4359 - accuracy: 0.7946 - val_loss: 2.2606 - val_accuracy: 0.6267\n",
      "Epoch 42/88\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.4832 - accuracy: 0.7778 - val_loss: 2.3588 - val_accuracy: 0.6400\n",
      "Epoch 43/88\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.4732 - accuracy: 0.7710 - val_loss: 2.2262 - val_accuracy: 0.6400\n",
      "Epoch 44/88\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.4356 - accuracy: 0.8047 - val_loss: 2.1575 - val_accuracy: 0.6267\n",
      "Epoch 45/88\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.5015 - accuracy: 0.7475 - val_loss: 2.2129 - val_accuracy: 0.6000\n",
      "Epoch 46/88\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.4691 - accuracy: 0.7677 - val_loss: 2.3497 - val_accuracy: 0.6267\n",
      "Epoch 47/88\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.4848 - accuracy: 0.7744 - val_loss: 2.2312 - val_accuracy: 0.6400\n",
      "Epoch 48/88\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.4631 - accuracy: 0.7879 - val_loss: 2.7281 - val_accuracy: 0.6400\n",
      "Epoch 49/88\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.4612 - accuracy: 0.7710 - val_loss: 3.0954 - val_accuracy: 0.6267\n",
      "Epoch 50/88\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.4901 - accuracy: 0.7778 - val_loss: 2.9776 - val_accuracy: 0.5733\n",
      "Epoch 51/88\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.5203 - accuracy: 0.6970 - val_loss: 2.7762 - val_accuracy: 0.6267\n",
      "Epoch 52/88\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.5112 - accuracy: 0.7475 - val_loss: 2.5399 - val_accuracy: 0.6133\n",
      "Epoch 53/88\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.5903 - accuracy: 0.7306 - val_loss: 2.9949 - val_accuracy: 0.5867\n",
      "Epoch 54/88\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.7619 - accuracy: 0.7677 - val_loss: 2.4720 - val_accuracy: 0.5333\n",
      "Epoch 55/88\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.9156 - accuracy: 0.7239 - val_loss: 1.8978 - val_accuracy: 0.5733\n",
      "Epoch 56/88\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.5278 - accuracy: 0.7475 - val_loss: 2.7927 - val_accuracy: 0.6267\n",
      "Epoch 57/88\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.0756 - accuracy: 0.7677 - val_loss: 2.1903 - val_accuracy: 0.6667\n",
      "Epoch 58/88\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1.8100 - accuracy: 0.7071 - val_loss: 1.6646 - val_accuracy: 0.6267\n",
      "Epoch 59/88\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1.3063 - accuracy: 0.7071 - val_loss: 1.9460 - val_accuracy: 0.6267\n",
      "Epoch 60/88\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.3431 - accuracy: 0.7239 - val_loss: 3.2468 - val_accuracy: 0.5867\n",
      "Epoch 61/88\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.0298 - accuracy: 0.7071 - val_loss: 3.9429 - val_accuracy: 0.5733\n",
      "Epoch 62/88\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 3.4392 - accuracy: 0.6667 - val_loss: 2.4582 - val_accuracy: 0.6267\n",
      "Epoch 63/88\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1.6105 - accuracy: 0.5657 - val_loss: 2.4885 - val_accuracy: 0.4267\n",
      "Epoch 64/88\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.6398 - accuracy: 0.5185 - val_loss: 3.3436 - val_accuracy: 0.6000\n",
      "Epoch 65/88\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.2693 - accuracy: 0.6162 - val_loss: 2.6831 - val_accuracy: 0.6000\n",
      "Epoch 66/88\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.9149 - accuracy: 0.6061 - val_loss: 2.0220 - val_accuracy: 0.4933\n",
      "Epoch 67/88\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.7822 - accuracy: 0.5926 - val_loss: 1.3529 - val_accuracy: 0.4933\n",
      "Epoch 68/88\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.7865 - accuracy: 0.5859 - val_loss: 1.2342 - val_accuracy: 0.5200\n",
      "Epoch 69/88\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.7999 - accuracy: 0.5892 - val_loss: 1.3818 - val_accuracy: 0.5867\n",
      "Epoch 70/88\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.9292 - accuracy: 0.6094 - val_loss: 1.0317 - val_accuracy: 0.4667\n",
      "Epoch 71/88\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 2.3283 - accuracy: 0.6296 - val_loss: 1.6110 - val_accuracy: 0.4667\n",
      "Epoch 72/88\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 1.2010 - accuracy: 0.6397 - val_loss: 1.7568 - val_accuracy: 0.5333\n",
      "Epoch 73/88\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.9338 - accuracy: 0.6330 - val_loss: 1.2450 - val_accuracy: 0.5067\n",
      "Epoch 74/88\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.7117 - accuracy: 0.6532 - val_loss: 1.0987 - val_accuracy: 0.4800\n",
      "Epoch 75/88\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.7836 - accuracy: 0.6263 - val_loss: 0.9199 - val_accuracy: 0.4933\n",
      "Epoch 76/88\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.8354 - accuracy: 0.6195 - val_loss: 0.9963 - val_accuracy: 0.5333\n",
      "Epoch 77/88\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.8349 - accuracy: 0.6633 - val_loss: 1.3065 - val_accuracy: 0.5600\n",
      "Epoch 78/88\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.8722 - accuracy: 0.6599 - val_loss: 1.6654 - val_accuracy: 0.5200\n",
      "Epoch 79/88\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.8463 - accuracy: 0.6801 - val_loss: 1.7646 - val_accuracy: 0.5200\n",
      "Epoch 80/88\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.6334 - accuracy: 0.7104 - val_loss: 1.8636 - val_accuracy: 0.5733\n",
      "Epoch 81/88\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.6525 - accuracy: 0.7003 - val_loss: 1.7471 - val_accuracy: 0.5733\n",
      "Epoch 82/88\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.6675 - accuracy: 0.7003 - val_loss: 1.5345 - val_accuracy: 0.5333\n",
      "Epoch 83/88\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.6470 - accuracy: 0.6902 - val_loss: 1.4776 - val_accuracy: 0.5333\n",
      "Epoch 84/88\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.6443 - accuracy: 0.6970 - val_loss: 1.4832 - val_accuracy: 0.5600\n",
      "Epoch 85/88\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.5980 - accuracy: 0.7071 - val_loss: 1.5697 - val_accuracy: 0.5600\n",
      "Epoch 86/88\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.6248 - accuracy: 0.7205 - val_loss: 1.7091 - val_accuracy: 0.5733\n",
      "Epoch 87/88\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.5969 - accuracy: 0.7205 - val_loss: 1.7617 - val_accuracy: 0.5733\n",
      "Epoch 88/88\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.6101 - accuracy: 0.7037 - val_loss: 1.6735 - val_accuracy: 0.5600\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "| \u001b[95m15       \u001b[0m | \u001b[95m0.6237   \u001b[0m | \u001b[95m0.2458   \u001b[0m | \u001b[95m85.69    \u001b[0m | \u001b[95m88.09    \u001b[0m | \u001b[95m0.05686  \u001b[0m | \u001b[95m2.085    \u001b[0m |\n",
      "Epoch 1/77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/rmsprop.py:140: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adagrad.py:81: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 1s 11ms/step - loss: 32.4112 - accuracy: 0.3737 - val_loss: 38.4812 - val_accuracy: 0.5867\n",
      "Epoch 2/77\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 32.9235 - accuracy: 0.3973 - val_loss: 18.4856 - val_accuracy: 0.5867\n",
      "Epoch 3/77\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 33.0124 - accuracy: 0.3603 - val_loss: 34.5781 - val_accuracy: 0.5867\n",
      "Epoch 4/77\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 31.4360 - accuracy: 0.4108 - val_loss: 13.3688 - val_accuracy: 0.5867\n",
      "Epoch 5/77\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 24.6348 - accuracy: 0.4545 - val_loss: 34.5025 - val_accuracy: 0.2400\n",
      "Epoch 6/77\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 29.1827 - accuracy: 0.3906 - val_loss: 11.4070 - val_accuracy: 0.2400\n",
      "Epoch 7/77\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 26.4076 - accuracy: 0.3939 - val_loss: 11.0307 - val_accuracy: 0.1600\n",
      "Epoch 8/77\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 39.6300 - accuracy: 0.3131 - val_loss: 10.5381 - val_accuracy: 0.1600\n",
      "Epoch 9/77\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 28.5395 - accuracy: 0.4007 - val_loss: 25.9174 - val_accuracy: 0.5867\n",
      "Epoch 10/77\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 32.4695 - accuracy: 0.3468 - val_loss: 16.5137 - val_accuracy: 0.5867\n",
      "Epoch 11/77\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 32.2638 - accuracy: 0.3468 - val_loss: 36.3269 - val_accuracy: 0.5867\n",
      "Epoch 12/77\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 25.9603 - accuracy: 0.4310 - val_loss: 32.0462 - val_accuracy: 0.1600\n",
      "Epoch 13/77\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 32.4977 - accuracy: 0.3805 - val_loss: 32.9623 - val_accuracy: 0.5867\n",
      "Epoch 14/77\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 32.1660 - accuracy: 0.3636 - val_loss: 10.3917 - val_accuracy: 0.5867\n",
      "Epoch 15/77\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 30.6574 - accuracy: 0.3771 - val_loss: 47.6532 - val_accuracy: 0.1600\n",
      "Epoch 16/77\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 30.3456 - accuracy: 0.4276 - val_loss: 57.0193 - val_accuracy: 0.1600\n",
      "Epoch 17/77\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 31.2960 - accuracy: 0.4040 - val_loss: 30.5464 - val_accuracy: 0.2400\n",
      "Epoch 18/77\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 30.9520 - accuracy: 0.3670 - val_loss: 20.7622 - val_accuracy: 0.5867\n",
      "Epoch 19/77\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 28.6584 - accuracy: 0.3737 - val_loss: 64.8216 - val_accuracy: 0.2400\n",
      "Epoch 20/77\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 29.0731 - accuracy: 0.3805 - val_loss: 12.8263 - val_accuracy: 0.2400\n",
      "Epoch 21/77\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 30.8857 - accuracy: 0.3603 - val_loss: 27.5796 - val_accuracy: 0.2400\n",
      "Epoch 22/77\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 29.6997 - accuracy: 0.3771 - val_loss: 17.0604 - val_accuracy: 0.5867\n",
      "Epoch 23/77\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 31.9999 - accuracy: 0.3535 - val_loss: 26.6815 - val_accuracy: 0.1600\n",
      "Epoch 24/77\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 32.9515 - accuracy: 0.3704 - val_loss: 13.6152 - val_accuracy: 0.5867\n",
      "Epoch 25/77\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 34.7020 - accuracy: 0.3535 - val_loss: 3.4754 - val_accuracy: 0.1600\n",
      "Epoch 26/77\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 36.9242 - accuracy: 0.3535 - val_loss: 46.0394 - val_accuracy: 0.1600\n",
      "Epoch 27/77\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 35.1752 - accuracy: 0.3737 - val_loss: 17.2415 - val_accuracy: 0.2400\n",
      "Epoch 28/77\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 24.0625 - accuracy: 0.4209 - val_loss: 20.7442 - val_accuracy: 0.5867\n",
      "Epoch 29/77\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 31.0524 - accuracy: 0.3704 - val_loss: 32.5340 - val_accuracy: 0.5867\n",
      "Epoch 30/77\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 32.9905 - accuracy: 0.4108 - val_loss: 27.7858 - val_accuracy: 0.5867\n",
      "Epoch 31/77\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 30.1214 - accuracy: 0.3872 - val_loss: 6.4536 - val_accuracy: 0.5867\n",
      "Epoch 32/77\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 24.1433 - accuracy: 0.4108 - val_loss: 15.4677 - val_accuracy: 0.5867\n",
      "Epoch 33/77\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 30.5539 - accuracy: 0.3973 - val_loss: 44.9163 - val_accuracy: 0.2400\n",
      "Epoch 34/77\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 30.8739 - accuracy: 0.3401 - val_loss: 19.7303 - val_accuracy: 0.5867\n",
      "Epoch 35/77\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 32.3960 - accuracy: 0.3569 - val_loss: 28.2928 - val_accuracy: 0.2400\n",
      "Epoch 36/77\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 30.2863 - accuracy: 0.3401 - val_loss: 14.8600 - val_accuracy: 0.2400\n",
      "Epoch 37/77\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 28.3143 - accuracy: 0.3838 - val_loss: 16.4665 - val_accuracy: 0.5867\n",
      "Epoch 38/77\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 32.9508 - accuracy: 0.3535 - val_loss: 22.1916 - val_accuracy: 0.5867\n",
      "Epoch 39/77\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 33.5147 - accuracy: 0.3569 - val_loss: 15.8288 - val_accuracy: 0.1600\n",
      "Epoch 40/77\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 20.9924 - accuracy: 0.4444 - val_loss: 30.0009 - val_accuracy: 0.5867\n",
      "Epoch 41/77\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 28.8071 - accuracy: 0.3939 - val_loss: 24.1375 - val_accuracy: 0.2400\n",
      "Epoch 42/77\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 33.4660 - accuracy: 0.3535 - val_loss: 26.2656 - val_accuracy: 0.5867\n",
      "Epoch 43/77\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 27.9712 - accuracy: 0.3737 - val_loss: 18.9733 - val_accuracy: 0.5867\n",
      "Epoch 44/77\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 25.7517 - accuracy: 0.3771 - val_loss: 43.6940 - val_accuracy: 0.5867\n",
      "Epoch 45/77\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 24.0234 - accuracy: 0.4343 - val_loss: 6.6446 - val_accuracy: 0.5867\n",
      "Epoch 46/77\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 27.0174 - accuracy: 0.4175 - val_loss: 17.6026 - val_accuracy: 0.2400\n",
      "Epoch 47/77\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 27.5075 - accuracy: 0.3670 - val_loss: 50.4231 - val_accuracy: 0.2400\n",
      "Epoch 48/77\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 32.3705 - accuracy: 0.3737 - val_loss: 10.6411 - val_accuracy: 0.5867\n",
      "Epoch 49/77\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 30.4805 - accuracy: 0.3535 - val_loss: 41.2392 - val_accuracy: 0.5867\n",
      "Epoch 50/77\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 30.2901 - accuracy: 0.3872 - val_loss: 19.8996 - val_accuracy: 0.2400\n",
      "Epoch 51/77\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 31.7621 - accuracy: 0.3872 - val_loss: 13.4069 - val_accuracy: 0.5867\n",
      "Epoch 52/77\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 31.7053 - accuracy: 0.3367 - val_loss: 14.7423 - val_accuracy: 0.2400\n",
      "Epoch 53/77\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 23.7151 - accuracy: 0.4444 - val_loss: 15.9245 - val_accuracy: 0.5867\n",
      "Epoch 54/77\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 26.5444 - accuracy: 0.4310 - val_loss: 18.7310 - val_accuracy: 0.5867\n",
      "Epoch 55/77\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 29.0997 - accuracy: 0.4175 - val_loss: 21.2368 - val_accuracy: 0.1600\n",
      "Epoch 56/77\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 37.4288 - accuracy: 0.3569 - val_loss: 31.4850 - val_accuracy: 0.1600\n",
      "Epoch 57/77\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 36.7252 - accuracy: 0.3502 - val_loss: 15.2710 - val_accuracy: 0.5867\n",
      "Epoch 58/77\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 24.2273 - accuracy: 0.4108 - val_loss: 24.5169 - val_accuracy: 0.5867\n",
      "Epoch 59/77\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 34.1132 - accuracy: 0.3434 - val_loss: 25.4497 - val_accuracy: 0.5867\n",
      "Epoch 60/77\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 36.4820 - accuracy: 0.3670 - val_loss: 9.4538 - val_accuracy: 0.5867\n",
      "Epoch 61/77\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 28.4480 - accuracy: 0.3670 - val_loss: 17.6482 - val_accuracy: 0.2400\n",
      "Epoch 62/77\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 33.3939 - accuracy: 0.3737 - val_loss: 42.0396 - val_accuracy: 0.2400\n",
      "Epoch 63/77\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 30.9434 - accuracy: 0.3939 - val_loss: 38.7694 - val_accuracy: 0.5867\n",
      "Epoch 64/77\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 28.4529 - accuracy: 0.3805 - val_loss: 11.2373 - val_accuracy: 0.2400\n",
      "Epoch 65/77\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 35.2484 - accuracy: 0.3771 - val_loss: 19.5595 - val_accuracy: 0.2400\n",
      "Epoch 66/77\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 29.3796 - accuracy: 0.4141 - val_loss: 39.6363 - val_accuracy: 0.5867\n",
      "Epoch 67/77\n",
      "25/25 [==============================] - 0s 13ms/step - loss: 25.7021 - accuracy: 0.4209 - val_loss: 25.3635 - val_accuracy: 0.2400\n",
      "Epoch 68/77\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 33.5865 - accuracy: 0.3771 - val_loss: 42.1257 - val_accuracy: 0.5867\n",
      "Epoch 69/77\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 28.4516 - accuracy: 0.4175 - val_loss: 37.6979 - val_accuracy: 0.5867\n",
      "Epoch 70/77\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 28.2199 - accuracy: 0.3805 - val_loss: 26.9026 - val_accuracy: 0.2400\n",
      "Epoch 71/77\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 30.3582 - accuracy: 0.3771 - val_loss: 71.6263 - val_accuracy: 0.1600\n",
      "Epoch 72/77\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 40.9850 - accuracy: 0.3434 - val_loss: 17.4823 - val_accuracy: 0.5867\n",
      "Epoch 73/77\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 27.2446 - accuracy: 0.4209 - val_loss: 31.5167 - val_accuracy: 0.2400\n",
      "Epoch 74/77\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 29.1963 - accuracy: 0.4108 - val_loss: 28.2320 - val_accuracy: 0.5867\n",
      "Epoch 75/77\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 31.1183 - accuracy: 0.3401 - val_loss: 3.3451 - val_accuracy: 0.5867\n",
      "Epoch 76/77\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 29.0481 - accuracy: 0.4074 - val_loss: 32.4841 - val_accuracy: 0.2400\n",
      "Epoch 77/77\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 27.1785 - accuracy: 0.4377 - val_loss: 22.5828 - val_accuracy: 0.1600\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "| \u001b[0m16       \u001b[0m | \u001b[0m0.2043   \u001b[0m | \u001b[0m1.535    \u001b[0m | \u001b[0m12.37    \u001b[0m | \u001b[0m76.58    \u001b[0m | \u001b[0m0.9151   \u001b[0m | \u001b[0m0.01716  \u001b[0m |\n",
      "Epoch 1/81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/rmsprop.py:140: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adagrad.py:81: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 2s 845ms/step - loss: 32365710.0000 - accuracy: 0.1380 - val_loss: 23212956.0000 - val_accuracy: 0.2400\n",
      "Epoch 2/81\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 136052784.0000 - accuracy: 0.2660 - val_loss: 9147841.0000 - val_accuracy: 0.5867\n",
      "Epoch 3/81\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 11194239.0000 - accuracy: 0.3973 - val_loss: 1114546.6250 - val_accuracy: 0.5867\n",
      "Epoch 4/81\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 729445.5000 - accuracy: 0.4815 - val_loss: 15908.7812 - val_accuracy: 0.5867\n",
      "Epoch 5/81\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 23888.0547 - accuracy: 0.4747 - val_loss: 9411.5732 - val_accuracy: 0.5867\n",
      "Epoch 6/81\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 23598.6758 - accuracy: 0.4545 - val_loss: 6975.8149 - val_accuracy: 0.5867\n",
      "Epoch 7/81\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 13725.0117 - accuracy: 0.4310 - val_loss: 6051.6348 - val_accuracy: 0.5867\n",
      "Epoch 8/81\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 5199.6665 - accuracy: 0.4175 - val_loss: 5076.0894 - val_accuracy: 0.5867\n",
      "Epoch 9/81\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1975.5751 - accuracy: 0.3939 - val_loss: 4831.4458 - val_accuracy: 0.5867\n",
      "Epoch 10/81\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 1264.6307 - accuracy: 0.3838 - val_loss: 4282.1431 - val_accuracy: 0.5867\n",
      "Epoch 11/81\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 2751.0669 - accuracy: 0.4613 - val_loss: 3333.4846 - val_accuracy: 0.5867\n",
      "Epoch 12/81\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 2402.5522 - accuracy: 0.3737 - val_loss: 3036.6382 - val_accuracy: 0.2133\n",
      "Epoch 13/81\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 80668.5703 - accuracy: 0.3737 - val_loss: 3119.3103 - val_accuracy: 0.5867\n",
      "Epoch 14/81\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 528.9658 - accuracy: 0.4175 - val_loss: 3065.2019 - val_accuracy: 0.5867\n",
      "Epoch 15/81\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 913.5299 - accuracy: 0.4007 - val_loss: 2871.3679 - val_accuracy: 0.5867\n",
      "Epoch 16/81\n",
      "2/2 [==============================] - 0s 141ms/step - loss: 481.4265 - accuracy: 0.4040 - val_loss: 2938.5481 - val_accuracy: 0.5867\n",
      "Epoch 17/81\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 690.7339 - accuracy: 0.3939 - val_loss: 2715.8008 - val_accuracy: 0.5867\n",
      "Epoch 18/81\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 457.7949 - accuracy: 0.3603 - val_loss: 2572.6599 - val_accuracy: 0.5867\n",
      "Epoch 19/81\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 389.0228 - accuracy: 0.3838 - val_loss: 2535.3262 - val_accuracy: 0.2000\n",
      "Epoch 20/81\n",
      "2/2 [==============================] - 0s 155ms/step - loss: 584.4044 - accuracy: 0.2795 - val_loss: 2103.8486 - val_accuracy: 0.1867\n",
      "Epoch 21/81\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 205.5229 - accuracy: 0.3434 - val_loss: 2160.0061 - val_accuracy: 0.1867\n",
      "Epoch 22/81\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 214.9542 - accuracy: 0.2929 - val_loss: 1899.7117 - val_accuracy: 0.5867\n",
      "Epoch 23/81\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 180.5912 - accuracy: 0.3333 - val_loss: 1960.8096 - val_accuracy: 0.1867\n",
      "Epoch 24/81\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 154.9756 - accuracy: 0.2626 - val_loss: 1966.7152 - val_accuracy: 0.2800\n",
      "Epoch 25/81\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 151.8722 - accuracy: 0.3030 - val_loss: 2050.8379 - val_accuracy: 0.1867\n",
      "Epoch 26/81\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 181.2842 - accuracy: 0.2963 - val_loss: 1944.1183 - val_accuracy: 0.2800\n",
      "Epoch 27/81\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 127.7283 - accuracy: 0.3098 - val_loss: 1982.7863 - val_accuracy: 0.2800\n",
      "Epoch 28/81\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 120.5618 - accuracy: 0.2997 - val_loss: 2020.0702 - val_accuracy: 0.2800\n",
      "Epoch 29/81\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 164.5764 - accuracy: 0.2458 - val_loss: 1963.0961 - val_accuracy: 0.2800\n",
      "Epoch 30/81\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 129.3419 - accuracy: 0.2660 - val_loss: 1953.3223 - val_accuracy: 0.2800\n",
      "Epoch 31/81\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 110.9410 - accuracy: 0.3636 - val_loss: 1968.3577 - val_accuracy: 0.2800\n",
      "Epoch 32/81\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 114.4228 - accuracy: 0.3535 - val_loss: 2007.6952 - val_accuracy: 0.2800\n",
      "Epoch 33/81\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 144.8071 - accuracy: 0.2795 - val_loss: 1976.6415 - val_accuracy: 0.2800\n",
      "Epoch 34/81\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 131.4055 - accuracy: 0.2929 - val_loss: 2132.6553 - val_accuracy: 0.5867\n",
      "Epoch 35/81\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 203.4230 - accuracy: 0.4108 - val_loss: 2043.8505 - val_accuracy: 0.2800\n",
      "Epoch 36/81\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 145.2014 - accuracy: 0.3199 - val_loss: 1964.2277 - val_accuracy: 0.5867\n",
      "Epoch 37/81\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 107.2342 - accuracy: 0.2795 - val_loss: 1964.1277 - val_accuracy: 0.1867\n",
      "Epoch 38/81\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 113.9090 - accuracy: 0.2929 - val_loss: 1774.1978 - val_accuracy: 0.2400\n",
      "Epoch 39/81\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 111.5385 - accuracy: 0.3333 - val_loss: 1710.5642 - val_accuracy: 0.2400\n",
      "Epoch 40/81\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 115.2901 - accuracy: 0.2997 - val_loss: 1780.1719 - val_accuracy: 0.1467\n",
      "Epoch 41/81\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 165.6040 - accuracy: 0.2593 - val_loss: 1694.6096 - val_accuracy: 0.2400\n",
      "Epoch 42/81\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 95.8502 - accuracy: 0.3434 - val_loss: 1705.0757 - val_accuracy: 0.2400\n",
      "Epoch 43/81\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 109.6080 - accuracy: 0.2761 - val_loss: 1679.7988 - val_accuracy: 0.5867\n",
      "Epoch 44/81\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 102.9376 - accuracy: 0.3401 - val_loss: 1684.3540 - val_accuracy: 0.2400\n",
      "Epoch 45/81\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 99.5452 - accuracy: 0.3199 - val_loss: 1788.1516 - val_accuracy: 0.5867\n",
      "Epoch 46/81\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 142.3383 - accuracy: 0.2795 - val_loss: 1688.4585 - val_accuracy: 0.2400\n",
      "Epoch 47/81\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 90.2984 - accuracy: 0.3064 - val_loss: 1735.1945 - val_accuracy: 0.2400\n",
      "Epoch 48/81\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 90.3605 - accuracy: 0.2761 - val_loss: 1704.6566 - val_accuracy: 0.2400\n",
      "Epoch 49/81\n",
      "2/2 [==============================] - 0s 124ms/step - loss: 73.0928 - accuracy: 0.3670 - val_loss: 1720.0101 - val_accuracy: 0.2400\n",
      "Epoch 50/81\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 105.2228 - accuracy: 0.3098 - val_loss: 1721.0951 - val_accuracy: 0.2400\n",
      "Epoch 51/81\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 87.1125 - accuracy: 0.3569 - val_loss: 1711.1466 - val_accuracy: 0.2400\n",
      "Epoch 52/81\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 88.5784 - accuracy: 0.3502 - val_loss: 1738.6584 - val_accuracy: 0.2400\n",
      "Epoch 53/81\n",
      "2/2 [==============================] - 0s 122ms/step - loss: 102.9541 - accuracy: 0.3030 - val_loss: 1714.6122 - val_accuracy: 0.2400\n",
      "Epoch 54/81\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 92.7825 - accuracy: 0.3232 - val_loss: 1692.0841 - val_accuracy: 0.2400\n",
      "Epoch 55/81\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 108.5449 - accuracy: 0.2896 - val_loss: 1731.2603 - val_accuracy: 0.2400\n",
      "Epoch 56/81\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 129.4100 - accuracy: 0.3603 - val_loss: 1747.8929 - val_accuracy: 0.2400\n",
      "Epoch 57/81\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 108.2253 - accuracy: 0.2525 - val_loss: 1664.9376 - val_accuracy: 0.5867\n",
      "Epoch 58/81\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 91.2901 - accuracy: 0.3030 - val_loss: 1702.3143 - val_accuracy: 0.2400\n",
      "Epoch 59/81\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 94.0998 - accuracy: 0.3603 - val_loss: 1748.1544 - val_accuracy: 0.2400\n",
      "Epoch 60/81\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 116.5222 - accuracy: 0.2862 - val_loss: 1713.6630 - val_accuracy: 0.2400\n",
      "Epoch 61/81\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 113.7172 - accuracy: 0.2559 - val_loss: 1697.6700 - val_accuracy: 0.1467\n",
      "Epoch 62/81\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 130.2753 - accuracy: 0.3165 - val_loss: 1705.6300 - val_accuracy: 0.2400\n",
      "Epoch 63/81\n",
      "2/2 [==============================] - 0s 122ms/step - loss: 91.9979 - accuracy: 0.3232 - val_loss: 1690.5319 - val_accuracy: 0.2400\n",
      "Epoch 64/81\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 80.3667 - accuracy: 0.3165 - val_loss: 1686.6715 - val_accuracy: 0.2400\n",
      "Epoch 65/81\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 69.3302 - accuracy: 0.3098 - val_loss: 1665.7709 - val_accuracy: 0.2400\n",
      "Epoch 66/81\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 78.8679 - accuracy: 0.3535 - val_loss: 1667.9568 - val_accuracy: 0.2400\n",
      "Epoch 67/81\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 87.1840 - accuracy: 0.2862 - val_loss: 1692.5532 - val_accuracy: 0.5867\n",
      "Epoch 68/81\n",
      "2/2 [==============================] - 0s 174ms/step - loss: 106.4993 - accuracy: 0.3300 - val_loss: 1699.3453 - val_accuracy: 0.1467\n",
      "Epoch 69/81\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 137.1883 - accuracy: 0.2997 - val_loss: 1756.3888 - val_accuracy: 0.2400\n",
      "Epoch 70/81\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 102.2441 - accuracy: 0.3266 - val_loss: 1726.2252 - val_accuracy: 0.2400\n",
      "Epoch 71/81\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 104.2287 - accuracy: 0.2862 - val_loss: 1075.3701 - val_accuracy: 0.5867\n",
      "Epoch 72/81\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 47299.4023 - accuracy: 0.4848 - val_loss: 36914.8672 - val_accuracy: 0.1867\n",
      "Epoch 73/81\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 12022.9160 - accuracy: 0.2828 - val_loss: 1500.5100 - val_accuracy: 0.5867\n",
      "Epoch 74/81\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 1152.8044 - accuracy: 0.4646 - val_loss: 204.2529 - val_accuracy: 0.1600\n",
      "Epoch 75/81\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 174.7991 - accuracy: 0.2626 - val_loss: 30.5170 - val_accuracy: 0.2400\n",
      "Epoch 76/81\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 89.6378 - accuracy: 0.2761 - val_loss: 40.4679 - val_accuracy: 0.2400\n",
      "Epoch 77/81\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 89.1344 - accuracy: 0.1818 - val_loss: 26.5117 - val_accuracy: 0.2400\n",
      "Epoch 78/81\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 2305.7795 - accuracy: 0.1818 - val_loss: 787.2237 - val_accuracy: 0.2400\n",
      "Epoch 79/81\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 614.2457 - accuracy: 0.3266 - val_loss: 53.0585 - val_accuracy: 0.1600\n",
      "Epoch 80/81\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 88.3051 - accuracy: 0.1919 - val_loss: 37.1350 - val_accuracy: 0.2400\n",
      "Epoch 81/81\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 68.8545 - accuracy: 0.2862 - val_loss: 36.4969 - val_accuracy: 0.2400\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "| \u001b[0m17       \u001b[0m | \u001b[0m0.2043   \u001b[0m | \u001b[0m0.7013   \u001b[0m | \u001b[0m148.9    \u001b[0m | \u001b[0m80.99    \u001b[0m | \u001b[0m0.7627   \u001b[0m | \u001b[0m1.427    \u001b[0m |\n",
      "Epoch 1/58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/rmsprop.py:140: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adagrad.py:81: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 36s 9s/step - loss: 1307.6616 - accuracy: 0.3737 - val_loss: 129663.0938 - val_accuracy: 0.2400\n",
      "Epoch 2/58\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 24740.8359 - accuracy: 0.4108 - val_loss: 159.0459 - val_accuracy: 0.1333\n",
      "Epoch 3/58\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 72.6877 - accuracy: 0.4108 - val_loss: 42.6168 - val_accuracy: 0.4000\n",
      "Epoch 4/58\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 46.7463 - accuracy: 0.3670 - val_loss: 30.9146 - val_accuracy: 0.5867\n",
      "Epoch 5/58\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 38.0901 - accuracy: 0.3805 - val_loss: 17.5011 - val_accuracy: 0.6000\n",
      "Epoch 6/58\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 31.2152 - accuracy: 0.3906 - val_loss: 16.3680 - val_accuracy: 0.5733\n",
      "Epoch 7/58\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 22.9859 - accuracy: 0.4141 - val_loss: 9.5091 - val_accuracy: 0.6133\n",
      "Epoch 8/58\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 18.6480 - accuracy: 0.4141 - val_loss: 9.2023 - val_accuracy: 0.5733\n",
      "Epoch 9/58\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 21.1770 - accuracy: 0.3973 - val_loss: 8.7163 - val_accuracy: 0.5867\n",
      "Epoch 10/58\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.7431 - accuracy: 0.3872 - val_loss: 7.8871 - val_accuracy: 0.6000\n",
      "Epoch 11/58\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 10.0559 - accuracy: 0.3973 - val_loss: 7.0530 - val_accuracy: 0.6000\n",
      "Epoch 12/58\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 10.5082 - accuracy: 0.3838 - val_loss: 3.8786 - val_accuracy: 0.5867\n",
      "Epoch 13/58\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.3314 - accuracy: 0.4074 - val_loss: 3.5653 - val_accuracy: 0.5467\n",
      "Epoch 14/58\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.8949 - accuracy: 0.4141 - val_loss: 4.3390 - val_accuracy: 0.5867\n",
      "Epoch 15/58\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 6.2004 - accuracy: 0.3872 - val_loss: 2.6854 - val_accuracy: 0.5600\n",
      "Epoch 16/58\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.3204 - accuracy: 0.4108 - val_loss: 3.3157 - val_accuracy: 0.5867\n",
      "Epoch 17/58\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.7601 - accuracy: 0.3838 - val_loss: 4.2910 - val_accuracy: 0.3067\n",
      "Epoch 18/58\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.0086 - accuracy: 0.3939 - val_loss: 5.4197 - val_accuracy: 0.6000\n",
      "Epoch 19/58\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.1510 - accuracy: 0.4613 - val_loss: 2.2397 - val_accuracy: 0.5067\n",
      "Epoch 20/58\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.5505 - accuracy: 0.4209 - val_loss: 3.4284 - val_accuracy: 0.5867\n",
      "Epoch 21/58\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.5955 - accuracy: 0.4074 - val_loss: 4.3073 - val_accuracy: 0.5733\n",
      "Epoch 22/58\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4.5824 - accuracy: 0.4377 - val_loss: 3.7641 - val_accuracy: 0.5733\n",
      "Epoch 23/58\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.6802 - accuracy: 0.4680 - val_loss: 2.8571 - val_accuracy: 0.5867\n",
      "Epoch 24/58\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.7041 - accuracy: 0.4343 - val_loss: 3.1797 - val_accuracy: 0.5733\n",
      "Epoch 25/58\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.6501 - accuracy: 0.4882 - val_loss: 3.5714 - val_accuracy: 0.5733\n",
      "Epoch 26/58\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.5777 - accuracy: 0.4007 - val_loss: 2.9768 - val_accuracy: 0.5600\n",
      "Epoch 27/58\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4.1230 - accuracy: 0.4377 - val_loss: 2.6862 - val_accuracy: 0.5867\n",
      "Epoch 28/58\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.6027 - accuracy: 0.4781 - val_loss: 2.5518 - val_accuracy: 0.5733\n",
      "Epoch 29/58\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.9808 - accuracy: 0.4512 - val_loss: 2.4176 - val_accuracy: 0.4933\n",
      "Epoch 30/58\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.1463 - accuracy: 0.4478 - val_loss: 4.0582 - val_accuracy: 0.6000\n",
      "Epoch 31/58\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.3420 - accuracy: 0.4377 - val_loss: 3.1062 - val_accuracy: 0.5733\n",
      "Epoch 32/58\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.9455 - accuracy: 0.4781 - val_loss: 1.8642 - val_accuracy: 0.5867\n",
      "Epoch 33/58\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.6971 - accuracy: 0.4478 - val_loss: 2.5263 - val_accuracy: 0.5733\n",
      "Epoch 34/58\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 3.5212 - accuracy: 0.4040 - val_loss: 2.6955 - val_accuracy: 0.5733\n",
      "Epoch 35/58\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.9477 - accuracy: 0.4310 - val_loss: 2.9154 - val_accuracy: 0.5867\n",
      "Epoch 36/58\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.2594 - accuracy: 0.4444 - val_loss: 2.8922 - val_accuracy: 0.5733\n",
      "Epoch 37/58\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3.2266 - accuracy: 0.4478 - val_loss: 2.7770 - val_accuracy: 0.5867\n",
      "Epoch 38/58\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.0485 - accuracy: 0.4209 - val_loss: 2.8328 - val_accuracy: 0.6000\n",
      "Epoch 39/58\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.5315 - accuracy: 0.4545 - val_loss: 2.7504 - val_accuracy: 0.6000\n",
      "Epoch 40/58\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 2.9488 - accuracy: 0.4545 - val_loss: 2.4106 - val_accuracy: 0.6000\n",
      "Epoch 41/58\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.3725 - accuracy: 0.4276 - val_loss: 2.3490 - val_accuracy: 0.5600\n",
      "Epoch 42/58\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.4003 - accuracy: 0.4545 - val_loss: 2.1712 - val_accuracy: 0.5733\n",
      "Epoch 43/58\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.1767 - accuracy: 0.4747 - val_loss: 1.8680 - val_accuracy: 0.5600\n",
      "Epoch 44/58\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.4241 - accuracy: 0.4242 - val_loss: 2.2596 - val_accuracy: 0.6000\n",
      "Epoch 45/58\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 2.9793 - accuracy: 0.4478 - val_loss: 2.3204 - val_accuracy: 0.5867\n",
      "Epoch 46/58\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 3.0543 - accuracy: 0.4242 - val_loss: 2.0300 - val_accuracy: 0.6267\n",
      "Epoch 47/58\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.0097 - accuracy: 0.4545 - val_loss: 2.6121 - val_accuracy: 0.6133\n",
      "Epoch 48/58\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.2393 - accuracy: 0.4411 - val_loss: 2.2625 - val_accuracy: 0.2933\n",
      "Epoch 49/58\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.1970 - accuracy: 0.4074 - val_loss: 2.3056 - val_accuracy: 0.6133\n",
      "Epoch 50/58\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.1251 - accuracy: 0.4040 - val_loss: 2.3256 - val_accuracy: 0.6133\n",
      "Epoch 51/58\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.6900 - accuracy: 0.4815 - val_loss: 2.0276 - val_accuracy: 0.5467\n",
      "Epoch 52/58\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.4802 - accuracy: 0.4613 - val_loss: 1.8938 - val_accuracy: 0.5467\n",
      "Epoch 53/58\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.0262 - accuracy: 0.4209 - val_loss: 1.9174 - val_accuracy: 0.5867\n",
      "Epoch 54/58\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 2.4263 - accuracy: 0.4815 - val_loss: 2.1587 - val_accuracy: 0.6267\n",
      "Epoch 55/58\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2.4409 - accuracy: 0.4545 - val_loss: 1.6751 - val_accuracy: 0.5733\n",
      "Epoch 56/58\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.3532 - accuracy: 0.4714 - val_loss: 2.0490 - val_accuracy: 0.6000\n",
      "Epoch 57/58\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 3.0610 - accuracy: 0.4141 - val_loss: 2.3409 - val_accuracy: 0.6000\n",
      "Epoch 58/58\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.2347 - accuracy: 0.4209 - val_loss: 2.8234 - val_accuracy: 0.6000\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "| \u001b[0m18       \u001b[0m | \u001b[0m0.4194   \u001b[0m | \u001b[0m1.101    \u001b[0m | \u001b[0m59.9     \u001b[0m | \u001b[0m58.08    \u001b[0m | \u001b[0m0.2457   \u001b[0m | \u001b[0m2.579    \u001b[0m |\n",
      "Epoch 1/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/rmsprop.py:140: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adagrad.py:81: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 29ms/step - loss: 2.3268 - accuracy: 0.3973 - val_loss: 2.3895 - val_accuracy: 0.5867\n",
      "Epoch 2/32\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 2.3682 - accuracy: 0.3872 - val_loss: 2.0487 - val_accuracy: 0.5867\n",
      "Epoch 3/32\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.7298 - accuracy: 0.4646 - val_loss: 2.4076 - val_accuracy: 0.2400\n",
      "Epoch 4/32\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.7773 - accuracy: 0.4141 - val_loss: 4.3263 - val_accuracy: 0.1600\n",
      "Epoch 5/32\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 2.7023 - accuracy: 0.3704 - val_loss: 1.7788 - val_accuracy: 0.2400\n",
      "Epoch 6/32\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.3451 - accuracy: 0.4983 - val_loss: 1.5888 - val_accuracy: 0.5867\n",
      "Epoch 7/32\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.2463 - accuracy: 0.4512 - val_loss: 4.2351 - val_accuracy: 0.1600\n",
      "Epoch 8/32\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 2.1864 - accuracy: 0.3872 - val_loss: 1.3026 - val_accuracy: 0.6667\n",
      "Epoch 9/32\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.4360 - accuracy: 0.4512 - val_loss: 1.7258 - val_accuracy: 0.2533\n",
      "Epoch 10/32\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.1019 - accuracy: 0.4781 - val_loss: 1.2026 - val_accuracy: 0.5200\n",
      "Epoch 11/32\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.2143 - accuracy: 0.4916 - val_loss: 1.2887 - val_accuracy: 0.5867\n",
      "Epoch 12/32\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.8011 - accuracy: 0.7340 - val_loss: 1.0399 - val_accuracy: 0.6000\n",
      "Epoch 13/32\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.1372 - accuracy: 0.5152 - val_loss: 2.1975 - val_accuracy: 0.1867\n",
      "Epoch 14/32\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.8428 - accuracy: 0.6869 - val_loss: 0.7457 - val_accuracy: 0.7200\n",
      "Epoch 15/32\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.3277 - accuracy: 0.9024 - val_loss: 0.7283 - val_accuracy: 0.7733\n",
      "Epoch 16/32\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.1909 - accuracy: 0.9461 - val_loss: 0.7665 - val_accuracy: 0.7733\n",
      "Epoch 17/32\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.1308 - accuracy: 0.9798 - val_loss: 0.6718 - val_accuracy: 0.7867\n",
      "Epoch 18/32\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.1090 - accuracy: 0.9798 - val_loss: 0.8617 - val_accuracy: 0.7600\n",
      "Epoch 19/32\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.1276 - accuracy: 0.9663 - val_loss: 0.6554 - val_accuracy: 0.7733\n",
      "Epoch 20/32\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0927 - accuracy: 0.9865 - val_loss: 0.6390 - val_accuracy: 0.7200\n",
      "Epoch 21/32\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1000 - accuracy: 0.9865 - val_loss: 0.6590 - val_accuracy: 0.7600\n",
      "Epoch 22/32\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0769 - accuracy: 0.9899 - val_loss: 0.6808 - val_accuracy: 0.7600\n",
      "Epoch 23/32\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0655 - accuracy: 0.9933 - val_loss: 0.6676 - val_accuracy: 0.7733\n",
      "Epoch 24/32\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0591 - accuracy: 0.9899 - val_loss: 0.6872 - val_accuracy: 0.7733\n",
      "Epoch 25/32\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0363 - accuracy: 0.9933 - val_loss: 0.9577 - val_accuracy: 0.7600\n",
      "Epoch 26/32\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0630 - accuracy: 0.9899 - val_loss: 0.7994 - val_accuracy: 0.8000\n",
      "Epoch 27/32\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0338 - accuracy: 0.9933 - val_loss: 0.7736 - val_accuracy: 0.7733\n",
      "Epoch 28/32\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0508 - accuracy: 0.9899 - val_loss: 3.8527 - val_accuracy: 0.2667\n",
      "Epoch 29/32\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 3.2782 - accuracy: 0.3838 - val_loss: 4.2407 - val_accuracy: 0.5867\n",
      "Epoch 30/32\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 4.0609 - accuracy: 0.4074 - val_loss: 1.3428 - val_accuracy: 0.4800\n",
      "Epoch 31/32\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.1441 - accuracy: 0.4141 - val_loss: 2.1971 - val_accuracy: 0.5867\n",
      "Epoch 32/32\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.8708 - accuracy: 0.4512 - val_loss: 1.9692 - val_accuracy: 0.1733\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "| \u001b[0m19       \u001b[0m | \u001b[0m0.172    \u001b[0m | \u001b[0m1.729    \u001b[0m | \u001b[0m41.53    \u001b[0m | \u001b[0m31.58    \u001b[0m | \u001b[0m0.1809   \u001b[0m | \u001b[0m0.002741 \u001b[0m |\n",
      "Epoch 1/21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/rmsprop.py:140: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adagrad.py:81: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 105ms/step - loss: 9.6141 - accuracy: 0.4074 - val_loss: 117.7171 - val_accuracy: 0.2400\n",
      "Epoch 2/21\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 85.1647 - accuracy: 0.3300 - val_loss: 7.4883 - val_accuracy: 0.1467\n",
      "Epoch 3/21\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 29.9831 - accuracy: 0.3906 - val_loss: 26.3682 - val_accuracy: 0.5867\n",
      "Epoch 4/21\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 31.9685 - accuracy: 0.3670 - val_loss: 44.1205 - val_accuracy: 0.5867\n",
      "Epoch 5/21\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 28.8584 - accuracy: 0.4343 - val_loss: 18.4686 - val_accuracy: 0.2400\n",
      "Epoch 6/21\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 27.4790 - accuracy: 0.3906 - val_loss: 21.9809 - val_accuracy: 0.5867\n",
      "Epoch 7/21\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 33.9435 - accuracy: 0.4444 - val_loss: 10.9064 - val_accuracy: 0.1600\n",
      "Epoch 8/21\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 22.8265 - accuracy: 0.3030 - val_loss: 29.2978 - val_accuracy: 0.5867\n",
      "Epoch 9/21\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 35.8508 - accuracy: 0.3906 - val_loss: 49.4759 - val_accuracy: 0.2400\n",
      "Epoch 10/21\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 34.9053 - accuracy: 0.4343 - val_loss: 17.6143 - val_accuracy: 0.5867\n",
      "Epoch 11/21\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 23.2796 - accuracy: 0.3670 - val_loss: 47.4923 - val_accuracy: 0.2400\n",
      "Epoch 12/21\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 38.9301 - accuracy: 0.3300 - val_loss: 29.5604 - val_accuracy: 0.5867\n",
      "Epoch 13/21\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 19.9791 - accuracy: 0.4310 - val_loss: 34.6974 - val_accuracy: 0.2400\n",
      "Epoch 14/21\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 30.7850 - accuracy: 0.3670 - val_loss: 25.8630 - val_accuracy: 0.2400\n",
      "Epoch 15/21\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 22.7355 - accuracy: 0.3603 - val_loss: 27.0137 - val_accuracy: 0.5867\n",
      "Epoch 16/21\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 38.0879 - accuracy: 0.4209 - val_loss: 2.0254 - val_accuracy: 0.5867\n",
      "Epoch 17/21\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 11.6140 - accuracy: 0.3670 - val_loss: 27.7741 - val_accuracy: 0.5867\n",
      "Epoch 18/21\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 27.3160 - accuracy: 0.4377 - val_loss: 35.4919 - val_accuracy: 0.1600\n",
      "Epoch 19/21\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 37.2260 - accuracy: 0.3434 - val_loss: 33.6833 - val_accuracy: 0.5867\n",
      "Epoch 20/21\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 21.1877 - accuracy: 0.4411 - val_loss: 17.7674 - val_accuracy: 0.2400\n",
      "Epoch 21/21\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 25.9707 - accuracy: 0.4074 - val_loss: 25.1200 - val_accuracy: 0.5867\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "| \u001b[0m20       \u001b[0m | \u001b[0m0.2043   \u001b[0m | \u001b[0m2.463    \u001b[0m | \u001b[0m117.3    \u001b[0m | \u001b[0m21.16    \u001b[0m | \u001b[0m0.3449   \u001b[0m | \u001b[0m0.6785   \u001b[0m |\n",
      "Epoch 1/51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/rmsprop.py:140: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adagrad.py:81: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 96ms/step - loss: 28.5950 - accuracy: 0.2896 - val_loss: 91.3521 - val_accuracy: 0.5733\n",
      "Epoch 2/51\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 114.9455 - accuracy: 0.3401 - val_loss: 114.5916 - val_accuracy: 0.2400\n",
      "Epoch 3/51\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 125.9701 - accuracy: 0.4242 - val_loss: 38.9793 - val_accuracy: 0.1600\n",
      "Epoch 4/51\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 78.6342 - accuracy: 0.3367 - val_loss: 88.9898 - val_accuracy: 0.5867\n",
      "Epoch 5/51\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 77.2779 - accuracy: 0.4209 - val_loss: 39.7531 - val_accuracy: 0.2400\n",
      "Epoch 6/51\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 51.6835 - accuracy: 0.4545 - val_loss: 40.1316 - val_accuracy: 0.5867\n",
      "Epoch 7/51\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 50.7866 - accuracy: 0.3939 - val_loss: 20.8268 - val_accuracy: 0.5867\n",
      "Epoch 8/51\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 44.0786 - accuracy: 0.3805 - val_loss: 17.8925 - val_accuracy: 0.5867\n",
      "Epoch 9/51\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 41.1241 - accuracy: 0.3670 - val_loss: 67.7384 - val_accuracy: 0.1600\n",
      "Epoch 10/51\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 71.3322 - accuracy: 0.3468 - val_loss: 57.0610 - val_accuracy: 0.5867\n",
      "Epoch 11/51\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 56.7763 - accuracy: 0.4310 - val_loss: 20.4424 - val_accuracy: 0.5867\n",
      "Epoch 12/51\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 45.9424 - accuracy: 0.3434 - val_loss: 155.4623 - val_accuracy: 0.1600\n",
      "Epoch 13/51\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 96.6488 - accuracy: 0.3300 - val_loss: 44.1712 - val_accuracy: 0.2400\n",
      "Epoch 14/51\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 62.9694 - accuracy: 0.3805 - val_loss: 64.2318 - val_accuracy: 0.2400\n",
      "Epoch 15/51\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 80.4122 - accuracy: 0.4478 - val_loss: 39.5778 - val_accuracy: 0.2400\n",
      "Epoch 16/51\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 62.9515 - accuracy: 0.4108 - val_loss: 38.4851 - val_accuracy: 0.5867\n",
      "Epoch 17/51\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 63.5752 - accuracy: 0.4007 - val_loss: 6.3155 - val_accuracy: 0.5867\n",
      "Epoch 18/51\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 23.4461 - accuracy: 0.4074 - val_loss: 35.1052 - val_accuracy: 0.2400\n",
      "Epoch 19/51\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 58.8301 - accuracy: 0.4108 - val_loss: 41.1044 - val_accuracy: 0.2400\n",
      "Epoch 20/51\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 64.6832 - accuracy: 0.4512 - val_loss: 45.5560 - val_accuracy: 0.5867\n",
      "Epoch 21/51\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 57.2815 - accuracy: 0.3064 - val_loss: 69.3362 - val_accuracy: 0.2400\n",
      "Epoch 22/51\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 89.0266 - accuracy: 0.4310 - val_loss: 68.9571 - val_accuracy: 0.1600\n",
      "Epoch 23/51\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 61.1833 - accuracy: 0.3704 - val_loss: 83.7515 - val_accuracy: 0.5867\n",
      "Epoch 24/51\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 57.6563 - accuracy: 0.4444 - val_loss: 93.0293 - val_accuracy: 0.5867\n",
      "Epoch 25/51\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 68.0597 - accuracy: 0.4512 - val_loss: 43.3282 - val_accuracy: 0.5867\n",
      "Epoch 26/51\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 44.9735 - accuracy: 0.3670 - val_loss: 163.8931 - val_accuracy: 0.2400\n",
      "Epoch 27/51\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 103.2364 - accuracy: 0.3805 - val_loss: 34.3284 - val_accuracy: 0.5867\n",
      "Epoch 28/51\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 38.5537 - accuracy: 0.3603 - val_loss: 92.0251 - val_accuracy: 0.2400\n",
      "Epoch 29/51\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 74.3697 - accuracy: 0.3939 - val_loss: 61.1664 - val_accuracy: 0.2400\n",
      "Epoch 30/51\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 83.9098 - accuracy: 0.3872 - val_loss: 46.5065 - val_accuracy: 0.5867\n",
      "Epoch 31/51\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 48.6139 - accuracy: 0.4175 - val_loss: 71.7472 - val_accuracy: 0.2400\n",
      "Epoch 32/51\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 53.1173 - accuracy: 0.3838 - val_loss: 71.8277 - val_accuracy: 0.0133\n",
      "Epoch 33/51\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 55.2781 - accuracy: 0.2660 - val_loss: 49.4061 - val_accuracy: 0.1600\n",
      "Epoch 34/51\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 61.8143 - accuracy: 0.4478 - val_loss: 61.5012 - val_accuracy: 0.5867\n",
      "Epoch 35/51\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 67.3150 - accuracy: 0.4343 - val_loss: 61.1040 - val_accuracy: 0.2400\n",
      "Epoch 36/51\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 73.2796 - accuracy: 0.4276 - val_loss: 58.8293 - val_accuracy: 0.2400\n",
      "Epoch 37/51\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 68.5265 - accuracy: 0.3434 - val_loss: 80.6976 - val_accuracy: 0.5867\n",
      "Epoch 38/51\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 84.8066 - accuracy: 0.3939 - val_loss: 14.9932 - val_accuracy: 0.1600\n",
      "Epoch 39/51\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 31.5280 - accuracy: 0.3401 - val_loss: 82.1038 - val_accuracy: 0.1600\n",
      "Epoch 40/51\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 63.1142 - accuracy: 0.3535 - val_loss: 70.3838 - val_accuracy: 0.5867\n",
      "Epoch 41/51\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 49.5523 - accuracy: 0.4343 - val_loss: 69.5605 - val_accuracy: 0.5867\n",
      "Epoch 42/51\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 68.0456 - accuracy: 0.3535 - val_loss: 98.6624 - val_accuracy: 0.2400\n",
      "Epoch 43/51\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 81.3460 - accuracy: 0.3973 - val_loss: 22.6811 - val_accuracy: 0.1600\n",
      "Epoch 44/51\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 32.9038 - accuracy: 0.3266 - val_loss: 41.9954 - val_accuracy: 0.2400\n",
      "Epoch 45/51\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 43.2058 - accuracy: 0.4579 - val_loss: 84.0475 - val_accuracy: 0.5867\n",
      "Epoch 46/51\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 72.7805 - accuracy: 0.4478 - val_loss: 21.8742 - val_accuracy: 0.5867\n",
      "Epoch 47/51\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 42.3631 - accuracy: 0.3906 - val_loss: 124.3913 - val_accuracy: 0.1600\n",
      "Epoch 48/51\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 86.4093 - accuracy: 0.2290 - val_loss: 16.5998 - val_accuracy: 0.5867\n",
      "Epoch 49/51\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 22.2431 - accuracy: 0.4276 - val_loss: 68.9658 - val_accuracy: 0.2400\n",
      "Epoch 50/51\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 57.0857 - accuracy: 0.3872 - val_loss: 45.6511 - val_accuracy: 0.5867\n",
      "Epoch 51/51\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 42.5521 - accuracy: 0.3838 - val_loss: 44.4788 - val_accuracy: 0.5867\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "| \u001b[0m21       \u001b[0m | \u001b[0m0.2043   \u001b[0m | \u001b[0m2.386    \u001b[0m | \u001b[0m142.0    \u001b[0m | \u001b[0m51.39    \u001b[0m | \u001b[0m0.8044   \u001b[0m | \u001b[0m0.6645   \u001b[0m |\n",
      "Epoch 1/22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/rmsprop.py:140: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adagrad.py:81: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 99ms/step - loss: 12.8974 - accuracy: 0.2290 - val_loss: 60.8214 - val_accuracy: 0.0133\n",
      "Epoch 2/22\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 47.0913 - accuracy: 0.2862 - val_loss: 17.4568 - val_accuracy: 0.2800\n",
      "Epoch 3/22\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 21.0692 - accuracy: 0.3771 - val_loss: 8.9790 - val_accuracy: 0.1733\n",
      "Epoch 4/22\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 15.6521 - accuracy: 0.3199 - val_loss: 11.6849 - val_accuracy: 0.5200\n",
      "Epoch 5/22\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 14.6608 - accuracy: 0.4074 - val_loss: 6.8067 - val_accuracy: 0.4400\n",
      "Epoch 6/22\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 15.5209 - accuracy: 0.3535 - val_loss: 8.6878 - val_accuracy: 0.5733\n",
      "Epoch 7/22\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 14.0802 - accuracy: 0.3737 - val_loss: 11.7864 - val_accuracy: 0.5867\n",
      "Epoch 8/22\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 15.8759 - accuracy: 0.4512 - val_loss: 12.1066 - val_accuracy: 0.2400\n",
      "Epoch 9/22\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 14.8190 - accuracy: 0.3367 - val_loss: 9.8271 - val_accuracy: 0.5867\n",
      "Epoch 10/22\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 13.3652 - accuracy: 0.3805 - val_loss: 6.9063 - val_accuracy: 0.3867\n",
      "Epoch 11/22\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 14.6490 - accuracy: 0.4209 - val_loss: 10.5167 - val_accuracy: 0.2800\n",
      "Epoch 12/22\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 14.5684 - accuracy: 0.3401 - val_loss: 11.2789 - val_accuracy: 0.5867\n",
      "Epoch 13/22\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 15.6082 - accuracy: 0.4848 - val_loss: 10.4839 - val_accuracy: 0.5200\n",
      "Epoch 14/22\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 13.7788 - accuracy: 0.3636 - val_loss: 10.6992 - val_accuracy: 0.4267\n",
      "Epoch 15/22\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 11.4551 - accuracy: 0.4949 - val_loss: 7.4098 - val_accuracy: 0.5867\n",
      "Epoch 16/22\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 12.7497 - accuracy: 0.3569 - val_loss: 9.3313 - val_accuracy: 0.3600\n",
      "Epoch 17/22\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 12.3995 - accuracy: 0.4175 - val_loss: 9.7273 - val_accuracy: 0.5600\n",
      "Epoch 18/22\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 9.5509 - accuracy: 0.4815 - val_loss: 12.5822 - val_accuracy: 0.2267\n",
      "Epoch 19/22\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 11.3264 - accuracy: 0.3333 - val_loss: 6.4647 - val_accuracy: 0.4667\n",
      "Epoch 20/22\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 10.7214 - accuracy: 0.4141 - val_loss: 3.9488 - val_accuracy: 0.5867\n",
      "Epoch 21/22\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 8.3106 - accuracy: 0.3906 - val_loss: 3.1311 - val_accuracy: 0.5733\n",
      "Epoch 22/22\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 7.6479 - accuracy: 0.4276 - val_loss: 5.0631 - val_accuracy: 0.4267\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "| \u001b[0m22       \u001b[0m | \u001b[0m0.2151   \u001b[0m | \u001b[0m1.535    \u001b[0m | \u001b[0m130.1    \u001b[0m | \u001b[0m22.25    \u001b[0m | \u001b[0m0.7027   \u001b[0m | \u001b[0m2.238    \u001b[0m |\n",
      "Epoch 1/38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/rmsprop.py:140: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adagrad.py:81: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 102ms/step - loss: 1021000.0000 - accuracy: 0.1919 - val_loss: 181042.3594 - val_accuracy: 0.2400\n",
      "Epoch 2/38\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 464811.0312 - accuracy: 0.3906 - val_loss: 204329.6875 - val_accuracy: 0.2400\n",
      "Epoch 3/38\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 98808.0625 - accuracy: 0.3603 - val_loss: 3350.2708 - val_accuracy: 0.4133\n",
      "Epoch 4/38\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 3280.0942 - accuracy: 0.3872 - val_loss: 2632.0071 - val_accuracy: 0.3467\n",
      "Epoch 5/38\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 3812.7366 - accuracy: 0.3333 - val_loss: 2186.9519 - val_accuracy: 0.4000\n",
      "Epoch 6/38\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 2382.0881 - accuracy: 0.4444 - val_loss: 1310.2067 - val_accuracy: 0.5867\n",
      "Epoch 7/38\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 2911.2563 - accuracy: 0.4343 - val_loss: 1114.1289 - val_accuracy: 0.5867\n",
      "Epoch 8/38\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 3670.0176 - accuracy: 0.4411 - val_loss: 657.3596 - val_accuracy: 0.3067\n",
      "Epoch 9/38\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 1268.3678 - accuracy: 0.3333 - val_loss: 558.7426 - val_accuracy: 0.2400\n",
      "Epoch 10/38\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 1126.0634 - accuracy: 0.3131 - val_loss: 535.6227 - val_accuracy: 0.4000\n",
      "Epoch 11/38\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 815.1279 - accuracy: 0.3771 - val_loss: 668.6213 - val_accuracy: 0.3733\n",
      "Epoch 12/38\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 725.5311 - accuracy: 0.3064 - val_loss: 464.7694 - val_accuracy: 0.4800\n",
      "Epoch 13/38\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 617.1239 - accuracy: 0.3636 - val_loss: 374.4343 - val_accuracy: 0.6000\n",
      "Epoch 14/38\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 604.2505 - accuracy: 0.3535 - val_loss: 206.3284 - val_accuracy: 0.3467\n",
      "Epoch 15/38\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 419.8469 - accuracy: 0.3030 - val_loss: 259.6655 - val_accuracy: 0.3333\n",
      "Epoch 16/38\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 399.2868 - accuracy: 0.3165 - val_loss: 150.8951 - val_accuracy: 0.2267\n",
      "Epoch 17/38\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 324.6699 - accuracy: 0.2929 - val_loss: 126.9120 - val_accuracy: 0.4133\n",
      "Epoch 18/38\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 260.2903 - accuracy: 0.3401 - val_loss: 115.6919 - val_accuracy: 0.4933\n",
      "Epoch 19/38\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 212.2298 - accuracy: 0.3535 - val_loss: 90.7400 - val_accuracy: 0.4933\n",
      "Epoch 20/38\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 179.6717 - accuracy: 0.3098 - val_loss: 73.6930 - val_accuracy: 0.4933\n",
      "Epoch 21/38\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 152.7976 - accuracy: 0.3367 - val_loss: 52.3294 - val_accuracy: 0.4667\n",
      "Epoch 22/38\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 150.7943 - accuracy: 0.3434 - val_loss: 66.7620 - val_accuracy: 0.4933\n",
      "Epoch 23/38\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 172.0038 - accuracy: 0.3131 - val_loss: 77.7451 - val_accuracy: 0.4933\n",
      "Epoch 24/38\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 148.4291 - accuracy: 0.3131 - val_loss: 50.6533 - val_accuracy: 0.5867\n",
      "Epoch 25/38\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 122.0342 - accuracy: 0.3199 - val_loss: 48.9765 - val_accuracy: 0.5867\n",
      "Epoch 26/38\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 110.7372 - accuracy: 0.3939 - val_loss: 34.6896 - val_accuracy: 0.1600\n",
      "Epoch 27/38\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 122.0882 - accuracy: 0.2222 - val_loss: 24.3355 - val_accuracy: 0.5867\n",
      "Epoch 28/38\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 104.1790 - accuracy: 0.3704 - val_loss: 44.9883 - val_accuracy: 0.2400\n",
      "Epoch 29/38\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 102.5332 - accuracy: 0.3367 - val_loss: 50.1134 - val_accuracy: 0.5867\n",
      "Epoch 30/38\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 114.5533 - accuracy: 0.3131 - val_loss: 19.8037 - val_accuracy: 0.2400\n",
      "Epoch 31/38\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 109.4562 - accuracy: 0.2896 - val_loss: 30.1136 - val_accuracy: 0.5867\n",
      "Epoch 32/38\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 101.2488 - accuracy: 0.3199 - val_loss: 43.7674 - val_accuracy: 0.2400\n",
      "Epoch 33/38\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 104.6854 - accuracy: 0.3131 - val_loss: 33.0132 - val_accuracy: 0.5867\n",
      "Epoch 34/38\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 102.0033 - accuracy: 0.3401 - val_loss: 28.5705 - val_accuracy: 0.2400\n",
      "Epoch 35/38\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 90.6054 - accuracy: 0.2626 - val_loss: 22.9333 - val_accuracy: 0.5867\n",
      "Epoch 36/38\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 100.3933 - accuracy: 0.3569 - val_loss: 34.5009 - val_accuracy: 0.5867\n",
      "Epoch 37/38\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 91.5442 - accuracy: 0.3165 - val_loss: 61.6647 - val_accuracy: 0.2400\n",
      "Epoch 38/38\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 100.1694 - accuracy: 0.3098 - val_loss: 33.2260 - val_accuracy: 0.2400\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "| \u001b[0m23       \u001b[0m | \u001b[0m0.2043   \u001b[0m | \u001b[0m1.385    \u001b[0m | \u001b[0m113.7    \u001b[0m | \u001b[0m38.03    \u001b[0m | \u001b[0m0.6761   \u001b[0m | \u001b[0m2.052    \u001b[0m |\n",
      "Epoch 1/75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/rmsprop.py:140: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adagrad.py:81: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 131ms/step - loss: 3.4868 - accuracy: 0.3535 - val_loss: 2.2314 - val_accuracy: 0.5867\n",
      "Epoch 2/75\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 4.2612 - accuracy: 0.3569 - val_loss: 3.6412 - val_accuracy: 0.5867\n",
      "Epoch 3/75\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 4.7390 - accuracy: 0.4815 - val_loss: 3.5210 - val_accuracy: 0.1600\n",
      "Epoch 4/75\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 3.5024 - accuracy: 0.3434 - val_loss: 3.3706 - val_accuracy: 0.2400\n",
      "Epoch 5/75\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 3.4472 - accuracy: 0.4141 - val_loss: 3.3288 - val_accuracy: 0.5867\n",
      "Epoch 6/75\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 3.2160 - accuracy: 0.4478 - val_loss: 2.2954 - val_accuracy: 0.2400\n",
      "Epoch 7/75\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 2.7082 - accuracy: 0.3401 - val_loss: 1.9069 - val_accuracy: 0.5867\n",
      "Epoch 8/75\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 2.7631 - accuracy: 0.4040 - val_loss: 1.8727 - val_accuracy: 0.2400\n",
      "Epoch 9/75\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 2.5128 - accuracy: 0.3838 - val_loss: 2.0909 - val_accuracy: 0.5867\n",
      "Epoch 10/75\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 2.1045 - accuracy: 0.4579 - val_loss: 1.5454 - val_accuracy: 0.2400\n",
      "Epoch 11/75\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 2.0044 - accuracy: 0.3199 - val_loss: 1.4939 - val_accuracy: 0.5867\n",
      "Epoch 12/75\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 1.8613 - accuracy: 0.3838 - val_loss: 1.3046 - val_accuracy: 0.5867\n",
      "Epoch 13/75\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 1.6182 - accuracy: 0.4276 - val_loss: 1.2651 - val_accuracy: 0.5867\n",
      "Epoch 14/75\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 1.6443 - accuracy: 0.4007 - val_loss: 1.3932 - val_accuracy: 0.5867\n",
      "Epoch 15/75\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 1.6830 - accuracy: 0.4444 - val_loss: 1.2494 - val_accuracy: 0.2400\n",
      "Epoch 16/75\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 1.7118 - accuracy: 0.3266 - val_loss: 1.1246 - val_accuracy: 0.5867\n",
      "Epoch 17/75\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 1.3640 - accuracy: 0.4007 - val_loss: 1.2417 - val_accuracy: 0.5867\n",
      "Epoch 18/75\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 1.4232 - accuracy: 0.4478 - val_loss: 1.1042 - val_accuracy: 0.5867\n",
      "Epoch 19/75\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 1.3012 - accuracy: 0.4512 - val_loss: 1.0990 - val_accuracy: 0.5867\n",
      "Epoch 20/75\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 1.3006 - accuracy: 0.3838 - val_loss: 1.0644 - val_accuracy: 0.5867\n",
      "Epoch 21/75\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 1.2779 - accuracy: 0.3973 - val_loss: 1.2104 - val_accuracy: 0.5867\n",
      "Epoch 22/75\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 1.2985 - accuracy: 0.4478 - val_loss: 1.0858 - val_accuracy: 0.5867\n",
      "Epoch 23/75\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 1.2165 - accuracy: 0.4781 - val_loss: 1.1226 - val_accuracy: 0.2400\n",
      "Epoch 24/75\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 1.2908 - accuracy: 0.4108 - val_loss: 1.0972 - val_accuracy: 0.5867\n",
      "Epoch 25/75\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 1.2444 - accuracy: 0.4242 - val_loss: 1.0743 - val_accuracy: 0.5867\n",
      "Epoch 26/75\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 1.2242 - accuracy: 0.4411 - val_loss: 1.0939 - val_accuracy: 0.5867\n",
      "Epoch 27/75\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 1.2699 - accuracy: 0.4613 - val_loss: 1.0412 - val_accuracy: 0.5867\n",
      "Epoch 28/75\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 1.2923 - accuracy: 0.4141 - val_loss: 1.1442 - val_accuracy: 0.5867\n",
      "Epoch 29/75\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 1.1854 - accuracy: 0.4310 - val_loss: 1.2190 - val_accuracy: 0.2400\n",
      "Epoch 30/75\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 1.2804 - accuracy: 0.4310 - val_loss: 1.0510 - val_accuracy: 0.5867\n",
      "Epoch 31/75\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 1.1935 - accuracy: 0.4209 - val_loss: 1.1525 - val_accuracy: 0.5867\n",
      "Epoch 32/75\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 1.3232 - accuracy: 0.4848 - val_loss: 1.3404 - val_accuracy: 0.1600\n",
      "Epoch 33/75\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 1.4124 - accuracy: 0.3939 - val_loss: 1.5672 - val_accuracy: 0.2400\n",
      "Epoch 34/75\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 1.5070 - accuracy: 0.3502 - val_loss: 1.2106 - val_accuracy: 0.5867\n",
      "Epoch 35/75\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 1.3455 - accuracy: 0.3872 - val_loss: 1.1110 - val_accuracy: 0.5867\n",
      "Epoch 36/75\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 1.2826 - accuracy: 0.4209 - val_loss: 1.0511 - val_accuracy: 0.5867\n",
      "Epoch 37/75\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 1.3215 - accuracy: 0.4377 - val_loss: 1.2587 - val_accuracy: 0.2400\n",
      "Epoch 38/75\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 1.2761 - accuracy: 0.4680 - val_loss: 1.3538 - val_accuracy: 0.2400\n",
      "Epoch 39/75\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 1.5688 - accuracy: 0.3232 - val_loss: 1.1727 - val_accuracy: 0.5867\n",
      "Epoch 40/75\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 1.5800 - accuracy: 0.2997 - val_loss: 1.3590 - val_accuracy: 0.5867\n",
      "Epoch 41/75\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 1.5288 - accuracy: 0.4613 - val_loss: 1.6835 - val_accuracy: 0.2400\n",
      "Epoch 42/75\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 1.5863 - accuracy: 0.4007 - val_loss: 1.1213 - val_accuracy: 0.5867\n",
      "Epoch 43/75\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 1.3909 - accuracy: 0.3737 - val_loss: 1.2629 - val_accuracy: 0.5867\n",
      "Epoch 44/75\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 1.4443 - accuracy: 0.3838 - val_loss: 1.0796 - val_accuracy: 0.5867\n",
      "Epoch 45/75\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 1.2832 - accuracy: 0.4714 - val_loss: 1.2413 - val_accuracy: 0.2400\n",
      "Epoch 46/75\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 1.3546 - accuracy: 0.4276 - val_loss: 1.1838 - val_accuracy: 0.2400\n",
      "Epoch 47/75\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 1.2838 - accuracy: 0.3872 - val_loss: 1.0262 - val_accuracy: 0.5867\n",
      "Epoch 48/75\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 1.2736 - accuracy: 0.3973 - val_loss: 1.1421 - val_accuracy: 0.5867\n",
      "Epoch 49/75\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 1.3035 - accuracy: 0.4276 - val_loss: 1.2165 - val_accuracy: 0.5867\n",
      "Epoch 50/75\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 1.2900 - accuracy: 0.4613 - val_loss: 1.1843 - val_accuracy: 0.5867\n",
      "Epoch 51/75\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 1.3215 - accuracy: 0.4209 - val_loss: 1.4627 - val_accuracy: 0.2400\n",
      "Epoch 52/75\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 1.3943 - accuracy: 0.4377 - val_loss: 1.1659 - val_accuracy: 0.5867\n",
      "Epoch 53/75\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 1.3796 - accuracy: 0.3670 - val_loss: 1.2320 - val_accuracy: 0.5867\n",
      "Epoch 54/75\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 1.2985 - accuracy: 0.4343 - val_loss: 1.3374 - val_accuracy: 0.1600\n",
      "Epoch 55/75\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 1.3918 - accuracy: 0.3771 - val_loss: 1.2078 - val_accuracy: 0.5867\n",
      "Epoch 56/75\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 1.3957 - accuracy: 0.3670 - val_loss: 1.1302 - val_accuracy: 0.5867\n",
      "Epoch 57/75\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 1.3536 - accuracy: 0.3906 - val_loss: 1.2205 - val_accuracy: 0.5867\n",
      "Epoch 58/75\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 1.4515 - accuracy: 0.4310 - val_loss: 1.2546 - val_accuracy: 0.5867\n",
      "Epoch 59/75\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 1.6044 - accuracy: 0.4141 - val_loss: 1.2490 - val_accuracy: 0.2400\n",
      "Epoch 60/75\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 1.3816 - accuracy: 0.3670 - val_loss: 1.0852 - val_accuracy: 0.5867\n",
      "Epoch 61/75\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 1.3728 - accuracy: 0.3973 - val_loss: 1.4729 - val_accuracy: 0.2400\n",
      "Epoch 62/75\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 1.5263 - accuracy: 0.4444 - val_loss: 1.3330 - val_accuracy: 0.1600\n",
      "Epoch 63/75\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 1.3984 - accuracy: 0.3872 - val_loss: 1.4476 - val_accuracy: 0.2400\n",
      "Epoch 64/75\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 1.4940 - accuracy: 0.4141 - val_loss: 1.1217 - val_accuracy: 0.5867\n",
      "Epoch 65/75\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 1.2884 - accuracy: 0.4579 - val_loss: 1.3128 - val_accuracy: 0.2400\n",
      "Epoch 66/75\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 1.3716 - accuracy: 0.3805 - val_loss: 1.1100 - val_accuracy: 0.5867\n",
      "Epoch 67/75\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 1.2965 - accuracy: 0.3939 - val_loss: 1.2447 - val_accuracy: 0.5867\n",
      "Epoch 68/75\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 1.3717 - accuracy: 0.4007 - val_loss: 1.2076 - val_accuracy: 0.5867\n",
      "Epoch 69/75\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 1.4859 - accuracy: 0.4613 - val_loss: 1.3272 - val_accuracy: 0.2400\n",
      "Epoch 70/75\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 1.3394 - accuracy: 0.4478 - val_loss: 1.1526 - val_accuracy: 0.2400\n",
      "Epoch 71/75\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 1.2577 - accuracy: 0.4175 - val_loss: 1.0890 - val_accuracy: 0.5867\n",
      "Epoch 72/75\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 1.2776 - accuracy: 0.4175 - val_loss: 1.2423 - val_accuracy: 0.1600\n",
      "Epoch 73/75\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 1.4216 - accuracy: 0.3872 - val_loss: 1.1527 - val_accuracy: 0.5867\n",
      "Epoch 74/75\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 1.3678 - accuracy: 0.3636 - val_loss: 1.1843 - val_accuracy: 0.5867\n",
      "Epoch 75/75\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 1.4595 - accuracy: 0.4545 - val_loss: 1.1613 - val_accuracy: 0.5867\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "| \u001b[0m24       \u001b[0m | \u001b[0m0.5376   \u001b[0m | \u001b[0m1.98     \u001b[0m | \u001b[0m108.4    \u001b[0m | \u001b[0m74.66    \u001b[0m | \u001b[0m0.09537  \u001b[0m | \u001b[0m2.132    \u001b[0m |\n",
      "Epoch 1/70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/rmsprop.py:140: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adagrad.py:81: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 1s 43ms/step - loss: nan - accuracy: 0.3737 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 2/70\n",
      "7/7 [==============================] - 0s 13ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 3/70\n",
      "7/7 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 4/70\n",
      "7/7 [==============================] - 0s 19ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 5/70\n",
      "7/7 [==============================] - 0s 16ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 6/70\n",
      "7/7 [==============================] - 0s 17ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 7/70\n",
      "7/7 [==============================] - 0s 30ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 8/70\n",
      "7/7 [==============================] - 0s 34ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 9/70\n",
      "7/7 [==============================] - 0s 25ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 10/70\n",
      "7/7 [==============================] - 0s 19ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 11/70\n",
      "7/7 [==============================] - 0s 20ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 12/70\n",
      "7/7 [==============================] - 0s 28ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 13/70\n",
      "7/7 [==============================] - 0s 21ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 14/70\n",
      "7/7 [==============================] - 0s 22ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 15/70\n",
      "7/7 [==============================] - 0s 22ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 16/70\n",
      "7/7 [==============================] - 0s 26ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 17/70\n",
      "7/7 [==============================] - 0s 26ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 18/70\n",
      "7/7 [==============================] - 0s 22ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 19/70\n",
      "7/7 [==============================] - 0s 23ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 20/70\n",
      "7/7 [==============================] - 0s 25ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 21/70\n",
      "7/7 [==============================] - 0s 29ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 22/70\n",
      "7/7 [==============================] - 0s 28ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 23/70\n",
      "7/7 [==============================] - 0s 25ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 24/70\n",
      "7/7 [==============================] - 0s 26ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 25/70\n",
      "7/7 [==============================] - 0s 23ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 26/70\n",
      "7/7 [==============================] - 0s 25ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 27/70\n",
      "7/7 [==============================] - 0s 51ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 28/70\n",
      "7/7 [==============================] - 0s 24ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 29/70\n",
      "7/7 [==============================] - 0s 22ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 30/70\n",
      "7/7 [==============================] - 0s 22ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 31/70\n",
      "7/7 [==============================] - 0s 28ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 32/70\n",
      "7/7 [==============================] - 0s 23ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 33/70\n",
      "7/7 [==============================] - 0s 24ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 34/70\n",
      "7/7 [==============================] - 0s 24ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 35/70\n",
      "7/7 [==============================] - 0s 19ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 36/70\n",
      "7/7 [==============================] - 0s 20ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 37/70\n",
      "7/7 [==============================] - 0s 22ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 38/70\n",
      "7/7 [==============================] - 0s 25ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 39/70\n",
      "7/7 [==============================] - 0s 20ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 40/70\n",
      "7/7 [==============================] - 0s 30ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 41/70\n",
      "7/7 [==============================] - 0s 31ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 42/70\n",
      "7/7 [==============================] - 0s 23ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 43/70\n",
      "7/7 [==============================] - 0s 22ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 44/70\n",
      "7/7 [==============================] - 0s 23ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 45/70\n",
      "7/7 [==============================] - 0s 26ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 46/70\n",
      "7/7 [==============================] - 0s 30ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 47/70\n",
      "7/7 [==============================] - 0s 23ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 48/70\n",
      "7/7 [==============================] - 0s 20ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 49/70\n",
      "7/7 [==============================] - 0s 18ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 50/70\n",
      "7/7 [==============================] - 0s 22ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 51/70\n",
      "7/7 [==============================] - 0s 25ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 52/70\n",
      "7/7 [==============================] - 0s 22ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 53/70\n",
      "7/7 [==============================] - 0s 22ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 54/70\n",
      "7/7 [==============================] - 0s 31ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 55/70\n",
      "7/7 [==============================] - 0s 22ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 56/70\n",
      "7/7 [==============================] - 0s 21ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 57/70\n",
      "7/7 [==============================] - 0s 22ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 58/70\n",
      "7/7 [==============================] - 0s 20ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 59/70\n",
      "7/7 [==============================] - 0s 25ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 60/70\n",
      "7/7 [==============================] - 0s 19ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 61/70\n",
      "7/7 [==============================] - 0s 19ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 62/70\n",
      "7/7 [==============================] - 0s 21ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 63/70\n",
      "7/7 [==============================] - 0s 26ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 64/70\n",
      "7/7 [==============================] - 0s 26ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 65/70\n",
      "7/7 [==============================] - 0s 22ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 66/70\n",
      "7/7 [==============================] - 0s 42ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 67/70\n",
      "7/7 [==============================] - 0s 22ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 68/70\n",
      "7/7 [==============================] - 0s 21ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 69/70\n",
      "7/7 [==============================] - 0s 21ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 70/70\n",
      "7/7 [==============================] - 0s 23ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "| \u001b[0m25       \u001b[0m | \u001b[0m0.2043   \u001b[0m | \u001b[0m1.499    \u001b[0m | \u001b[0m46.86    \u001b[0m | \u001b[0m69.64    \u001b[0m | \u001b[0m0.4334   \u001b[0m | \u001b[0m0.2741   \u001b[0m |\n",
      "Epoch 1/79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/rmsprop.py:140: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adagrad.py:81: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 2s 229ms/step - loss: 47547.0625 - accuracy: 0.3266 - val_loss: 100.8588 - val_accuracy: 0.2133\n",
      "Epoch 2/79\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 162.4419 - accuracy: 0.4209 - val_loss: 3.6390 - val_accuracy: 0.5867\n",
      "Epoch 3/79\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 57.2584 - accuracy: 0.4377 - val_loss: 225.0609 - val_accuracy: 0.5867\n",
      "Epoch 4/79\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 171.2869 - accuracy: 0.4848 - val_loss: 32.1849 - val_accuracy: 0.5867\n",
      "Epoch 5/79\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 15.0752 - accuracy: 0.5253 - val_loss: 2.3877 - val_accuracy: 0.5867\n",
      "Epoch 6/79\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 8.1674 - accuracy: 0.4108 - val_loss: 1.0842 - val_accuracy: 0.2533\n",
      "Epoch 7/79\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 3.8144 - accuracy: 0.4276 - val_loss: 1.0498 - val_accuracy: 0.5867\n",
      "Epoch 8/79\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.9934 - accuracy: 0.5320 - val_loss: 1.0196 - val_accuracy: 0.5867\n",
      "Epoch 9/79\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.8808 - accuracy: 0.5253 - val_loss: 1.0249 - val_accuracy: 0.5867\n",
      "Epoch 10/79\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 7.2308 - accuracy: 0.5354 - val_loss: 1.1019 - val_accuracy: 0.5867\n",
      "Epoch 11/79\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 21.3381 - accuracy: 0.5286 - val_loss: 7.2676 - val_accuracy: 0.5867\n",
      "Epoch 12/79\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 3.0030 - accuracy: 0.5320 - val_loss: 18.6591 - val_accuracy: 0.2667\n",
      "Epoch 13/79\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 1.0238 - accuracy: 0.3535 - val_loss: 38.1615 - val_accuracy: 0.2667\n",
      "Epoch 14/79\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 10.1573 - accuracy: 0.4545 - val_loss: 54.5209 - val_accuracy: 0.5867\n",
      "Epoch 15/79\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.9868 - accuracy: 0.5354 - val_loss: 66.7761 - val_accuracy: 0.5867\n",
      "Epoch 16/79\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 20.9353 - accuracy: 0.5320 - val_loss: 107.0658 - val_accuracy: 0.5867\n",
      "Epoch 17/79\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 10.7545 - accuracy: 0.5286 - val_loss: 80.4176 - val_accuracy: 0.5867\n",
      "Epoch 18/79\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.9894 - accuracy: 0.5320 - val_loss: 83.7131 - val_accuracy: 0.5867\n",
      "Epoch 19/79\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.9858 - accuracy: 0.5320 - val_loss: 85.9721 - val_accuracy: 0.5867\n",
      "Epoch 20/79\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 2.1693 - accuracy: 0.5320 - val_loss: 87.4083 - val_accuracy: 0.5867\n",
      "Epoch 21/79\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.9922 - accuracy: 0.5320 - val_loss: 88.3728 - val_accuracy: 0.5867\n",
      "Epoch 22/79\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 14.5737 - accuracy: 0.5286 - val_loss: 1.0021 - val_accuracy: 0.5867\n",
      "Epoch 23/79\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 1.7176 - accuracy: 0.5320 - val_loss: 8.3843 - val_accuracy: 0.6000\n",
      "Epoch 24/79\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 153.4467 - accuracy: 0.5320 - val_loss: 229.9317 - val_accuracy: 0.5867\n",
      "Epoch 25/79\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 53.1018 - accuracy: 0.5286 - val_loss: 12.6346 - val_accuracy: 0.5867\n",
      "Epoch 26/79\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 77.3966 - accuracy: 0.5253 - val_loss: 5.5406 - val_accuracy: 0.5867\n",
      "Epoch 27/79\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 184.6965 - accuracy: 0.5253 - val_loss: 74.9099 - val_accuracy: 0.5733\n",
      "Epoch 28/79\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 3.2726 - accuracy: 0.5522 - val_loss: 30.6159 - val_accuracy: 0.5867\n",
      "Epoch 29/79\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 223.6949 - accuracy: 0.5488 - val_loss: 8.1063 - val_accuracy: 0.5733\n",
      "Epoch 30/79\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 33.7139 - accuracy: 0.5354 - val_loss: 109.5927 - val_accuracy: 0.5600\n",
      "Epoch 31/79\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 12.9951 - accuracy: 0.5320 - val_loss: 369.9454 - val_accuracy: 0.5600\n",
      "Epoch 32/79\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 107.8553 - accuracy: 0.5286 - val_loss: 1054.9851 - val_accuracy: 0.5733\n",
      "Epoch 33/79\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 346.4903 - accuracy: 0.5320 - val_loss: 54.5261 - val_accuracy: 0.5867\n",
      "Epoch 34/79\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 54.4530 - accuracy: 0.5387 - val_loss: 61.6474 - val_accuracy: 0.6000\n",
      "Epoch 35/79\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.0323 - accuracy: 0.5421 - val_loss: 112.2563 - val_accuracy: 0.5867\n",
      "Epoch 36/79\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 380.8847 - accuracy: 0.5387 - val_loss: 141.6566 - val_accuracy: 0.5867\n",
      "Epoch 37/79\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 48.5734 - accuracy: 0.5387 - val_loss: 157.0370 - val_accuracy: 0.5733\n",
      "Epoch 38/79\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.0064 - accuracy: 0.4613 - val_loss: 739.2170 - val_accuracy: 0.2800\n",
      "Epoch 39/79\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 9.2226 - accuracy: 0.4444 - val_loss: 1223.1168 - val_accuracy: 0.5600\n",
      "Epoch 40/79\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1138.3883 - accuracy: 0.5354 - val_loss: 1547.4329 - val_accuracy: 0.5600\n",
      "Epoch 41/79\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 74.8028 - accuracy: 0.5387 - val_loss: 2531.3752 - val_accuracy: 0.5600\n",
      "Epoch 42/79\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 630.7513 - accuracy: 0.5286 - val_loss: 2468.2847 - val_accuracy: 0.5733\n",
      "Epoch 43/79\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 27.2756 - accuracy: 0.5354 - val_loss: 2219.8782 - val_accuracy: 0.5733\n",
      "Epoch 44/79\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.1783 - accuracy: 0.5387 - val_loss: 2023.4248 - val_accuracy: 0.5733\n",
      "Epoch 45/79\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 2.8878 - accuracy: 0.5387 - val_loss: 1678.6488 - val_accuracy: 0.5733\n",
      "Epoch 46/79\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 92.8201 - accuracy: 0.5387 - val_loss: 649.6337 - val_accuracy: 0.5867\n",
      "Epoch 47/79\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 56.4718 - accuracy: 0.5320 - val_loss: 306.9777 - val_accuracy: 0.6000\n",
      "Epoch 48/79\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.9883 - accuracy: 0.5421 - val_loss: 328.0023 - val_accuracy: 0.6000\n",
      "Epoch 49/79\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.9949 - accuracy: 0.5421 - val_loss: 338.0121 - val_accuracy: 0.6000\n",
      "Epoch 50/79\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 2.0022 - accuracy: 0.5387 - val_loss: 342.8566 - val_accuracy: 0.6000\n",
      "Epoch 51/79\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.9891 - accuracy: 0.5421 - val_loss: 345.9436 - val_accuracy: 0.6000\n",
      "Epoch 52/79\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 0.9943 - accuracy: 0.5387 - val_loss: 347.9823 - val_accuracy: 0.6000\n",
      "Epoch 53/79\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 513.4183 - accuracy: 0.5354 - val_loss: 379.1411 - val_accuracy: 0.6000\n",
      "Epoch 54/79\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 273.7276 - accuracy: 0.5354 - val_loss: 455.5255 - val_accuracy: 0.5867\n",
      "Epoch 55/79\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 2.4497 - accuracy: 0.5152 - val_loss: 427.0658 - val_accuracy: 0.5867\n",
      "Epoch 56/79\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 26.5848 - accuracy: 0.5320 - val_loss: 413.7775 - val_accuracy: 0.5867\n",
      "Epoch 57/79\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.0087 - accuracy: 0.5354 - val_loss: 604.9713 - val_accuracy: 0.5733\n",
      "Epoch 58/79\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 17.7929 - accuracy: 0.5320 - val_loss: 589.1852 - val_accuracy: 0.5733\n",
      "Epoch 59/79\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1.0051 - accuracy: 0.5354 - val_loss: 560.3912 - val_accuracy: 0.5733\n",
      "Epoch 60/79\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 95.1183 - accuracy: 0.5286 - val_loss: 749.6818 - val_accuracy: 0.5733\n",
      "Epoch 61/79\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 8.4394 - accuracy: 0.5320 - val_loss: 691.1741 - val_accuracy: 0.5733\n",
      "Epoch 62/79\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.9976 - accuracy: 0.5354 - val_loss: 598.9033 - val_accuracy: 0.5733\n",
      "Epoch 63/79\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 0.9922 - accuracy: 0.5354 - val_loss: 593.4030 - val_accuracy: 0.5733\n",
      "Epoch 64/79\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 103.3994 - accuracy: 0.5286 - val_loss: 440.5418 - val_accuracy: 0.5733\n",
      "Epoch 65/79\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 14.0863 - accuracy: 0.5320 - val_loss: 2044.3835 - val_accuracy: 0.5600\n",
      "Epoch 66/79\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 310.6975 - accuracy: 0.5320 - val_loss: 354.0352 - val_accuracy: 0.5867\n",
      "Epoch 67/79\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 9.7593 - accuracy: 0.5320 - val_loss: 352.0573 - val_accuracy: 0.5867\n",
      "Epoch 68/79\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1.0083 - accuracy: 0.5354 - val_loss: 350.5475 - val_accuracy: 0.5867\n",
      "Epoch 69/79\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1.0072 - accuracy: 0.5354 - val_loss: 349.4832 - val_accuracy: 0.5733\n",
      "Epoch 70/79\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1.0139 - accuracy: 0.5354 - val_loss: 348.7607 - val_accuracy: 0.5733\n",
      "Epoch 71/79\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 52.5329 - accuracy: 0.5320 - val_loss: 348.0175 - val_accuracy: 0.5733\n",
      "Epoch 72/79\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1.0029 - accuracy: 0.5354 - val_loss: 347.4976 - val_accuracy: 0.5733\n",
      "Epoch 73/79\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1.0062 - accuracy: 0.5354 - val_loss: 347.1354 - val_accuracy: 0.5733\n",
      "Epoch 74/79\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 2.0464 - accuracy: 0.5354 - val_loss: 347.4571 - val_accuracy: 0.5733\n",
      "Epoch 75/79\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1.0126 - accuracy: 0.5354 - val_loss: 347.6251 - val_accuracy: 0.5733\n",
      "Epoch 76/79\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1.0021 - accuracy: 0.5354 - val_loss: 347.7226 - val_accuracy: 0.5733\n",
      "Epoch 77/79\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1.0045 - accuracy: 0.5354 - val_loss: 347.8154 - val_accuracy: 0.5733\n",
      "Epoch 78/79\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.0007 - accuracy: 0.5354 - val_loss: 347.8643 - val_accuracy: 0.5733\n",
      "Epoch 79/79\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.9995 - accuracy: 0.5354 - val_loss: 347.9097 - val_accuracy: 0.5733\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "| \u001b[0m26       \u001b[0m | \u001b[0m0.5161   \u001b[0m | \u001b[0m0.03732  \u001b[0m | \u001b[0m91.36    \u001b[0m | \u001b[0m78.69    \u001b[0m | \u001b[0m0.4661   \u001b[0m | \u001b[0m1.906    \u001b[0m |\n",
      "Epoch 1/59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/rmsprop.py:140: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adagrad.py:81: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 69ms/step - loss: 13.8542 - accuracy: 0.3670 - val_loss: 1.3237 - val_accuracy: 0.5867\n",
      "Epoch 2/59\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.3644 - accuracy: 0.4579 - val_loss: 1.2687 - val_accuracy: 0.2400\n",
      "Epoch 3/59\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 1.3687 - accuracy: 0.3367 - val_loss: 1.1439 - val_accuracy: 0.3067\n",
      "Epoch 4/59\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.1357 - accuracy: 0.4040 - val_loss: 1.0159 - val_accuracy: 0.5867\n",
      "Epoch 5/59\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 1.0483 - accuracy: 0.4983 - val_loss: 1.0042 - val_accuracy: 0.5867\n",
      "Epoch 6/59\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.0570 - accuracy: 0.5152 - val_loss: 0.9994 - val_accuracy: 0.5867\n",
      "Epoch 7/59\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 1.0355 - accuracy: 0.5152 - val_loss: 0.9968 - val_accuracy: 0.5867\n",
      "Epoch 8/59\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 1.0080 - accuracy: 0.5152 - val_loss: 0.9888 - val_accuracy: 0.5867\n",
      "Epoch 9/59\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.9957 - accuracy: 0.5118 - val_loss: 0.9872 - val_accuracy: 0.6000\n",
      "Epoch 10/59\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.9758 - accuracy: 0.5253 - val_loss: 0.9672 - val_accuracy: 0.6000\n",
      "Epoch 11/59\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.9599 - accuracy: 0.5286 - val_loss: 0.9258 - val_accuracy: 0.6133\n",
      "Epoch 12/59\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.9041 - accuracy: 0.5926 - val_loss: 0.9076 - val_accuracy: 0.6400\n",
      "Epoch 13/59\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.8471 - accuracy: 0.6498 - val_loss: 0.8344 - val_accuracy: 0.6667\n",
      "Epoch 14/59\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.7737 - accuracy: 0.6700 - val_loss: 0.7806 - val_accuracy: 0.6533\n",
      "Epoch 15/59\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.7268 - accuracy: 0.6734 - val_loss: 0.8690 - val_accuracy: 0.6933\n",
      "Epoch 16/59\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.7198 - accuracy: 0.6869 - val_loss: 0.9718 - val_accuracy: 0.6800\n",
      "Epoch 17/59\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.7362 - accuracy: 0.7172 - val_loss: 0.7435 - val_accuracy: 0.6533\n",
      "Epoch 18/59\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.6289 - accuracy: 0.7138 - val_loss: 0.6728 - val_accuracy: 0.6933\n",
      "Epoch 19/59\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.5802 - accuracy: 0.7273 - val_loss: 0.6824 - val_accuracy: 0.6800\n",
      "Epoch 20/59\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.5421 - accuracy: 0.7744 - val_loss: 0.6504 - val_accuracy: 0.7067\n",
      "Epoch 21/59\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.5428 - accuracy: 0.7542 - val_loss: 0.7651 - val_accuracy: 0.6933\n",
      "Epoch 22/59\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.5339 - accuracy: 0.7643 - val_loss: 0.7513 - val_accuracy: 0.6933\n",
      "Epoch 23/59\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.5174 - accuracy: 0.7778 - val_loss: 0.7269 - val_accuracy: 0.6533\n",
      "Epoch 24/59\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.4917 - accuracy: 0.8114 - val_loss: 0.6887 - val_accuracy: 0.7333\n",
      "Epoch 25/59\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.4891 - accuracy: 0.8215 - val_loss: 0.7073 - val_accuracy: 0.6933\n",
      "Epoch 26/59\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.4937 - accuracy: 0.7778 - val_loss: 0.7477 - val_accuracy: 0.6267\n",
      "Epoch 27/59\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.4387 - accuracy: 0.8249 - val_loss: 0.7236 - val_accuracy: 0.6800\n",
      "Epoch 28/59\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.4095 - accuracy: 0.8215 - val_loss: 0.7103 - val_accuracy: 0.7333\n",
      "Epoch 29/59\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 0.3541 - accuracy: 0.8855 - val_loss: 0.7710 - val_accuracy: 0.7733\n",
      "Epoch 30/59\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.2986 - accuracy: 0.8788 - val_loss: 0.7508 - val_accuracy: 0.8000\n",
      "Epoch 31/59\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.2856 - accuracy: 0.9158 - val_loss: 0.7377 - val_accuracy: 0.7867\n",
      "Epoch 32/59\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.2641 - accuracy: 0.9091 - val_loss: 0.8874 - val_accuracy: 0.7467\n",
      "Epoch 33/59\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.3220 - accuracy: 0.8687 - val_loss: 0.7493 - val_accuracy: 0.7733\n",
      "Epoch 34/59\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.2840 - accuracy: 0.8956 - val_loss: 0.7252 - val_accuracy: 0.8000\n",
      "Epoch 35/59\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.2207 - accuracy: 0.9461 - val_loss: 0.7809 - val_accuracy: 0.8000\n",
      "Epoch 36/59\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.2191 - accuracy: 0.9394 - val_loss: 0.9099 - val_accuracy: 0.7733\n",
      "Epoch 37/59\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.2005 - accuracy: 0.9461 - val_loss: 1.0687 - val_accuracy: 0.7867\n",
      "Epoch 38/59\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.1949 - accuracy: 0.9259 - val_loss: 1.1591 - val_accuracy: 0.7867\n",
      "Epoch 39/59\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.1939 - accuracy: 0.9360 - val_loss: 1.2626 - val_accuracy: 0.7467\n",
      "Epoch 40/59\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.2338 - accuracy: 0.9226 - val_loss: 1.2081 - val_accuracy: 0.7467\n",
      "Epoch 41/59\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.1737 - accuracy: 0.9394 - val_loss: 1.2639 - val_accuracy: 0.7467\n",
      "Epoch 42/59\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.1636 - accuracy: 0.9529 - val_loss: 1.2516 - val_accuracy: 0.7467\n",
      "Epoch 43/59\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.1509 - accuracy: 0.9562 - val_loss: 1.2430 - val_accuracy: 0.7600\n",
      "Epoch 44/59\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.2073 - accuracy: 0.9259 - val_loss: 1.1627 - val_accuracy: 0.7867\n",
      "Epoch 45/59\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.1639 - accuracy: 0.9428 - val_loss: 1.1283 - val_accuracy: 0.7733\n",
      "Epoch 46/59\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.1238 - accuracy: 0.9596 - val_loss: 1.3385 - val_accuracy: 0.7600\n",
      "Epoch 47/59\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.1207 - accuracy: 0.9562 - val_loss: 1.4572 - val_accuracy: 0.7600\n",
      "Epoch 48/59\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.0934 - accuracy: 0.9697 - val_loss: 1.6099 - val_accuracy: 0.7600\n",
      "Epoch 49/59\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.1160 - accuracy: 0.9562 - val_loss: 1.6655 - val_accuracy: 0.7867\n",
      "Epoch 50/59\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.0969 - accuracy: 0.9596 - val_loss: 1.7921 - val_accuracy: 0.7867\n",
      "Epoch 51/59\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.0776 - accuracy: 0.9764 - val_loss: 1.9958 - val_accuracy: 0.7867\n",
      "Epoch 52/59\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.0871 - accuracy: 0.9731 - val_loss: 2.5019 - val_accuracy: 0.7467\n",
      "Epoch 53/59\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.0989 - accuracy: 0.9663 - val_loss: 2.1073 - val_accuracy: 0.7867\n",
      "Epoch 54/59\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 0.1152 - accuracy: 0.9529 - val_loss: 2.4521 - val_accuracy: 0.7333\n",
      "Epoch 55/59\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 0.1310 - accuracy: 0.9529 - val_loss: 1.9476 - val_accuracy: 0.7733\n",
      "Epoch 56/59\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.1838 - accuracy: 0.9327 - val_loss: 1.7297 - val_accuracy: 0.7867\n",
      "Epoch 57/59\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.1348 - accuracy: 0.9630 - val_loss: 1.7969 - val_accuracy: 0.7733\n",
      "Epoch 58/59\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.0993 - accuracy: 0.9697 - val_loss: 2.0215 - val_accuracy: 0.7600\n",
      "Epoch 59/59\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.0941 - accuracy: 0.9663 - val_loss: 2.2048 - val_accuracy: 0.7467\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "| \u001b[95m27       \u001b[0m | \u001b[95m0.7527   \u001b[0m | \u001b[95m2.93     \u001b[0m | \u001b[95m90.04    \u001b[0m | \u001b[95m58.65    \u001b[0m | \u001b[95m0.02253  \u001b[0m | \u001b[95m2.231    \u001b[0m |\n",
      "Epoch 1/94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/rmsprop.py:140: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adagrad.py:81: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 105ms/step - loss: 3.5795 - accuracy: 0.0808 - val_loss: 6.6943 - val_accuracy: 0.5867\n",
      "Epoch 2/94\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 10.9121 - accuracy: 0.3973 - val_loss: 3.4158 - val_accuracy: 0.5867\n",
      "Epoch 3/94\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 8.4848 - accuracy: 0.3737 - val_loss: 13.8127 - val_accuracy: 0.1600\n",
      "Epoch 4/94\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 13.9739 - accuracy: 0.3098 - val_loss: 9.6452 - val_accuracy: 0.5867\n",
      "Epoch 5/94\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 7.5798 - accuracy: 0.3939 - val_loss: 12.3616 - val_accuracy: 0.2400\n",
      "Epoch 6/94\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 9.8241 - accuracy: 0.3670 - val_loss: 7.2076 - val_accuracy: 0.2400\n",
      "Epoch 7/94\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 7.7552 - accuracy: 0.4478 - val_loss: 7.4738 - val_accuracy: 0.5867\n",
      "Epoch 8/94\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 6.1126 - accuracy: 0.3939 - val_loss: 6.8616 - val_accuracy: 0.2400\n",
      "Epoch 9/94\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 6.9986 - accuracy: 0.3906 - val_loss: 3.1967 - val_accuracy: 0.5867\n",
      "Epoch 10/94\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 3.9860 - accuracy: 0.3603 - val_loss: 6.0189 - val_accuracy: 0.2133\n",
      "Epoch 11/94\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 5.4662 - accuracy: 0.3737 - val_loss: 2.6938 - val_accuracy: 0.2933\n",
      "Epoch 12/94\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 3.0256 - accuracy: 0.4343 - val_loss: 3.1873 - val_accuracy: 0.5867\n",
      "Epoch 13/94\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 3.9153 - accuracy: 0.4108 - val_loss: 4.9468 - val_accuracy: 0.2533\n",
      "Epoch 14/94\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 4.3040 - accuracy: 0.4310 - val_loss: 2.1673 - val_accuracy: 0.5867\n",
      "Epoch 15/94\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 3.1592 - accuracy: 0.3535 - val_loss: 7.9485 - val_accuracy: 0.2400\n",
      "Epoch 16/94\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 5.2755 - accuracy: 0.3333 - val_loss: 10.0990 - val_accuracy: 0.2400\n",
      "Epoch 17/94\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 6.3987 - accuracy: 0.4040 - val_loss: 2.7952 - val_accuracy: 0.5867\n",
      "Epoch 18/94\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 3.6445 - accuracy: 0.3838 - val_loss: 4.2255 - val_accuracy: 0.2400\n",
      "Epoch 19/94\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 4.3829 - accuracy: 0.3973 - val_loss: 3.4318 - val_accuracy: 0.5867\n",
      "Epoch 20/94\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 3.0999 - accuracy: 0.4242 - val_loss: 3.7821 - val_accuracy: 0.2400\n",
      "Epoch 21/94\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 4.3711 - accuracy: 0.3636 - val_loss: 1.8557 - val_accuracy: 0.2400\n",
      "Epoch 22/94\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 2.7760 - accuracy: 0.4108 - val_loss: 4.1574 - val_accuracy: 0.5867\n",
      "Epoch 23/94\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 4.3665 - accuracy: 0.4007 - val_loss: 2.1521 - val_accuracy: 0.2400\n",
      "Epoch 24/94\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 2.9358 - accuracy: 0.3468 - val_loss: 1.5664 - val_accuracy: 0.5867\n",
      "Epoch 25/94\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 2.2079 - accuracy: 0.4007 - val_loss: 2.0923 - val_accuracy: 0.3467\n",
      "Epoch 26/94\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 2.5806 - accuracy: 0.3872 - val_loss: 2.6191 - val_accuracy: 0.2400\n",
      "Epoch 27/94\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 3.2300 - accuracy: 0.4175 - val_loss: 6.4817 - val_accuracy: 0.5867\n",
      "Epoch 28/94\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 5.3063 - accuracy: 0.4747 - val_loss: 2.2475 - val_accuracy: 0.2133\n",
      "Epoch 29/94\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 3.2335 - accuracy: 0.3603 - val_loss: 6.1610 - val_accuracy: 0.2133\n",
      "Epoch 30/94\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 6.5869 - accuracy: 0.3502 - val_loss: 1.8778 - val_accuracy: 0.5867\n",
      "Epoch 31/94\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 2.3007 - accuracy: 0.3670 - val_loss: 1.4815 - val_accuracy: 0.5867\n",
      "Epoch 32/94\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 2.3812 - accuracy: 0.3872 - val_loss: 4.0044 - val_accuracy: 0.5867\n",
      "Epoch 33/94\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 3.1800 - accuracy: 0.4815 - val_loss: 2.4964 - val_accuracy: 0.2400\n",
      "Epoch 34/94\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 1.9817 - accuracy: 0.4579 - val_loss: 3.7525 - val_accuracy: 0.2133\n",
      "Epoch 35/94\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 3.2116 - accuracy: 0.3603 - val_loss: 3.7849 - val_accuracy: 0.5867\n",
      "Epoch 36/94\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 4.2609 - accuracy: 0.3603 - val_loss: 4.1462 - val_accuracy: 0.2400\n",
      "Epoch 37/94\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 4.5070 - accuracy: 0.3367 - val_loss: 2.2751 - val_accuracy: 0.5867\n",
      "Epoch 38/94\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 2.4620 - accuracy: 0.4209 - val_loss: 2.8942 - val_accuracy: 0.3467\n",
      "Epoch 39/94\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 2.9024 - accuracy: 0.3973 - val_loss: 3.6191 - val_accuracy: 0.5867\n",
      "Epoch 40/94\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 3.3325 - accuracy: 0.4343 - val_loss: 1.5729 - val_accuracy: 0.2400\n",
      "Epoch 41/94\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 1.9190 - accuracy: 0.4242 - val_loss: 2.2244 - val_accuracy: 0.5867\n",
      "Epoch 42/94\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 2.3107 - accuracy: 0.4377 - val_loss: 3.5969 - val_accuracy: 0.2400\n",
      "Epoch 43/94\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 3.7108 - accuracy: 0.3300 - val_loss: 2.4979 - val_accuracy: 0.2400\n",
      "Epoch 44/94\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 2.6054 - accuracy: 0.4714 - val_loss: 2.4006 - val_accuracy: 0.5867\n",
      "Epoch 45/94\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 2.8370 - accuracy: 0.3636 - val_loss: 4.9830 - val_accuracy: 0.2267\n",
      "Epoch 46/94\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 3.7896 - accuracy: 0.2761 - val_loss: 1.2184 - val_accuracy: 0.5867\n",
      "Epoch 47/94\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 1.9038 - accuracy: 0.3838 - val_loss: 1.1253 - val_accuracy: 0.5867\n",
      "Epoch 48/94\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 1.5584 - accuracy: 0.4040 - val_loss: 2.0247 - val_accuracy: 0.5867\n",
      "Epoch 49/94\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 2.4001 - accuracy: 0.4007 - val_loss: 2.3308 - val_accuracy: 0.2133\n",
      "Epoch 50/94\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 2.7211 - accuracy: 0.3670 - val_loss: 3.5524 - val_accuracy: 0.5867\n",
      "Epoch 51/94\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 2.7836 - accuracy: 0.4310 - val_loss: 2.4024 - val_accuracy: 0.5867\n",
      "Epoch 52/94\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 2.1306 - accuracy: 0.4377 - val_loss: 5.1598 - val_accuracy: 0.2400\n",
      "Epoch 53/94\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 3.2927 - accuracy: 0.4007 - val_loss: 1.5112 - val_accuracy: 0.2400\n",
      "Epoch 54/94\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 1.7655 - accuracy: 0.4209 - val_loss: 2.5640 - val_accuracy: 0.5867\n",
      "Epoch 55/94\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 2.6307 - accuracy: 0.4579 - val_loss: 1.7311 - val_accuracy: 0.5867\n",
      "Epoch 56/94\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 2.0020 - accuracy: 0.4276 - val_loss: 2.2092 - val_accuracy: 0.2000\n",
      "Epoch 57/94\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 2.5311 - accuracy: 0.3569 - val_loss: 1.5769 - val_accuracy: 0.5867\n",
      "Epoch 58/94\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 1.8942 - accuracy: 0.4209 - val_loss: 2.4535 - val_accuracy: 0.2267\n",
      "Epoch 59/94\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 2.2862 - accuracy: 0.3805 - val_loss: 2.9735 - val_accuracy: 0.5867\n",
      "Epoch 60/94\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 2.8299 - accuracy: 0.3603 - val_loss: 1.3652 - val_accuracy: 0.3067\n",
      "Epoch 61/94\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 1.5922 - accuracy: 0.4478 - val_loss: 5.2140 - val_accuracy: 0.1600\n",
      "Epoch 62/94\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 4.1951 - accuracy: 0.3232 - val_loss: 3.4414 - val_accuracy: 0.5867\n",
      "Epoch 63/94\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 2.6691 - accuracy: 0.4444 - val_loss: 2.0052 - val_accuracy: 0.5867\n",
      "Epoch 64/94\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 1.9996 - accuracy: 0.4175 - val_loss: 4.9142 - val_accuracy: 0.2400\n",
      "Epoch 65/94\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 3.4815 - accuracy: 0.3199 - val_loss: 1.4972 - val_accuracy: 0.3467\n",
      "Epoch 66/94\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 1.8858 - accuracy: 0.3939 - val_loss: 2.3150 - val_accuracy: 0.2133\n",
      "Epoch 67/94\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 2.2082 - accuracy: 0.3468 - val_loss: 2.4347 - val_accuracy: 0.6533\n",
      "Epoch 68/94\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 2.2659 - accuracy: 0.4579 - val_loss: 2.3918 - val_accuracy: 0.5867\n",
      "Epoch 69/94\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 2.3882 - accuracy: 0.4074 - val_loss: 2.8892 - val_accuracy: 0.3200\n",
      "Epoch 70/94\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 2.1803 - accuracy: 0.3872 - val_loss: 1.2331 - val_accuracy: 0.3467\n",
      "Epoch 71/94\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 1.4876 - accuracy: 0.4108 - val_loss: 1.2885 - val_accuracy: 0.5867\n",
      "Epoch 72/94\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 1.6444 - accuracy: 0.3872 - val_loss: 3.7112 - val_accuracy: 0.1600\n",
      "Epoch 73/94\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 2.7364 - accuracy: 0.3333 - val_loss: 2.4991 - val_accuracy: 0.2400\n",
      "Epoch 74/94\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 2.4986 - accuracy: 0.3838 - val_loss: 1.5438 - val_accuracy: 0.5867\n",
      "Epoch 75/94\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 1.5982 - accuracy: 0.4343 - val_loss: 1.2110 - val_accuracy: 0.5867\n",
      "Epoch 76/94\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 1.4016 - accuracy: 0.4310 - val_loss: 1.9391 - val_accuracy: 0.2400\n",
      "Epoch 77/94\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 2.2032 - accuracy: 0.3771 - val_loss: 2.2205 - val_accuracy: 0.3467\n",
      "Epoch 78/94\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 2.1982 - accuracy: 0.4646 - val_loss: 1.3558 - val_accuracy: 0.2400\n",
      "Epoch 79/94\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 1.4693 - accuracy: 0.4478 - val_loss: 1.2329 - val_accuracy: 0.3467\n",
      "Epoch 80/94\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 1.3994 - accuracy: 0.4040 - val_loss: 1.7589 - val_accuracy: 0.2400\n",
      "Epoch 81/94\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 1.9123 - accuracy: 0.4007 - val_loss: 2.8945 - val_accuracy: 0.5867\n",
      "Epoch 82/94\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 2.3738 - accuracy: 0.4444 - val_loss: 1.9886 - val_accuracy: 0.5867\n",
      "Epoch 83/94\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 1.8197 - accuracy: 0.4108 - val_loss: 2.3816 - val_accuracy: 0.2400\n",
      "Epoch 84/94\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 2.3049 - accuracy: 0.3704 - val_loss: 2.1904 - val_accuracy: 0.5867\n",
      "Epoch 85/94\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 2.1088 - accuracy: 0.4040 - val_loss: 1.2171 - val_accuracy: 0.5867\n",
      "Epoch 86/94\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 1.4310 - accuracy: 0.4242 - val_loss: 1.7517 - val_accuracy: 0.2533\n",
      "Epoch 87/94\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 1.7394 - accuracy: 0.3603 - val_loss: 2.5566 - val_accuracy: 0.2133\n",
      "Epoch 88/94\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 2.7721 - accuracy: 0.3603 - val_loss: 1.8619 - val_accuracy: 0.5867\n",
      "Epoch 89/94\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 1.8597 - accuracy: 0.4242 - val_loss: 4.2528 - val_accuracy: 0.2400\n",
      "Epoch 90/94\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 2.8850 - accuracy: 0.3401 - val_loss: 2.4009 - val_accuracy: 0.2400\n",
      "Epoch 91/94\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 2.4125 - accuracy: 0.3704 - val_loss: 1.8043 - val_accuracy: 0.5867\n",
      "Epoch 92/94\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 2.0204 - accuracy: 0.3838 - val_loss: 4.1267 - val_accuracy: 0.3200\n",
      "Epoch 93/94\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 2.6393 - accuracy: 0.2795 - val_loss: 5.4802 - val_accuracy: 0.2400\n",
      "Epoch 94/94\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 2.8527 - accuracy: 0.4310 - val_loss: 1.7048 - val_accuracy: 0.2400\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "| \u001b[0m28       \u001b[0m | \u001b[0m0.3118   \u001b[0m | \u001b[0m1.796    \u001b[0m | \u001b[0m142.9    \u001b[0m | \u001b[0m93.91    \u001b[0m | \u001b[0m0.3884   \u001b[0m | \u001b[0m2.714    \u001b[0m |\n",
      "=====================================================================================\n"
     ]
    }
   ],
   "source": [
    "params_cnn ={\n",
    "    'optimizer_index':(0,3),\n",
    "    'activation_index':(0, 3),\n",
    "    'learning_rate':learning_rates,\n",
    "    'epoch':epochs,\n",
    "    'batch_size':batch_sizes\n",
    "    \n",
    "}\n",
    "\n",
    "nn_bo = BayesianOptimization(objective_func1, params_cnn, random_state=110)\n",
    "nn_bo.maximize(init_points=25, n_iter=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'softplus',\n",
       " 'optimizer': 'Adam',\n",
       " 'batch_size': 90,\n",
       " 'epoch': 59,\n",
       " 'learning_rate': 0.022531078608418083}"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_cnn_ = nn_bo.max['params']\n",
    "\n",
    "best_params_cnn = {}\n",
    "\n",
    "best_params_cnn['activation'] = activations_list[round(params_cnn_['activation_index'])]\n",
    "best_params_cnn['optimizer'] = optimizers_list[round(params_cnn_['optimizer_index'])]\n",
    "best_params_cnn['batch_size'] = round(params_cnn_['batch_size'])\n",
    "best_params_cnn['epoch'] = round(params_cnn_['epoch'])\n",
    "best_params_cnn['learning_rate'] = params_cnn_['learning_rate']\n",
    "\n",
    "best_params_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reulst on best model\n",
    "\n",
    "def create_best_CNN_model():\n",
    "    CNN = Sequential()\n",
    "    # The Embedding layer takes the embedding matrix as an argument and transform the inputed the sequences of index to sequences of vectors.\n",
    "    CNN.add(Embedding(len(word_index) + 1, word_dimension, weights=[embedding_matrix], input_length = maxlen, trainable=False))\n",
    "\n",
    "\n",
    "    CNN.add(Convolution1D(64, 5, activation = 'softplus'))\n",
    "    CNN.add(MaxPooling1D(pool_size = 5))\n",
    "\n",
    "    CNN.add(Convolution1D(32, 5, activation = 'softplus'))\n",
    "    CNN.add(MaxPooling1D(pool_size = 5))\n",
    "\n",
    "    CNN.add(Flatten())\n",
    "    CNN.add(Dense(units = 128 , activation = 'softplus'))\n",
    "    CNN.add(Dropout(0.5))\n",
    "\n",
    "    #CNN.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "    CNN.add(Dense(units = 4, activation = 'sigmoid'))\n",
    "\n",
    "    #CNN.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    CNN.compile(optimizer = 'Adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    return CNN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Tunned Model predicted on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/59\n",
      "4/4 [==============================] - 1s 145ms/step - loss: 1.6011 - accuracy: 0.3569 - val_loss: 1.0563 - val_accuracy: 0.5867\n",
      "Epoch 2/59\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 1.4415 - accuracy: 0.4680 - val_loss: 1.0039 - val_accuracy: 0.5867\n",
      "Epoch 3/59\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 1.1617 - accuracy: 0.4646 - val_loss: 1.0737 - val_accuracy: 0.3867\n",
      "Epoch 4/59\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 1.2402 - accuracy: 0.4175 - val_loss: 0.9924 - val_accuracy: 0.5867\n",
      "Epoch 5/59\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 1.1781 - accuracy: 0.4579 - val_loss: 0.9688 - val_accuracy: 0.5867\n",
      "Epoch 6/59\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 1.1089 - accuracy: 0.4882 - val_loss: 0.9578 - val_accuracy: 0.5867\n",
      "Epoch 7/59\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 1.0967 - accuracy: 0.4882 - val_loss: 0.9575 - val_accuracy: 0.6000\n",
      "Epoch 8/59\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 1.0880 - accuracy: 0.4815 - val_loss: 0.9323 - val_accuracy: 0.6000\n",
      "Epoch 9/59\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 1.0737 - accuracy: 0.5152 - val_loss: 0.9065 - val_accuracy: 0.6000\n",
      "Epoch 10/59\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.9909 - accuracy: 0.5488 - val_loss: 0.9176 - val_accuracy: 0.6800\n",
      "Epoch 11/59\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.9824 - accuracy: 0.5118 - val_loss: 0.8753 - val_accuracy: 0.6800\n",
      "Epoch 12/59\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.9477 - accuracy: 0.5892 - val_loss: 0.8610 - val_accuracy: 0.6667\n",
      "Epoch 13/59\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.8775 - accuracy: 0.6397 - val_loss: 0.8694 - val_accuracy: 0.7067\n",
      "Epoch 14/59\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.8741 - accuracy: 0.6128 - val_loss: 0.8248 - val_accuracy: 0.6933\n",
      "Epoch 15/59\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.8133 - accuracy: 0.6465 - val_loss: 0.8006 - val_accuracy: 0.7067\n",
      "Epoch 16/59\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7792 - accuracy: 0.6835 - val_loss: 0.7670 - val_accuracy: 0.7067\n",
      "Epoch 17/59\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7661 - accuracy: 0.7138 - val_loss: 0.7261 - val_accuracy: 0.7067\n",
      "Epoch 18/59\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.7385 - accuracy: 0.7104 - val_loss: 0.6988 - val_accuracy: 0.7733\n",
      "Epoch 19/59\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.6623 - accuracy: 0.7374 - val_loss: 0.6779 - val_accuracy: 0.7867\n",
      "Epoch 20/59\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.6111 - accuracy: 0.7710 - val_loss: 0.6569 - val_accuracy: 0.8400\n",
      "Epoch 21/59\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.5856 - accuracy: 0.7912 - val_loss: 0.6222 - val_accuracy: 0.7867\n",
      "Epoch 22/59\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.5203 - accuracy: 0.7879 - val_loss: 0.6359 - val_accuracy: 0.8000\n",
      "Epoch 23/59\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.5329 - accuracy: 0.8182 - val_loss: 0.5883 - val_accuracy: 0.8400\n",
      "Epoch 24/59\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.5070 - accuracy: 0.8215 - val_loss: 0.6145 - val_accuracy: 0.8000\n",
      "Epoch 25/59\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.4325 - accuracy: 0.8485 - val_loss: 0.5776 - val_accuracy: 0.8400\n",
      "Epoch 26/59\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 0.3865 - accuracy: 0.8788 - val_loss: 0.5496 - val_accuracy: 0.8533\n",
      "Epoch 27/59\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.4053 - accuracy: 0.8451 - val_loss: 0.5785 - val_accuracy: 0.8400\n",
      "Epoch 28/59\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.3632 - accuracy: 0.8754 - val_loss: 0.5629 - val_accuracy: 0.8400\n",
      "Epoch 29/59\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.3318 - accuracy: 0.8822 - val_loss: 0.5349 - val_accuracy: 0.8667\n",
      "Epoch 30/59\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.3304 - accuracy: 0.8990 - val_loss: 0.5644 - val_accuracy: 0.8133\n",
      "Epoch 31/59\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.2717 - accuracy: 0.9192 - val_loss: 0.5418 - val_accuracy: 0.8533\n",
      "Epoch 32/59\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.2490 - accuracy: 0.9192 - val_loss: 0.5658 - val_accuracy: 0.8133\n",
      "Epoch 33/59\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.2365 - accuracy: 0.9293 - val_loss: 0.5733 - val_accuracy: 0.8533\n",
      "Epoch 34/59\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.2625 - accuracy: 0.9057 - val_loss: 0.5262 - val_accuracy: 0.8400\n",
      "Epoch 35/59\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.1886 - accuracy: 0.9596 - val_loss: 0.5212 - val_accuracy: 0.8533\n",
      "Epoch 36/59\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.1984 - accuracy: 0.9226 - val_loss: 0.5773 - val_accuracy: 0.8533\n",
      "Epoch 37/59\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.2006 - accuracy: 0.9293 - val_loss: 0.5812 - val_accuracy: 0.8267\n",
      "Epoch 38/59\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 0.1883 - accuracy: 0.9327 - val_loss: 0.5510 - val_accuracy: 0.8667\n",
      "Epoch 39/59\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.1637 - accuracy: 0.9529 - val_loss: 0.5397 - val_accuracy: 0.8533\n",
      "Epoch 40/59\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.1760 - accuracy: 0.9428 - val_loss: 0.6355 - val_accuracy: 0.8133\n",
      "Epoch 41/59\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.2016 - accuracy: 0.9327 - val_loss: 0.7465 - val_accuracy: 0.7867\n",
      "Epoch 42/59\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.2246 - accuracy: 0.9226 - val_loss: 0.9868 - val_accuracy: 0.6800\n",
      "Epoch 43/59\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1728 - accuracy: 0.9529 - val_loss: 0.8473 - val_accuracy: 0.8133\n",
      "Epoch 44/59\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.1677 - accuracy: 0.9394 - val_loss: 0.9153 - val_accuracy: 0.7200\n",
      "Epoch 45/59\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.1453 - accuracy: 0.9495 - val_loss: 0.6753 - val_accuracy: 0.8400\n",
      "Epoch 46/59\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.1608 - accuracy: 0.9529 - val_loss: 0.8027 - val_accuracy: 0.8133\n",
      "Epoch 47/59\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1704 - accuracy: 0.9630 - val_loss: 0.6448 - val_accuracy: 0.8667\n",
      "Epoch 48/59\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.1308 - accuracy: 0.9630 - val_loss: 0.6102 - val_accuracy: 0.8533\n",
      "Epoch 49/59\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.0992 - accuracy: 0.9798 - val_loss: 0.6511 - val_accuracy: 0.8400\n",
      "Epoch 50/59\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.0899 - accuracy: 0.9697 - val_loss: 0.6495 - val_accuracy: 0.8533\n",
      "Epoch 51/59\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.0626 - accuracy: 0.9798 - val_loss: 0.7247 - val_accuracy: 0.8533\n",
      "Epoch 52/59\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1036 - accuracy: 0.9630 - val_loss: 0.6751 - val_accuracy: 0.8533\n",
      "Epoch 53/59\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.0976 - accuracy: 0.9630 - val_loss: 0.7222 - val_accuracy: 0.8533\n",
      "Epoch 54/59\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.1127 - accuracy: 0.9663 - val_loss: 0.7725 - val_accuracy: 0.8400\n",
      "Epoch 55/59\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.0832 - accuracy: 0.9731 - val_loss: 0.6001 - val_accuracy: 0.8400\n",
      "Epoch 56/59\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.0955 - accuracy: 0.9764 - val_loss: 0.6410 - val_accuracy: 0.8400\n",
      "Epoch 57/59\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.1016 - accuracy: 0.9596 - val_loss: 0.7438 - val_accuracy: 0.8533\n",
      "Epoch 58/59\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.0863 - accuracy: 0.9697 - val_loss: 0.6140 - val_accuracy: 0.8533\n",
      "Epoch 59/59\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.1195 - accuracy: 0.9697 - val_loss: 0.6516 - val_accuracy: 0.8667\n",
      "3/3 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8817204301075269"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_CNN_model = create_best_CNN_model()\n",
    "\n",
    "best_CNN_model.fit(feature_train, y_train, epochs=59, batch_size=90, validation_data=(feature_val, y_val))\n",
    "\n",
    "y_pred_best_CNN = best_CNN_model.predict(feature_test)\n",
    "y_pred_best_CNN_class = np.argmax(y_pred_best_CNN, axis=1)\n",
    "\n",
    "accuracy_score(y_test_class, y_pred_best_CNN_class)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_RNN_model():\n",
    "    RNN = Sequential()\n",
    "    RNN.add(Embedding(len(word_index) + 1, word_dimension, weights=[embedding_matrix], input_length = maxlen, trainable=False))\n",
    "\n",
    "    RNN.add(Bidirectional(LSTM(word_dimension)))\n",
    "    RNN.add(Dense(word_dimension, activation='relu'))\n",
    "    RNN.add(Dense(4, activation='sigmoid'))\n",
    "    RNN.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "    #RNN.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "    \n",
    "    return RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN_model = create_RNN_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "19/19 [==============================] - 5s 66ms/step - loss: 1.2195 - accuracy: 0.4983 - val_loss: 1.0080 - val_accuracy: 0.5867\n",
      "Epoch 2/50\n",
      "19/19 [==============================] - 1s 36ms/step - loss: 0.9363 - accuracy: 0.6296 - val_loss: 0.8367 - val_accuracy: 0.6667\n",
      "Epoch 3/50\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 0.7396 - accuracy: 0.7306 - val_loss: 0.7466 - val_accuracy: 0.6800\n",
      "Epoch 4/50\n",
      "19/19 [==============================] - 1s 35ms/step - loss: 0.6051 - accuracy: 0.7946 - val_loss: 0.7185 - val_accuracy: 0.8000\n",
      "Epoch 5/50\n",
      "19/19 [==============================] - 1s 35ms/step - loss: 0.5036 - accuracy: 0.8350 - val_loss: 0.7619 - val_accuracy: 0.7333\n",
      "Epoch 6/50\n",
      "19/19 [==============================] - 1s 36ms/step - loss: 0.4890 - accuracy: 0.8519 - val_loss: 0.6560 - val_accuracy: 0.8267\n",
      "Epoch 7/50\n",
      "19/19 [==============================] - 1s 35ms/step - loss: 0.4332 - accuracy: 0.8552 - val_loss: 0.6980 - val_accuracy: 0.8133\n",
      "Epoch 8/50\n",
      "19/19 [==============================] - 1s 37ms/step - loss: 0.3859 - accuracy: 0.8687 - val_loss: 0.6846 - val_accuracy: 0.8267\n",
      "Epoch 9/50\n",
      "19/19 [==============================] - 1s 37ms/step - loss: 0.3777 - accuracy: 0.8788 - val_loss: 0.6808 - val_accuracy: 0.8000\n",
      "Epoch 10/50\n",
      "19/19 [==============================] - 1s 44ms/step - loss: 0.3305 - accuracy: 0.8990 - val_loss: 0.6744 - val_accuracy: 0.8400\n",
      "Epoch 11/50\n",
      "19/19 [==============================] - 1s 55ms/step - loss: 0.3447 - accuracy: 0.8923 - val_loss: 0.6884 - val_accuracy: 0.8000\n",
      "Epoch 12/50\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 0.3137 - accuracy: 0.8956 - val_loss: 0.6618 - val_accuracy: 0.8533\n",
      "Epoch 13/50\n",
      "19/19 [==============================] - 1s 44ms/step - loss: 0.2487 - accuracy: 0.9327 - val_loss: 0.7314 - val_accuracy: 0.7733\n",
      "Epoch 14/50\n",
      "19/19 [==============================] - 1s 43ms/step - loss: 0.2485 - accuracy: 0.9259 - val_loss: 0.6744 - val_accuracy: 0.8400\n",
      "Epoch 15/50\n",
      "19/19 [==============================] - 1s 60ms/step - loss: 0.2285 - accuracy: 0.9360 - val_loss: 0.6505 - val_accuracy: 0.7867\n",
      "Epoch 16/50\n",
      "19/19 [==============================] - 1s 51ms/step - loss: 0.2397 - accuracy: 0.9259 - val_loss: 0.8224 - val_accuracy: 0.7867\n",
      "Epoch 17/50\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 0.2209 - accuracy: 0.9259 - val_loss: 1.0904 - val_accuracy: 0.7067\n",
      "Epoch 18/50\n",
      "19/19 [==============================] - 1s 46ms/step - loss: 0.2639 - accuracy: 0.9057 - val_loss: 0.6009 - val_accuracy: 0.8133\n",
      "Epoch 19/50\n",
      "19/19 [==============================] - 1s 43ms/step - loss: 0.1665 - accuracy: 0.9495 - val_loss: 0.6157 - val_accuracy: 0.8133\n",
      "Epoch 20/50\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 0.1453 - accuracy: 0.9461 - val_loss: 0.8142 - val_accuracy: 0.8000\n",
      "Epoch 21/50\n",
      "19/19 [==============================] - 1s 55ms/step - loss: 0.1730 - accuracy: 0.9495 - val_loss: 0.6513 - val_accuracy: 0.8400\n",
      "Epoch 22/50\n",
      "19/19 [==============================] - 1s 44ms/step - loss: 0.1104 - accuracy: 0.9663 - val_loss: 0.6689 - val_accuracy: 0.8400\n",
      "Epoch 23/50\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 0.1006 - accuracy: 0.9731 - val_loss: 0.6700 - val_accuracy: 0.8267\n",
      "Epoch 24/50\n",
      "19/19 [==============================] - 1s 42ms/step - loss: 0.0983 - accuracy: 0.9731 - val_loss: 0.6659 - val_accuracy: 0.8267\n",
      "Epoch 25/50\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 0.0791 - accuracy: 0.9764 - val_loss: 0.6808 - val_accuracy: 0.8667\n",
      "Epoch 26/50\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 0.0705 - accuracy: 0.9832 - val_loss: 0.6871 - val_accuracy: 0.8400\n",
      "Epoch 27/50\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 0.0683 - accuracy: 0.9865 - val_loss: 0.6641 - val_accuracy: 0.8667\n",
      "Epoch 28/50\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 0.0516 - accuracy: 0.9899 - val_loss: 0.6897 - val_accuracy: 0.8667\n",
      "Epoch 29/50\n",
      "19/19 [==============================] - 1s 44ms/step - loss: 0.0514 - accuracy: 0.9865 - val_loss: 0.6731 - val_accuracy: 0.8667\n",
      "Epoch 30/50\n",
      "19/19 [==============================] - 1s 39ms/step - loss: 0.0446 - accuracy: 0.9899 - val_loss: 0.6689 - val_accuracy: 0.8533\n",
      "Epoch 31/50\n",
      "19/19 [==============================] - 1s 39ms/step - loss: 0.0400 - accuracy: 0.9865 - val_loss: 0.7108 - val_accuracy: 0.8667\n",
      "Epoch 32/50\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 0.0728 - accuracy: 0.9697 - val_loss: 0.7251 - val_accuracy: 0.8400\n",
      "Epoch 33/50\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 0.0807 - accuracy: 0.9764 - val_loss: 0.8081 - val_accuracy: 0.8133\n",
      "Epoch 34/50\n",
      "19/19 [==============================] - 1s 50ms/step - loss: 0.0929 - accuracy: 0.9663 - val_loss: 0.7402 - val_accuracy: 0.8267\n",
      "Epoch 35/50\n",
      "19/19 [==============================] - 1s 38ms/step - loss: 0.0571 - accuracy: 0.9899 - val_loss: 0.8730 - val_accuracy: 0.8533\n",
      "Epoch 36/50\n",
      "19/19 [==============================] - 1s 42ms/step - loss: 0.0420 - accuracy: 0.9865 - val_loss: 0.7759 - val_accuracy: 0.8400\n",
      "Epoch 37/50\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 0.0398 - accuracy: 0.9899 - val_loss: 0.8211 - val_accuracy: 0.8400\n",
      "Epoch 38/50\n",
      "19/19 [==============================] - 1s 43ms/step - loss: 0.0368 - accuracy: 0.9899 - val_loss: 0.7989 - val_accuracy: 0.8400\n",
      "Epoch 39/50\n",
      "19/19 [==============================] - 1s 38ms/step - loss: 0.0278 - accuracy: 0.9899 - val_loss: 0.8144 - val_accuracy: 0.8533\n",
      "Epoch 40/50\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 0.0227 - accuracy: 0.9966 - val_loss: 0.8114 - val_accuracy: 0.8667\n",
      "Epoch 41/50\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 0.0207 - accuracy: 0.9933 - val_loss: 0.8221 - val_accuracy: 0.8400\n",
      "Epoch 42/50\n",
      "19/19 [==============================] - 1s 39ms/step - loss: 0.0238 - accuracy: 0.9933 - val_loss: 0.8022 - val_accuracy: 0.8667\n",
      "Epoch 43/50\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 0.0198 - accuracy: 0.9966 - val_loss: 0.8223 - val_accuracy: 0.8533\n",
      "Epoch 44/50\n",
      "19/19 [==============================] - 1s 44ms/step - loss: 0.0170 - accuracy: 0.9966 - val_loss: 0.8387 - val_accuracy: 0.8533\n",
      "Epoch 45/50\n",
      "19/19 [==============================] - 1s 43ms/step - loss: 0.0171 - accuracy: 0.9933 - val_loss: 0.8440 - val_accuracy: 0.8667\n",
      "Epoch 46/50\n",
      "19/19 [==============================] - 1s 64ms/step - loss: 0.0180 - accuracy: 0.9933 - val_loss: 0.8456 - val_accuracy: 0.8533\n",
      "Epoch 47/50\n",
      "19/19 [==============================] - 1s 45ms/step - loss: 0.0154 - accuracy: 0.9966 - val_loss: 0.8509 - val_accuracy: 0.8400\n",
      "Epoch 48/50\n",
      "19/19 [==============================] - 1s 45ms/step - loss: 0.0164 - accuracy: 0.9966 - val_loss: 0.8622 - val_accuracy: 0.8533\n",
      "Epoch 49/50\n",
      "19/19 [==============================] - 1s 48ms/step - loss: 0.0167 - accuracy: 0.9966 - val_loss: 0.8610 - val_accuracy: 0.8667\n",
      "Epoch 50/50\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 0.0158 - accuracy: 0.9966 - val_loss: 0.8593 - val_accuracy: 0.8533\n"
     ]
    }
   ],
   "source": [
    "RNN_history = RNN_model.fit(feature_train, y_train, epochs=50, batch_size=16, validation_data=(feature_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.figure(figsize=(9,6))\n",
    "plt.plot(RNN_history.history['accuracy'])\n",
    "plt.plot(RNN_history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAikAAAGDCAYAAADu/IALAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABXkklEQVR4nO3dd3zV5fn/8dd9TvYmIQFCEobsjYQhDtzbqnXXUW2to3W0/dpau7S1/dWqrdbW1lpXbV24qtYNVRAXBIQIsncIIyRkQHZy//64TyBAds7JOUnez8cjj3PO53zO51w5jFy57+u+bmOtRURERCTUeIIdgIiIiEhTlKSIiIhISFKSIiIiIiFJSYqIiIiEJCUpIiIiEpKUpIiIiEhIUpIiIl3OGDPYGGONMWFtOPdqY8yCzl5HRLofJSki0iJjzCZjTLUxpu8hx5f6EoTBQQpNRHo4JSki0hYbgcsaHhhjxgPRwQtHRHoDJSki0hb/Aq5q9PibwNONTzDGJBpjnjbGFBhjNhtjfm6M8fie8xpj7jfG7DbGbADOauK1jxtjthtjthljfmOM8bY3SGNMujHmdWNMkTFmnTHmO42em2aMyTHGlBpjdhpj/ug7HmWM+bcxptAYU2yMWWSM6dfe9xYR/1OSIiJt8RmQYIwZ7UseLgH+fcg5fwYSgaHALFxSc43vue8AZwOTgWzgwkNe+0+gFhjmO+dU4NoOxPkckAek+97j/xljTvI99yfgT9baBOAIYLbv+Dd9cWcCKcANQEUH3ltE/ExJioi0VcNoyinAKmBbwxONEpc7rLVl1tpNwB+AK32nXAw8aK3daq0tAn7X6LX9gDOA71tr91lrdwEPAJe2JzhjTCZwDHC7tbbSWrsUeKxRDDXAMGNMX2vtXmvtZ42OpwDDrLV11trF1trS9ry3iASGkhQRaat/Ad8AruaQqR6gLxABbG50bDMw0Hc/Hdh6yHMNBgHhwHbfdEsx8HcgrZ3xpQNF1tqyZmL4NjACWOWb0jm70ff1LvC8MSbfGHOvMSa8ne8tIgGgJEVE2sRauxlXQHsm8MohT+/GjUgManQsiwOjLdtx0ymNn2uwFagC+lprk3xfCdbase0MMR9INsbENxWDtXattfYyXPLze+AlY0ystbbGWvsra+0YYCZuWuoqRCTolKSISHt8GzjRWruv8UFrbR2uxuO3xph4Y8wg4IccqFuZDdxijMkwxvQBftLotduB94A/GGMSjDEeY8wRxphZ7QnMWrsV+AT4na8YdoIv3mcAjDFXGGNSrbX1QLHvZXXGmBOMMeN9U1aluGSrrj3vLSKBoSRFRNrMWrveWpvTzNM3A/uADcAC4FngCd9z/8BNqSwDlnD4SMxVuOmir4A9wEvAgA6EeBkwGDeq8ipwp7X2fd9zpwMrjDF7cUW0l1prK4H+vvcrBVYC8zi8KFhEgsBYa4Mdg4iIiMhhNJIiIiIiIUlJioiIiIQkJSkiIiISkpSkiIiISEhSkiIiIiIhKSzYAbRX37597eDBg4MdhoiIiPjB4sWLd1trU5t6rtslKYMHDyYnp7k2DSIiItKdGGM2N/ecpntEREQkJClJERERkZCkJEVERERCUrerSWlKTU0NeXl5VFZWBjuUgIuKiiIjI4PwcO0kLyIiPVuPSFLy8vKIj49n8ODBGGOCHU7AWGspLCwkLy+PIUOGBDscERGRgOoR0z2VlZWkpKT06AQFwBhDSkpKrxgxEhER6RFJCtDjE5QGveX7FBER6TFJSjAVFhYyadIkJk2aRP/+/Rk4cOD+x9XV1S2+Nicnh1tuuaWLIhUREek+ekRNSrClpKSwdOlSAO666y7i4uK47bbb9j9fW1tLWFjTH3V2djbZ2dldEaaIiEi3opGUALn66qv54Q9/yAknnMDtt9/OwoULmTlzJpMnT2bmzJmsXr0agA8//JCzzz4bcAnOt771LY4//niGDh3KQw89FMxvQUREJKh63EjKr95YwVf5pX695pj0BO48Z2y7X7dmzRrmzJmD1+ultLSU+fPnExYWxpw5c/jpT3/Kyy+/fNhrVq1axQcffEBZWRkjR47kxhtv1HJjERHplXpcktJR9dYC4PFjYepFF12E1+sFoKSkhG9+85usXbsWYww1NTVNvuass84iMjKSyMhI0tLS2LlzJxkZGX6LSUREpLvocUlKR0Y8ADYU7KXeWoalxfstltjY2P33f/GLX3DCCSfw6quvsmnTJo4//vgmXxMZGbn/vtfrpba21m/xiIiIdCeqSfGJCPNQXVsfsOuXlJQwcOBAAJ566qmAvY+IiEhPEbAkxRjzhDFmlzFmeTPPX26MyfV9fWKMmRioWNoiIsxDbb2lrj4wicqPf/xj7rjjDo4++mjq6uoC8h4iIiI9ibG+Wgy/X9iY44C9wNPW2nFNPD8TWGmt3WOMOQO4y1o7vbXrZmdn25ycnIOOrVy5ktGjR3cq3pLyajYXlTM8LY7oiNCeBfPH9ysiIhIKjDGLrbVN9uII2EiKtXY+UNTC859Ya/f4Hn4GBLU6NCLMfRSBnPIRERGRtguVmpRvA28396Qx5jpjTI4xJqegoCAgAexPUuqUpIiIiISCoCcpxpgTcEnK7c2dY6191Fqbba3NTk1NDUgcXo8Hr8doJEVERCREBLX4whgzAXgMOMNaWxjMWMCNplQpSREREQkJQRtJMcZkAa8AV1pr1wQrjsYivB5qNN0jIiISEgI2kmKMeQ44HuhrjMkD7gTCAay1jwC/BFKAvxrX5bW2uererhIZ5qG0ohZrLcaPnWdFRESk/QKWpFhrL2vl+WuBawP1/h0REebBYqmpqycizNvm1xUWFnLSSScBsGPHDrxeLw21MwsXLiQiIqLF13/44YdEREQwc+bMjgcvIiLSw4R2Q5AuFuE9sAy5PUlKSkoKS5cuBdxOxnFxcdx2221tfv2HH35IXFyckhQREZFGgr66J5T4cxny4sWLmTVrFlOmTOG0005j+/btADz00EOMGTOGCRMmcOmll7Jp0yYeeeQRHnjgASZNmsRHH33U6fcWERHpCXreSMrbP4EdX3bopeFYhlbVERFmwNtoJKX/eDjjnjZfx1rLzTffzGuvvUZqaiovvPACP/vZz3jiiSe455572LhxI5GRkRQXF5OUlMQNN9zQ7tEXERGRnq7nJSmdYDB4DNR3cqeAqqoqli9fzimnnAJAXV0dAwYMAGDChAlcfvnlnHfeeZx33nmdjFhERKTn6nlJSjtGPJqyo2AvddYyPC2+w9ew1jJ27Fg+/fTTw5578803mT9/Pq+//jp33303K1as6Ey4IiIiPZZqUg4RGebpdNfZyMhICgoK9icpNTU1rFixgvr6erZu3coJJ5zAvffeS3FxMXv37iU+Pp6ysjJ/hC8iItJjKEk5RESYh7p6S219xxMVj8fDSy+9xO23387EiROZNGkSn3zyCXV1dVxxxRWMHz+eyZMn84Mf/ICkpCTOOeccXn31VRXOioiINNLzpns6qWGFT01tPWER7c/h7rrrrv3358+ff9jzCxYsOOzYiBEjyM3Nbfd7iYiI9GQaSTlE414pIiIiEjxKUg7RMJJSpT18REREgkpJyiG8Hg9hHqORFBERkSDrMUmKtZ1sbtJIhB9W+ASKP79PERGRUNYjkpSoqCgKCwv99gM8wuv1S2t8f7PWUlhYSFRUVLBDERERCbgesbonIyODvLw8CgoK/HK9kooa9lbWUl8UhTHGL9f0l6ioKDIyMoIdhoiISMD1iCQlPDycIUOG+O16Lyzawu2vf8lHPz6BzOQYv11XRERE2q5HTPf4W0NisqWoPMiRiIiI9F5KUpowKCUWUJIiIiISTEpSmtA/IYpwr2FzoZIUERGRYFGS0gSvx5DRJ4atGkkREREJGiUpzchMjtF0j4iISBApSWlGVnK0khTpnF2rYKN2tRYR6SglKc0YlBxLSUUNJeU1wQ5Fuqu5v4bXvhfsKEREui0lKc3QMmTptMJ1sG93sKMQEem2lKQ0I0tJinRGfR3s2Qg1+6CmMtjRiIh0S0pSmpGVoiRFOqE0H+qq3f2KouDGIiLSTSlJaUZcZBgpsRFKUqRjijYcuF9eGLw4RES6MSUpLchMVq8U6SAlKSIinaYkpQVZyTFsLtoX7DCkOzooSdF0j4hIRyhJaUFWcgz5xZXU1NUHOxTpboo2QHQfd18jKSIiHaIkpQVZyTHU1Vu2F2t1hrRT0QYYOMXd10iKiEiHKElpgVb4SIfU10PRRug7EqISNZIiItJBSlJaoF4p0iF7d0BtBSQPgZgUJSkiIh2kJKUF/RKiiPB6VDwr7dNQNJs8FKKT1SdFRKSDlKS0wOsxZPSJ1jJkaZ+GJCXlCI2kiIh0gpKUVmQmx2i6R9qnaAN4wiEhw5ekaCRFRKQjlKS0YlBKDFsKlaRIOxRtgD6DwBsGMckaSRER6SAlKa3ISo6htLKWkvKaYIci3UXhBlePAi5JqSmHmorgxiQi0g0pSWlFpm+Fj4pnpU2sdSMp+5OUFHerKR8RkXZTktIKLUOWdtm7C2r2NZGkaMpHRKS9lKS0QkmKtMv+5cdHuFslKSIiHRawJMUY84QxZpcxZnkzzxtjzEPGmHXGmFxjzJGBiqVNirdA/tLDDsdGhtE3LkLLkKVt9icpQ9ytkhQRkQ4L5EjKU8DpLTx/BjDc93Ud8LcAxtK6V2+E//6gyacyk2PYrBU+0hZFG8B4ISnLPY5OdrcVe4IXk4hINxWwJMVaOx9oqVrwXOBp63wGJBljBgQqnlZlZMOO3CZXYWSpV4q0VdEGl6B4w91j7YQsItJhwaxJGQhsbfQ4z3csODKnQX0tbF922FNZyTHkF1dQU1cfhMCkWylaf6BoFlyvlKgkJSkiIh0QzCTFNHHMNnmiMdcZY3KMMTkFBQWBiSZjqrvNW3TYU1nJMdRbyC9WrwtpgbVu9+PGSQqoNb6ISAcFM0nJAzIbPc4A8ps60Vr7qLU221qbnZqaGpho4tIgaRBsXXjYU1rhI21SXghVpU0kKeo6KyLSEcFMUl4HrvKt8pkBlFhrtwcxHjeakpdz2OGsFF9DNxXPSksabyzYmPbvERHpkEAuQX4O+BQYaYzJM8Z82xhzgzHmBt8pbwEbgHXAP4DvBiqWNsucBmX5UJJ30OF+8VFEhHm0DFlatn/5cVPTPUpSRETaKyxQF7bWXtbK8xb4XqDev0Ma16UkZuw/7PEYMvtEa7pHWla0AYznwPLjBpruERHpEHWcbazfOAiLgq1NF88qSZEWFW1wyW1Y5MHHY1KgtgKq9fdHRKQ9lKQ0FhYB6ZObXeGzpbAcNwAk0oTC9YdP9UCjhm6a8hERaQ8lKYfKyIbtS6G26qDDmckxlFXVUlxeE5y4JPQ13v24MbXGFxHpECUph8qYBnXVsD33oMNahiwtKi+CyuIDGws2piRFRKRDlKQcqpmmboNSYgElKdKMoo3utsWRFE33iIi0h5KUQyUMgMRMyDu4qVtmcjSgJEWa0dzyY3Cre0AjKSIi7aQkpSkZ2Yc1dYuJCKNvXKR6pUjTijYABvoMPvy5qCT3nEZSRETaRUlKUzKmQclWKD24AW5WcrS6zkrTijZAwkAIjzr8OW8YRCdpJEVEpJ2UpDSlhboUTfdIk4rWQ/KQ5p/XJoMiIu2mJKUpAyaAN6KJupQYtpdUUF1bH6TAJGQ1t/y4gZIUEZF2U5LSlLBIGDDpsLqUoX1jqbewqXBfcOKS0FRR7BKQQzcWbCw6WTUpIiLtpCSlORlTIf8LqK3ef2hMegIAK/JLghWVhKI9LSw/bhCToo6zIiLtpCSlOZlTobYSdi7ff2ho31giwzys2FYaxMAk5LS0/LhBwyaD2lZBRKTNlKQ0p4ni2TCvh1EDEliukRRprCFJaWr5cYOYFJf01qjwWkSkrZSkNCcxA+LTD1vhMzY9ga/yS7XRoBxQtBHiB0BEbPPnqKGbiEi7KUlpSUY2bD14hc+49ERKK2vJ21MRpKAk5DS3+3Fjao0vItJuSlJakjkNijfD3l37D41V8awcqrXlx6BNBkVEOkBJSkuaqEsZ2T8er8ewIl/FswJUlcG+XRpJEREJACUpLRkwETzhB035RIV7GZYax/JtGkkRWt79uDGNpIiItJuSlJaER0P/8Yc1dRubnqCRFHHasvwYICoRt8mgkhQRkbZSktKazGmQvwTqavcfGjswkV1lVRSUVQUxMAkJ+5OUFvbtAfB4IbqPGrqJiLSDkpTWZEx1vS12rdh/SMWzsl/RBohNg8j41s/V/j0iIu2iJKU1DcWzjepSDrTH15RPr1e0sfWpngZKUkRE2kVJSmuSsiCu30F1KQlR4WQlx2gkRaBofcsbCzYWo00GRUTaQ0lKa4xxoyl5Bzd1U/GsUL0Pyra3Xo/SQEmKiEi7KElpi4yprvZg34Gh+nEDE9lcWE5pZU0QA5Og2rPJ3bZ3ukdbKkiwWQtPnQ2fPxrsSERapCSlLZpo6tZQl7JSoym9V1uXHzeISYG6KjcCIxJMu1bCpo/g4wehvi7Y0Yg0KyzYAXQL6ZPBeF2SMvJ04MAKn+X5pUwfmhLM6CRY9u9+3NbpnkYN3SLjAhOTSFuse9/dlm6D9f+D4acENx7xv/p62Pkl7CuAsCjfV2TTt94IV9oQgpSktEVEDPQfd1BdSlp8FKnxkSqe7c2KNrjEIzqpbedHN9oJuc+ggIUl0qq170PfEa5GasnTSlJ6iup9sGEerHkH1rwLe3e08YXG7eIeEQvhMc3fn3I1pE8K4DdwOCUpbZUxDZY954ZGPV7AjaZ8peme3qtoAyS3cWUPHBhJUUM3CaaqMtjyGcy4EWw9fP4I7C2AuNRgRyYdUbwV1r4Lq9+BjfPdlHJEPAw7CUac7qaj66qgtgpqK91tTcWB+7WV7qu6HKr3ur5gDfer97oNdhuOjzyjy789JSltlTEVFv3DzeX2HwfAuPREPlq7m8qaOqLCvUEOULpc4QYYfEzbz9cmgxIKNsyD+ho3ehLXDz79i/sF7Ohbgh2ZtMRalzAUbXBfu1fDurmwc7l7vs8QmPptGHEaZM2EsIjgxusnSlLaKrOheHbh/iRlbHoCdfWWNTvLmJCRFLzYpOvVVEBpXtuLZsEtQQY1dJPgWvc+RMRB5gz3gyxzhpvymXlzyNYl9Gi11VCzz41e1JS7KZuKPbBno2sWWbTBrSQs2ujOa+AJc392p9ztRkz6Du+Rf35KUtqqzxD3m3BeDmR/C4Cx6YkALN9WqiSlt9mz2d22J0mJSgLjUZIiwWMtrJ0DQ48/8Jv2kVfCa9+DrZ9D1oyghtejVOzxjXo0SjaKNrhC1oYplZp9UF/b/DW8Ee5nT/IQGHKc+/+m4XFSFnjDu+77CRIlKW1ljKtLadQePzM5mvioMBXP9kbtXX4M4PG4TQaVpEiwFKxyI4DH3Xbg2Jjz4O2fuNEUJSkdU7odlj3rygEakpGKPQefkzDQ/X+RPulAQWp4jO9+zMHHohKhz2BISN9fA9lbKUlpj8ypsOZtKNsB8f0xxjBmgDrP9kpt3f34UDEpqkmR4FnrW3rceDVPZByMvwByZ8Ppv3M/IKVtti5yhcdf/cctqkjKconI2PPdbcNXn8EQHh3saLslJSntMfpcmPtrWPIvmPUjwHWefebzzdTVW7yenjcfKM0o2uCmbxrqTNpKmwxKMK17H1JHQ2LGwcePvAoWPwXLX94/nS3NqKuBr16Dz/4K2xZDZAJMvwGmfcclI+JX6jjbHn2HwdATIOcJqHPziGPTE6isqWdDwd4gByddqmhD2zcWbEwjKRIsVWWw+VMYfvLhz6UfCWlj3S9g0rR9u2HeffDgeHj521BZAmfeDz9cCaf9VglKgChJaa9p10FZPqx+E2hUPKu6lN6laH376lEaqCZFgmXjfLf0eFgTjduMcaMp+Utgx5ftv3Zpfufj86c9m2HZ81C4vvPX2r3OFRb/cQx88BtIGwOXvwTfW+RGT9Q9OqCUpLTXiNMgMQsW/gOAI1JjiQzzsGKb6lJ6jcpS10ApZXj7XxuT4pq5aZNB6WprfUuPs45q+vkJF4M3sv2jKfPvgz+OhucuO1Cr1dVqKl3PkHfugD9nw58mwKvXw1+mwhu3diyJKs13r314Gix/BSZfAd9bCFe+4mp6PPrx2RVUk9JeHi9M/RbMuQt2rSQsbTSj+sereLY3yV8CWMjIbv9rY1Kgrtp1cIyM929cO1e4ZY0NPX1EGlgL6+bAkFnNN/mKSYbR50DuC3DKryE8qvXrrvgP/O83kDndjdQ8PMP1Wzn2h26lSnvUVsHKN6Bwnft3EpPsu230FRZ54PzC9S4xWfc+bPwIaitckjX4aFdXkzkdcp+HnCfdqMq078AxP2y9jqy8yG28+PnfXTHstO/AsbepI2+QBDRJMcacDvwJ8AKPWWvvOeT5RODfQJYvlvuttU8GMia/mHwVfPA7WPQYnPUHxg5M5L/L8rHWYnpgMx05RMNu2AOntP+1B20y6Ock5e3b3TD3DzowXC89W8FqKNnqkoeWHHklLH8JVv0Xxl/Y8rn5X8CrN7jWDFe97pbczrkTPrrfJQWn3u1WubT2f+KeTS6R+OLfUL675XMj4l2SYS2UbHHHkoe6uIed4jpAR8QcOD9jChz1PfjwHvjkL7D4ny6JmnHj4f/+qve5lToL/gRVpTDhEjjhDtWaBFnAkhRjjBd4GDgFyAMWGWNet9Z+1ei07wFfWWvPMcakAquNMc9Ya6sDFZdfxKbAuAvcP8ST7mRsegLPfr6FvD0VZCbHtP566d62LoK+I9u+sWBjjbvO+vM/v/p62L7M/edasg0SB/rv2hI6FjzoVpZ8652DRxVa07DrcVP1KI0NPg6SBsGSf7acpJRud9M7sX3h0mfcqEv4APj6o24U463b4KVr3CKDM34P/cYe/Pr6Olj7Hix63I3wGAMjz3SvHXwsVBa7fyOHfu3z3dZVwcybYNjJrRew9xkM5z8CR9/qRn0++K0bJTnuNvd+xuO+33n3wt6dLo4Tf354zBIUgRxJmQass9ZuADDGPA+cCzROUiwQb9zwQxxQBLTQfi+ETLvWNe9Z9jxj0y8GYEV+iZKUns5aN5Iy6syOvT5Q+/cUb3YJCsDWzyDxAv9eX4Kvqgw++iNUlbiauJk3tf21a9+H1FGQlNnyeR6PG5X43298G2g2URxeXQ7PX+Zqs779HsSlHfx81gy4bp77wT/31/DIsTD1WjcqUVsNXzztRjRKtkJcf5j1Yzjymwcn1nFph1+3s9JGu4QqLwfm/gre+Ql8+rBrL79no6vVuVgN7UJNICt/BgJbGz3O8x1r7C/AaCAf+BK41VpbH8CY/GfgFPe16B+M6heH12NUl9IbFG1wha8ZHaz7CFSSsiP3wP0tn/n32hIalvzLJSh9R8L8e9v+d6hqL2z51I06tMWky93owhf/Pvw5a+G170L+Urjgsf37mB3G43WjFDcvgexr3Oasf5oID4xxCVDyUJcQ/GA5nPDTrh35y8iGb74BV73musDGJMM3XoRr3laCEoICmaQ0NRF56JKG04ClQDowCfiLMSbhsAsZc50xJscYk1NQUODvODtu6ndg9xqi8hZwRGqskpTeoKEepcNJSoA2GdyeC8brNhxTktLz1NW45mFZM+Gip9yoyrx72/bajfNdsfbwVqZ6GiSku2mhL57Z3w9qv3m/hxWvwim/attoYkwynPUHuH4+HHEiTLsebloM33wdxpwb3L1nhh4P334XvvM/GHFqj9ycrycIZJKSBzQeW8zAjZg0dg3winXWARuBUYdeyFr7qLU221qbnZoaQhXWY893vxkv/Afj0hO1h09vkLfIFe+lHvbXtG0iE10y4e8kZUcupI6EobPc1u1VZf69vgTXiv+46ZGjb4F+Y2DylW50oi19QNa9D+GxzS89bsqRV8HeHa5epMHyl+HD38HEb8DMW9oXf//xLrk6/f+5ppgibRTIJGURMNwYM8QYEwFcCrx+yDlbgJMAjDH9gJFAkBbad0B4lPvHvPotpibvY2dpFQVlVcGOSgIpbxEMPLLjm34FapPB7bnQf4Ibrrb1B0Z8pPuzFj55CPqOgOGnuWMn/Mwtt51zZ+uvXTvHJa/tKbQdcRrEprlNB8G1f//Pd91I3TkPatRBukzAkhRrbS1wE/AusBKYba1dYYy5wRhzg++0u4GZxpgvgbnA7dbaVtaghRjfPhfHlrwBoNGUnqx6H+xY3vGpngYNDd38Ze8u91vvgAkuNuPRlE9PsnGeGyk76qYDDcTi+8Ex33d9RTZ/0vxrd69xS3XbWo/SwBsOky6DNe+4BOW5b7hC1kufaV+yI9JJAW2ZZ619y1o7wlp7hLX2t75jj1hrH/Hdz7fWnmqtHW+tHWetbaJSK8QlZcGIM0hfP5tIqlWX0pPlLwVbB5nTOncdf+/f01A023+C6/3Qb5ySlJ7k44fcqMaESw4+ftRNEJ8O7/7MLUFvSlO7HrfV5Kvc3/cnz3TNBy97wS05FulC6uvrD9OuxVNRyJUJX/CVkpSea38Ttw50mm0sJtm/0z3bG5KU8e42a4ZbZnlo0aN0PzuWw/q5MP36wzvARsTASb9wHZBXvNL069e971YDJWW1/737DoNBR7tOsBc+4WphRLqYkhR/GHI8pAzncvOepnt6srxFbulkbErnruPvJGVHrvsh1NBcLmsG1OyDneo82+19+hdX9OqbVj7MhEtdcjrnV27/msaq9rqpoI6MojQ4/+9w9ZuuRkUkCJSk+IPHA1OvZUjVSuKLllNaWRPsiMTfGpq4dbYeBXzTPYX+22SwoWi2Qaav18OWz/1zfQmOkm3w5YuuuVpz+814PHDqb13dyeePHPzcpo/c0uP21qM0lpTp9sIRCRIlKf4y6TJqw2K4yvseK/015VOw2rVv1o65wVey1bXM9leSUl/rn2XCVWVQtB4GTDxwLHGg26l7y6edv74Ez+ePuH/7M77b8nlDZ8GI0+GjP8C+RusO1s1xozCDZgY2TpEAUpLiL1GJVI+5iK95P2Xdpi2dv17xVvjn1+DtH7v6AgmurQvdrb+SFPDPlM/OFe628UgKQNZ02Pq5EtzuqrIUFj8FY8+DPoNaP/+UX7vVZx/69nC11hXNDjlOq3GkW1OS4kcxR99ApKkhcdXznbtQZQk8ezHUlENYlNs6XYIrLwfCov2z6Zg/W+M3FM0OOCRJyZwOZdvdnj7S/Sx+yu3FNPPmtp2fOhKmXO029Nu9FgrXuT/74Z2Y6hEJAUpS/KnfGFZFTiB79ytul8+OqK2GF650/Q0u+Zcbxl3ximuLLcHT0MTNH228o/3YGn/HMojpC/EDDj7e0F1UdSndT201fPY3txtw+uS2v+74OyA8Bt7/5YGlx63teiwS4pSk+NnqQZfSv34XNR//uf1D7dbCG7e65k1f+4vbW2LCJe6H2fr/BSReaYOaSti+zG1M5g/+3L9ne65b3XFoB9C00RCZoLqU7mjFK1CWD0ff2r7XxaXCsT+E1W+53X37jmjbVJFICFOS4mcRY8/hg7qJhM+9E176lptbbqsP74Flz8LxP3XdHsFV5kf3gdzZgQlYWrcjF+pr/FOPAgemezrbdba2GnatPHyqB1zb/sxpri5Fug9rXfO2tDEdW5Uz40ZIzITSPI2iSI+gJMXPxmb05Vs1P+KLEbfCV6/B34+FbUtaf+EXz8C8e9w26bN+fOB4WITbyHDVm9o0Llg6u/PxoaL8tMlgwSqXPB1aNNsgcwbs+goq9nTufaTrrJ8Lu1a4brId2R8nPBpOvsvdb8suxSIhTkmKn2UmRzMgMYa/150L17zlun4+fqqbY25u+mf9B/DGLTD0BDjnT4f/5zT+YqitcImKNC2QNTtbF7olvfH9/XM9Yw70SumMHb5mbY2XHzeW5euXslWbDXYbn/zZ1ReNv6jj1xh/Idy6DAYf47+4RIJESYqfGWOYNTKVj9ftpmbgNLjhIzds+85P4PlvHL6iY+cKmH2Va1198dNNF2ZmTncdRbXKp2nV++Dh6fDG9wNz/bwc/9WjNPBH19kdua4PRvLQpp8fOAU8YapL6S62L4MNH8L0G9wIamf0GeyPiESCTklKAMwakUZZVS1fbCl2P4wuew5O+52ruH/k2AMrLkrz4ZmLICIOLn8RohKavqDH436z2vAhlO3sqm+j+/jsr66h2eInYfU7/r12ab6b3+/spoKHikmB8k5Ow2zPdUuiPd6mn4+IcaMsqksJfaXbYe7dEBEP2dcEOxqRkKEkJQBmDkshzGOYt2aXO2AMHPVd+PZ74A2DJ8+AeffBMxe7wtrLZ7suoS0ZfzHY+uY3Euut9u2GBX+C4adB2lj47/f9W4Ph73qUBp0dSamvd9M9TRXNNpY5A7YtdkW2Elpqq2DFf9wvKg+McZsBHvN9V7MkIoCSlIBIiArnyEF9mLem4OAnBh4J18+HMV+DD37jihov/ueB3WtbkjbKFUhqyudg8+51Te9O/Q2c9zDs3eW2rveXvEXgjWjbn1F7dLYmZc9GqC5rvmi2QdZ0qPUtoZbgsxbyl8JbP4Y/jIQXv+l2Oj7mB3DTYjjutmBHKBJSwoIdQE81a0Qq9727ml1llaTFN9piPSoRLnwSRp7lpneGndT2i064BN77meso2Xe4/4Puboo2uA6bR14JqSPcsWN+AB/dD2POgxGndv498nLclIm/W4tHJx/YZLAjqzj2F822YSQFXF1Kpp9Hg6Tt9u12bQSWPgM7l4M3EkafDZO+4Qrmm5uyE+nlNJISILNGpALw0Zrdhz9pDEy4qP3bn4+7ADDqmdJg7t2u0Pj4Ow4cm/VjSB3tmuJVFHfu+rXVkP8FZPi5HgXcSIqtc1sgdMSOXFcUmzam5fPi+0GfIapLCaa1c+CPY+DdO9yo3Fl/gNtWw4VPuKJ6JSgizVKSEiBjBiTQNy7y8CmfzkgY4HY8/XK2No7bttjV5xz1vYOXBodFwnl/dTsWv9fJaZ+dy91Uib9X9kDnG7ptz4XUUW0b4ck6CrZ8pr8zwZCXA7OvdHvrfPczuO4DmHqta9AoIq1SkhIgHo/huBF9+WhtAXX1fvzhMP5i2LPpQEFnb2QtvH+n+0E/85bDnx94JBx9C3zxb/dbbEc17D7t76JZ6Pwmgzty214nkzUdyndD4fqOvZd0zO61rig2Lg2ueNltVSAi7aIkJYBmjUhlT3kNX27r4JB+U0af49sZuR1TPnU18OoN8OwlkPui6yvSna19HzZ9BLN+0vyy7Vk/cb1n3ril41MqeQtdY63EjI7H2pz9SUoHimfLdrqRotaKZhs0bDa49bP2v5d0TOl2+NfX3VTOFa+4REVE2k1JSgAdOzwVY2Deaj9O+UQlwMgz2r4zsrXw+i2w7DlXX/HKtXDfMHj5WljzbvfbXbm+Dubc6eosplzd/HnhUW7ap2w7vPeLjr1X3iI31dORwtbWxPiG+zuSpOzIdbetFc02SBnuphfU1K1rVBTDvy9wU3mXvwgpRwQ7IpFuS0lKACXHRjAhI+lAvxR/ac/OyHPucpsWnvAz+OEquOZtmHgprJsDz14M949wnVo3fex6b3SVulpY8x4sf7l977vsebd0+6Rftt6VMyMbZt4MS/4J6+a2L769BW5aLRBTPdC56Z6GJKWt0z0ej1vls6UbF89aCyV5/hkF3PSx61E071735+xPNZWus/TuNXDJvyF9sn+vL9LLaAlygM0akcpf/reW4vJqkmI62eq6wREn+XZGfqHlFUKf/Q0+ftAV6h33IzciMGim+zr997DhA/jyRXedxU9CwkA3SpOU5aY54vtDXH93GxnvnxGFHcvdqE7ubNjnS94GPwnnP9L6tEpNBXzwW0g/0m262BbH/xRWv+1W+9z4SfPTQ4fa38QtACt7ACIT3OqcjoykbM91bc/b0/QrazqsedsthY3t2/737CoNyUjBKrfDc8FqKPDdVu+FmL5w6t0w8bL2/32sLof/3e3+XUT3gbXvwvz73Uq76TdC/3Gdi72+zo1Ubv4YLngcjjihc9cTESUpgTZrRCoPzV3LgnW7OXtCun8uGhYBY78OS591OyNHxh9+zpcvuf2CRn8Nzrj38P/QwyJcgjPiNKja636Qf/kiLH0Oapr4bTU81iUr8QPcKqO+I9zqkrQxkDyk5WWUewvctZc96/p7eMLd+068zA2Jv3MH/G0mnPVHtzlacz5/BEq3wfl/b/sPqPAoOPev8MSp8P4v4ZwH2/a6vEUuiWhu877O6swmgzty216P0qChX8rWz2HUWe1/z0Cx1k1D5c5231dDMtIgNs01Mpz0DTdt9eWL8J8bYcnTbilvv7Fte5+tC93rCtfB1O/AKb+Ckm3u79Sy51yR9ZDjYMZ3XfdiTzsHma2Ft26DlW/A6fe0/PdYRNpMSUqATcxIJDE6nHmrC/yXpABMuBhyHoeV/4VJlx383PoPXKHsoGPg6/9ovQ9DZJz7bXKCb+fVqjIo2+HqOZq63fK5+2HRICzKNZdLG3MgcUkd4X7jX/acK3S1dW7o+4z7XL+X2JQDrx98DLxyPbz8bVjzDpx5P0QnHRxjeRF89ID7ATLk2PZ9VplT3VLlT/4MY85t22+4eYug3zi3/02gRHegNX5lqWtiN/Eb7Xtd+mTXo2PLp6GRpOzb7ZLsJU9D4Vq3f1X6ZJeMpI7y/T0a7bYPaGzqta4h2vu/dPtgzbgRjv9J04k6uOmXD/+f+7NPGAhXvQZDj3fPpY6As/8IJ/7cxbHwH/Dcpa7eafoNMPny5q97qHn3usaCR3/fxSQifqEkJcDCvB6OGd6XeWsKsNZi/FWE2bAz8pezD05S8pfCC1e4kY5Ln3EjCe0VGe++WupqW73P/da7a6WrESlYBZsWHN62P36AqwuZeJn7jbgpyUNdrcyCP8KH98DmT930T+Nk5KM/uDbwJ9/V/u8HXE3O6rddInTGvS5Rau7Poq4Wti1xP6QCKSal/TUpO5e727YWzTYIj3JJQDDrUurr3RTjkqdh1ZtQX+P+Hh/zsJu+i4ht/Roej+swPOosmPsr+PRhV9d02v9z12j8Z5r/hUvWC1bBkVfBqb9terovJtntmXPUTbDqDTcd9M7tbmpx8LFuX62EdEjI8N36vhp61OQ86RKhid/o+N9PEWmSkpQuMGtEKm/mbmfVjjJGD2hjTURrjHE9Uxb80S1Jje/nfsN+5kL3G/oVLx8+GuFPEbGuH8nAIw8+XlHsqyNY5WpMhh7fto6a3jDXLfaIk+CV78A/z3HJzYk/d6M3Cx91PwT6tdJhtTnh0XDpc/DqdS5RWfa8my7oM+jwcwtWuimvQBXNNohJdgWW7dHQDr+90z0AWTPg07+62p7w6KbPsRY2f+JGBfbuhLpqtxFeXbVrbFdbDXVVB27DotwIRUK6mwbcfz/d3Y8f4BLapc/CF09D8Rb393PadS5xaC5xbU1MMpzzJ5h8Jfz3B/DSNS75OfN+l7zPv88ltnFpcPlLMPyU1q/pDXOJztjzXbPAhf9wex5tXtD0MvbYVPf97VwOw0+Frz0UmJVgIr2YkpQu0NAif96aAv8lKeCmfD663/0mOf5C15ehvg6ufMX9wAiG6CRXpJk1vWOvz5gCN3wE7/0cPnnITV3F9wPjgRN+2rnYUkfAtXNdwjP3bvjrDDfCMv0G9wOqwf6i2QB0mm2sIzUp23N9Pxz7t37uoTJnwMd/ciMMg2Ye/Fx9vZtqW/CA6w8Tney6pIZFuQJdb4S7Hxbpu++7ramA0nxXK7Qj123wSDPNC4ce70YaRp3tv72QMrLhug9h0eOuKPZvR0FiJhStd6N3p/+uY91dB06B86cceFy198D3uf/Wd7/fODjrfrdFg4j4lZKULtAvIYpR/eOZt7qAG2b5sWdC6khX2Ln0GTfNsncnfPON7r/5YEQsnP2A++30tZtg55durj9xYOev7fG6moFRZ8Ob/+da5385G855CNInuXO2LnKrSPoM6fz7taRhuqe+vu2FmjuWuVGUjvzGnulLHLd8eiBJqa2G5S+55KVglRuFOPN+mHR5x+pxaqth7w7fD3LfV32N2/AxOUCfp8cL069z9Ubv/8JNF176rH9rbyLjXJLbsJGliHQJJSldZNbIVJ5YsJG9VbXERfrxY59wCbz7UzBeuOy5wP/235VGnuH2O/lyNhz5Tf9eOykTvvECfPUfeOvH8I8T3MqOE37qa+I2NfBD9zHJrqC4qqRtv+3XVsOuVTDz5I69X2yKq1Xa8rkbGVjytKvpKM1zowFff8xNdXg78fczLMIlOklZHb9GR8X3g68/2vXvKyIBo2ZuXWTWiFRq6iyfru/AktOWjL8I+o133VXbu6tydxCX6lbmRMb5/9rGuB/KNy109RGf/gUenu5Wm3RFstfehm4FK92oRFubuDUlawZsnA8PjnO78vYZ5Go2bljgVnd1JkEREfGzNiUpxphYY4zHd3+EMeZrxhhNwLZD9qBkYiO8/u8+G5cGNy5wXWSlY6L7uCLMa96BcN8Ux6E1G4HQ3iRle0On2U70bhl2CtRWQNZM+Pb7cM1brqhUBZ8iEoLa+mvTfOBYY0wfYC6QA1wCBHiNZs8REeZh5rC+fLjaz0uRxX8GHeWKdrfnut4qgdbQA6StxbM7vnT9RJKHdvw9R58Dd+S1vf+HiEgQtXW6x1hry4GvA3+21p4PdHAtaO81a0QqeXsq2Li7m+9C3JOFRXZNggJuBQ20I0nJdbUj7e2G2pgxSlBEpNtoc5JijDkKN3Lypu+YJq/bqfFSZJED0z1tSFLq691ISnubuImIdGNtTVK+D9wBvGqtXWGMGQp8ELCoeqjM5BiGpsYqSREnMt7tY1TRhpqUPRvdnjadKZoVEelm2jQaYq2dB8wD8BXQ7rbW3hLIwHqqWSNSefbzLVTW1BEV3oZOrNJztWeTwe3L3G1HOs2KiHRTbV3d86wxJsEYEwt8Baw2xvwosKH1TLNGpFJVW8/nG9u5Z4v0TG3dv2dHrtuVOW104GMSEQkRbZ3uGWOtLQXOA94CsoArAxVUTzZjaAqRYR7mrdaUj+BW+LRlJGXHl5A62n/t5EVEuoG2Jinhvr4o5wGvWWtraHaDDmlJVLiX6UNT/N8vRbqntiQpO5a7XZlVNCsivUxbk5S/A5uAWGC+MWYQUBqooHq6WSNSWV+wj61F5cEORYKtuemeqjJY/E/4x4nwyNGuaHbc17s+PhGRIGpTkmKtfchaO9Bae6Z1NgMntPY6Y8zpxpjVxph1xpifNHPO8caYpcaYFcaYee2Mv1tqWIo8f62mfHq9mBS3uqe+HqyFvBx4/Wa4fyS8cQtU74PTfgf/txqGdXDPHhGRbqpNq3uMMYnAncBxvkPzgF8DJS28xgs8DJwC5AGLjDGvW2u/anROEvBX4HRr7RZjTFpHvonu5ojUWAYmRfPBql1cPn1QsMORYIpOBlsPHz8AX74Mu1a41vzjvu42VeyKjQ5FREJUW6d7ngDKgIt9X6XAk628Zhqwzlq7wVpbDTwPnHvIOd8AXrHWbgGw1vaKQg1jDGeO78+8NQUU7asOdjgSTLF93e3cX7sdhM9+0I2anPswZE5TgiIivVpbk5QjrLV3+hKODdbaXwGtbSAyENja6HGe71hjI4A+xpgPjTGLjTFXNXUhY8x1xpgcY0xOQUHPmCK5YEoGNXWW15duC3YoEkwjz4CT74LrP4LrPoTsayAqIdhRiYiEhLYmKRXGmGMaHhhjjgYqWnlNU78CHroiKAyYApwFnAb8whgz4rAXWfuotTbbWpudmpraxpBD26j+CYxNT+ClJXnBDkWCKTIejvmBVu6IiDShrUnKDcDDxphNxphNwF+A61t5TR6Q2ehxBpDfxDnvWGv3WWt343Zb7sQ+9N3LhVMyWL6tlFU7tFBKRETkUG1d3bPMWjsRmABMsNZOBk5s5WWLgOHGmCHGmAjgUuD1Q855DTjWGBNmjIkBpgMr2/UddGNfm5hOmMfw8mKNpoiIiByqXXu+W2tLfZ1nAX7Yyrm1wE3Au7jEY7Zvc8IbjDE3+M5ZCbwD5AILgcestcvb+T10WylxkZw4Ko1Xv8intq4+2OGIiIiElDYtQW5Gq8sOrLVv4droNz72yCGP7wPu60Qc3doFUzJ476udzF9bwImj+gU7HBERkZDRrpGUQ6gtvh+cMDKN5NgIXl6sVT4iIiKNtTiSYowpo+lkxADRAYmol4kI8/C1iek8+/kWSsprSIwJD3ZIIiIiIaHFkRRrbby1NqGJr3hrbWemiqSRC6dkUF1Xz+u5hy5+EhER6b06M90jfjI2PYFR/eO1ykdERKQRJSkhwBjDBUdmsHRrMet27Q12OCIiIiFBSUqIOHdyOl6P4WV1oBUREQGUpISMtPgoZo1I5ZUledTVa+GUiIiIkpQQcsGRGewsreLjdbuDHYqIiEjQKUkJISeNTiMxOlxTPiIiIihJCSlR4V7OmTiAd5bvoLSyJtjhiIiIBJWSlBBz4ZRMqmrreSt3e7BDERERCSolKSFmYkYiR6TG8pJ6poiISC+nJCXEGGO4cEomOZv3sGn3vmCHIyIiEjRKUkLQ+ZMH4jGogFZERHo1JSkhqH9iFEcP68srS7ZRr54pIiLSSylJCVEXTslgW3EFn20sDHYoIiIiQaEkJUSdNrY/8ZFhKqAVEZFeKyzYAUjTosK9nD1xAC8v3kZMhJdLsrMYNzABY0ywQxMREekSSlJC2A9OGUFFdR0v5uTx78+2MHpAAhdnZ3DepIH0iY0IdngiIiIBZaztXoWZ2dnZNicnJ9hhdKmSihpeX5bPizlbyc0rIcLr4ZSx/bgkO5NjhvXF49HoioiIdE/GmMXW2uwmn1OS0r18lV/K7Jyt/GfpNorLaxiYFM2FUzK4ftZQYiI0MCYiIt2LkpQeqKq2jve/2snsnDw+WlvABUdmcP9FE4MdloiISLu0lKRodU83FRnm5ewJ6Tz9rWncdMIwXlqcx/tf7Qx2WCIiIn6jJKUHuPnE4YwekMAdr3zJnn3VwQ5HRETEL5Sk9AARYR7+ePFESiqq+cVry4MdjoiIiF8oSekhRg9I4Psnj+C/udv5b25+sMMRERHpNCUpPcj1xw1lYmYSv/jPcnaVVQY7HBERkU5RktKDhHk9/OGiiZRX1/HTV5bT3VZuiYiINKYkpYcZlhbHj04byZyVO3l5ybZghyMiItJhSlJ6oG8dPYRpg5P51RsryC+uCHY4IiIiHaIkpQfyeAz3XTSBunrL7S/natpHRES6JSUpPdSglFjuOHM0H63dzbMLtwQ7HBERkXZTktKDXTE9i2OH9+W3b65kS2F5sMMRERFpFyUpPZgxht9fMAGvMdz20jLq6zXtIyIi3YeSlB4uPSmaX54zhoUbi3h8wcZghyMiItJmSlJ6gQunZHDqmH78/p1VfL6hMNjhiIiItImSlF7AGMP9F08kKyWG7z6zRMuSRUSkW1CS0kskRIXz6JXZVNXWc+O/F1NZUxfskERERFqkJKUXGZYWxx8vnsiyvBJ+/h+1zRcRkdCmJKWXOXVsf245aTgvLc7jX59tDnY4IiIizQpokmKMOd0Ys9oYs84Y85MWzptqjKkzxlwYyHjE+f5JwzlpVBq/fuMrFm4sCnY4IiIiTQpYkmKM8QIPA2cAY4DLjDFjmjnv98C7gYpFDubxGB64dBJZyTF895nFbC9RIa2IiISeQI6kTAPWWWs3WGurgeeBc5s472bgZWBXAGORQyREhfPoVVOoqK7jhn8vUSGtiIiEnEAmKQOBrY0e5/mO7WeMGQicDzzS0oWMMdcZY3KMMTkFBQV+D7S3GpYWzx8vmcSyrcX88jUV0oqISGgJZJJimjh26E/BB4HbrbUt/hpvrX3UWpttrc1OTU31V3wCnDa2P7ecOIzZOXn8W4W0IiISQsICeO08ILPR4wwg/5BzsoHnjTEAfYEzjTG11tr/BDAuOcT3Tx7B8vxSfvXGV4wakMDUwcnBDklERAQTqCF+Y0wYsAY4CdgGLAK+Ya1d0cz5TwH/tda+1NJ1s7OzbU5Ojp+jlZKKGs57+GPyiyuYmJnE5MwkJmclMSmzD/0To4IdnoiI9FDGmMXW2uymngvYSIq1ttYYcxNu1Y4XeMJau8IYc4Pv+RbrUKRrJUaH8/S3pvH4go18sbWYJz7eSM18l8D2T4hiUmYSk7Jc8jI+I5GYiEAOwomIiARwJCVQNJLSNapq6/gqv5SlW4v5YksxS7cWs6WoHIAIr4eHLpvE6eMGBDlKERHp7oIykiLdW2SYl8lZfZic1YdrjnbHCvdWsSyvmD/NXccPZy9jSN84RvaPD26gIiLSY6ktvrRZSlwkJ47qx6NXTiE2Mozr/pVDSXlNsMMSEZEeSkmKtFu/hCgeueJI8osruPn5L6ir715ThiIi0j0oSZEOmTIomV+fO475awq4/73VwQ5HRER6INWkSIddNi2LL7eV8LcP1zM2PYGzJ6QHOyQREelBNJIinXLXOWOZMqgPP3oxl5XbS4MdjoiI9CBKUqRTIsI8/O3yI0mIdoW0xeXVwQ5JRER6CCUp0mlpCVE8csUUdpZUcfNzX1BbV9/i+XX1lvlrCrj1+S+4/l85bC+p6KJIRUSkO1GSIn4xOasPd583lo/W7ua+d5supF23ay+/f2cVR9/zP656YiEfri5gwdrdnPPnj1m8eU8XRywiIqFOhbPiN5dMzWL5tlL+Pn8DYwcm8rWJ6ZSU1/BGbj4vLc5j6dZivB7DrBGp/PKcMZw0Oo3NheV85+kcLnv0M35z/jguzs5s/Y1ERKRXUFt88avq2nouf+wzvtxWwvEj0vjf6l1U19Yzsl88F07J4NzJ6aTFH7xhYXF5Nd97dgkfryvkW0cP4adnjiLMq0E+EZHeoKW2+EpSxO8Kyqo47+GPKa+u5dxJA7lwSgZj0xMwxjT7mtq6en7z5kqe+mQTxw7vy58vm0xSTEQXRi0iIsGgJEW6XGVNHV6PIbydIyKzF23lZ//5kvSkaB67Kpvh/bQ3kIhIT9ZSkqIxdQmIqHBvuxMUgIunZvL8dTPYV1XH+X/9hDlf7QxAdCIi0h0oSZGQM2VQMq/fdDRD+sbynX/l8PAH6+huI34iItJ5SlIkJKUnRTP7+qM4e0I69727mhcX5wU7JBER6WJKUiRkRUd4eejSSRyZlcS976ymrLIm2CGJiEgXUpIiIc0Yw53njGX33ir+/L91wQ5HRES6kJIUCXkTM5O4aEoGT368kQ0Fe4MdjoiIdBElKdIt/Oj0kUSGefnNmyuDHYqIiHQRJSnSLaTFR3HLScP436pdfLB6V7DDERGRLqAkRbqNq2cOYWjfWO5+4yuqa1veaVlERLo/JSnSbUSEefjF2WPYsHsf//xkU7DDERGRAFOSIt3KCaPSOGFkKg/NXUtBWVWwwxERkQBSkiLdzi/OHkNlbR33vbsq2KGIiEgAKUmRbmdoahzXHD2EFxfnkZtXHOxwREQkQJSkSLd084nDSImN5K7XV2hfHxGRHkpJinRL8VHh/Pj0kSzZUsx/lm4Ldjgd9mbudk57YD75xRXBDkVEJOQoSZFu68IjM5iYkcg9b69iX1VtsMNpt882FPKDF5ayemcZzy/aGuxwRERCjpIU6bY8HsOdXxvLztIqHv6ge+3rs3ZnGdc9nUNmcjRTB/fhxZyt1NVr2kpEpLGwYAcg0hlHZvXh65MH8thHG5k6JJnE6HAMbmNCA3iMwRh3rjHQLyGKvnGRwQyZnaWVXP3kIiLDvTx1zTRy80r43rNL+GhtAcePTAtqbCIioURJinR7t58xive+2sk1Ty5q9dxwr+Hy6YP43gnDSI3v+mRlb1Ut1zy5iD3l1cy+/igyk2NIS4gkOTaCFxZtVZIiItKIkhTp9volRPHeD45j7a69WGuxABbqrcVasIC1lnoL89YU8K/PNjM7ZyvfPmYI3zluKAlR4V0SZ01dPd99Zgmrd5bx+DezGTcwEYDIMC/nTx7I059uYvfeqqCP9IiIhArT3ZZvZmdn25ycnGCHId3YhoK9/OH9NbyZu52kmHC+e/wRXHXUYKLCvS2+rmhfNR+u3sXcVbv4dH0ho/rHc8tJw5kxNKXV97TWcvvLuczOyeP3F4znkqlZBz2/ZmcZpz4wn5+dOZrvHDe0U9+fiEh3YoxZbK3NbvI5JSnSWy3fVsJ9765m3poC+idEcevJw7loSgZhXldPbq1l5fYyPli9i7krd/LF1mKshdT4SI4amsIn6wvZvbeK6UOSufXk4Rw1NAXTUABziAfnrOHBOWu55aTh/PCUEU2ec/5fP6asspb3f3Bcs9cREelplKSItOCzDYXc+84qlmwpZkjfWK6eOZg1O8v436pdbC+pBGBCRiInjkrjxFFpjEtPxOMxVFTX8ezCLTwybz0FZVVMG+ySlZlHHJyszM7Zyo9fyuXCKRncd+GEZhOQFxZt4faXv+TlG49iyqDkLvneRUSCTUmKSCustcxZuYv7313N6p1lxEZ4OXZ4KieOSuP4UamkxUc1+9rKmjqe8yUrO0uryB7Uh1tPHs4xw/oyf+1uvvXUImYekcITV08l3Nv8qv+9VbVM++0czp4wgHsvnBiIb1NEJOQoSRFpo7p6y9pdZQzpG0tkWMs1KoeqrKljds5W/vrBenaUVjI5K4k1O8rISoll9vUziG9Dge7tL+XyRm4+C392MnGRqmsXkZ6vpSRFzdxEGvF6DKP6J7Q7QQGICvdy1VGDmffj47n7vHHsLKkkKSaCp66Z2qYEBeDiqZmUV9fx32X57X5/EZGeRr+qifhZZJiXK2cM4rKpmdTW21ZXDTV2ZFYSw9PieCFnK5dOy2r9BSIiPVhAR1KMMacbY1YbY9YZY37SxPOXG2NyfV+fGGM0ES89RpjX064EBVyn3EumZvLFlmLW7CwLUGQiIt1DwJIUY4wXeBg4AxgDXGaMGXPIaRuBWdbaCcDdwKOBikekuzh/8kDCvYYXtOmgiPRygRxJmQass9ZusNZWA88D5zY+wVr7ibV2j+/hZ0BGAOMR6RZS4iI5ZUw/XlmSR1VtXbDDEREJmkAmKQOBxr8K5vmONefbwNsBjEek27hkahZ7ymuY89WuYIciIhI0gUxSmupY1eR6Z2PMCbgk5fZmnr/OGJNjjMkpKCjwY4gioemYYX1JT4zi+UVbgh2KiEjQBDJJyQMyGz3OAA5bV2mMmQA8BpxrrS1s6kLW2kettdnW2uzU1NSABCsSSrwew4XZmSxYt5u8PeXBDkdEJCgCmaQsAoYbY4YYYyKAS4HXG59gjMkCXgGutNauCWAsIt3ORVNcidaLOXlBjkREJDgClqRYa2uBm4B3gZXAbGvtCmPMDcaYG3yn/RJIAf5qjFlqjFErWRGfzOQYjhnWl5cW51FX3706Q4uI+ENA+6RYa9+y1o6w1h5hrf2t79gj1tpHfPevtdb2sdZO8n012RZXpLe6ZGom24or+Hjd7mCHIiLS5dQWXySEnTKmH31iwv3WM2V9wV4e+2gDNXX1frmeiEggqS2+SAiLDPNy/uQM/vXZJor2VZMcG9Gh61hreXFxHne+toKKGtd75dpjh/ozVBERv9NIikiIu2RqJjV1lh/OXsrmwn3tfn1ZZQ23Pr+UH7+Uy8TMRGYekcKDc9ays7QyANGKiPiPkhSREDeyfzw/P2s0CzcWcfIf5/HbN7+ipKKmTa9dtrWYsx5awH9z8/m/U0bwzLUz+N3Xx1NdV89v3lwZ4MhFRDpHSYpIN3DtsUP58Lbj+frkDB5bsJHj7/uAf36yqdnakvp6y6Pz13PB3z6htq6eF64/iptPGo7XYxiUEsuNs47gjWX5KsgVkZBmrO1eSxuzs7NtTo5WKkvvtSK/hN++uZJP1hdyRGosPztrNCeMTMMY1+R5994q/m/2MuatKeC0sf34/QUTSIo5uJalsqaOUx+YT7jX8PatxxERpt9XRCQ4jDGLm1vdq/+ZRLqZsemJPHPtdB67Khtr4VtP5XDl4wtZub2UBWt3c8afPuLTDYXcfd44HrliymEJCkBUuJe7vjaG9QX7eHzBxiB8FyIirdNIikg3VlNXzzOfbebBuWv316kckRrHny+bzOgBCa2+/jtP57Bg7W7m/N8sBiZFBzpcEZHDtDSSoiRFpAcoKa/hr/PWUV1bz49OG0lMRNu6C+TtKefkP87j+BFpPHLllABHKSJyuJaSFPVJEekBEmPCueOM0e1+XUafGG4+cTj3vbuaD1fv4viRaQGITkSkY1STItLLXXvsEIb2jeXO11dQ6Wv0JiISCpSkiPRykWFefnXuWDYXlvPo/A3BDkdEZD8lKSLCscNTOWv8AB7+YB1bi8qDHY6ICKAkRUR8fn72aLwew12vrwh2KCIigJIUEfEZkBjN908eztxVu5jz1c5ghyMioiRFRA645ughDE+L4643VlBeXRvscESkl1OSIiL7hXs93H3eOPL2VDDl7jlc+fjnPDJvPbl5xdTVd6+eSiLS/alPiogcZMbQFJ69djrvrtjBJ+sLueftVQDER4UxY2gKM49IYeYRfRnRL27/fkEiIoGgJEVEDjNzWF9mDusLwK6ySj5dX8in6wv5ZH0h7/vqVfrGRTCqfwKJ0eEkRIeREBVOQnQ4CVFhvlt3vH9itFrui0iHKEkRkRalxUdx7qSBnDtpIABbi8r5dINLWjYX7mNHaSWlFTWUVtZQWVPf5DXOGNef7588gpH947sydBHp5pSkiEi7ZCbHkJkcw8XZmYc9V1VbR1llLaUVNZRU1FBaWUvOpiKe/HgT76zYwVnjB/D9k4czLE3Jir/V1tWzcGMRby/fweqdZfzotJFMHZwc7LBEOkUbDIpIwO3ZV81jCzbw5MebqKip49yJ6dxy0nCGpsYFO7Ruraq2jk/WFfL28u28/9VO9pTXEBXuIT4qnLLKGv5xVTbHDk8NdpgiLdIuyCISEgr3VvHoRxt4+pPNVNXWcd7kgdxy4nAG940NdmjdRnl1LfNWF/DOih38b+UuyqpqiY8M48TRaZwxrj/HjUilvLqOKx9fyPpde3nossmcPq5/sMMWaZaSFBEJKQVlVfx93nr+9dlmaustX588kLMnpjM5K4mEqPBghxdSdpVWsnRrMcvyilm2tYSczUVU1tTTJyacU8f05/Tx/Zl5RAqRYd6DXldSXsPVTy0kN6+E+y+awPmTM4L0HYi0TEmKiISkXaWV/G3eep75fAvVtfUYAyPS4jlyUB+m+L4Gp8T0mqXOZZU1fLmthGVbS1jmS0y2l1QCEOYxjBoQT/agZE4d249pg5MJ87bc6mpfVS3feTqHTzcUcve547hixqCu+DZE2kVJioiEtL1VtSzbWszizXtYvHkPX2zZQ2ml63ibHBvBkVlJHDmoD0P7xu1f4hwfFUZ8lLsNb+WHdagrKKvi1ue/4NMNhTT8lzw4JYaJmUlMzEhiUlYSYwYkEBXubflCTaisqeN7zyxh7qpd3HHGKK6fdYSfoxfpHCUpItKt1Ndb1hfs3Z+0LN6yhw0F+5o9PzrcS7wveUlPiuYb0zI5ZUx/vJ7QH4FZu7OMa55axO69VVx33BFMGdSHiRmJJMVE+O09aurq+cELS/lv7nZuPnEYPzxlRK8ZnZLQ11KSoiXIIhJyPB7D8H7xDO8Xz6XTsgC3Qii/pGL/EueyylrKKt0y57JK97i0sobcvBJu+PcSMpOjuWbmEC6emklcZGj+V/fJ+t1c/6/FRIZ5eeG6o5iYmRSQ9wn3evjTpZOJjQjjz/9bR1llLb88ewyebpDESe8Wmv9yRUQO0Sc2gj6xrY8u1NVb3luxg8cXbOTX//2KB95fwyVTM/nmzMFkJsd0QaRt8/LiPH7ySi6DU2J54uqpAY/N6zHcc8F4YiPDeOLjjZRX1/K7r0/oFqNN0ntpukdEeqxlW4t5fMFG3vpyO/XWcvq4/nz7mCEcmdUnaNMd1loenLOWP81dy8wjUvjbFVNIjO66FU3WWh6Ys5aH5q5lZL94vjE9i/MmD+zSGEQaU02KiPRq20sq+Ocnm3lu4RZKKmoYPzCRjD7ReIwBAx5jMIA56L4hNT6S0QPiGdU/gaGpsZ0u0K2urecnL+fyyhfbuHBKBv/v/PFEhAWn6Pe1pdt4fMFGcvNKiAr3cNb4dL4xPTOoCZz0TkpSRERwjdBeXpzHy0u2sa+qFgvUWwvW3TY8thasdZsr1tS5/yMjvB6OSItjdP94RvkSl1ED4kmNi2zTD/WS8hqu/3cOn20o4oenjODmE4eFRDKwfFsJzy3cwmtL89lbVcuIfnFcNi2Lr0/OIDFGoysSeEpSREQ6oLq2ng2797Jqexkrd5SyansZq3eUsaO0cv85idHhZPRxOz2nJ0Xvvz/Qd5scG0HengqufnIhW4rKuffC0Gystq+qljeW5fPcwi0syyshMszDWeMHcOrYfiTFRLjVU1Fud+u4qDDVsojfKEkREfGjPfuqWbWjjFU7Slm3ay/5xRVsK65g254K9lXXHXRuVLgHgyEizMPfr5zCjKEpQYq67ZZvK+H5RVv4zxdudKUpsRHe/X1qEqLD6RMTQXJsOH1iI0iOiSA51n31iY0gxXerbsLSFCUpIiJdwFpLSUXN/oRlW3EF+cVu2fS1xw5lWFr32lCxvLqW9bv27V/qXVp5YOl349uSihr2lNewZ181Rfuqqa6rb/J66YlRZA9OZuqQZKYNTmZ4WpyWQYv6pIiIdAVjDEkxESTFRDA2PTHY4XRaTEQY4zPa931Ya9lXXbc/YSkqr2bPvmoKyqrI3VbCZxsKeX1ZPgBJMeFkD+rDVF/iMi49MWiFxBKalKSIiIjfGGOIiwwjLjKsyd4v1lq2FJWzcGMRizYVkbNpD3NW7gLc1NjoAQkMSo4hKzmGrJRYd5scQ1p8pEZdeiFN94iISFAVlFWRs6mIhZuKWL2jjM2F5WwvqaC+0Y+niDAPmX2iyUqOYWCfaBKjw4mLdEW8CVFh+xOjuKgw4iPDiY30sq+qjsJ9VRTtq6awYWRnXzW791btv2+AfglR9E+McrcJUQxIjKJforsfG6LdinsS1aSIiEi3Ul1bT35xBVuKytlcVM7WonK2FJazpaicbcUV7K2qpa6+/T+/IsM89I2L3F/YW28tO0sr2VFSuX9Ty8biI8NIS4ikj28ar0+MKw5O9BUL94kJJynGPQ73Gizs3yTSYg/ct+5xfT1U19VTXVtPTZ37qq6tp7qunpo6S3VtPRZLQlQ4STHhJEW7ayfGhBMfGdau0SRrLfW+5fX11r33/vvW7ZFV7wswPMxDhNd9dfWIlWpSRESkW4kI8zC4byyD+8Y2+by1lsqaesqqathbWUtZZS17qw7c7q2sISYyjL5xESTHRpLiS0piIrzN9qcpr65lR0klO0orfYlLFTtKKthVVsWe8mry9pSzfFsNe8qrqaptujg4kDwGEqLDSYx2S8EtlppaS01dPVWNkp6GZKe5AubWeD2GcK8h3OshMsxDuNd9/frcsRw/Ms3P31XLApqkGGNOB/4EeIHHrLX3HPK88T1/JlAOXG2tXRLImEREpPszxhAd4SU6wktavH+uGRMRxtDUOIamtr4Kq7Kmjj3l1ezZV0NxRTUl5TXU+UYlDIaGPKihk3HDozCPITzMQ7jXHJQARPhGMhq6GpdW1lBcXkNJRQ3F5dWUVNTs/your6G0sgavcYlEU9cL93qI8BrCvB48xn1eHmPwenxdlY3BY1xCYi0HJTf7R3gakp5aS3VdPclt2DvL3wKWpBhjvMDDwClAHrDIGPO6tfarRqedAQz3fU0H/ua7FRERCVlR4V4GJEYzIDE6INfvnxgVkOt2N4Fc6zUNWGet3WCtrQaeB8495Jxzgaet8xmQZIwZEMCYREREpJsIZJIyENja6HGe71h7zxEREZFeKJBJSlOVSYeWYrflHIwx1xljcowxOQUFBX4JTkREREJbIJOUPCCz0eMMIL8D52CtfdRam22tzU5NTfV7oCIiIhJ6ApmkLAKGG2OGGGMigEuB1w8553XgKuPMAEqstdsDGJOIiIh0EwFb3WOtrTXG3AS8i1uC/IS1doUx5gbf848Ab+GWH6/DLUG+JlDxiIiISPcS0D4p1tq3cIlI42OPNLpvge8FMgYRERHpnrTdpIiIiIQkJSkiIiISkpSkiIiISEhSkiIiIiIhSUmKiIiIhCQlKSIiIhKSjLWHdaEPacaYAmBzgC7fF9gdoGtL0/SZdz195sGhz73r6TPveh35zAdZa5tsJ9/tkpRAMsbkWGuzgx1Hb6LPvOvpMw8Ofe5dT5951/P3Z67pHhEREQlJSlJEREQkJClJOdijwQ6gF9Jn3vX0mQeHPveup8+86/n1M1dNioiIiIQkjaSIiIhISFKSAhhjTjfGrDbGrDPG/CTY8fRUxpgnjDG7jDHLGx1LNsa8b4xZ67vtE8wYexpjTKYx5gNjzEpjzApjzK2+4/rcA8QYE2WMWWiMWeb7zH/lO67PPMCMMV5jzBfGmP/6HuszDyBjzCZjzJfGmKXGmBzfMb9+5r0+STHGeIGHgTOAMcBlxpgxwY2qx3oKOP2QYz8B5lprhwNzfY/Ff2qB/7PWjgZmAN/z/f3W5x44VcCJ1tqJwCTgdGPMDPSZd4VbgZWNHuszD7wTrLWTGi079utn3uuTFGAasM5au8FaWw08D5wb5Jh6JGvtfKDokMPnAv/03f8ncF5XxtTTWWu3W2uX+O6X4f4DH4g+94Cxzl7fw3Dfl0WfeUAZYzKAs4DHGh3WZ971/PqZK0lx/2FvbfQ4z3dMukY/a+12cD9QgbQgx9NjGWMGA5OBz9HnHlC+aYelwC7gfWutPvPAexD4MVDf6Jg+88CywHvGmMXGmOt8x/z6mYd1MsCewDRxTEuepEcxxsQBLwPft9aWGtPUX3vxF2ttHTDJGJMEvGqMGRfkkHo0Y8zZwC5r7WJjzPFBDqc3Odpam2+MSQPeN8as8vcbaCTFjZxkNnqcAeQHKZbeaKcxZgCA73ZXkOPpcYwx4bgE5Rlr7Su+w/rcu4C1thj4EFeLpc88cI4GvmaM2YSbsj/RGPNv9JkHlLU233e7C3gVVz7h189cSQosAoYbY4YYYyKAS4HXgxxTb/I68E3f/W8CrwUxlh7HuCGTx4GV1to/NnpKn3uAGGNSfSMoGGOigZOBVegzDxhr7R3W2gxr7WDc/+H/s9ZegT7zgDHGxBpj4hvuA6cCy/HzZ65mboAx5kzcfKYXeMJa+9vgRtQzGWOeA47H7ZK5E7gT+A8wG8gCtgAXWWsPLa6VDjLGHAN8BHzJgbn6n+LqUvS5B4AxZgKuYNCL+0VwtrX218aYFPSZB5xvuuc2a+3Z+swDxxgzFDd6Aq505Flr7W/9/ZkrSREREZGQpOkeERERCUlKUkRERCQkKUkRERGRkKQkRUREREKSkhQREREJSUpSRCSgjDF1vl1SG778tsmbMWZw4121RaRnUVt8EQm0CmvtpGAHISLdj0ZSRCQojDGbjDG/N8Ys9H0N8x0fZIyZa4zJ9d1m+Y73M8a8aoxZ5vua6buU1xjzD2PMCmPMe74uryLSAyhJEZFAiz5kuueSRs+VWmunAX/BdX3Gd/9pa+0E4BngId/xh4B51tqJwJHACt/x4cDD1tqxQDFwQUC/GxHpMuo4KyIBZYzZa62Na+L4JuBEa+0G3yaIO6y1KcaY3cAAa22N7/h2a21fY0wBkGGtrWp0jcHA+9ba4b7HtwPh1trfdMG3JiIBppEUEQkm28z95s5pSlWj+3Wo1k6kx1CSIiLBdEmj20999z/B7WQLcDmwwHd/LnAjgDHGa4xJ6KogRSQ49BuHiARatDFmaaPH71hrG5YhRxpjPsf9wnSZ79gtwBPGmB8BBcA1vuO3Ao8aY76NGzG5Edge6OBFJHhUkyIiQeGrScm21u4OdiwiEpo03SMiIiIhSSMpIiIiEpI0kiIiIiIhSUmKiIiIhCQlKSIiIhKSlKSIiIhISFKSIiIiIiFJSYqIiIiEpP8PhsUWZMR9+S0AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training & validation loss values\n",
    "plt.figure(figsize=(9,6))\n",
    "plt.plot(RNN_history.history['loss'])\n",
    "plt.plot(RNN_history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 18ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_RNN = RNN_model.predict(feature_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 1, 1, 2, 2, 0, 1, 1, 2, 2, 1, 0, 2, 1, 1, 2, 2, 1, 0, 0,\n",
       "       0, 1, 0, 1, 0, 2, 1, 2, 0, 2, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 2,\n",
       "       1, 0, 1, 2, 2, 2, 0, 0, 1, 1, 1, 2, 0, 1, 2, 1, 1, 2, 1, 2, 1, 2,\n",
       "       0, 2, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 2, 1, 2, 1, 1, 1, 1, 2, 0,\n",
       "       1, 2, 1, 1, 1])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_RNN_class = np.argmax(y_pred_RNN, axis=1)\n",
    "y_pred_RNN_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8602150537634409"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test_class, y_pred_RNN_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.74      0.72        19\n",
      "           1       0.98      0.90      0.94        50\n",
      "           2       0.78      0.91      0.84        23\n",
      "           3       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.86        93\n",
      "   macro avg       0.61      0.64      0.62        93\n",
      "weighted avg       0.86      0.86      0.86        93\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_class, y_pred_RNN_class))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters tuning for LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_func2(optimizer_index, activation_index, learning_rate, epoch, batch_size):\n",
    "\n",
    "    optimizers_dict = {'SGD':SGD(lr=learning_rate), 'RMSprop':RMSprop(lr=learning_rate), 'Adam':Adam(lr=learning_rate), 'Adagrad':Adagrad(lr=learning_rate)}\n",
    "\n",
    "    optimizer = optimizers_dict[optimizers_list[round(optimizer_index)]]\n",
    "    activation = activations_list[round(activation_index)]\n",
    "\n",
    "    def create_RNN_model():\n",
    "        RNN = Sequential()\n",
    "        RNN.add(Embedding(len(word_index) + 1, word_dimension, weights=[embedding_matrix], input_length = maxlen, trainable=False))\n",
    "\n",
    "        RNN.add(Bidirectional(LSTM(word_dimension)))\n",
    "        RNN.add(Dense(word_dimension, activation=activation))\n",
    "        RNN.add(Dense(4, activation='sigmoid'))\n",
    "        RNN.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "        #RNN.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "    \n",
    "        return RNN\n",
    "    \n",
    "    RNN_model = create_RNN_model()\n",
    "\n",
    "    RNN_model.fit(feature_train, y_train, epochs=round(epoch), batch_size=round(batch_size), validation_data=(feature_val, y_val))\n",
    "\n",
    "    y_pred_RNN = RNN_model.predict(feature_test)\n",
    "    y_pred_RNN_class = np.argmax(y_pred_RNN, axis=1)\n",
    "        \n",
    "    return accuracy_score(y_test_class, y_pred_RNN_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | activa... | batch_... |   epoch   | learni... | optimi... |\n",
      "-------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/rmsprop.py:140: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adagrad.py:81: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3/3 [==============================] - 1s 161ms/step - loss: 219597.8125 - accuracy: 0.3805 - val_loss: 776.2170 - val_accuracy: 0.2800\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 603.6285 - accuracy: 0.2997 - val_loss: 913.0525 - val_accuracy: 0.5733\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 171.2936 - accuracy: 0.4848 - val_loss: 209.2118 - val_accuracy: 0.0933\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 158.9744 - accuracy: 0.3973 - val_loss: 14.0238 - val_accuracy: 0.6000\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 205.3590 - accuracy: 0.4074 - val_loss: 134.6695 - val_accuracy: 0.2400\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 291.7925 - accuracy: 0.3300 - val_loss: 507.3029 - val_accuracy: 0.2400\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 264.9625 - accuracy: 0.4377 - val_loss: 1020.1664 - val_accuracy: 0.5733\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 197.0872 - accuracy: 0.5219 - val_loss: 1080.3062 - val_accuracy: 0.6000\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 45.2841 - accuracy: 0.5219 - val_loss: 1291.0170 - val_accuracy: 0.5867\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 374.5885 - accuracy: 0.5118 - val_loss: 1773.3458 - val_accuracy: 0.5867\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 279.1190 - accuracy: 0.5219 - val_loss: 21.0572 - val_accuracy: 0.5733\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 47.5783 - accuracy: 0.5219 - val_loss: 1.0008 - val_accuracy: 0.6000\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 8.8078 - accuracy: 0.5320 - val_loss: 1.0078 - val_accuracy: 0.6000\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 191.7193 - accuracy: 0.5219 - val_loss: 0.9944 - val_accuracy: 0.6000\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 13.4578 - accuracy: 0.5185 - val_loss: 2.0766 - val_accuracy: 0.2667\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 35.2334 - accuracy: 0.4983 - val_loss: 0.9900 - val_accuracy: 0.6000\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 127.5253 - accuracy: 0.5286 - val_loss: 657.8663 - val_accuracy: 0.2533\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 117.7709 - accuracy: 0.4916 - val_loss: 2421.8901 - val_accuracy: 0.5733\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 277.0359 - accuracy: 0.5253 - val_loss: 2593.9958 - val_accuracy: 0.5733\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 59.8900 - accuracy: 0.5286 - val_loss: 2086.9148 - val_accuracy: 0.5867\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 32.3003 - accuracy: 0.5320 - val_loss: 1142.3859 - val_accuracy: 0.5867\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 154.6109 - accuracy: 0.5253 - val_loss: 780.9052 - val_accuracy: 0.5867\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 20.2976 - accuracy: 0.5152 - val_loss: 630.7523 - val_accuracy: 0.6000\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 5.6531 - accuracy: 0.5286 - val_loss: 530.0188 - val_accuracy: 0.6000\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 2.8460 - accuracy: 0.5286 - val_loss: 330.5265 - val_accuracy: 0.5867\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 16.5960 - accuracy: 0.5286 - val_loss: 186.3808 - val_accuracy: 0.5867\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.0106 - accuracy: 0.5354 - val_loss: 88.0829 - val_accuracy: 0.5867\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.9995 - accuracy: 0.5354 - val_loss: 24.8652 - val_accuracy: 0.5867\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 1035.3409 - accuracy: 0.5320 - val_loss: 794.4859 - val_accuracy: 0.5867\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 48.8093 - accuracy: 0.5286 - val_loss: 2379.9114 - val_accuracy: 0.5867\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 7.5083 - accuracy: 0.5253 - val_loss: 3975.4609 - val_accuracy: 0.5867\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 101.1245 - accuracy: 0.4646 - val_loss: 5268.6499 - val_accuracy: 0.5867\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 1.1365 - accuracy: 0.5286 - val_loss: 6040.7422 - val_accuracy: 0.5733\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 1.7743 - accuracy: 0.5286 - val_loss: 6633.0522 - val_accuracy: 0.5733\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 1.1154 - accuracy: 0.5320 - val_loss: 7068.6919 - val_accuracy: 0.5733\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 60.9176 - accuracy: 0.5286 - val_loss: 7215.1973 - val_accuracy: 0.5867\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 1401.9852 - accuracy: 0.5253 - val_loss: 2260.3696 - val_accuracy: 0.5733\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 438.1672 - accuracy: 0.5253 - val_loss: 93.9888 - val_accuracy: 0.6267\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 1.0060 - accuracy: 0.5354 - val_loss: 145.1114 - val_accuracy: 0.6133\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 6.9897 - accuracy: 0.5320 - val_loss: 330.2599 - val_accuracy: 0.6133\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 89.7642 - accuracy: 0.5219 - val_loss: 502.9385 - val_accuracy: 0.6133\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 119.6991 - accuracy: 0.5185 - val_loss: 738.3275 - val_accuracy: 0.6133\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 49.6467 - accuracy: 0.5253 - val_loss: 1028.8268 - val_accuracy: 0.6133\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 278.0204 - accuracy: 0.5118 - val_loss: 906.1896 - val_accuracy: 0.4267\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 823.1338 - accuracy: 0.4478 - val_loss: 671.5876 - val_accuracy: 0.2533\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 271.1957 - accuracy: 0.3333 - val_loss: 970.7615 - val_accuracy: 0.5733\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 324.6995 - accuracy: 0.5354 - val_loss: 1023.5496 - val_accuracy: 0.5867\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 296.4073 - accuracy: 0.5286 - val_loss: 1192.1584 - val_accuracy: 0.5867\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 99.5799 - accuracy: 0.5286 - val_loss: 1298.8835 - val_accuracy: 0.5867\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 1425.4346 - accuracy: 0.5253 - val_loss: 1028.9298 - val_accuracy: 0.5867\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m0.5376   \u001b[0m | \u001b[0m0.3482   \u001b[0m | \u001b[0m100.5    \u001b[0m | \u001b[0m50.05    \u001b[0m | \u001b[0m0.6167   \u001b[0m | \u001b[0m2.038    \u001b[0m |\n",
      "Epoch 1/71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/rmsprop.py:140: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adagrad.py:81: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 147ms/step - loss: 1.8987 - accuracy: 0.2828 - val_loss: 8.4880 - val_accuracy: 0.1600\n",
      "Epoch 2/71\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 7.4467 - accuracy: 0.3535 - val_loss: 12.0312 - val_accuracy: 0.1333\n",
      "Epoch 3/71\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 11.3572 - accuracy: 0.3266 - val_loss: 13.0117 - val_accuracy: 0.5867\n",
      "Epoch 4/71\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 16.3560 - accuracy: 0.4714 - val_loss: 20.8721 - val_accuracy: 0.1600\n",
      "Epoch 5/71\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 16.2803 - accuracy: 0.3468 - val_loss: 19.5635 - val_accuracy: 0.5867\n",
      "Epoch 6/71\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 14.5232 - accuracy: 0.3704 - val_loss: 29.8827 - val_accuracy: 0.2400\n",
      "Epoch 7/71\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 21.4665 - accuracy: 0.4040 - val_loss: 13.3676 - val_accuracy: 0.2800\n",
      "Epoch 8/71\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 20.1095 - accuracy: 0.4141 - val_loss: 14.2750 - val_accuracy: 0.5867\n",
      "Epoch 9/71\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 17.6672 - accuracy: 0.3502 - val_loss: 27.0846 - val_accuracy: 0.2400\n",
      "Epoch 10/71\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 19.9058 - accuracy: 0.2727 - val_loss: 3.2113 - val_accuracy: 0.5867\n",
      "Epoch 11/71\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 10.8263 - accuracy: 0.3838 - val_loss: 17.7670 - val_accuracy: 0.1600\n",
      "Epoch 12/71\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 12.7682 - accuracy: 0.3367 - val_loss: 8.5906 - val_accuracy: 0.2400\n",
      "Epoch 13/71\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 11.7703 - accuracy: 0.4007 - val_loss: 11.7836 - val_accuracy: 0.2400\n",
      "Epoch 14/71\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 16.0300 - accuracy: 0.4343 - val_loss: 17.7702 - val_accuracy: 0.5867\n",
      "Epoch 15/71\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 16.1198 - accuracy: 0.3434 - val_loss: 31.2751 - val_accuracy: 0.2400\n",
      "Epoch 16/71\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 22.6934 - accuracy: 0.4276 - val_loss: 16.9271 - val_accuracy: 0.5867\n",
      "Epoch 17/71\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 17.6054 - accuracy: 0.3434 - val_loss: 54.1838 - val_accuracy: 0.2400\n",
      "Epoch 18/71\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 27.5492 - accuracy: 0.3939 - val_loss: 15.2190 - val_accuracy: 0.5867\n",
      "Epoch 19/71\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 13.2649 - accuracy: 0.3872 - val_loss: 23.2181 - val_accuracy: 0.2400\n",
      "Epoch 20/71\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 19.2116 - accuracy: 0.4175 - val_loss: 14.0624 - val_accuracy: 0.2400\n",
      "Epoch 21/71\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 18.8543 - accuracy: 0.4276 - val_loss: 30.0557 - val_accuracy: 0.5867\n",
      "Epoch 22/71\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 23.5366 - accuracy: 0.4478 - val_loss: 19.1496 - val_accuracy: 0.2400\n",
      "Epoch 23/71\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 15.8058 - accuracy: 0.3636 - val_loss: 23.1953 - val_accuracy: 0.5867\n",
      "Epoch 24/71\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 22.2261 - accuracy: 0.4343 - val_loss: 3.3789 - val_accuracy: 0.2933\n",
      "Epoch 25/71\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 8.2363 - accuracy: 0.4108 - val_loss: 9.7788 - val_accuracy: 0.2400\n",
      "Epoch 26/71\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 12.6411 - accuracy: 0.4175 - val_loss: 18.0386 - val_accuracy: 0.5867\n",
      "Epoch 27/71\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 18.0564 - accuracy: 0.3535 - val_loss: 32.2085 - val_accuracy: 0.2400\n",
      "Epoch 28/71\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 28.6636 - accuracy: 0.4040 - val_loss: 6.4743 - val_accuracy: 0.5867\n",
      "Epoch 29/71\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 14.0937 - accuracy: 0.3838 - val_loss: 31.3193 - val_accuracy: 0.1600\n",
      "Epoch 30/71\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 22.7740 - accuracy: 0.2761 - val_loss: 3.6688 - val_accuracy: 0.5867\n",
      "Epoch 31/71\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 9.4574 - accuracy: 0.3468 - val_loss: 26.7685 - val_accuracy: 0.2400\n",
      "Epoch 32/71\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 20.0897 - accuracy: 0.3468 - val_loss: 17.8840 - val_accuracy: 0.2400\n",
      "Epoch 33/71\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 17.0775 - accuracy: 0.3636 - val_loss: 19.1111 - val_accuracy: 0.5867\n",
      "Epoch 34/71\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 20.1694 - accuracy: 0.4411 - val_loss: 7.0920 - val_accuracy: 0.2400\n",
      "Epoch 35/71\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 10.6497 - accuracy: 0.4377 - val_loss: 12.3839 - val_accuracy: 0.5867\n",
      "Epoch 36/71\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 15.0745 - accuracy: 0.4242 - val_loss: 8.1948 - val_accuracy: 0.5867\n",
      "Epoch 37/71\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 8.7327 - accuracy: 0.3771 - val_loss: 7.9997 - val_accuracy: 0.2400\n",
      "Epoch 38/71\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 13.1843 - accuracy: 0.4377 - val_loss: 15.5194 - val_accuracy: 0.5867\n",
      "Epoch 39/71\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 20.2387 - accuracy: 0.4343 - val_loss: 5.7243 - val_accuracy: 0.2400\n",
      "Epoch 40/71\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 8.9115 - accuracy: 0.4310 - val_loss: 19.3236 - val_accuracy: 0.5867\n",
      "Epoch 41/71\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 21.4935 - accuracy: 0.3939 - val_loss: 7.8200 - val_accuracy: 0.2400\n",
      "Epoch 42/71\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 13.0009 - accuracy: 0.3737 - val_loss: 12.2329 - val_accuracy: 0.5867\n",
      "Epoch 43/71\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 14.4965 - accuracy: 0.3468 - val_loss: 15.0038 - val_accuracy: 0.5867\n",
      "Epoch 44/71\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 20.6752 - accuracy: 0.3872 - val_loss: 3.4029 - val_accuracy: 0.5867\n",
      "Epoch 45/71\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 8.6304 - accuracy: 0.3872 - val_loss: 5.7937 - val_accuracy: 0.1600\n",
      "Epoch 46/71\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 8.8731 - accuracy: 0.3838 - val_loss: 28.0623 - val_accuracy: 0.5867\n",
      "Epoch 47/71\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 22.4472 - accuracy: 0.4983 - val_loss: 15.6951 - val_accuracy: 0.1600\n",
      "Epoch 48/71\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 14.7483 - accuracy: 0.3535 - val_loss: 9.0953 - val_accuracy: 0.5867\n",
      "Epoch 49/71\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 12.2292 - accuracy: 0.4512 - val_loss: 31.0501 - val_accuracy: 0.1600\n",
      "Epoch 50/71\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 23.6480 - accuracy: 0.3569 - val_loss: 15.0785 - val_accuracy: 0.5867\n",
      "Epoch 51/71\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 13.3955 - accuracy: 0.3333 - val_loss: 13.8236 - val_accuracy: 0.1600\n",
      "Epoch 52/71\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 13.8875 - accuracy: 0.3636 - val_loss: 26.4931 - val_accuracy: 0.5867\n",
      "Epoch 53/71\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 20.2878 - accuracy: 0.4478 - val_loss: 7.1524 - val_accuracy: 0.1600\n",
      "Epoch 54/71\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 10.8585 - accuracy: 0.3771 - val_loss: 14.7074 - val_accuracy: 0.5867\n",
      "Epoch 55/71\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 16.5431 - accuracy: 0.3670 - val_loss: 11.8494 - val_accuracy: 0.5867\n",
      "Epoch 56/71\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 18.4325 - accuracy: 0.3838 - val_loss: 9.9989 - val_accuracy: 0.2400\n",
      "Epoch 57/71\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 13.7786 - accuracy: 0.4276 - val_loss: 9.9823 - val_accuracy: 0.5867\n",
      "Epoch 58/71\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 12.0428 - accuracy: 0.4411 - val_loss: 17.9115 - val_accuracy: 0.5867\n",
      "Epoch 59/71\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 19.0969 - accuracy: 0.3367 - val_loss: 32.7169 - val_accuracy: 0.2400\n",
      "Epoch 60/71\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 23.6750 - accuracy: 0.4175 - val_loss: 15.1090 - val_accuracy: 0.5867\n",
      "Epoch 61/71\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 15.0431 - accuracy: 0.3468 - val_loss: 32.0889 - val_accuracy: 0.2400\n",
      "Epoch 62/71\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 21.5616 - accuracy: 0.3838 - val_loss: 16.3559 - val_accuracy: 0.5867\n",
      "Epoch 63/71\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 18.0985 - accuracy: 0.4444 - val_loss: 10.4658 - val_accuracy: 0.2400\n",
      "Epoch 64/71\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 14.2262 - accuracy: 0.4276 - val_loss: 16.4630 - val_accuracy: 0.5867\n",
      "Epoch 65/71\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 19.2046 - accuracy: 0.4175 - val_loss: 18.2560 - val_accuracy: 0.1600\n",
      "Epoch 66/71\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 14.2466 - accuracy: 0.3805 - val_loss: 18.4080 - val_accuracy: 0.5867\n",
      "Epoch 67/71\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 15.5292 - accuracy: 0.3973 - val_loss: 21.3023 - val_accuracy: 0.1600\n",
      "Epoch 68/71\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 16.9492 - accuracy: 0.3333 - val_loss: 10.7266 - val_accuracy: 0.5867\n",
      "Epoch 69/71\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 15.0452 - accuracy: 0.4141 - val_loss: 55.1913 - val_accuracy: 0.1600\n",
      "Epoch 70/71\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 28.3699 - accuracy: 0.3165 - val_loss: 10.5248 - val_accuracy: 0.5867\n",
      "Epoch 71/71\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 20.0277 - accuracy: 0.3569 - val_loss: 25.0670 - val_accuracy: 0.2400\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "| \u001b[0m2        \u001b[0m | \u001b[0m0.2473   \u001b[0m | \u001b[0m2.047    \u001b[0m | \u001b[0m143.5    \u001b[0m | \u001b[0m70.98    \u001b[0m | \u001b[0m0.5178   \u001b[0m | \u001b[0m0.2585   \u001b[0m |\n",
      "Epoch 1/31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/rmsprop.py:140: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adagrad.py:81: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 1s 36ms/step - loss: 65.2860 - accuracy: 0.3199 - val_loss: 4.7329 - val_accuracy: 0.5867\n",
      "Epoch 2/31\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 13.2930 - accuracy: 0.3670 - val_loss: 5.2564 - val_accuracy: 0.5867\n",
      "Epoch 3/31\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 3.0307 - accuracy: 0.4411 - val_loss: 2.3202 - val_accuracy: 0.5867\n",
      "Epoch 4/31\n",
      "7/7 [==============================] - 0s 44ms/step - loss: 1.6792 - accuracy: 0.4242 - val_loss: 1.5066 - val_accuracy: 0.5867\n",
      "Epoch 5/31\n",
      "7/7 [==============================] - 0s 33ms/step - loss: 1.4653 - accuracy: 0.4512 - val_loss: 2.2239 - val_accuracy: 0.2533\n",
      "Epoch 6/31\n",
      "7/7 [==============================] - 0s 48ms/step - loss: 1.7340 - accuracy: 0.3838 - val_loss: 1.9139 - val_accuracy: 0.2400\n",
      "Epoch 7/31\n",
      "7/7 [==============================] - 0s 29ms/step - loss: 1.4819 - accuracy: 0.4310 - val_loss: 0.9574 - val_accuracy: 0.6000\n",
      "Epoch 8/31\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 1.3918 - accuracy: 0.4175 - val_loss: 1.6343 - val_accuracy: 0.6000\n",
      "Epoch 9/31\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 1.4583 - accuracy: 0.4579 - val_loss: 3.5887 - val_accuracy: 0.2533\n",
      "Epoch 10/31\n",
      "7/7 [==============================] - 0s 30ms/step - loss: 7.0014 - accuracy: 0.3535 - val_loss: 3.7181 - val_accuracy: 0.6533\n",
      "Epoch 11/31\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 2.4413 - accuracy: 0.4242 - val_loss: 1.6962 - val_accuracy: 0.5867\n",
      "Epoch 12/31\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 1.3818 - accuracy: 0.4949 - val_loss: 1.9052 - val_accuracy: 0.6000\n",
      "Epoch 13/31\n",
      "7/7 [==============================] - 0s 29ms/step - loss: 1.4986 - accuracy: 0.4646 - val_loss: 1.5483 - val_accuracy: 0.6667\n",
      "Epoch 14/31\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 1.3992 - accuracy: 0.5320 - val_loss: 2.0537 - val_accuracy: 0.3600\n",
      "Epoch 15/31\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 1.9681 - accuracy: 0.4209 - val_loss: 2.3206 - val_accuracy: 0.5867\n",
      "Epoch 16/31\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 2.3183 - accuracy: 0.4377 - val_loss: 2.8344 - val_accuracy: 0.6000\n",
      "Epoch 17/31\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 4.7614 - accuracy: 0.4310 - val_loss: 1.5032 - val_accuracy: 0.2267\n",
      "Epoch 18/31\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 1.2877 - accuracy: 0.4646 - val_loss: 0.8860 - val_accuracy: 0.6667\n",
      "Epoch 19/31\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 1.2525 - accuracy: 0.4983 - val_loss: 1.0381 - val_accuracy: 0.5733\n",
      "Epoch 20/31\n",
      "7/7 [==============================] - 0s 40ms/step - loss: 1.4512 - accuracy: 0.4949 - val_loss: 0.9750 - val_accuracy: 0.6133\n",
      "Epoch 21/31\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 1.3650 - accuracy: 0.5421 - val_loss: 1.7950 - val_accuracy: 0.6667\n",
      "Epoch 22/31\n",
      "7/7 [==============================] - 0s 29ms/step - loss: 1.4543 - accuracy: 0.5387 - val_loss: 3.0356 - val_accuracy: 0.2533\n",
      "Epoch 23/31\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 1.9456 - accuracy: 0.4680 - val_loss: 1.0269 - val_accuracy: 0.6667\n",
      "Epoch 24/31\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 1.3215 - accuracy: 0.5488 - val_loss: 1.1919 - val_accuracy: 0.4800\n",
      "Epoch 25/31\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 1.1751 - accuracy: 0.5657 - val_loss: 1.0021 - val_accuracy: 0.6933\n",
      "Epoch 26/31\n",
      "7/7 [==============================] - 0s 30ms/step - loss: 1.5998 - accuracy: 0.5623 - val_loss: 1.2535 - val_accuracy: 0.5467\n",
      "Epoch 27/31\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.9708 - accuracy: 0.6229 - val_loss: 1.0062 - val_accuracy: 0.6933\n",
      "Epoch 28/31\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 1.6215 - accuracy: 0.6330 - val_loss: 1.5629 - val_accuracy: 0.5333\n",
      "Epoch 29/31\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 1.4847 - accuracy: 0.5589 - val_loss: 0.8254 - val_accuracy: 0.7200\n",
      "Epoch 30/31\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.9201 - accuracy: 0.6431 - val_loss: 1.0502 - val_accuracy: 0.6133\n",
      "Epoch 31/31\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 1.6901 - accuracy: 0.5522 - val_loss: 0.8104 - val_accuracy: 0.7200\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "| \u001b[95m3        \u001b[0m | \u001b[95m0.6022   \u001b[0m | \u001b[95m1.162    \u001b[0m | \u001b[95m47.11    \u001b[0m | \u001b[95m30.83    \u001b[0m | \u001b[95m0.02     \u001b[0m | \u001b[95m1.238    \u001b[0m |\n",
      "Epoch 1/65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/rmsprop.py:140: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adagrad.py:81: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 1s 8ms/step - loss: 1373.4286 - accuracy: 0.4040 - val_loss: 6.1245 - val_accuracy: 0.4267\n",
      "Epoch 2/65\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 8.3308 - accuracy: 0.3771 - val_loss: 4.3941 - val_accuracy: 0.2400\n",
      "Epoch 3/65\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 4.3561 - accuracy: 0.4007 - val_loss: 7.0632 - val_accuracy: 0.1600\n",
      "Epoch 4/65\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 19.9585 - accuracy: 0.3434 - val_loss: 7.6335 - val_accuracy: 0.5867\n",
      "Epoch 5/65\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 7.1041 - accuracy: 0.4040 - val_loss: 13.3316 - val_accuracy: 0.2400\n",
      "Epoch 6/65\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 181.3262 - accuracy: 0.4108 - val_loss: 58.3159 - val_accuracy: 0.5600\n",
      "Epoch 7/65\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 24.2035 - accuracy: 0.3468 - val_loss: 3.0447 - val_accuracy: 0.5867\n",
      "Epoch 8/65\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 36.7163 - accuracy: 0.3300 - val_loss: 18.9961 - val_accuracy: 0.1600\n",
      "Epoch 9/65\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 6.5354 - accuracy: 0.3872 - val_loss: 10.8904 - val_accuracy: 0.2400\n",
      "Epoch 10/65\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 855.8900 - accuracy: 0.4310 - val_loss: 12.7090 - val_accuracy: 0.5867\n",
      "Epoch 11/65\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 14.6581 - accuracy: 0.3266 - val_loss: 5.4366 - val_accuracy: 0.1600\n",
      "Epoch 12/65\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 8.2493 - accuracy: 0.3535 - val_loss: 8.4020 - val_accuracy: 0.1600\n",
      "Epoch 13/65\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 11.4143 - accuracy: 0.3838 - val_loss: 16.2770 - val_accuracy: 0.1600\n",
      "Epoch 14/65\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 8.4807 - accuracy: 0.3569 - val_loss: 12.3172 - val_accuracy: 0.2400\n",
      "Epoch 15/65\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 7.1134 - accuracy: 0.3805 - val_loss: 6.6973 - val_accuracy: 0.5867\n",
      "Epoch 16/65\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 7.6593 - accuracy: 0.4242 - val_loss: 8.8612 - val_accuracy: 0.5867\n",
      "Epoch 17/65\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 7.5115 - accuracy: 0.3872 - val_loss: 4.8229 - val_accuracy: 0.5867\n",
      "Epoch 18/65\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 6.4771 - accuracy: 0.4209 - val_loss: 13.3473 - val_accuracy: 0.2400\n",
      "Epoch 19/65\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 7.4511 - accuracy: 0.3973 - val_loss: 10.2173 - val_accuracy: 0.5867\n",
      "Epoch 20/65\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 8.2447 - accuracy: 0.3535 - val_loss: 13.7611 - val_accuracy: 0.2400\n",
      "Epoch 21/65\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 6.9405 - accuracy: 0.3973 - val_loss: 13.5756 - val_accuracy: 0.5867\n",
      "Epoch 22/65\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 7.3564 - accuracy: 0.3704 - val_loss: 7.6590 - val_accuracy: 0.5867\n",
      "Epoch 23/65\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 6.9091 - accuracy: 0.4545 - val_loss: 6.9408 - val_accuracy: 0.5867\n",
      "Epoch 24/65\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 6.5135 - accuracy: 0.4377 - val_loss: 3.0788 - val_accuracy: 0.5867\n",
      "Epoch 25/65\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 7.2939 - accuracy: 0.3906 - val_loss: 8.1597 - val_accuracy: 0.5867\n",
      "Epoch 26/65\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 7.2986 - accuracy: 0.3872 - val_loss: 8.6746 - val_accuracy: 0.5867\n",
      "Epoch 27/65\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 7.0431 - accuracy: 0.4007 - val_loss: 8.0670 - val_accuracy: 0.5867\n",
      "Epoch 28/65\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 6.2862 - accuracy: 0.4141 - val_loss: 14.7169 - val_accuracy: 0.2400\n",
      "Epoch 29/65\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 7.4147 - accuracy: 0.3771 - val_loss: 7.0939 - val_accuracy: 0.5867\n",
      "Epoch 30/65\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 7.8369 - accuracy: 0.3872 - val_loss: 4.0337 - val_accuracy: 0.5867\n",
      "Epoch 31/65\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 6.9470 - accuracy: 0.4040 - val_loss: 5.4820 - val_accuracy: 0.2400\n",
      "Epoch 32/65\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 6.5598 - accuracy: 0.4175 - val_loss: 9.0097 - val_accuracy: 0.5867\n",
      "Epoch 33/65\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 7.6295 - accuracy: 0.3805 - val_loss: 11.0477 - val_accuracy: 0.5867\n",
      "Epoch 34/65\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 6.6605 - accuracy: 0.3771 - val_loss: 17.1727 - val_accuracy: 0.2400\n",
      "Epoch 35/65\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 7.9315 - accuracy: 0.3636 - val_loss: 1.8055 - val_accuracy: 0.5867\n",
      "Epoch 36/65\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 7.5499 - accuracy: 0.3771 - val_loss: 3.8457 - val_accuracy: 0.5867\n",
      "Epoch 37/65\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 7.2410 - accuracy: 0.3502 - val_loss: 6.8069 - val_accuracy: 0.5867\n",
      "Epoch 38/65\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 6.2703 - accuracy: 0.4209 - val_loss: 17.3582 - val_accuracy: 0.2400\n",
      "Epoch 39/65\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 7.7142 - accuracy: 0.3805 - val_loss: 11.0372 - val_accuracy: 0.2400\n",
      "Epoch 40/65\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 5.9303 - accuracy: 0.4579 - val_loss: 19.2988 - val_accuracy: 0.2400\n",
      "Epoch 41/65\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 7.6049 - accuracy: 0.3636 - val_loss: 6.0586 - val_accuracy: 0.5867\n",
      "Epoch 42/65\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 6.7577 - accuracy: 0.3737 - val_loss: 2.7353 - val_accuracy: 0.5867\n",
      "Epoch 43/65\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 7.9236 - accuracy: 0.3603 - val_loss: 2.1709 - val_accuracy: 0.2400\n",
      "Epoch 44/65\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 6.2990 - accuracy: 0.4108 - val_loss: 3.7939 - val_accuracy: 0.2400\n",
      "Epoch 45/65\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 7.5190 - accuracy: 0.3603 - val_loss: 1.8430 - val_accuracy: 0.5867\n",
      "Epoch 46/65\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 6.6882 - accuracy: 0.4074 - val_loss: 8.5484 - val_accuracy: 0.1600\n",
      "Epoch 47/65\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 7.0666 - accuracy: 0.3737 - val_loss: 9.5122 - val_accuracy: 0.5867\n",
      "Epoch 48/65\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 7.8299 - accuracy: 0.3838 - val_loss: 8.4522 - val_accuracy: 0.5867\n",
      "Epoch 49/65\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 5.8976 - accuracy: 0.4141 - val_loss: 7.2062 - val_accuracy: 0.5867\n",
      "Epoch 50/65\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 7.4545 - accuracy: 0.3973 - val_loss: 14.1558 - val_accuracy: 0.5867\n",
      "Epoch 51/65\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 7.5935 - accuracy: 0.3805 - val_loss: 22.9424 - val_accuracy: 0.2400\n",
      "Epoch 52/65\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 6.5488 - accuracy: 0.4074 - val_loss: 3.1470 - val_accuracy: 0.5867\n",
      "Epoch 53/65\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 7.0354 - accuracy: 0.3670 - val_loss: 2.1265 - val_accuracy: 0.5867\n",
      "Epoch 54/65\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 7.7412 - accuracy: 0.3603 - val_loss: 2.1678 - val_accuracy: 0.5867\n",
      "Epoch 55/65\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 6.6443 - accuracy: 0.3569 - val_loss: 13.5870 - val_accuracy: 0.2400\n",
      "Epoch 56/65\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 7.9736 - accuracy: 0.3771 - val_loss: 19.5932 - val_accuracy: 0.2400\n",
      "Epoch 57/65\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 6.4833 - accuracy: 0.4108 - val_loss: 18.6583 - val_accuracy: 0.1600\n",
      "Epoch 58/65\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 7.5609 - accuracy: 0.3704 - val_loss: 14.6682 - val_accuracy: 0.2400\n",
      "Epoch 59/65\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 7.0682 - accuracy: 0.3367 - val_loss: 7.2967 - val_accuracy: 0.1600\n",
      "Epoch 60/65\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 6.7484 - accuracy: 0.4007 - val_loss: 11.6119 - val_accuracy: 0.5867\n",
      "Epoch 61/65\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 7.0770 - accuracy: 0.4209 - val_loss: 5.4494 - val_accuracy: 0.5867\n",
      "Epoch 62/65\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 6.0921 - accuracy: 0.4175 - val_loss: 6.4300 - val_accuracy: 0.5867\n",
      "Epoch 63/65\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 7.2012 - accuracy: 0.4007 - val_loss: 9.4382 - val_accuracy: 0.1600\n",
      "Epoch 64/65\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 7.6981 - accuracy: 0.3636 - val_loss: 12.1858 - val_accuracy: 0.2400\n",
      "Epoch 65/65\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 6.3592 - accuracy: 0.4310 - val_loss: 7.9964 - val_accuracy: 0.5867\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "| \u001b[0m4        \u001b[0m | \u001b[0m0.2043   \u001b[0m | \u001b[0m1.478    \u001b[0m | \u001b[0m8.103    \u001b[0m | \u001b[0m64.76    \u001b[0m | \u001b[0m0.08684  \u001b[0m | \u001b[0m1.223    \u001b[0m |\n",
      "Epoch 1/68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/rmsprop.py:140: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adagrad.py:81: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 162ms/step - loss: 2674884.0000 - accuracy: 0.2256 - val_loss: 27343916.0000 - val_accuracy: 0.0133\n",
      "Epoch 2/68\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 22949950.0000 - accuracy: 0.2862 - val_loss: 306049.7812 - val_accuracy: 0.5600\n",
      "Epoch 3/68\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 187596.7969 - accuracy: 0.4545 - val_loss: 8611.2754 - val_accuracy: 0.4800\n",
      "Epoch 4/68\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 13643.5615 - accuracy: 0.4310 - val_loss: 2262.4470 - val_accuracy: 0.3733\n",
      "Epoch 5/68\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 4102.5537 - accuracy: 0.4815 - val_loss: 3403.1526 - val_accuracy: 0.3600\n",
      "Epoch 6/68\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 1754.4897 - accuracy: 0.5354 - val_loss: 659.5407 - val_accuracy: 0.3600\n",
      "Epoch 7/68\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 2070.8728 - accuracy: 0.4848 - val_loss: 1881.9315 - val_accuracy: 0.5600\n",
      "Epoch 8/68\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 2743.3679 - accuracy: 0.4512 - val_loss: 422.1865 - val_accuracy: 0.5733\n",
      "Epoch 9/68\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 815.5657 - accuracy: 0.4983 - val_loss: 361.7771 - val_accuracy: 0.5600\n",
      "Epoch 10/68\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 698.3859 - accuracy: 0.5185 - val_loss: 261.9442 - val_accuracy: 0.5733\n",
      "Epoch 11/68\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 441.5085 - accuracy: 0.5084 - val_loss: 238.1354 - val_accuracy: 0.5733\n",
      "Epoch 12/68\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 940.8811 - accuracy: 0.4613 - val_loss: 6823.3413 - val_accuracy: 0.5333\n",
      "Epoch 13/68\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 8423.3994 - accuracy: 0.4276 - val_loss: 2379.5454 - val_accuracy: 0.5467\n",
      "Epoch 14/68\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 878.2045 - accuracy: 0.4579 - val_loss: 346.1494 - val_accuracy: 0.2800\n",
      "Epoch 15/68\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 312.3834 - accuracy: 0.4815 - val_loss: 60.7956 - val_accuracy: 0.2533\n",
      "Epoch 16/68\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 203.2756 - accuracy: 0.4478 - val_loss: 32.7915 - val_accuracy: 0.6000\n",
      "Epoch 17/68\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 93.8621 - accuracy: 0.4310 - val_loss: 22.0368 - val_accuracy: 0.2400\n",
      "Epoch 18/68\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 148.8921 - accuracy: 0.4613 - val_loss: 27.0731 - val_accuracy: 0.5867\n",
      "Epoch 19/68\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 56.4053 - accuracy: 0.4209 - val_loss: 10.0372 - val_accuracy: 0.5867\n",
      "Epoch 20/68\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 84.4693 - accuracy: 0.4276 - val_loss: 6.3367 - val_accuracy: 0.6000\n",
      "Epoch 21/68\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 22.5719 - accuracy: 0.4411 - val_loss: 43.1407 - val_accuracy: 0.6000\n",
      "Epoch 22/68\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 31.0465 - accuracy: 0.5084 - val_loss: 7.5140 - val_accuracy: 0.5867\n",
      "Epoch 23/68\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 38.7000 - accuracy: 0.3838 - val_loss: 20.0690 - val_accuracy: 0.5867\n",
      "Epoch 24/68\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 58.5004 - accuracy: 0.4411 - val_loss: 11.3965 - val_accuracy: 0.6000\n",
      "Epoch 25/68\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 68.8354 - accuracy: 0.4478 - val_loss: 7.1652 - val_accuracy: 0.5867\n",
      "Epoch 26/68\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 21.0998 - accuracy: 0.4310 - val_loss: 14.2221 - val_accuracy: 0.5867\n",
      "Epoch 27/68\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 81.5180 - accuracy: 0.5118 - val_loss: 10.9981 - val_accuracy: 0.5867\n",
      "Epoch 28/68\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 74.6121 - accuracy: 0.3502 - val_loss: 16.8410 - val_accuracy: 0.6000\n",
      "Epoch 29/68\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 22.7889 - accuracy: 0.4141 - val_loss: 10.6684 - val_accuracy: 0.5867\n",
      "Epoch 30/68\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 18.2300 - accuracy: 0.4209 - val_loss: 11.1190 - val_accuracy: 0.5867\n",
      "Epoch 31/68\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 28.6025 - accuracy: 0.4680 - val_loss: 38.5190 - val_accuracy: 0.2800\n",
      "Epoch 32/68\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 28.4358 - accuracy: 0.4141 - val_loss: 13.0573 - val_accuracy: 0.5733\n",
      "Epoch 33/68\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 22.0145 - accuracy: 0.3805 - val_loss: 13.0855 - val_accuracy: 0.5733\n",
      "Epoch 34/68\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 21.4163 - accuracy: 0.4411 - val_loss: 12.8126 - val_accuracy: 0.5733\n",
      "Epoch 35/68\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 20.9077 - accuracy: 0.4040 - val_loss: 14.0990 - val_accuracy: 0.5733\n",
      "Epoch 36/68\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 35.3300 - accuracy: 0.4074 - val_loss: 13.3373 - val_accuracy: 0.5867\n",
      "Epoch 37/68\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 17.7033 - accuracy: 0.4108 - val_loss: 10.8665 - val_accuracy: 0.5867\n",
      "Epoch 38/68\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 19.2951 - accuracy: 0.4007 - val_loss: 9.5361 - val_accuracy: 0.5867\n",
      "Epoch 39/68\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 15.7896 - accuracy: 0.4209 - val_loss: 13.4753 - val_accuracy: 0.5867\n",
      "Epoch 40/68\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 16.9451 - accuracy: 0.4714 - val_loss: 10.4530 - val_accuracy: 0.5867\n",
      "Epoch 41/68\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 18.3921 - accuracy: 0.4007 - val_loss: 9.4948 - val_accuracy: 0.5867\n",
      "Epoch 42/68\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 17.9737 - accuracy: 0.4343 - val_loss: 9.1908 - val_accuracy: 0.2933\n",
      "Epoch 43/68\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 18.5463 - accuracy: 0.3872 - val_loss: 10.2324 - val_accuracy: 0.5867\n",
      "Epoch 44/68\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 18.8431 - accuracy: 0.3838 - val_loss: 10.1576 - val_accuracy: 0.5867\n",
      "Epoch 45/68\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 143.9571 - accuracy: 0.4613 - val_loss: 613.9999 - val_accuracy: 0.3067\n",
      "Epoch 46/68\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 1817139.2500 - accuracy: 0.2727 - val_loss: 366.1574 - val_accuracy: 0.2400\n",
      "Epoch 47/68\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 315.0892 - accuracy: 0.3872 - val_loss: 61.2587 - val_accuracy: 0.2400\n",
      "Epoch 48/68\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 76.8561 - accuracy: 0.3199 - val_loss: 62.5697 - val_accuracy: 0.5867\n",
      "Epoch 49/68\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 81.7409 - accuracy: 0.4074 - val_loss: 25.3515 - val_accuracy: 0.5867\n",
      "Epoch 50/68\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 55.0682 - accuracy: 0.3569 - val_loss: 43.4828 - val_accuracy: 0.2400\n",
      "Epoch 51/68\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 59.7740 - accuracy: 0.2795 - val_loss: 46.4797 - val_accuracy: 0.1600\n",
      "Epoch 52/68\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 95.7850 - accuracy: 0.2222 - val_loss: 36.6808 - val_accuracy: 0.2400\n",
      "Epoch 53/68\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 49.0097 - accuracy: 0.2896 - val_loss: 63.1706 - val_accuracy: 0.2400\n",
      "Epoch 54/68\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 72.0894 - accuracy: 0.2391 - val_loss: 39.5786 - val_accuracy: 0.0133\n",
      "Epoch 55/68\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 63.7037 - accuracy: 0.2559 - val_loss: 39.3354 - val_accuracy: 0.2400\n",
      "Epoch 56/68\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 72.9477 - accuracy: 0.2323 - val_loss: 19.5706 - val_accuracy: 0.5867\n",
      "Epoch 57/68\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 80.9638 - accuracy: 0.2391 - val_loss: 67.3123 - val_accuracy: 0.2400\n",
      "Epoch 58/68\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 64.9945 - accuracy: 0.2256 - val_loss: 56.2794 - val_accuracy: 0.2400\n",
      "Epoch 59/68\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 54.7929 - accuracy: 0.2121 - val_loss: 44.2833 - val_accuracy: 0.2400\n",
      "Epoch 60/68\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 40.8009 - accuracy: 0.2492 - val_loss: 30.5402 - val_accuracy: 0.2400\n",
      "Epoch 61/68\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 28.5109 - accuracy: 0.2862 - val_loss: 16.9167 - val_accuracy: 0.2400\n",
      "Epoch 62/68\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 21.7889 - accuracy: 0.3165 - val_loss: 7.3026 - val_accuracy: 0.2400\n",
      "Epoch 63/68\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 18.5180 - accuracy: 0.3165 - val_loss: 3.1727 - val_accuracy: 0.5867\n",
      "Epoch 64/68\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 17.3086 - accuracy: 0.3300 - val_loss: 3.3900 - val_accuracy: 0.5867\n",
      "Epoch 65/68\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 15.6767 - accuracy: 0.3771 - val_loss: 4.2561 - val_accuracy: 0.5867\n",
      "Epoch 66/68\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 15.9027 - accuracy: 0.4074 - val_loss: 5.8181 - val_accuracy: 0.5867\n",
      "Epoch 67/68\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 16.0678 - accuracy: 0.4276 - val_loss: 4.2234 - val_accuracy: 0.5867\n",
      "Epoch 68/68\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 17.5549 - accuracy: 0.3367 - val_loss: 4.4613 - val_accuracy: 0.5867\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "| \u001b[0m5        \u001b[0m | \u001b[0m0.2043   \u001b[0m | \u001b[0m0.9423   \u001b[0m | \u001b[0m116.7    \u001b[0m | \u001b[0m68.08    \u001b[0m | \u001b[0m0.4232   \u001b[0m | \u001b[0m1.005    \u001b[0m |\n",
      "Epoch 1/88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/rmsprop.py:140: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adagrad.py:81: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 1s 16ms/step - loss: 851074.1875 - accuracy: 0.3603 - val_loss: 98.6777 - val_accuracy: 0.2267\n",
      "Epoch 2/88\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 2.1404 - accuracy: 0.4680 - val_loss: 95.1300 - val_accuracy: 0.2000\n",
      "Epoch 3/88\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1.0834 - accuracy: 0.5017 - val_loss: 94.8512 - val_accuracy: 0.6000\n",
      "Epoch 4/88\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 1.0947 - accuracy: 0.4916 - val_loss: 94.8672 - val_accuracy: 0.6000\n",
      "Epoch 5/88\n",
      "17/17 [==============================] - 0s 14ms/step - loss: 1.1017 - accuracy: 0.4714 - val_loss: 94.7992 - val_accuracy: 0.6000\n",
      "Epoch 6/88\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 1.0952 - accuracy: 0.5118 - val_loss: 94.9377 - val_accuracy: 0.6000\n",
      "Epoch 7/88\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 1.0931 - accuracy: 0.5051 - val_loss: 95.2245 - val_accuracy: 0.2400\n",
      "Epoch 8/88\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 1.1028 - accuracy: 0.4983 - val_loss: 94.9215 - val_accuracy: 0.6000\n",
      "Epoch 9/88\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 1.1223 - accuracy: 0.4646 - val_loss: 94.9376 - val_accuracy: 0.2267\n",
      "Epoch 10/88\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 1.0873 - accuracy: 0.4747 - val_loss: 94.8542 - val_accuracy: 0.6000\n",
      "Epoch 11/88\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 1.1007 - accuracy: 0.5017 - val_loss: 94.9689 - val_accuracy: 0.2267\n",
      "Epoch 12/88\n",
      "17/17 [==============================] - 0s 14ms/step - loss: 1.1086 - accuracy: 0.4040 - val_loss: 94.9468 - val_accuracy: 0.6000\n",
      "Epoch 13/88\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 3.3182 - accuracy: 0.4242 - val_loss: 6.0263 - val_accuracy: 0.1733\n",
      "Epoch 14/88\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 1.1035 - accuracy: 0.4714 - val_loss: 5.8046 - val_accuracy: 0.2400\n",
      "Epoch 15/88\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 1.1223 - accuracy: 0.4310 - val_loss: 5.7000 - val_accuracy: 0.5867\n",
      "Epoch 16/88\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 1.1148 - accuracy: 0.4377 - val_loss: 5.8587 - val_accuracy: 0.2400\n",
      "Epoch 17/88\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 1.0925 - accuracy: 0.4680 - val_loss: 5.6854 - val_accuracy: 0.5867\n",
      "Epoch 18/88\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 1.1426 - accuracy: 0.4377 - val_loss: 5.6837 - val_accuracy: 0.5867\n",
      "Epoch 19/88\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 1.1116 - accuracy: 0.4882 - val_loss: 5.7584 - val_accuracy: 0.5867\n",
      "Epoch 20/88\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 1.1091 - accuracy: 0.4714 - val_loss: 5.8414 - val_accuracy: 0.5867\n",
      "Epoch 21/88\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 1.0915 - accuracy: 0.4545 - val_loss: 5.7073 - val_accuracy: 0.5867\n",
      "Epoch 22/88\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 1.1265 - accuracy: 0.4714 - val_loss: 6.1257 - val_accuracy: 0.1733\n",
      "Epoch 23/88\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 1.1161 - accuracy: 0.4310 - val_loss: 6.2110 - val_accuracy: 0.2400\n",
      "Epoch 24/88\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 1.1212 - accuracy: 0.4747 - val_loss: 5.8613 - val_accuracy: 0.2400\n",
      "Epoch 25/88\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1.1023 - accuracy: 0.4242 - val_loss: 5.7032 - val_accuracy: 0.5867\n",
      "Epoch 26/88\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1.1313 - accuracy: 0.4074 - val_loss: 5.6998 - val_accuracy: 0.5867\n",
      "Epoch 27/88\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 1.0915 - accuracy: 0.4646 - val_loss: 5.7209 - val_accuracy: 0.5867\n",
      "Epoch 28/88\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 1.0903 - accuracy: 0.4815 - val_loss: 5.8002 - val_accuracy: 0.2400\n",
      "Epoch 29/88\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 1.1252 - accuracy: 0.4074 - val_loss: 5.7044 - val_accuracy: 0.5867\n",
      "Epoch 30/88\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 1.1257 - accuracy: 0.4983 - val_loss: 5.6896 - val_accuracy: 0.5867\n",
      "Epoch 31/88\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 1.0896 - accuracy: 0.4411 - val_loss: 5.8147 - val_accuracy: 0.2400\n",
      "Epoch 32/88\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 1.0962 - accuracy: 0.4141 - val_loss: 6.1568 - val_accuracy: 0.1733\n",
      "Epoch 33/88\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 1.1114 - accuracy: 0.4579 - val_loss: 5.7510 - val_accuracy: 0.5867\n",
      "Epoch 34/88\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 1.1093 - accuracy: 0.4949 - val_loss: 6.0292 - val_accuracy: 0.2400\n",
      "Epoch 35/88\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 1.0832 - accuracy: 0.4882 - val_loss: 5.6861 - val_accuracy: 0.5867\n",
      "Epoch 36/88\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 1.1013 - accuracy: 0.5084 - val_loss: 5.7550 - val_accuracy: 0.5867\n",
      "Epoch 37/88\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 1.1312 - accuracy: 0.4747 - val_loss: 5.9478 - val_accuracy: 0.2400\n",
      "Epoch 38/88\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1.1226 - accuracy: 0.4377 - val_loss: 5.7956 - val_accuracy: 0.2400\n",
      "Epoch 39/88\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1.0945 - accuracy: 0.4680 - val_loss: 5.7726 - val_accuracy: 0.5867\n",
      "Epoch 40/88\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1.0997 - accuracy: 0.4545 - val_loss: 5.7700 - val_accuracy: 0.5867\n",
      "Epoch 41/88\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1.0974 - accuracy: 0.4815 - val_loss: 5.8348 - val_accuracy: 0.5867\n",
      "Epoch 42/88\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1.1170 - accuracy: 0.4781 - val_loss: 5.8326 - val_accuracy: 0.2400\n",
      "Epoch 43/88\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1.1064 - accuracy: 0.4579 - val_loss: 5.8348 - val_accuracy: 0.2400\n",
      "Epoch 44/88\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1.0784 - accuracy: 0.4983 - val_loss: 5.7884 - val_accuracy: 0.5867\n",
      "Epoch 45/88\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1.0877 - accuracy: 0.4848 - val_loss: 5.7176 - val_accuracy: 0.5867\n",
      "Epoch 46/88\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 1.1056 - accuracy: 0.4848 - val_loss: 5.7312 - val_accuracy: 0.5867\n",
      "Epoch 47/88\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 1.0931 - accuracy: 0.4848 - val_loss: 5.7308 - val_accuracy: 0.5867\n",
      "Epoch 48/88\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1.1507 - accuracy: 0.4276 - val_loss: 5.7008 - val_accuracy: 0.5867\n",
      "Epoch 49/88\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 1.1236 - accuracy: 0.4680 - val_loss: 5.7558 - val_accuracy: 0.5867\n",
      "Epoch 50/88\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 1.1024 - accuracy: 0.4916 - val_loss: 5.7604 - val_accuracy: 0.5867\n",
      "Epoch 51/88\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 1.0881 - accuracy: 0.4882 - val_loss: 5.7505 - val_accuracy: 0.5867\n",
      "Epoch 52/88\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 1.1396 - accuracy: 0.4714 - val_loss: 5.6843 - val_accuracy: 0.5867\n",
      "Epoch 53/88\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 1.0820 - accuracy: 0.4815 - val_loss: 5.8396 - val_accuracy: 0.2400\n",
      "Epoch 54/88\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1.1159 - accuracy: 0.4646 - val_loss: 5.7532 - val_accuracy: 0.5867\n",
      "Epoch 55/88\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1.1064 - accuracy: 0.4983 - val_loss: 5.7492 - val_accuracy: 0.5867\n",
      "Epoch 56/88\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1.1195 - accuracy: 0.4579 - val_loss: 5.8446 - val_accuracy: 0.1733\n",
      "Epoch 57/88\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1.1309 - accuracy: 0.4512 - val_loss: 5.7189 - val_accuracy: 0.5867\n",
      "Epoch 58/88\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1.1028 - accuracy: 0.4882 - val_loss: 5.6888 - val_accuracy: 0.5867\n",
      "Epoch 59/88\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1.1181 - accuracy: 0.4781 - val_loss: 5.6879 - val_accuracy: 0.5867\n",
      "Epoch 60/88\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1.1123 - accuracy: 0.4613 - val_loss: 5.6906 - val_accuracy: 0.5867\n",
      "Epoch 61/88\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 1.0893 - accuracy: 0.5051 - val_loss: 5.7560 - val_accuracy: 0.5867\n",
      "Epoch 62/88\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 1.1141 - accuracy: 0.4916 - val_loss: 5.7241 - val_accuracy: 0.5867\n",
      "Epoch 63/88\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 1.1241 - accuracy: 0.4714 - val_loss: 5.7371 - val_accuracy: 0.5867\n",
      "Epoch 64/88\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 1.1106 - accuracy: 0.4545 - val_loss: 6.0421 - val_accuracy: 0.2400\n",
      "Epoch 65/88\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 1.1246 - accuracy: 0.4646 - val_loss: 5.6745 - val_accuracy: 0.5867\n",
      "Epoch 66/88\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 1.1093 - accuracy: 0.4310 - val_loss: 5.7117 - val_accuracy: 0.5867\n",
      "Epoch 67/88\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 1.1015 - accuracy: 0.4680 - val_loss: 5.7400 - val_accuracy: 0.5867\n",
      "Epoch 68/88\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 1.1051 - accuracy: 0.4848 - val_loss: 5.7875 - val_accuracy: 0.5867\n",
      "Epoch 69/88\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 1.0899 - accuracy: 0.5051 - val_loss: 5.8176 - val_accuracy: 0.5867\n",
      "Epoch 70/88\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 1.1066 - accuracy: 0.4815 - val_loss: 6.0984 - val_accuracy: 0.2400\n",
      "Epoch 71/88\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 1.1129 - accuracy: 0.5017 - val_loss: 5.7083 - val_accuracy: 0.5867\n",
      "Epoch 72/88\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1.1039 - accuracy: 0.4579 - val_loss: 5.6875 - val_accuracy: 0.5867\n",
      "Epoch 73/88\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1.1204 - accuracy: 0.4276 - val_loss: 5.7448 - val_accuracy: 0.5867\n",
      "Epoch 74/88\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1.0962 - accuracy: 0.4882 - val_loss: 5.8464 - val_accuracy: 0.2400\n",
      "Epoch 75/88\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 1.1127 - accuracy: 0.4680 - val_loss: 5.7785 - val_accuracy: 0.5867\n",
      "Epoch 76/88\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1.0722 - accuracy: 0.4949 - val_loss: 5.8551 - val_accuracy: 0.2400\n",
      "Epoch 77/88\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1.1294 - accuracy: 0.4781 - val_loss: 5.8328 - val_accuracy: 0.1733\n",
      "Epoch 78/88\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 1.0988 - accuracy: 0.4781 - val_loss: 5.6946 - val_accuracy: 0.5867\n",
      "Epoch 79/88\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1.1164 - accuracy: 0.4444 - val_loss: 5.7471 - val_accuracy: 0.5867\n",
      "Epoch 80/88\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1.1300 - accuracy: 0.4478 - val_loss: 5.6795 - val_accuracy: 0.5867\n",
      "Epoch 81/88\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 1.0940 - accuracy: 0.4579 - val_loss: 5.6882 - val_accuracy: 0.5867\n",
      "Epoch 82/88\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 1.1239 - accuracy: 0.4781 - val_loss: 5.8300 - val_accuracy: 0.2400\n",
      "Epoch 83/88\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 1.0845 - accuracy: 0.4916 - val_loss: 6.1602 - val_accuracy: 0.2400\n",
      "Epoch 84/88\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 1.1569 - accuracy: 0.4579 - val_loss: 5.7914 - val_accuracy: 0.2400\n",
      "Epoch 85/88\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1.1069 - accuracy: 0.4646 - val_loss: 5.7257 - val_accuracy: 0.5867\n",
      "Epoch 86/88\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 1.0816 - accuracy: 0.4983 - val_loss: 5.9133 - val_accuracy: 0.2400\n",
      "Epoch 87/88\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1.1588 - accuracy: 0.3737 - val_loss: 5.6853 - val_accuracy: 0.5867\n",
      "Epoch 88/88\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1.0882 - accuracy: 0.4848 - val_loss: 5.6906 - val_accuracy: 0.5867\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "| \u001b[0m6        \u001b[0m | \u001b[0m0.5376   \u001b[0m | \u001b[0m0.07513  \u001b[0m | \u001b[0m17.98    \u001b[0m | \u001b[0m88.33    \u001b[0m | \u001b[0m0.4962   \u001b[0m | \u001b[0m0.7488   \u001b[0m |\n",
      "Epoch 1/51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/rmsprop.py:140: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adagrad.py:81: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 4s 1s/step - loss: 101.4022 - accuracy: 0.2155 - val_loss: 26.3152 - val_accuracy: 0.5867\n",
      "Epoch 2/51\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 67.2478 - accuracy: 0.3872 - val_loss: 65.9524 - val_accuracy: 0.5867\n",
      "Epoch 3/51\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 66.0385 - accuracy: 0.4747 - val_loss: 66.6456 - val_accuracy: 0.2400\n",
      "Epoch 4/51\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 84.4293 - accuracy: 0.3098 - val_loss: 80.5177 - val_accuracy: 0.2400\n",
      "Epoch 5/51\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 47.5737 - accuracy: 0.4343 - val_loss: 56.7403 - val_accuracy: 0.2400\n",
      "Epoch 6/51\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 50.3396 - accuracy: 0.3704 - val_loss: 50.7875 - val_accuracy: 0.5867\n",
      "Epoch 7/51\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 52.7977 - accuracy: 0.4141 - val_loss: 51.1975 - val_accuracy: 0.5867\n",
      "Epoch 8/51\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 57.3899 - accuracy: 0.4074 - val_loss: 54.7925 - val_accuracy: 0.5867\n",
      "Epoch 9/51\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 47.8110 - accuracy: 0.4377 - val_loss: 51.0661 - val_accuracy: 0.5867\n",
      "Epoch 10/51\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 48.1440 - accuracy: 0.4040 - val_loss: 45.9581 - val_accuracy: 0.5867\n",
      "Epoch 11/51\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 52.6341 - accuracy: 0.4007 - val_loss: 55.0041 - val_accuracy: 0.5867\n",
      "Epoch 12/51\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 58.8687 - accuracy: 0.3670 - val_loss: 55.5106 - val_accuracy: 0.5867\n",
      "Epoch 13/51\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 52.2057 - accuracy: 0.3906 - val_loss: 36.3721 - val_accuracy: 0.5867\n",
      "Epoch 14/51\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 52.8326 - accuracy: 0.4040 - val_loss: 35.7968 - val_accuracy: 0.5867\n",
      "Epoch 15/51\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 56.6312 - accuracy: 0.3872 - val_loss: 22.6179 - val_accuracy: 0.5867\n",
      "Epoch 16/51\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 45.4628 - accuracy: 0.3838 - val_loss: 39.7445 - val_accuracy: 0.5867\n",
      "Epoch 17/51\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 58.2010 - accuracy: 0.4040 - val_loss: 31.7752 - val_accuracy: 0.5867\n",
      "Epoch 18/51\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 52.4334 - accuracy: 0.3569 - val_loss: 53.8587 - val_accuracy: 0.5867\n",
      "Epoch 19/51\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 56.5968 - accuracy: 0.3670 - val_loss: 28.3225 - val_accuracy: 0.5867\n",
      "Epoch 20/51\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 43.2848 - accuracy: 0.3805 - val_loss: 42.1707 - val_accuracy: 0.5867\n",
      "Epoch 21/51\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 53.8424 - accuracy: 0.4310 - val_loss: 45.6676 - val_accuracy: 0.5867\n",
      "Epoch 22/51\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 58.1735 - accuracy: 0.3670 - val_loss: 54.5177 - val_accuracy: 0.5867\n",
      "Epoch 23/51\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 51.1395 - accuracy: 0.3670 - val_loss: 45.5370 - val_accuracy: 0.5867\n",
      "Epoch 24/51\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 53.7691 - accuracy: 0.4242 - val_loss: 43.2597 - val_accuracy: 0.5867\n",
      "Epoch 25/51\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 50.3047 - accuracy: 0.3502 - val_loss: 38.2706 - val_accuracy: 0.5867\n",
      "Epoch 26/51\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 58.9278 - accuracy: 0.3670 - val_loss: 65.5175 - val_accuracy: 0.5867\n",
      "Epoch 27/51\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 38.2435 - accuracy: 0.4276 - val_loss: 22.1939 - val_accuracy: 0.5867\n",
      "Epoch 28/51\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 48.2541 - accuracy: 0.4007 - val_loss: 52.3321 - val_accuracy: 0.5867\n",
      "Epoch 29/51\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 67.8895 - accuracy: 0.3569 - val_loss: 33.8716 - val_accuracy: 0.5867\n",
      "Epoch 30/51\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 50.5375 - accuracy: 0.3872 - val_loss: 47.6248 - val_accuracy: 0.2400\n",
      "Epoch 31/51\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 54.4792 - accuracy: 0.3434 - val_loss: 83.9048 - val_accuracy: 0.2400\n",
      "Epoch 32/51\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 46.4074 - accuracy: 0.4074 - val_loss: 57.0108 - val_accuracy: 0.2400\n",
      "Epoch 33/51\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 48.2343 - accuracy: 0.3872 - val_loss: 78.6829 - val_accuracy: 0.2400\n",
      "Epoch 34/51\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 47.0844 - accuracy: 0.4007 - val_loss: 50.6333 - val_accuracy: 0.5867\n",
      "Epoch 35/51\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 55.3451 - accuracy: 0.3805 - val_loss: 42.8240 - val_accuracy: 0.5867\n",
      "Epoch 36/51\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 65.2840 - accuracy: 0.3771 - val_loss: 46.6366 - val_accuracy: 0.5867\n",
      "Epoch 37/51\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 54.6675 - accuracy: 0.3300 - val_loss: 71.9032 - val_accuracy: 0.2400\n",
      "Epoch 38/51\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 51.7752 - accuracy: 0.3636 - val_loss: 57.6816 - val_accuracy: 0.2400\n",
      "Epoch 39/51\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 49.0398 - accuracy: 0.4310 - val_loss: 37.6457 - val_accuracy: 0.1600\n",
      "Epoch 40/51\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 57.2327 - accuracy: 0.3569 - val_loss: 30.3018 - val_accuracy: 0.0133\n",
      "Epoch 41/51\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 38.8896 - accuracy: 0.3333 - val_loss: 27.0303 - val_accuracy: 0.5867\n",
      "Epoch 42/51\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 50.1815 - accuracy: 0.3838 - val_loss: 25.3923 - val_accuracy: 0.5867\n",
      "Epoch 43/51\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 42.6684 - accuracy: 0.3670 - val_loss: 36.9374 - val_accuracy: 0.5867\n",
      "Epoch 44/51\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 38.9694 - accuracy: 0.3535 - val_loss: 70.4140 - val_accuracy: 0.5867\n",
      "Epoch 45/51\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 75.6740 - accuracy: 0.3569 - val_loss: 67.9583 - val_accuracy: 0.5867\n",
      "Epoch 46/51\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 38.8861 - accuracy: 0.4242 - val_loss: 53.6317 - val_accuracy: 0.1600\n",
      "Epoch 47/51\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 69.9894 - accuracy: 0.3367 - val_loss: 5.2038 - val_accuracy: 0.5867\n",
      "Epoch 48/51\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 27.6017 - accuracy: 0.4007 - val_loss: 37.8941 - val_accuracy: 0.5867\n",
      "Epoch 49/51\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 46.7849 - accuracy: 0.4512 - val_loss: 44.5575 - val_accuracy: 0.5867\n",
      "Epoch 50/51\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 66.5024 - accuracy: 0.3939 - val_loss: 59.8835 - val_accuracy: 0.5867\n",
      "Epoch 51/51\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 66.5824 - accuracy: 0.3906 - val_loss: 55.0015 - val_accuracy: 0.5867\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m0.2043   \u001b[0m | \u001b[0m2.284    \u001b[0m | \u001b[0m83.33    \u001b[0m | \u001b[0m50.85    \u001b[0m | \u001b[0m0.6476   \u001b[0m | \u001b[0m0.515    \u001b[0m |\n",
      "Epoch 1/68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/rmsprop.py:140: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adagrad.py:81: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 1s 9ms/step - loss: 17.4261 - accuracy: 0.3973 - val_loss: 17.7321 - val_accuracy: 0.5867\n",
      "Epoch 2/68\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 16.8582 - accuracy: 0.4242 - val_loss: 18.6145 - val_accuracy: 0.2400\n",
      "Epoch 3/68\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 17.6299 - accuracy: 0.3906 - val_loss: 23.8161 - val_accuracy: 0.2400\n",
      "Epoch 4/68\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 18.4205 - accuracy: 0.3468 - val_loss: 21.4338 - val_accuracy: 0.2400\n",
      "Epoch 5/68\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 19.0657 - accuracy: 0.3434 - val_loss: 10.8953 - val_accuracy: 0.5867\n",
      "Epoch 6/68\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 15.3829 - accuracy: 0.3939 - val_loss: 12.6978 - val_accuracy: 0.2533\n",
      "Epoch 7/68\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 16.1060 - accuracy: 0.4209 - val_loss: 6.7823 - val_accuracy: 0.5867\n",
      "Epoch 8/68\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 16.4022 - accuracy: 0.3704 - val_loss: 21.0181 - val_accuracy: 0.2400\n",
      "Epoch 9/68\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 17.5007 - accuracy: 0.4007 - val_loss: 7.4476 - val_accuracy: 0.5867\n",
      "Epoch 10/68\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 17.1024 - accuracy: 0.3771 - val_loss: 7.5643 - val_accuracy: 0.5867\n",
      "Epoch 11/68\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 15.4564 - accuracy: 0.3973 - val_loss: 14.8228 - val_accuracy: 0.5867\n",
      "Epoch 12/68\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 14.3229 - accuracy: 0.4175 - val_loss: 5.3750 - val_accuracy: 0.5867\n",
      "Epoch 13/68\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 18.5801 - accuracy: 0.3670 - val_loss: 8.7861 - val_accuracy: 0.2400\n",
      "Epoch 14/68\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 13.3527 - accuracy: 0.4377 - val_loss: 8.9438 - val_accuracy: 0.2400\n",
      "Epoch 15/68\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 15.1795 - accuracy: 0.3603 - val_loss: 36.3555 - val_accuracy: 0.1600\n",
      "Epoch 16/68\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 17.1429 - accuracy: 0.3636 - val_loss: 25.1557 - val_accuracy: 0.1600\n",
      "Epoch 17/68\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 17.4427 - accuracy: 0.3906 - val_loss: 8.2865 - val_accuracy: 0.5333\n",
      "Epoch 18/68\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 16.7934 - accuracy: 0.3603 - val_loss: 15.4911 - val_accuracy: 0.5867\n",
      "Epoch 19/68\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 14.5305 - accuracy: 0.4141 - val_loss: 8.8865 - val_accuracy: 0.3067\n",
      "Epoch 20/68\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 13.6869 - accuracy: 0.3838 - val_loss: 11.1210 - val_accuracy: 0.5867\n",
      "Epoch 21/68\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 17.0644 - accuracy: 0.3670 - val_loss: 3.1919 - val_accuracy: 0.4800\n",
      "Epoch 22/68\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 14.1455 - accuracy: 0.4074 - val_loss: 4.5492 - val_accuracy: 0.5867\n",
      "Epoch 23/68\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 15.5285 - accuracy: 0.3636 - val_loss: 7.6199 - val_accuracy: 0.4933\n",
      "Epoch 24/68\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 14.0308 - accuracy: 0.4175 - val_loss: 11.9383 - val_accuracy: 0.5867\n",
      "Epoch 25/68\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 15.4182 - accuracy: 0.3805 - val_loss: 14.7827 - val_accuracy: 0.2400\n",
      "Epoch 26/68\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 15.4528 - accuracy: 0.4074 - val_loss: 21.5601 - val_accuracy: 0.1600\n",
      "Epoch 27/68\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 17.1356 - accuracy: 0.3704 - val_loss: 8.7309 - val_accuracy: 0.5867\n",
      "Epoch 28/68\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 14.5287 - accuracy: 0.3939 - val_loss: 15.4479 - val_accuracy: 0.5867\n",
      "Epoch 29/68\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 17.0849 - accuracy: 0.3569 - val_loss: 15.5681 - val_accuracy: 0.5867\n",
      "Epoch 30/68\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 17.5081 - accuracy: 0.3805 - val_loss: 13.2877 - val_accuracy: 0.2400\n",
      "Epoch 31/68\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 14.1686 - accuracy: 0.3670 - val_loss: 27.4176 - val_accuracy: 0.2400\n",
      "Epoch 32/68\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 14.4021 - accuracy: 0.4276 - val_loss: 10.2331 - val_accuracy: 0.5867\n",
      "Epoch 33/68\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 16.2483 - accuracy: 0.3872 - val_loss: 15.7896 - val_accuracy: 0.2267\n",
      "Epoch 34/68\n",
      "27/27 [==============================] - 0s 8ms/step - loss: 15.9708 - accuracy: 0.3939 - val_loss: 3.9940 - val_accuracy: 0.4667\n",
      "Epoch 35/68\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 15.0508 - accuracy: 0.4007 - val_loss: 11.2488 - val_accuracy: 0.2267\n",
      "Epoch 36/68\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 14.5698 - accuracy: 0.3872 - val_loss: 7.8831 - val_accuracy: 0.2533\n",
      "Epoch 37/68\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 13.9528 - accuracy: 0.4074 - val_loss: 8.7264 - val_accuracy: 0.2800\n",
      "Epoch 38/68\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 16.7660 - accuracy: 0.3434 - val_loss: 10.0518 - val_accuracy: 0.5867\n",
      "Epoch 39/68\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 15.3007 - accuracy: 0.4209 - val_loss: 8.6367 - val_accuracy: 0.4267\n",
      "Epoch 40/68\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 14.2462 - accuracy: 0.3906 - val_loss: 17.1106 - val_accuracy: 0.5867\n",
      "Epoch 41/68\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 14.0551 - accuracy: 0.4242 - val_loss: 3.3229 - val_accuracy: 0.5867\n",
      "Epoch 42/68\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 14.8591 - accuracy: 0.3872 - val_loss: 21.8921 - val_accuracy: 0.5867\n",
      "Epoch 43/68\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 16.4959 - accuracy: 0.3939 - val_loss: 12.6892 - val_accuracy: 0.3067\n",
      "Epoch 44/68\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 15.4892 - accuracy: 0.3805 - val_loss: 7.0394 - val_accuracy: 0.5867\n",
      "Epoch 45/68\n",
      "27/27 [==============================] - 0s 8ms/step - loss: 12.1936 - accuracy: 0.4646 - val_loss: 14.1189 - val_accuracy: 0.5867\n",
      "Epoch 46/68\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 14.8045 - accuracy: 0.3603 - val_loss: 10.9073 - val_accuracy: 0.2533\n",
      "Epoch 47/68\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 14.4640 - accuracy: 0.3973 - val_loss: 14.4677 - val_accuracy: 0.5867\n",
      "Epoch 48/68\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 16.1529 - accuracy: 0.4074 - val_loss: 7.8849 - val_accuracy: 0.5867\n",
      "Epoch 49/68\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 14.3829 - accuracy: 0.3737 - val_loss: 9.9371 - val_accuracy: 0.2400\n",
      "Epoch 50/68\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 13.2979 - accuracy: 0.4209 - val_loss: 14.3551 - val_accuracy: 0.5867\n",
      "Epoch 51/68\n",
      "27/27 [==============================] - 0s 8ms/step - loss: 16.5864 - accuracy: 0.3771 - val_loss: 15.9824 - val_accuracy: 0.4267\n",
      "Epoch 52/68\n",
      "27/27 [==============================] - 0s 8ms/step - loss: 14.8383 - accuracy: 0.3973 - val_loss: 12.1107 - val_accuracy: 0.3867\n",
      "Epoch 53/68\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 13.2315 - accuracy: 0.3872 - val_loss: 5.5532 - val_accuracy: 0.4267\n",
      "Epoch 54/68\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 15.7456 - accuracy: 0.3805 - val_loss: 9.6449 - val_accuracy: 0.1867\n",
      "Epoch 55/68\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 11.5428 - accuracy: 0.4411 - val_loss: 7.6554 - val_accuracy: 0.5200\n",
      "Epoch 56/68\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 15.2058 - accuracy: 0.4310 - val_loss: 10.6974 - val_accuracy: 0.5867\n",
      "Epoch 57/68\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 15.2210 - accuracy: 0.4007 - val_loss: 13.1340 - val_accuracy: 0.2400\n",
      "Epoch 58/68\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 14.0418 - accuracy: 0.3939 - val_loss: 9.6763 - val_accuracy: 0.5867\n",
      "Epoch 59/68\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 15.9488 - accuracy: 0.3771 - val_loss: 11.3146 - val_accuracy: 0.2400\n",
      "Epoch 60/68\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 14.4439 - accuracy: 0.4074 - val_loss: 14.6838 - val_accuracy: 0.2400\n",
      "Epoch 61/68\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 15.7578 - accuracy: 0.3603 - val_loss: 9.1126 - val_accuracy: 0.1733\n",
      "Epoch 62/68\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 15.7696 - accuracy: 0.3502 - val_loss: 12.0214 - val_accuracy: 0.2933\n",
      "Epoch 63/68\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 14.1243 - accuracy: 0.4108 - val_loss: 7.5570 - val_accuracy: 0.2400\n",
      "Epoch 64/68\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 16.8258 - accuracy: 0.4007 - val_loss: 6.4255 - val_accuracy: 0.3200\n",
      "Epoch 65/68\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 13.6327 - accuracy: 0.3939 - val_loss: 4.8836 - val_accuracy: 0.5733\n",
      "Epoch 66/68\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 14.3686 - accuracy: 0.4175 - val_loss: 18.5335 - val_accuracy: 0.1733\n",
      "Epoch 67/68\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 15.9250 - accuracy: 0.3737 - val_loss: 13.0628 - val_accuracy: 0.5867\n",
      "Epoch 68/68\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 12.7280 - accuracy: 0.4343 - val_loss: 7.7378 - val_accuracy: 0.5867\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "| \u001b[0m8        \u001b[0m | \u001b[0m0.2043   \u001b[0m | \u001b[0m2.128    \u001b[0m | \u001b[0m10.83    \u001b[0m | \u001b[0m67.99    \u001b[0m | \u001b[0m0.2113   \u001b[0m | \u001b[0m0.7468   \u001b[0m |\n",
      "Epoch 1/83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/rmsprop.py:140: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adagrad.py:81: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 110ms/step - loss: 96598088.0000 - accuracy: 0.1852 - val_loss: 225895088.0000 - val_accuracy: 0.2267\n",
      "Epoch 2/83\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 129450536.0000 - accuracy: 0.4882 - val_loss: 685267.6875 - val_accuracy: 0.5200\n",
      "Epoch 3/83\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 483377.1250 - accuracy: 0.3838 - val_loss: 29203.8965 - val_accuracy: 0.5867\n",
      "Epoch 4/83\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 22387.8809 - accuracy: 0.4175 - val_loss: 1193.8579 - val_accuracy: 0.5867\n",
      "Epoch 5/83\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 7446.9150 - accuracy: 0.3704 - val_loss: 2412.8560 - val_accuracy: 0.5867\n",
      "Epoch 6/83\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 5938.2617 - accuracy: 0.3165 - val_loss: 1257.7762 - val_accuracy: 0.1733\n",
      "Epoch 7/83\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 4034.4604 - accuracy: 0.3569 - val_loss: 3720.3191 - val_accuracy: 0.5867\n",
      "Epoch 8/83\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 4108.4253 - accuracy: 0.3805 - val_loss: 2323.1257 - val_accuracy: 0.5867\n",
      "Epoch 9/83\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 3433.1841 - accuracy: 0.3906 - val_loss: 1384.7784 - val_accuracy: 0.2533\n",
      "Epoch 10/83\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 2820.5447 - accuracy: 0.3502 - val_loss: 1163.0173 - val_accuracy: 0.5867\n",
      "Epoch 11/83\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 2051.0593 - accuracy: 0.3973 - val_loss: 1817.1367 - val_accuracy: 0.2533\n",
      "Epoch 12/83\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 2332.2795 - accuracy: 0.3771 - val_loss: 1931.2869 - val_accuracy: 0.5867\n",
      "Epoch 13/83\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 1692.5530 - accuracy: 0.4444 - val_loss: 772.6981 - val_accuracy: 0.5867\n",
      "Epoch 14/83\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 1581.8274 - accuracy: 0.3805 - val_loss: 506.4902 - val_accuracy: 0.5867\n",
      "Epoch 15/83\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 1322.2461 - accuracy: 0.4175 - val_loss: 402.2780 - val_accuracy: 0.2533\n",
      "Epoch 16/83\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 1475.5253 - accuracy: 0.3636 - val_loss: 449.9646 - val_accuracy: 0.5867\n",
      "Epoch 17/83\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 1418.7694 - accuracy: 0.3468 - val_loss: 594.4448 - val_accuracy: 0.5867\n",
      "Epoch 18/83\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 1250.2677 - accuracy: 0.3973 - val_loss: 200.6880 - val_accuracy: 0.5867\n",
      "Epoch 19/83\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 1237.2068 - accuracy: 0.4040 - val_loss: 396.0749 - val_accuracy: 0.5867\n",
      "Epoch 20/83\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 1068.2498 - accuracy: 0.4209 - val_loss: 309.1943 - val_accuracy: 0.5867\n",
      "Epoch 21/83\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 1194.5150 - accuracy: 0.3939 - val_loss: 830.6535 - val_accuracy: 0.5867\n",
      "Epoch 22/83\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 1266.4250 - accuracy: 0.3603 - val_loss: 437.2154 - val_accuracy: 0.5867\n",
      "Epoch 23/83\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 954.3626 - accuracy: 0.4108 - val_loss: 252.5917 - val_accuracy: 0.5867\n",
      "Epoch 24/83\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 997.4116 - accuracy: 0.3973 - val_loss: 231.7122 - val_accuracy: 0.5867\n",
      "Epoch 25/83\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 899.3146 - accuracy: 0.4007 - val_loss: 316.0439 - val_accuracy: 0.2533\n",
      "Epoch 26/83\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 844.1143 - accuracy: 0.3973 - val_loss: 420.0970 - val_accuracy: 0.5867\n",
      "Epoch 27/83\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 732.8334 - accuracy: 0.3906 - val_loss: 185.6465 - val_accuracy: 0.2533\n",
      "Epoch 28/83\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 1081.7654 - accuracy: 0.3805 - val_loss: 660.9994 - val_accuracy: 0.2533\n",
      "Epoch 29/83\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 673.0974 - accuracy: 0.3401 - val_loss: 268.9221 - val_accuracy: 0.5867\n",
      "Epoch 30/83\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 525.2778 - accuracy: 0.3906 - val_loss: 385.2314 - val_accuracy: 0.2533\n",
      "Epoch 31/83\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 508.7390 - accuracy: 0.3569 - val_loss: 179.6291 - val_accuracy: 0.5867\n",
      "Epoch 32/83\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 435.4307 - accuracy: 0.3401 - val_loss: 341.2491 - val_accuracy: 0.5867\n",
      "Epoch 33/83\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 442.5444 - accuracy: 0.3872 - val_loss: 19.3585 - val_accuracy: 0.5867\n",
      "Epoch 34/83\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 259.3138 - accuracy: 0.3569 - val_loss: 175.4812 - val_accuracy: 0.2533\n",
      "Epoch 35/83\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 300.4533 - accuracy: 0.3232 - val_loss: 145.3240 - val_accuracy: 0.5867\n",
      "Epoch 36/83\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 207.6059 - accuracy: 0.3939 - val_loss: 96.7795 - val_accuracy: 0.1733\n",
      "Epoch 37/83\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 164.8218 - accuracy: 0.2862 - val_loss: 131.6866 - val_accuracy: 0.2533\n",
      "Epoch 38/83\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 181.5262 - accuracy: 0.3131 - val_loss: 42.1421 - val_accuracy: 0.2533\n",
      "Epoch 39/83\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 119.8453 - accuracy: 0.3098 - val_loss: 61.9359 - val_accuracy: 0.2533\n",
      "Epoch 40/83\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 234.3114 - accuracy: 0.3165 - val_loss: 106.5642 - val_accuracy: 0.2533\n",
      "Epoch 41/83\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 141.9513 - accuracy: 0.3300 - val_loss: 128.1114 - val_accuracy: 0.2400\n",
      "Epoch 42/83\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 96.8333 - accuracy: 0.3199 - val_loss: 721.9574 - val_accuracy: 0.5733\n",
      "Epoch 43/83\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 223.8274 - accuracy: 0.3636 - val_loss: 613.1877 - val_accuracy: 0.2400\n",
      "Epoch 44/83\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 505.9778 - accuracy: 0.3199 - val_loss: 888.2112 - val_accuracy: 0.2400\n",
      "Epoch 45/83\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 108.6099 - accuracy: 0.3064 - val_loss: 1053.2518 - val_accuracy: 0.2400\n",
      "Epoch 46/83\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 91.5450 - accuracy: 0.2458 - val_loss: 1112.7455 - val_accuracy: 0.2400\n",
      "Epoch 47/83\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 108.0877 - accuracy: 0.3165 - val_loss: 1206.0543 - val_accuracy: 0.1600\n",
      "Epoch 48/83\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 117.8685 - accuracy: 0.2626 - val_loss: 1294.7640 - val_accuracy: 0.2400\n",
      "Epoch 49/83\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 16199.5137 - accuracy: 0.3737 - val_loss: 489131.3125 - val_accuracy: 0.5333\n",
      "Epoch 50/83\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 341280.0938 - accuracy: 0.4007 - val_loss: 260.6010 - val_accuracy: 0.5867\n",
      "Epoch 51/83\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 213.5448 - accuracy: 0.3704 - val_loss: 53.4259 - val_accuracy: 0.5867\n",
      "Epoch 52/83\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 102.1428 - accuracy: 0.3266 - val_loss: 34.4402 - val_accuracy: 0.5867\n",
      "Epoch 53/83\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 99.5706 - accuracy: 0.3064 - val_loss: 29.2873 - val_accuracy: 0.5867\n",
      "Epoch 54/83\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 95.3409 - accuracy: 0.3704 - val_loss: 58.4406 - val_accuracy: 0.5867\n",
      "Epoch 55/83\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 422.5927 - accuracy: 0.3165 - val_loss: 34.9705 - val_accuracy: 0.5867\n",
      "Epoch 56/83\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 87.2113 - accuracy: 0.3300 - val_loss: 31.3632 - val_accuracy: 0.5867\n",
      "Epoch 57/83\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 77.8797 - accuracy: 0.3131 - val_loss: 48.0084 - val_accuracy: 0.5867\n",
      "Epoch 58/83\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 78.7238 - accuracy: 0.3569 - val_loss: 117.2818 - val_accuracy: 0.2400\n",
      "Epoch 59/83\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 161.0872 - accuracy: 0.3030 - val_loss: 67.2946 - val_accuracy: 0.5867\n",
      "Epoch 60/83\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 113.4641 - accuracy: 0.3098 - val_loss: 50.4602 - val_accuracy: 0.5867\n",
      "Epoch 61/83\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 240.5346 - accuracy: 0.2929 - val_loss: 62.0720 - val_accuracy: 0.5867\n",
      "Epoch 62/83\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 90.0282 - accuracy: 0.3737 - val_loss: 57.6610 - val_accuracy: 0.5867\n",
      "Epoch 63/83\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 87.1401 - accuracy: 0.4040 - val_loss: 54.4466 - val_accuracy: 0.5867\n",
      "Epoch 64/83\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 75.8399 - accuracy: 0.3939 - val_loss: 49.6920 - val_accuracy: 0.5867\n",
      "Epoch 65/83\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 73.7533 - accuracy: 0.4007 - val_loss: 44.8669 - val_accuracy: 0.5867\n",
      "Epoch 66/83\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 63.6948 - accuracy: 0.4242 - val_loss: 39.7455 - val_accuracy: 0.5867\n",
      "Epoch 67/83\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 63.8188 - accuracy: 0.4007 - val_loss: 34.9961 - val_accuracy: 0.5867\n",
      "Epoch 68/83\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 57.0508 - accuracy: 0.4175 - val_loss: 29.9264 - val_accuracy: 0.5867\n",
      "Epoch 69/83\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 45.7735 - accuracy: 0.4141 - val_loss: 27.4898 - val_accuracy: 0.5867\n",
      "Epoch 70/83\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 45.6628 - accuracy: 0.4007 - val_loss: 23.7338 - val_accuracy: 0.5867\n",
      "Epoch 71/83\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 40.5968 - accuracy: 0.4007 - val_loss: 19.7879 - val_accuracy: 0.5867\n",
      "Epoch 72/83\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 35.8341 - accuracy: 0.3805 - val_loss: 16.8419 - val_accuracy: 0.5867\n",
      "Epoch 73/83\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 35.8565 - accuracy: 0.3973 - val_loss: 16.9698 - val_accuracy: 0.5867\n",
      "Epoch 74/83\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 31.7872 - accuracy: 0.3771 - val_loss: 15.7982 - val_accuracy: 0.5867\n",
      "Epoch 75/83\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 34.8511 - accuracy: 0.4040 - val_loss: 13.4173 - val_accuracy: 0.5867\n",
      "Epoch 76/83\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 32.1139 - accuracy: 0.4175 - val_loss: 15.9055 - val_accuracy: 0.5867\n",
      "Epoch 77/83\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 31.1591 - accuracy: 0.4074 - val_loss: 10.6655 - val_accuracy: 0.5867\n",
      "Epoch 78/83\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 30.4217 - accuracy: 0.4108 - val_loss: 17.6382 - val_accuracy: 0.5867\n",
      "Epoch 79/83\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 35.6405 - accuracy: 0.3939 - val_loss: 13.8093 - val_accuracy: 0.5867\n",
      "Epoch 80/83\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 34.2561 - accuracy: 0.3872 - val_loss: 13.7658 - val_accuracy: 0.5867\n",
      "Epoch 81/83\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 31.0252 - accuracy: 0.4276 - val_loss: 8.7484 - val_accuracy: 0.2400\n",
      "Epoch 82/83\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 31.1726 - accuracy: 0.4007 - val_loss: 8.8157 - val_accuracy: 0.5867\n",
      "Epoch 83/83\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 36.7996 - accuracy: 0.3805 - val_loss: 17.2835 - val_accuracy: 0.5867\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m0.2043   \u001b[0m | \u001b[0m1.197    \u001b[0m | \u001b[0m108.5    \u001b[0m | \u001b[0m83.4     \u001b[0m | \u001b[0m0.8959   \u001b[0m | \u001b[0m0.6616   \u001b[0m |\n",
      "Epoch 1/35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/rmsprop.py:140: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adagrad.py:81: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 85ms/step - loss: 539.0833 - accuracy: 0.3199 - val_loss: 1.0771 - val_accuracy: 0.5867\n",
      "Epoch 2/35\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 1.1225 - accuracy: 0.4714 - val_loss: 1.0692 - val_accuracy: 0.5867\n",
      "Epoch 3/35\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.1194 - accuracy: 0.4983 - val_loss: 1.0494 - val_accuracy: 0.5867\n",
      "Epoch 4/35\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.0643 - accuracy: 0.5152 - val_loss: 1.0193 - val_accuracy: 0.5867\n",
      "Epoch 5/35\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.0678 - accuracy: 0.5152 - val_loss: 1.0649 - val_accuracy: 0.5867\n",
      "Epoch 6/35\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 1.0677 - accuracy: 0.5152 - val_loss: 1.0259 - val_accuracy: 0.5867\n",
      "Epoch 7/35\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 1.0633 - accuracy: 0.5152 - val_loss: 1.0227 - val_accuracy: 0.5867\n",
      "Epoch 8/35\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 1.0552 - accuracy: 0.5152 - val_loss: 1.0106 - val_accuracy: 0.5867\n",
      "Epoch 9/35\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 1.0726 - accuracy: 0.5152 - val_loss: 1.0231 - val_accuracy: 0.5867\n",
      "Epoch 10/35\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 1.0593 - accuracy: 0.5152 - val_loss: 1.0282 - val_accuracy: 0.5867\n",
      "Epoch 11/35\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 1.0565 - accuracy: 0.5152 - val_loss: 1.0190 - val_accuracy: 0.5867\n",
      "Epoch 12/35\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 1.0580 - accuracy: 0.5152 - val_loss: 1.0161 - val_accuracy: 0.5867\n",
      "Epoch 13/35\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 1.0581 - accuracy: 0.5152 - val_loss: 1.0224 - val_accuracy: 0.5867\n",
      "Epoch 14/35\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 1.0472 - accuracy: 0.5152 - val_loss: 1.0217 - val_accuracy: 0.5867\n",
      "Epoch 15/35\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 1.0594 - accuracy: 0.5152 - val_loss: 1.0159 - val_accuracy: 0.5867\n",
      "Epoch 16/35\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 1.0600 - accuracy: 0.5152 - val_loss: 1.0168 - val_accuracy: 0.5867\n",
      "Epoch 17/35\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 1.0472 - accuracy: 0.5152 - val_loss: 1.0128 - val_accuracy: 0.5867\n",
      "Epoch 18/35\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 1.0567 - accuracy: 0.5152 - val_loss: 1.0096 - val_accuracy: 0.5867\n",
      "Epoch 19/35\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 1.0499 - accuracy: 0.5152 - val_loss: 1.0254 - val_accuracy: 0.5867\n",
      "Epoch 20/35\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 1.0540 - accuracy: 0.5152 - val_loss: 1.0123 - val_accuracy: 0.5867\n",
      "Epoch 21/35\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 1.0528 - accuracy: 0.5152 - val_loss: 1.0188 - val_accuracy: 0.5867\n",
      "Epoch 22/35\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 1.0479 - accuracy: 0.5152 - val_loss: 1.0161 - val_accuracy: 0.5867\n",
      "Epoch 23/35\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 1.0496 - accuracy: 0.5152 - val_loss: 1.0159 - val_accuracy: 0.5867\n",
      "Epoch 24/35\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 1.0516 - accuracy: 0.5152 - val_loss: 1.0221 - val_accuracy: 0.5867\n",
      "Epoch 25/35\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 1.0527 - accuracy: 0.5152 - val_loss: 1.0175 - val_accuracy: 0.5867\n",
      "Epoch 26/35\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 1.0458 - accuracy: 0.5152 - val_loss: 1.0153 - val_accuracy: 0.5867\n",
      "Epoch 27/35\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 1.0488 - accuracy: 0.5152 - val_loss: 1.0123 - val_accuracy: 0.5867\n",
      "Epoch 28/35\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 1.0548 - accuracy: 0.5152 - val_loss: 1.0272 - val_accuracy: 0.5867\n",
      "Epoch 29/35\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 1.0520 - accuracy: 0.5152 - val_loss: 1.0286 - val_accuracy: 0.5867\n",
      "Epoch 30/35\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 1.0494 - accuracy: 0.5152 - val_loss: 1.0285 - val_accuracy: 0.5867\n",
      "Epoch 31/35\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 1.0478 - accuracy: 0.5152 - val_loss: 1.0158 - val_accuracy: 0.5867\n",
      "Epoch 32/35\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 1.0430 - accuracy: 0.5152 - val_loss: 1.0196 - val_accuracy: 0.5867\n",
      "Epoch 33/35\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 1.0549 - accuracy: 0.5152 - val_loss: 1.0199 - val_accuracy: 0.5867\n",
      "Epoch 34/35\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 1.0510 - accuracy: 0.5152 - val_loss: 1.0171 - val_accuracy: 0.5867\n",
      "Epoch 35/35\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 1.0472 - accuracy: 0.5152 - val_loss: 1.0123 - val_accuracy: 0.5867\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "| \u001b[0m10       \u001b[0m | \u001b[0m0.5376   \u001b[0m | \u001b[0m0.03892  \u001b[0m | \u001b[0m115.3    \u001b[0m | \u001b[0m34.61    \u001b[0m | \u001b[0m0.7956   \u001b[0m | \u001b[0m2.852    \u001b[0m |\n",
      "Epoch 1/91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/rmsprop.py:140: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adagrad.py:81: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 80ms/step - loss: 4117.7710 - accuracy: 0.2828 - val_loss: 1.7697 - val_accuracy: 0.2000\n",
      "Epoch 2/91\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 1.9633 - accuracy: 0.3805 - val_loss: 1.1328 - val_accuracy: 0.2400\n",
      "Epoch 3/91\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 1.3903 - accuracy: 0.4781 - val_loss: 1.0493 - val_accuracy: 0.5867\n",
      "Epoch 4/91\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 1.0487 - accuracy: 0.5286 - val_loss: 1.0321 - val_accuracy: 0.5867\n",
      "Epoch 5/91\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 1.0505 - accuracy: 0.5286 - val_loss: 1.0399 - val_accuracy: 0.5867\n",
      "Epoch 6/91\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 1.0398 - accuracy: 0.5320 - val_loss: 1.0191 - val_accuracy: 0.5867\n",
      "Epoch 7/91\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 1.0371 - accuracy: 0.5320 - val_loss: 1.0108 - val_accuracy: 0.5867\n",
      "Epoch 8/91\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.0400 - accuracy: 0.5320 - val_loss: 1.0233 - val_accuracy: 0.5867\n",
      "Epoch 9/91\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 1.0303 - accuracy: 0.5320 - val_loss: 1.0285 - val_accuracy: 0.5867\n",
      "Epoch 10/91\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 1.0282 - accuracy: 0.5320 - val_loss: 1.0637 - val_accuracy: 0.5867\n",
      "Epoch 11/91\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 1.0466 - accuracy: 0.4882 - val_loss: 1.0084 - val_accuracy: 0.5867\n",
      "Epoch 12/91\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 1.0335 - accuracy: 0.5320 - val_loss: 1.0096 - val_accuracy: 0.5867\n",
      "Epoch 13/91\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 1.0291 - accuracy: 0.5320 - val_loss: 1.0144 - val_accuracy: 0.5867\n",
      "Epoch 14/91\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 1.0251 - accuracy: 0.5320 - val_loss: 1.0043 - val_accuracy: 0.5867\n",
      "Epoch 15/91\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 1.0105 - accuracy: 0.5320 - val_loss: 1.0870 - val_accuracy: 0.5867\n",
      "Epoch 16/91\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 1.0706 - accuracy: 0.4781 - val_loss: 1.0253 - val_accuracy: 0.5867\n",
      "Epoch 17/91\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 1.0239 - accuracy: 0.5320 - val_loss: 1.0552 - val_accuracy: 0.5867\n",
      "Epoch 18/91\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 1.0297 - accuracy: 0.5286 - val_loss: 1.0363 - val_accuracy: 0.5867\n",
      "Epoch 19/91\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 1.0189 - accuracy: 0.5320 - val_loss: 1.0496 - val_accuracy: 0.5867\n",
      "Epoch 20/91\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 1.0143 - accuracy: 0.5320 - val_loss: 1.0161 - val_accuracy: 0.5867\n",
      "Epoch 21/91\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 1.0093 - accuracy: 0.5320 - val_loss: 1.0255 - val_accuracy: 0.5867\n",
      "Epoch 22/91\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 1.0132 - accuracy: 0.5320 - val_loss: 1.0178 - val_accuracy: 0.5867\n",
      "Epoch 23/91\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 1.0076 - accuracy: 0.5320 - val_loss: 1.0144 - val_accuracy: 0.5867\n",
      "Epoch 24/91\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 1.0127 - accuracy: 0.5320 - val_loss: 1.0218 - val_accuracy: 0.5867\n",
      "Epoch 25/91\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 1.0057 - accuracy: 0.5320 - val_loss: 1.0019 - val_accuracy: 0.5867\n",
      "Epoch 26/91\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 1.0002 - accuracy: 0.5320 - val_loss: 1.0031 - val_accuracy: 0.5867\n",
      "Epoch 27/91\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 1.0098 - accuracy: 0.5320 - val_loss: 1.0051 - val_accuracy: 0.5867\n",
      "Epoch 28/91\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.9990 - accuracy: 0.5320 - val_loss: 1.0107 - val_accuracy: 0.5867\n",
      "Epoch 29/91\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 1.0007 - accuracy: 0.5320 - val_loss: 1.0146 - val_accuracy: 0.5867\n",
      "Epoch 30/91\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.9994 - accuracy: 0.5320 - val_loss: 1.0011 - val_accuracy: 0.5867\n",
      "Epoch 31/91\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.9974 - accuracy: 0.5320 - val_loss: 0.9995 - val_accuracy: 0.5867\n",
      "Epoch 32/91\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 1.0108 - accuracy: 0.5320 - val_loss: 1.0260 - val_accuracy: 0.5867\n",
      "Epoch 33/91\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.9981 - accuracy: 0.5320 - val_loss: 1.0073 - val_accuracy: 0.5867\n",
      "Epoch 34/91\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.9941 - accuracy: 0.5320 - val_loss: 1.0110 - val_accuracy: 0.5867\n",
      "Epoch 35/91\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.9957 - accuracy: 0.5320 - val_loss: 0.9981 - val_accuracy: 0.5867\n",
      "Epoch 36/91\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.9994 - accuracy: 0.5320 - val_loss: 1.0014 - val_accuracy: 0.5867\n",
      "Epoch 37/91\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.9873 - accuracy: 0.5320 - val_loss: 1.0039 - val_accuracy: 0.5867\n",
      "Epoch 38/91\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.9891 - accuracy: 0.5320 - val_loss: 0.9935 - val_accuracy: 0.5867\n",
      "Epoch 39/91\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.9849 - accuracy: 0.5320 - val_loss: 1.0038 - val_accuracy: 0.5867\n",
      "Epoch 40/91\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.9802 - accuracy: 0.5320 - val_loss: 1.7080 - val_accuracy: 0.5733\n",
      "Epoch 41/91\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 1.4520 - accuracy: 0.4242 - val_loss: 1.0452 - val_accuracy: 0.5867\n",
      "Epoch 42/91\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 1.0144 - accuracy: 0.5320 - val_loss: 1.0158 - val_accuracy: 0.5867\n",
      "Epoch 43/91\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 1.0018 - accuracy: 0.5320 - val_loss: 1.0461 - val_accuracy: 0.6000\n",
      "Epoch 44/91\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 1.0156 - accuracy: 0.5320 - val_loss: 1.0301 - val_accuracy: 0.6000\n",
      "Epoch 45/91\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 1.0071 - accuracy: 0.5320 - val_loss: 1.0161 - val_accuracy: 0.5867\n",
      "Epoch 46/91\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.9956 - accuracy: 0.5320 - val_loss: 1.0114 - val_accuracy: 0.5867\n",
      "Epoch 47/91\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.9938 - accuracy: 0.5320 - val_loss: 1.0053 - val_accuracy: 0.5867\n",
      "Epoch 48/91\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.9933 - accuracy: 0.5320 - val_loss: 1.0204 - val_accuracy: 0.6000\n",
      "Epoch 49/91\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.9972 - accuracy: 0.5320 - val_loss: 0.9954 - val_accuracy: 0.5867\n",
      "Epoch 50/91\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.9968 - accuracy: 0.5320 - val_loss: 0.9901 - val_accuracy: 0.5867\n",
      "Epoch 51/91\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.9879 - accuracy: 0.5320 - val_loss: 1.0054 - val_accuracy: 0.6000\n",
      "Epoch 52/91\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.9870 - accuracy: 0.5320 - val_loss: 0.9844 - val_accuracy: 0.5867\n",
      "Epoch 53/91\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.9923 - accuracy: 0.5320 - val_loss: 0.9981 - val_accuracy: 0.6000\n",
      "Epoch 54/91\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.9843 - accuracy: 0.5320 - val_loss: 0.9883 - val_accuracy: 0.5867\n",
      "Epoch 55/91\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.9877 - accuracy: 0.5320 - val_loss: 0.9941 - val_accuracy: 0.5867\n",
      "Epoch 56/91\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.9940 - accuracy: 0.5320 - val_loss: 0.9942 - val_accuracy: 0.6000\n",
      "Epoch 57/91\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.9867 - accuracy: 0.5320 - val_loss: 0.9904 - val_accuracy: 0.6000\n",
      "Epoch 58/91\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.9898 - accuracy: 0.5320 - val_loss: 0.9907 - val_accuracy: 0.6000\n",
      "Epoch 59/91\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.9862 - accuracy: 0.5320 - val_loss: 0.9891 - val_accuracy: 0.6000\n",
      "Epoch 60/91\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.9871 - accuracy: 0.5320 - val_loss: 0.9938 - val_accuracy: 0.6000\n",
      "Epoch 61/91\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.9834 - accuracy: 0.5320 - val_loss: 1.0067 - val_accuracy: 0.6000\n",
      "Epoch 62/91\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.9850 - accuracy: 0.5320 - val_loss: 0.9927 - val_accuracy: 0.6000\n",
      "Epoch 63/91\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.9833 - accuracy: 0.5320 - val_loss: 1.0062 - val_accuracy: 0.6000\n",
      "Epoch 64/91\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.9850 - accuracy: 0.5320 - val_loss: 0.9948 - val_accuracy: 0.6000\n",
      "Epoch 65/91\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.9828 - accuracy: 0.5320 - val_loss: 0.9869 - val_accuracy: 0.6000\n",
      "Epoch 66/91\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.9819 - accuracy: 0.5320 - val_loss: 0.9831 - val_accuracy: 0.5867\n",
      "Epoch 67/91\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.9844 - accuracy: 0.5320 - val_loss: 0.9909 - val_accuracy: 0.5867\n",
      "Epoch 68/91\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.9822 - accuracy: 0.5320 - val_loss: 0.9850 - val_accuracy: 0.6000\n",
      "Epoch 69/91\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.9801 - accuracy: 0.5354 - val_loss: 1.0030 - val_accuracy: 0.6133\n",
      "Epoch 70/91\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.9837 - accuracy: 0.5320 - val_loss: 0.9884 - val_accuracy: 0.6133\n",
      "Epoch 71/91\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.9757 - accuracy: 0.5387 - val_loss: 0.9821 - val_accuracy: 0.6133\n",
      "Epoch 72/91\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.9773 - accuracy: 0.5387 - val_loss: 0.9927 - val_accuracy: 0.6133\n",
      "Epoch 73/91\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.9774 - accuracy: 0.5387 - val_loss: 0.9864 - val_accuracy: 0.6133\n",
      "Epoch 74/91\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.9815 - accuracy: 0.5387 - val_loss: 0.9830 - val_accuracy: 0.6133\n",
      "Epoch 75/91\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.9774 - accuracy: 0.5387 - val_loss: 0.9951 - val_accuracy: 0.6133\n",
      "Epoch 76/91\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.9793 - accuracy: 0.5387 - val_loss: 0.9921 - val_accuracy: 0.6133\n",
      "Epoch 77/91\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.9751 - accuracy: 0.5387 - val_loss: 0.9883 - val_accuracy: 0.6133\n",
      "Epoch 78/91\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.9756 - accuracy: 0.5387 - val_loss: 0.9903 - val_accuracy: 0.6000\n",
      "Epoch 79/91\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.9739 - accuracy: 0.5421 - val_loss: 0.9861 - val_accuracy: 0.5867\n",
      "Epoch 80/91\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.9761 - accuracy: 0.5354 - val_loss: 0.9834 - val_accuracy: 0.6000\n",
      "Epoch 81/91\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.9768 - accuracy: 0.5387 - val_loss: 0.9931 - val_accuracy: 0.6000\n",
      "Epoch 82/91\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.9738 - accuracy: 0.5421 - val_loss: 0.9944 - val_accuracy: 0.6000\n",
      "Epoch 83/91\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.9754 - accuracy: 0.5421 - val_loss: 0.9851 - val_accuracy: 0.6000\n",
      "Epoch 84/91\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.9755 - accuracy: 0.5421 - val_loss: 0.9759 - val_accuracy: 0.6000\n",
      "Epoch 85/91\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.9764 - accuracy: 0.5421 - val_loss: 0.9827 - val_accuracy: 0.6000\n",
      "Epoch 86/91\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.9737 - accuracy: 0.5421 - val_loss: 0.9836 - val_accuracy: 0.6000\n",
      "Epoch 87/91\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.9739 - accuracy: 0.5421 - val_loss: 0.9824 - val_accuracy: 0.6000\n",
      "Epoch 88/91\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.9765 - accuracy: 0.5421 - val_loss: 0.9789 - val_accuracy: 0.6000\n",
      "Epoch 89/91\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.9753 - accuracy: 0.5421 - val_loss: 0.9859 - val_accuracy: 0.6000\n",
      "Epoch 90/91\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.9759 - accuracy: 0.5387 - val_loss: 0.9947 - val_accuracy: 0.6000\n",
      "Epoch 91/91\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.9748 - accuracy: 0.5387 - val_loss: 0.9921 - val_accuracy: 0.6000\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "| \u001b[0m11       \u001b[0m | \u001b[0m0.5376   \u001b[0m | \u001b[0m0.01165  \u001b[0m | \u001b[0m135.3    \u001b[0m | \u001b[0m90.91    \u001b[0m | \u001b[0m0.9871   \u001b[0m | \u001b[0m2.577    \u001b[0m |\n",
      "Epoch 1/59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/rmsprop.py:140: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adagrad.py:81: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 88ms/step - loss: 145.9163 - accuracy: 0.3502 - val_loss: 22426.6973 - val_accuracy: 0.5867\n",
      "Epoch 2/59\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 106336.8047 - accuracy: 0.3906 - val_loss: 10109.4990 - val_accuracy: 0.1600\n",
      "Epoch 3/59\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 7898.1602 - accuracy: 0.4108 - val_loss: 8570.7197 - val_accuracy: 0.2400\n",
      "Epoch 4/59\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 6060.5200 - accuracy: 0.3737 - val_loss: 1381.8862 - val_accuracy: 0.2667\n",
      "Epoch 5/59\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 970.3765 - accuracy: 0.3468 - val_loss: 79.9377 - val_accuracy: 0.6000\n",
      "Epoch 6/59\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 172.7393 - accuracy: 0.4040 - val_loss: 70.5690 - val_accuracy: 0.6000\n",
      "Epoch 7/59\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 99.1459 - accuracy: 0.4646 - val_loss: 38.9030 - val_accuracy: 0.2400\n",
      "Epoch 8/59\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 65.5146 - accuracy: 0.3872 - val_loss: 25.3373 - val_accuracy: 0.3333\n",
      "Epoch 9/59\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 39.3412 - accuracy: 0.4411 - val_loss: 27.5184 - val_accuracy: 0.5867\n",
      "Epoch 10/59\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 35.4770 - accuracy: 0.4444 - val_loss: 18.1392 - val_accuracy: 0.2400\n",
      "Epoch 11/59\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 22.4549 - accuracy: 0.4310 - val_loss: 20.2393 - val_accuracy: 0.6000\n",
      "Epoch 12/59\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 27.2393 - accuracy: 0.4074 - val_loss: 7.4176 - val_accuracy: 0.3867\n",
      "Epoch 13/59\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 15.9459 - accuracy: 0.4141 - val_loss: 8.5558 - val_accuracy: 0.3200\n",
      "Epoch 14/59\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 13.7198 - accuracy: 0.4411 - val_loss: 10.8121 - val_accuracy: 0.3733\n",
      "Epoch 15/59\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 11.8298 - accuracy: 0.4411 - val_loss: 5.0530 - val_accuracy: 0.5200\n",
      "Epoch 16/59\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 8.9141 - accuracy: 0.4512 - val_loss: 7.3906 - val_accuracy: 0.6133\n",
      "Epoch 17/59\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 31.8512 - accuracy: 0.4108 - val_loss: 7.6232 - val_accuracy: 0.3067\n",
      "Epoch 18/59\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 8.6543 - accuracy: 0.4175 - val_loss: 3.9721 - val_accuracy: 0.5733\n",
      "Epoch 19/59\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 6.9406 - accuracy: 0.4175 - val_loss: 3.0633 - val_accuracy: 0.5867\n",
      "Epoch 20/59\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 6.3416 - accuracy: 0.4781 - val_loss: 2.3180 - val_accuracy: 0.5467\n",
      "Epoch 21/59\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 5.6439 - accuracy: 0.4848 - val_loss: 1.8415 - val_accuracy: 0.5067\n",
      "Epoch 22/59\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 6.0338 - accuracy: 0.4613 - val_loss: 3.0120 - val_accuracy: 0.5733\n",
      "Epoch 23/59\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 5.4501 - accuracy: 0.4680 - val_loss: 10.6489 - val_accuracy: 0.2267\n",
      "Epoch 24/59\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 7.8224 - accuracy: 0.4646 - val_loss: 4.3274 - val_accuracy: 0.6133\n",
      "Epoch 25/59\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 5.8763 - accuracy: 0.4377 - val_loss: 4.8434 - val_accuracy: 0.6000\n",
      "Epoch 26/59\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 5.5145 - accuracy: 0.4310 - val_loss: 3.4850 - val_accuracy: 0.4267\n",
      "Epoch 27/59\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 5.8396 - accuracy: 0.4478 - val_loss: 2.7853 - val_accuracy: 0.5733\n",
      "Epoch 28/59\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 5.7771 - accuracy: 0.4512 - val_loss: 3.0991 - val_accuracy: 0.6000\n",
      "Epoch 29/59\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 5.1546 - accuracy: 0.4983 - val_loss: 1.5228 - val_accuracy: 0.5467\n",
      "Epoch 30/59\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 5.4299 - accuracy: 0.4141 - val_loss: 1.7676 - val_accuracy: 0.5733\n",
      "Epoch 31/59\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 4.4704 - accuracy: 0.4882 - val_loss: 3.1646 - val_accuracy: 0.5867\n",
      "Epoch 32/59\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 4.8375 - accuracy: 0.4815 - val_loss: 1.6908 - val_accuracy: 0.5733\n",
      "Epoch 33/59\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 5.1230 - accuracy: 0.4613 - val_loss: 1.8972 - val_accuracy: 0.6133\n",
      "Epoch 34/59\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 5.2857 - accuracy: 0.4377 - val_loss: 2.8087 - val_accuracy: 0.6000\n",
      "Epoch 35/59\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 5.2175 - accuracy: 0.4747 - val_loss: 1.4844 - val_accuracy: 0.6133\n",
      "Epoch 36/59\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 4.7332 - accuracy: 0.4646 - val_loss: 2.1110 - val_accuracy: 0.5600\n",
      "Epoch 37/59\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 4.4061 - accuracy: 0.4916 - val_loss: 2.9504 - val_accuracy: 0.6133\n",
      "Epoch 38/59\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 5.0192 - accuracy: 0.5118 - val_loss: 1.4255 - val_accuracy: 0.6533\n",
      "Epoch 39/59\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 3.7910 - accuracy: 0.5084 - val_loss: 3.3826 - val_accuracy: 0.6000\n",
      "Epoch 40/59\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 8.6903 - accuracy: 0.4916 - val_loss: 1.3642 - val_accuracy: 0.6133\n",
      "Epoch 41/59\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 4.3644 - accuracy: 0.5118 - val_loss: 3.8682 - val_accuracy: 0.4133\n",
      "Epoch 42/59\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 6.2118 - accuracy: 0.4613 - val_loss: 1.4269 - val_accuracy: 0.5733\n",
      "Epoch 43/59\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 4.5407 - accuracy: 0.4411 - val_loss: 1.3983 - val_accuracy: 0.6400\n",
      "Epoch 44/59\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 3.6951 - accuracy: 0.5185 - val_loss: 1.6993 - val_accuracy: 0.5867\n",
      "Epoch 45/59\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 3.8577 - accuracy: 0.5152 - val_loss: 2.2413 - val_accuracy: 0.6533\n",
      "Epoch 46/59\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 4.9802 - accuracy: 0.4815 - val_loss: 2.6324 - val_accuracy: 0.4800\n",
      "Epoch 47/59\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 4.1072 - accuracy: 0.4680 - val_loss: 1.8483 - val_accuracy: 0.6133\n",
      "Epoch 48/59\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 4.3665 - accuracy: 0.4579 - val_loss: 2.2451 - val_accuracy: 0.6400\n",
      "Epoch 49/59\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 3.6979 - accuracy: 0.5556 - val_loss: 1.5148 - val_accuracy: 0.5600\n",
      "Epoch 50/59\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 4.3862 - accuracy: 0.4882 - val_loss: 2.0053 - val_accuracy: 0.5867\n",
      "Epoch 51/59\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 4.4676 - accuracy: 0.5051 - val_loss: 2.5871 - val_accuracy: 0.6000\n",
      "Epoch 52/59\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 3.7198 - accuracy: 0.5253 - val_loss: 1.8925 - val_accuracy: 0.6267\n",
      "Epoch 53/59\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 3.3096 - accuracy: 0.5892 - val_loss: 1.5003 - val_accuracy: 0.6267\n",
      "Epoch 54/59\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 3.8175 - accuracy: 0.5152 - val_loss: 2.3061 - val_accuracy: 0.5600\n",
      "Epoch 55/59\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 3.5570 - accuracy: 0.5556 - val_loss: 1.8763 - val_accuracy: 0.6267\n",
      "Epoch 56/59\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 4.8223 - accuracy: 0.4882 - val_loss: 1.4039 - val_accuracy: 0.6133\n",
      "Epoch 57/59\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 4.1782 - accuracy: 0.4916 - val_loss: 1.8751 - val_accuracy: 0.6400\n",
      "Epoch 58/59\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 3.7490 - accuracy: 0.5253 - val_loss: 4.2828 - val_accuracy: 0.6000\n",
      "Epoch 59/59\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 4.8506 - accuracy: 0.4646 - val_loss: 2.1496 - val_accuracy: 0.6133\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "| \u001b[0m12       \u001b[0m | \u001b[0m0.3978   \u001b[0m | \u001b[0m0.8706   \u001b[0m | \u001b[0m134.4    \u001b[0m | \u001b[0m58.96    \u001b[0m | \u001b[0m0.4965   \u001b[0m | \u001b[0m2.719    \u001b[0m |\n",
      "Epoch 1/52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/rmsprop.py:140: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adagrad.py:81: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 92ms/step - loss: 82.7029 - accuracy: 0.1953 - val_loss: 104.0866 - val_accuracy: 0.5867\n",
      "Epoch 2/52\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 148.6683 - accuracy: 0.4579 - val_loss: 93.9974 - val_accuracy: 0.2400\n",
      "Epoch 3/52\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 93.8083 - accuracy: 0.3232 - val_loss: 67.8945 - val_accuracy: 0.5867\n",
      "Epoch 4/52\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 110.2359 - accuracy: 0.4242 - val_loss: 36.2323 - val_accuracy: 0.2400\n",
      "Epoch 5/52\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 61.8734 - accuracy: 0.3367 - val_loss: 69.7944 - val_accuracy: 0.5867\n",
      "Epoch 6/52\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 86.5479 - accuracy: 0.4040 - val_loss: 71.7562 - val_accuracy: 0.1600\n",
      "Epoch 7/52\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 55.1427 - accuracy: 0.3098 - val_loss: 68.4348 - val_accuracy: 0.5867\n",
      "Epoch 8/52\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 71.2460 - accuracy: 0.4310 - val_loss: 54.6335 - val_accuracy: 0.1600\n",
      "Epoch 9/52\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 65.3215 - accuracy: 0.3165 - val_loss: 87.6315 - val_accuracy: 0.5867\n",
      "Epoch 10/52\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 71.0647 - accuracy: 0.3906 - val_loss: 106.7977 - val_accuracy: 0.2400\n",
      "Epoch 11/52\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 74.0322 - accuracy: 0.3872 - val_loss: 11.8064 - val_accuracy: 0.5867\n",
      "Epoch 12/52\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 58.4602 - accuracy: 0.3872 - val_loss: 72.1049 - val_accuracy: 0.1600\n",
      "Epoch 13/52\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 96.8721 - accuracy: 0.3098 - val_loss: 65.2612 - val_accuracy: 0.5867\n",
      "Epoch 14/52\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 73.0951 - accuracy: 0.3805 - val_loss: 55.3634 - val_accuracy: 0.2400\n",
      "Epoch 15/52\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 60.2510 - accuracy: 0.3300 - val_loss: 55.0983 - val_accuracy: 0.2400\n",
      "Epoch 16/52\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 66.9305 - accuracy: 0.3973 - val_loss: 59.2879 - val_accuracy: 0.2400\n",
      "Epoch 17/52\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 81.6460 - accuracy: 0.2929 - val_loss: 66.3017 - val_accuracy: 0.5867\n",
      "Epoch 18/52\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 81.8852 - accuracy: 0.4646 - val_loss: 16.4212 - val_accuracy: 0.2400\n",
      "Epoch 19/52\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 46.4902 - accuracy: 0.3872 - val_loss: 53.3086 - val_accuracy: 0.5867\n",
      "Epoch 20/52\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 74.2847 - accuracy: 0.3468 - val_loss: 116.4985 - val_accuracy: 0.2400\n",
      "Epoch 21/52\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 75.6837 - accuracy: 0.3199 - val_loss: 45.3366 - val_accuracy: 0.5867\n",
      "Epoch 22/52\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 62.8956 - accuracy: 0.4579 - val_loss: 18.8696 - val_accuracy: 0.1600\n",
      "Epoch 23/52\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 50.0858 - accuracy: 0.3973 - val_loss: 58.6352 - val_accuracy: 0.5867\n",
      "Epoch 24/52\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 63.5789 - accuracy: 0.4141 - val_loss: 141.1825 - val_accuracy: 0.2400\n",
      "Epoch 25/52\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 73.9969 - accuracy: 0.3771 - val_loss: 84.2639 - val_accuracy: 0.2400\n",
      "Epoch 26/52\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 55.5940 - accuracy: 0.3199 - val_loss: 32.3610 - val_accuracy: 0.2400\n",
      "Epoch 27/52\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 50.6110 - accuracy: 0.3737 - val_loss: 47.4064 - val_accuracy: 0.2400\n",
      "Epoch 28/52\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 59.4950 - accuracy: 0.3939 - val_loss: 57.7003 - val_accuracy: 0.5867\n",
      "Epoch 29/52\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 91.0806 - accuracy: 0.4175 - val_loss: 63.8710 - val_accuracy: 0.1600\n",
      "Epoch 30/52\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 51.5821 - accuracy: 0.3502 - val_loss: 53.1228 - val_accuracy: 0.2400\n",
      "Epoch 31/52\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 81.9247 - accuracy: 0.3064 - val_loss: 74.8557 - val_accuracy: 0.5867\n",
      "Epoch 32/52\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 92.0144 - accuracy: 0.4377 - val_loss: 8.5370 - val_accuracy: 0.5867\n",
      "Epoch 33/52\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 42.4861 - accuracy: 0.4175 - val_loss: 97.1423 - val_accuracy: 0.1600\n",
      "Epoch 34/52\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 95.8048 - accuracy: 0.2963 - val_loss: 65.2545 - val_accuracy: 0.5867\n",
      "Epoch 35/52\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 75.7656 - accuracy: 0.3670 - val_loss: 27.6297 - val_accuracy: 0.2400\n",
      "Epoch 36/52\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 59.5002 - accuracy: 0.3569 - val_loss: 62.6019 - val_accuracy: 0.5867\n",
      "Epoch 37/52\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 83.6323 - accuracy: 0.4343 - val_loss: 8.3047 - val_accuracy: 0.2400\n",
      "Epoch 38/52\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 36.2131 - accuracy: 0.3333 - val_loss: 46.3002 - val_accuracy: 0.5867\n",
      "Epoch 39/52\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 73.9280 - accuracy: 0.4545 - val_loss: 11.0578 - val_accuracy: 0.5867\n",
      "Epoch 40/52\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 59.7470 - accuracy: 0.3805 - val_loss: 64.8832 - val_accuracy: 0.1600\n",
      "Epoch 41/52\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 82.6854 - accuracy: 0.3232 - val_loss: 68.3039 - val_accuracy: 0.5867\n",
      "Epoch 42/52\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 55.8010 - accuracy: 0.4478 - val_loss: 74.1701 - val_accuracy: 0.1600\n",
      "Epoch 43/52\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 95.5552 - accuracy: 0.2862 - val_loss: 53.8206 - val_accuracy: 0.5867\n",
      "Epoch 44/52\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 57.6780 - accuracy: 0.4276 - val_loss: 47.0751 - val_accuracy: 0.2400\n",
      "Epoch 45/52\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 44.7566 - accuracy: 0.3973 - val_loss: 43.4669 - val_accuracy: 0.5867\n",
      "Epoch 46/52\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 78.0236 - accuracy: 0.4108 - val_loss: 19.8621 - val_accuracy: 0.2533\n",
      "Epoch 47/52\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 68.0985 - accuracy: 0.3434 - val_loss: 61.0950 - val_accuracy: 0.5867\n",
      "Epoch 48/52\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 54.7624 - accuracy: 0.4343 - val_loss: 96.8032 - val_accuracy: 0.2400\n",
      "Epoch 49/52\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 65.0701 - accuracy: 0.3569 - val_loss: 51.9873 - val_accuracy: 0.5867\n",
      "Epoch 50/52\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 83.0003 - accuracy: 0.4545 - val_loss: 39.3193 - val_accuracy: 0.0133\n",
      "Epoch 51/52\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 47.9636 - accuracy: 0.2525 - val_loss: 46.0519 - val_accuracy: 0.5867\n",
      "Epoch 52/52\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 69.6028 - accuracy: 0.3939 - val_loss: 31.9848 - val_accuracy: 0.5867\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "| \u001b[0m13       \u001b[0m | \u001b[0m0.2043   \u001b[0m | \u001b[0m2.319    \u001b[0m | \u001b[0m101.0    \u001b[0m | \u001b[0m52.06    \u001b[0m | \u001b[0m0.8403   \u001b[0m | \u001b[0m1.216    \u001b[0m |\n",
      "Epoch 1/34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/rmsprop.py:140: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adagrad.py:81: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 86ms/step - loss: 61210880.0000 - accuracy: 0.3098 - val_loss: 523.1671 - val_accuracy: 0.5867\n",
      "Epoch 2/34\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 411.3868 - accuracy: 0.3939 - val_loss: 512.3804 - val_accuracy: 0.2400\n",
      "Epoch 3/34\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 11.5205 - accuracy: 0.3300 - val_loss: 499.6380 - val_accuracy: 0.5733\n",
      "Epoch 4/34\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 2.8486 - accuracy: 0.4579 - val_loss: 503.8954 - val_accuracy: 0.1600\n",
      "Epoch 5/34\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 1.1138 - accuracy: 0.4007 - val_loss: 503.7284 - val_accuracy: 0.5733\n",
      "Epoch 6/34\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1.1569 - accuracy: 0.4108 - val_loss: 504.5439 - val_accuracy: 0.2400\n",
      "Epoch 7/34\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 1.2979 - accuracy: 0.4444 - val_loss: 504.0312 - val_accuracy: 0.2400\n",
      "Epoch 8/34\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 1.1487 - accuracy: 0.4411 - val_loss: 503.9519 - val_accuracy: 0.5733\n",
      "Epoch 9/34\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1.1989 - accuracy: 0.4209 - val_loss: 504.5406 - val_accuracy: 0.1600\n",
      "Epoch 10/34\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.3272 - accuracy: 0.4007 - val_loss: 503.7231 - val_accuracy: 0.5733\n",
      "Epoch 11/34\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.0981 - accuracy: 0.5152 - val_loss: 503.8241 - val_accuracy: 0.5733\n",
      "Epoch 12/34\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.1624 - accuracy: 0.4242 - val_loss: 503.7371 - val_accuracy: 0.5733\n",
      "Epoch 13/34\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.1059 - accuracy: 0.5152 - val_loss: 504.2858 - val_accuracy: 0.2400\n",
      "Epoch 14/34\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1.3574 - accuracy: 0.4040 - val_loss: 503.9058 - val_accuracy: 0.2400\n",
      "Epoch 15/34\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.1883 - accuracy: 0.3569 - val_loss: 503.8387 - val_accuracy: 0.5733\n",
      "Epoch 16/34\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.1161 - accuracy: 0.5152 - val_loss: 503.6804 - val_accuracy: 0.5733\n",
      "Epoch 17/34\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.0927 - accuracy: 0.5152 - val_loss: 504.2013 - val_accuracy: 0.2400\n",
      "Epoch 18/34\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.2495 - accuracy: 0.4714 - val_loss: 503.6544 - val_accuracy: 0.5733\n",
      "Epoch 19/34\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.0786 - accuracy: 0.5118 - val_loss: 503.6670 - val_accuracy: 0.5733\n",
      "Epoch 20/34\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1.2229 - accuracy: 0.4411 - val_loss: 503.8063 - val_accuracy: 0.5733\n",
      "Epoch 21/34\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 1.1306 - accuracy: 0.4007 - val_loss: 503.7271 - val_accuracy: 0.5733\n",
      "Epoch 22/34\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 1.1144 - accuracy: 0.4343 - val_loss: 504.5763 - val_accuracy: 0.1600\n",
      "Epoch 23/34\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 1.2429 - accuracy: 0.3569 - val_loss: 503.9312 - val_accuracy: 0.2400\n",
      "Epoch 24/34\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 1.1409 - accuracy: 0.4579 - val_loss: 504.2679 - val_accuracy: 0.2400\n",
      "Epoch 25/34\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 1.2751 - accuracy: 0.3569 - val_loss: 503.6624 - val_accuracy: 0.5733\n",
      "Epoch 26/34\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1.1070 - accuracy: 0.4512 - val_loss: 503.8134 - val_accuracy: 0.1600\n",
      "Epoch 27/34\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1.1040 - accuracy: 0.4175 - val_loss: 504.3524 - val_accuracy: 0.2400\n",
      "Epoch 28/34\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 1.3414 - accuracy: 0.4040 - val_loss: 504.5430 - val_accuracy: 0.2400\n",
      "Epoch 29/34\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 1.2609 - accuracy: 0.4545 - val_loss: 503.9493 - val_accuracy: 0.2400\n",
      "Epoch 30/34\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 1.1458 - accuracy: 0.4680 - val_loss: 503.7545 - val_accuracy: 0.2400\n",
      "Epoch 31/34\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 1.1398 - accuracy: 0.3535 - val_loss: 504.0170 - val_accuracy: 0.5733\n",
      "Epoch 32/34\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 1.2439 - accuracy: 0.5152 - val_loss: 503.7639 - val_accuracy: 0.5733\n",
      "Epoch 33/34\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 1.0985 - accuracy: 0.4444 - val_loss: 503.7737 - val_accuracy: 0.5733\n",
      "Epoch 34/34\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1.1416 - accuracy: 0.4512 - val_loss: 503.6523 - val_accuracy: 0.5733\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "| \u001b[0m14       \u001b[0m | \u001b[0m0.5376   \u001b[0m | \u001b[0m0.2      \u001b[0m | \u001b[0m96.99    \u001b[0m | \u001b[0m33.59    \u001b[0m | \u001b[0m0.8808   \u001b[0m | \u001b[0m0.6819   \u001b[0m |\n",
      "Epoch 1/88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/rmsprop.py:140: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adagrad.py:81: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 60ms/step - loss: 98.8690 - accuracy: 0.3603 - val_loss: 1.3139 - val_accuracy: 0.5733\n",
      "Epoch 2/88\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 1.2787 - accuracy: 0.4983 - val_loss: 1.0900 - val_accuracy: 0.6000\n",
      "Epoch 3/88\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 1.1583 - accuracy: 0.4444 - val_loss: 1.0272 - val_accuracy: 0.5867\n",
      "Epoch 4/88\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.0755 - accuracy: 0.4613 - val_loss: 1.0100 - val_accuracy: 0.6000\n",
      "Epoch 5/88\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 1.0229 - accuracy: 0.5354 - val_loss: 1.0041 - val_accuracy: 0.6000\n",
      "Epoch 6/88\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 1.0339 - accuracy: 0.5354 - val_loss: 1.0018 - val_accuracy: 0.6000\n",
      "Epoch 7/88\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 1.0044 - accuracy: 0.5354 - val_loss: 1.0085 - val_accuracy: 0.6000\n",
      "Epoch 8/88\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 1.0127 - accuracy: 0.5219 - val_loss: 1.0224 - val_accuracy: 0.6000\n",
      "Epoch 9/88\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 1.0129 - accuracy: 0.5286 - val_loss: 1.0096 - val_accuracy: 0.6000\n",
      "Epoch 10/88\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 1.0111 - accuracy: 0.5421 - val_loss: 1.0120 - val_accuracy: 0.6000\n",
      "Epoch 11/88\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 1.0103 - accuracy: 0.5455 - val_loss: 1.0238 - val_accuracy: 0.6000\n",
      "Epoch 12/88\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 1.0026 - accuracy: 0.5522 - val_loss: 1.0246 - val_accuracy: 0.6000\n",
      "Epoch 13/88\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 1.0059 - accuracy: 0.5421 - val_loss: 1.0172 - val_accuracy: 0.6000\n",
      "Epoch 14/88\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.9971 - accuracy: 0.5455 - val_loss: 1.0180 - val_accuracy: 0.6000\n",
      "Epoch 15/88\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.9942 - accuracy: 0.5421 - val_loss: 1.0174 - val_accuracy: 0.6000\n",
      "Epoch 16/88\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.9953 - accuracy: 0.5455 - val_loss: 1.0145 - val_accuracy: 0.5867\n",
      "Epoch 17/88\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1.0035 - accuracy: 0.5421 - val_loss: 1.0249 - val_accuracy: 0.6000\n",
      "Epoch 18/88\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.9875 - accuracy: 0.5455 - val_loss: 1.0781 - val_accuracy: 0.5867\n",
      "Epoch 19/88\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.9998 - accuracy: 0.5320 - val_loss: 1.1153 - val_accuracy: 0.5867\n",
      "Epoch 20/88\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 1.0112 - accuracy: 0.5421 - val_loss: 1.1206 - val_accuracy: 0.5867\n",
      "Epoch 21/88\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1.0050 - accuracy: 0.5455 - val_loss: 1.0437 - val_accuracy: 0.6000\n",
      "Epoch 22/88\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 1.0073 - accuracy: 0.5455 - val_loss: 1.0104 - val_accuracy: 0.6000\n",
      "Epoch 23/88\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.0285 - accuracy: 0.5219 - val_loss: 0.9803 - val_accuracy: 0.6000\n",
      "Epoch 24/88\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 1.0018 - accuracy: 0.5455 - val_loss: 0.9831 - val_accuracy: 0.6000\n",
      "Epoch 25/88\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 1.0067 - accuracy: 0.5455 - val_loss: 0.9791 - val_accuracy: 0.6000\n",
      "Epoch 26/88\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.9939 - accuracy: 0.5455 - val_loss: 0.9836 - val_accuracy: 0.6000\n",
      "Epoch 27/88\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.9936 - accuracy: 0.5455 - val_loss: 0.9830 - val_accuracy: 0.6000\n",
      "Epoch 28/88\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.9965 - accuracy: 0.5455 - val_loss: 0.9883 - val_accuracy: 0.6000\n",
      "Epoch 29/88\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.0020 - accuracy: 0.5455 - val_loss: 0.9937 - val_accuracy: 0.6000\n",
      "Epoch 30/88\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.9876 - accuracy: 0.5455 - val_loss: 0.9964 - val_accuracy: 0.6000\n",
      "Epoch 31/88\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.9965 - accuracy: 0.5455 - val_loss: 0.9999 - val_accuracy: 0.6000\n",
      "Epoch 32/88\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1.0040 - accuracy: 0.5455 - val_loss: 0.9980 - val_accuracy: 0.6000\n",
      "Epoch 33/88\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.9978 - accuracy: 0.5455 - val_loss: 0.9996 - val_accuracy: 0.6000\n",
      "Epoch 34/88\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.9987 - accuracy: 0.5455 - val_loss: 0.9982 - val_accuracy: 0.6000\n",
      "Epoch 35/88\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1.0050 - accuracy: 0.5455 - val_loss: 1.0096 - val_accuracy: 0.6000\n",
      "Epoch 36/88\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.9888 - accuracy: 0.5455 - val_loss: 1.0627 - val_accuracy: 0.6000\n",
      "Epoch 37/88\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.9862 - accuracy: 0.5455 - val_loss: 1.1377 - val_accuracy: 0.6000\n",
      "Epoch 38/88\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.9842 - accuracy: 0.5455 - val_loss: 1.2240 - val_accuracy: 0.6000\n",
      "Epoch 39/88\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.9810 - accuracy: 0.5455 - val_loss: 1.3015 - val_accuracy: 0.6000\n",
      "Epoch 40/88\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.9878 - accuracy: 0.5455 - val_loss: 1.6687 - val_accuracy: 0.5733\n",
      "Epoch 41/88\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 1.0239 - accuracy: 0.5387 - val_loss: 1.2933 - val_accuracy: 0.6000\n",
      "Epoch 42/88\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.9842 - accuracy: 0.5455 - val_loss: 1.2948 - val_accuracy: 0.6000\n",
      "Epoch 43/88\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 1.0731 - accuracy: 0.5387 - val_loss: 1.0392 - val_accuracy: 0.6000\n",
      "Epoch 44/88\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 1.0065 - accuracy: 0.5387 - val_loss: 0.9803 - val_accuracy: 0.6000\n",
      "Epoch 45/88\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.9953 - accuracy: 0.5354 - val_loss: 0.9740 - val_accuracy: 0.6000\n",
      "Epoch 46/88\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 1.0066 - accuracy: 0.5387 - val_loss: 0.9688 - val_accuracy: 0.6000\n",
      "Epoch 47/88\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 1.0027 - accuracy: 0.5387 - val_loss: 0.9542 - val_accuracy: 0.6000\n",
      "Epoch 48/88\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 1.0001 - accuracy: 0.5387 - val_loss: 0.9481 - val_accuracy: 0.6000\n",
      "Epoch 49/88\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.9934 - accuracy: 0.5387 - val_loss: 0.9484 - val_accuracy: 0.6000\n",
      "Epoch 50/88\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.9901 - accuracy: 0.5387 - val_loss: 0.9492 - val_accuracy: 0.6000\n",
      "Epoch 51/88\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.9910 - accuracy: 0.5387 - val_loss: 0.9500 - val_accuracy: 0.6000\n",
      "Epoch 52/88\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.9869 - accuracy: 0.5387 - val_loss: 0.9495 - val_accuracy: 0.6000\n",
      "Epoch 53/88\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.9896 - accuracy: 0.5387 - val_loss: 0.9499 - val_accuracy: 0.6000\n",
      "Epoch 54/88\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.9947 - accuracy: 0.5387 - val_loss: 0.9496 - val_accuracy: 0.6000\n",
      "Epoch 55/88\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.9906 - accuracy: 0.5387 - val_loss: 0.9504 - val_accuracy: 0.6000\n",
      "Epoch 56/88\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.9849 - accuracy: 0.5387 - val_loss: 0.9502 - val_accuracy: 0.6000\n",
      "Epoch 57/88\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.9871 - accuracy: 0.5387 - val_loss: 0.9482 - val_accuracy: 0.6000\n",
      "Epoch 58/88\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.9845 - accuracy: 0.5387 - val_loss: 0.9465 - val_accuracy: 0.6000\n",
      "Epoch 59/88\n",
      "4/4 [==============================] - 0s 88ms/step - loss: 0.9971 - accuracy: 0.5387 - val_loss: 0.9477 - val_accuracy: 0.6000\n",
      "Epoch 60/88\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.9938 - accuracy: 0.5387 - val_loss: 0.9497 - val_accuracy: 0.6000\n",
      "Epoch 61/88\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.9906 - accuracy: 0.5387 - val_loss: 0.9520 - val_accuracy: 0.6000\n",
      "Epoch 62/88\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.9879 - accuracy: 0.5387 - val_loss: 0.9507 - val_accuracy: 0.6000\n",
      "Epoch 63/88\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.9882 - accuracy: 0.5387 - val_loss: 0.9483 - val_accuracy: 0.6000\n",
      "Epoch 64/88\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.9849 - accuracy: 0.5387 - val_loss: 0.9464 - val_accuracy: 0.6000\n",
      "Epoch 65/88\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.9908 - accuracy: 0.5387 - val_loss: 0.9456 - val_accuracy: 0.6000\n",
      "Epoch 66/88\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.9903 - accuracy: 0.5387 - val_loss: 0.9481 - val_accuracy: 0.6000\n",
      "Epoch 67/88\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.9887 - accuracy: 0.5387 - val_loss: 0.9524 - val_accuracy: 0.6000\n",
      "Epoch 68/88\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.9854 - accuracy: 0.5387 - val_loss: 0.9537 - val_accuracy: 0.6000\n",
      "Epoch 69/88\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.9913 - accuracy: 0.5387 - val_loss: 0.9529 - val_accuracy: 0.6000\n",
      "Epoch 70/88\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.9842 - accuracy: 0.5387 - val_loss: 0.9491 - val_accuracy: 0.6000\n",
      "Epoch 71/88\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.9932 - accuracy: 0.5387 - val_loss: 0.9483 - val_accuracy: 0.6000\n",
      "Epoch 72/88\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.9812 - accuracy: 0.5387 - val_loss: 0.9503 - val_accuracy: 0.6000\n",
      "Epoch 73/88\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.9860 - accuracy: 0.5387 - val_loss: 0.9527 - val_accuracy: 0.6000\n",
      "Epoch 74/88\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.9906 - accuracy: 0.5387 - val_loss: 0.9489 - val_accuracy: 0.6000\n",
      "Epoch 75/88\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1.0012 - accuracy: 0.5387 - val_loss: 0.9503 - val_accuracy: 0.6000\n",
      "Epoch 76/88\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.9929 - accuracy: 0.5387 - val_loss: 0.9494 - val_accuracy: 0.6000\n",
      "Epoch 77/88\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.9903 - accuracy: 0.5387 - val_loss: 0.9458 - val_accuracy: 0.6000\n",
      "Epoch 78/88\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.9943 - accuracy: 0.5387 - val_loss: 0.9458 - val_accuracy: 0.6000\n",
      "Epoch 79/88\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.9894 - accuracy: 0.5387 - val_loss: 0.9469 - val_accuracy: 0.6000\n",
      "Epoch 80/88\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.9918 - accuracy: 0.5387 - val_loss: 0.9467 - val_accuracy: 0.6000\n",
      "Epoch 81/88\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.9903 - accuracy: 0.5387 - val_loss: 0.9457 - val_accuracy: 0.6000\n",
      "Epoch 82/88\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.9892 - accuracy: 0.5387 - val_loss: 0.9467 - val_accuracy: 0.6000\n",
      "Epoch 83/88\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.9902 - accuracy: 0.5387 - val_loss: 0.9465 - val_accuracy: 0.6000\n",
      "Epoch 84/88\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.9885 - accuracy: 0.5387 - val_loss: 0.9459 - val_accuracy: 0.6000\n",
      "Epoch 85/88\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.9880 - accuracy: 0.5387 - val_loss: 0.9471 - val_accuracy: 0.6000\n",
      "Epoch 86/88\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.9899 - accuracy: 0.5387 - val_loss: 0.9487 - val_accuracy: 0.6000\n",
      "Epoch 87/88\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.9900 - accuracy: 0.5387 - val_loss: 0.9485 - val_accuracy: 0.6000\n",
      "Epoch 88/88\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.9887 - accuracy: 0.5387 - val_loss: 0.9475 - val_accuracy: 0.6000\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "| \u001b[0m15       \u001b[0m | \u001b[0m0.5484   \u001b[0m | \u001b[0m0.2458   \u001b[0m | \u001b[0m85.69    \u001b[0m | \u001b[0m88.09    \u001b[0m | \u001b[0m0.05686  \u001b[0m | \u001b[0m2.085    \u001b[0m |\n",
      "Epoch 1/77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/rmsprop.py:140: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adagrad.py:81: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 1s 14ms/step - loss: 30.9305 - accuracy: 0.3805 - val_loss: 20.9725 - val_accuracy: 0.5867\n",
      "Epoch 2/77\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 41.4559 - accuracy: 0.3199 - val_loss: 41.5883 - val_accuracy: 0.5867\n",
      "Epoch 3/77\n",
      "25/25 [==============================] - 0s 13ms/step - loss: 29.1204 - accuracy: 0.4108 - val_loss: 47.4735 - val_accuracy: 0.5867\n",
      "Epoch 4/77\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 34.0982 - accuracy: 0.3771 - val_loss: 29.5855 - val_accuracy: 0.5867\n",
      "Epoch 5/77\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 29.4349 - accuracy: 0.3838 - val_loss: 35.3283 - val_accuracy: 0.5867\n",
      "Epoch 6/77\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 34.6793 - accuracy: 0.3838 - val_loss: 40.0783 - val_accuracy: 0.5867\n",
      "Epoch 7/77\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 27.2591 - accuracy: 0.4545 - val_loss: 18.7861 - val_accuracy: 0.5867\n",
      "Epoch 8/77\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 27.6839 - accuracy: 0.4141 - val_loss: 61.6179 - val_accuracy: 0.2400\n",
      "Epoch 9/77\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 29.2616 - accuracy: 0.3906 - val_loss: 51.6307 - val_accuracy: 0.2400\n",
      "Epoch 10/77\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 30.2488 - accuracy: 0.4141 - val_loss: 36.3175 - val_accuracy: 0.1600\n",
      "Epoch 11/77\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 29.2158 - accuracy: 0.4040 - val_loss: 20.9066 - val_accuracy: 0.2400\n",
      "Epoch 12/77\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 31.1837 - accuracy: 0.3737 - val_loss: 22.7186 - val_accuracy: 0.1600\n",
      "Epoch 13/77\n",
      "25/25 [==============================] - 0s 18ms/step - loss: 37.7354 - accuracy: 0.3300 - val_loss: 41.4319 - val_accuracy: 0.1600\n",
      "Epoch 14/77\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 28.7978 - accuracy: 0.3838 - val_loss: 33.8692 - val_accuracy: 0.2400\n",
      "Epoch 15/77\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 32.6025 - accuracy: 0.3771 - val_loss: 48.4320 - val_accuracy: 0.2400\n",
      "Epoch 16/77\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 29.0840 - accuracy: 0.3737 - val_loss: 6.1769 - val_accuracy: 0.2400\n",
      "Epoch 17/77\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 29.0831 - accuracy: 0.3838 - val_loss: 8.3922 - val_accuracy: 0.1600\n",
      "Epoch 18/77\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 32.0334 - accuracy: 0.3906 - val_loss: 26.5932 - val_accuracy: 0.2400\n",
      "Epoch 19/77\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 31.2849 - accuracy: 0.3670 - val_loss: 24.4830 - val_accuracy: 0.2400\n",
      "Epoch 20/77\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 28.8424 - accuracy: 0.3838 - val_loss: 25.6560 - val_accuracy: 0.5867\n",
      "Epoch 21/77\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 32.4197 - accuracy: 0.3838 - val_loss: 25.0126 - val_accuracy: 0.1600\n",
      "Epoch 22/77\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 26.6764 - accuracy: 0.4108 - val_loss: 18.1986 - val_accuracy: 0.2400\n",
      "Epoch 23/77\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 27.6382 - accuracy: 0.3906 - val_loss: 33.3838 - val_accuracy: 0.5867\n",
      "Epoch 24/77\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 24.4168 - accuracy: 0.4209 - val_loss: 70.7747 - val_accuracy: 0.2400\n",
      "Epoch 25/77\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 26.1330 - accuracy: 0.4276 - val_loss: 34.8504 - val_accuracy: 0.2400\n",
      "Epoch 26/77\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 27.8534 - accuracy: 0.3838 - val_loss: 24.3051 - val_accuracy: 0.5867\n",
      "Epoch 27/77\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 28.3984 - accuracy: 0.3872 - val_loss: 25.8012 - val_accuracy: 0.1600\n",
      "Epoch 28/77\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 33.9141 - accuracy: 0.3468 - val_loss: 42.7251 - val_accuracy: 0.5867\n",
      "Epoch 29/77\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 34.0252 - accuracy: 0.3939 - val_loss: 6.5999 - val_accuracy: 0.1600\n",
      "Epoch 30/77\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 34.8217 - accuracy: 0.3737 - val_loss: 36.4340 - val_accuracy: 0.5867\n",
      "Epoch 31/77\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 32.2884 - accuracy: 0.4007 - val_loss: 48.2105 - val_accuracy: 0.2400\n",
      "Epoch 32/77\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 32.2138 - accuracy: 0.3670 - val_loss: 14.5132 - val_accuracy: 0.5867\n",
      "Epoch 33/77\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 29.3746 - accuracy: 0.3973 - val_loss: 17.2686 - val_accuracy: 0.5867\n",
      "Epoch 34/77\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 29.3384 - accuracy: 0.4074 - val_loss: 16.3365 - val_accuracy: 0.2400\n",
      "Epoch 35/77\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 24.3102 - accuracy: 0.4141 - val_loss: 15.6937 - val_accuracy: 0.1600\n",
      "Epoch 36/77\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 26.2393 - accuracy: 0.4108 - val_loss: 27.2381 - val_accuracy: 0.2400\n",
      "Epoch 37/77\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 31.8244 - accuracy: 0.3603 - val_loss: 19.1962 - val_accuracy: 0.5867\n",
      "Epoch 38/77\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 31.3508 - accuracy: 0.3973 - val_loss: 27.4499 - val_accuracy: 0.5867\n",
      "Epoch 39/77\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 27.7691 - accuracy: 0.3906 - val_loss: 11.5622 - val_accuracy: 0.5467\n",
      "Epoch 40/77\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 27.4779 - accuracy: 0.3670 - val_loss: 29.3199 - val_accuracy: 0.5867\n",
      "Epoch 41/77\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 24.0780 - accuracy: 0.3906 - val_loss: 18.9141 - val_accuracy: 0.5867\n",
      "Epoch 42/77\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 20.7816 - accuracy: 0.4377 - val_loss: 6.2600 - val_accuracy: 0.5733\n",
      "Epoch 43/77\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 28.5388 - accuracy: 0.4209 - val_loss: 9.2031 - val_accuracy: 0.4533\n",
      "Epoch 44/77\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 24.0161 - accuracy: 0.4545 - val_loss: 12.6547 - val_accuracy: 0.3067\n",
      "Epoch 45/77\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 30.6304 - accuracy: 0.3771 - val_loss: 62.5268 - val_accuracy: 0.2400\n",
      "Epoch 46/77\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 25.3022 - accuracy: 0.4242 - val_loss: 46.9051 - val_accuracy: 0.1600\n",
      "Epoch 47/77\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 30.3999 - accuracy: 0.3906 - val_loss: 60.6276 - val_accuracy: 0.2400\n",
      "Epoch 48/77\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 31.0891 - accuracy: 0.4074 - val_loss: 24.7549 - val_accuracy: 0.5867\n",
      "Epoch 49/77\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 27.0182 - accuracy: 0.3838 - val_loss: 50.3917 - val_accuracy: 0.2400\n",
      "Epoch 50/77\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 27.0795 - accuracy: 0.3805 - val_loss: 39.6969 - val_accuracy: 0.5867\n",
      "Epoch 51/77\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 27.7199 - accuracy: 0.4108 - val_loss: 19.3540 - val_accuracy: 0.2400\n",
      "Epoch 52/77\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 26.7183 - accuracy: 0.4074 - val_loss: 31.9886 - val_accuracy: 0.5867\n",
      "Epoch 53/77\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 28.6124 - accuracy: 0.3939 - val_loss: 22.4978 - val_accuracy: 0.5867\n",
      "Epoch 54/77\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 24.2158 - accuracy: 0.4074 - val_loss: 16.9469 - val_accuracy: 0.5867\n",
      "Epoch 55/77\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 32.3895 - accuracy: 0.3704 - val_loss: 9.9174 - val_accuracy: 0.5867\n",
      "Epoch 56/77\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 31.0623 - accuracy: 0.3704 - val_loss: 16.1737 - val_accuracy: 0.5867\n",
      "Epoch 57/77\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 29.7563 - accuracy: 0.3636 - val_loss: 33.3641 - val_accuracy: 0.5867\n",
      "Epoch 58/77\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 25.7237 - accuracy: 0.4411 - val_loss: 44.0793 - val_accuracy: 0.1600\n",
      "Epoch 59/77\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 30.0369 - accuracy: 0.3636 - val_loss: 15.1603 - val_accuracy: 0.5867\n",
      "Epoch 60/77\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 25.5429 - accuracy: 0.4310 - val_loss: 21.9059 - val_accuracy: 0.2400\n",
      "Epoch 61/77\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 28.0531 - accuracy: 0.3939 - val_loss: 35.0547 - val_accuracy: 0.5867\n",
      "Epoch 62/77\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 21.0271 - accuracy: 0.4646 - val_loss: 24.2414 - val_accuracy: 0.5867\n",
      "Epoch 63/77\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 31.4229 - accuracy: 0.3569 - val_loss: 12.9188 - val_accuracy: 0.2400\n",
      "Epoch 64/77\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 25.8734 - accuracy: 0.3636 - val_loss: 17.0209 - val_accuracy: 0.5867\n",
      "Epoch 65/77\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 26.7856 - accuracy: 0.4377 - val_loss: 48.1676 - val_accuracy: 0.2400\n",
      "Epoch 66/77\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 32.7352 - accuracy: 0.3704 - val_loss: 38.3667 - val_accuracy: 0.2400\n",
      "Epoch 67/77\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 28.7080 - accuracy: 0.3973 - val_loss: 37.8240 - val_accuracy: 0.2400\n",
      "Epoch 68/77\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 32.4799 - accuracy: 0.3872 - val_loss: 19.1793 - val_accuracy: 0.2400\n",
      "Epoch 69/77\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 24.8764 - accuracy: 0.3838 - val_loss: 19.7849 - val_accuracy: 0.5867\n",
      "Epoch 70/77\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 26.7870 - accuracy: 0.4007 - val_loss: 52.4193 - val_accuracy: 0.1600\n",
      "Epoch 71/77\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 28.8727 - accuracy: 0.3670 - val_loss: 38.9005 - val_accuracy: 0.5867\n",
      "Epoch 72/77\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 20.4352 - accuracy: 0.4680 - val_loss: 25.1043 - val_accuracy: 0.2400\n",
      "Epoch 73/77\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 35.5115 - accuracy: 0.4108 - val_loss: 22.0164 - val_accuracy: 0.2400\n",
      "Epoch 74/77\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 35.2682 - accuracy: 0.3569 - val_loss: 20.3222 - val_accuracy: 0.5867\n",
      "Epoch 75/77\n",
      "25/25 [==============================] - 0s 14ms/step - loss: 24.8056 - accuracy: 0.4377 - val_loss: 5.2631 - val_accuracy: 0.5867\n",
      "Epoch 76/77\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 24.6152 - accuracy: 0.4377 - val_loss: 39.6218 - val_accuracy: 0.5867\n",
      "Epoch 77/77\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 23.5223 - accuracy: 0.4310 - val_loss: 8.6737 - val_accuracy: 0.5867\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "| \u001b[0m16       \u001b[0m | \u001b[0m0.5376   \u001b[0m | \u001b[0m1.535    \u001b[0m | \u001b[0m12.37    \u001b[0m | \u001b[0m76.58    \u001b[0m | \u001b[0m0.9151   \u001b[0m | \u001b[0m0.01716  \u001b[0m |\n",
      "Epoch 1/81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/rmsprop.py:140: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adagrad.py:81: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 193ms/step - loss: 32524406.0000 - accuracy: 0.1785 - val_loss: 21939640.0000 - val_accuracy: 0.2400\n",
      "Epoch 2/81\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 96735384.0000 - accuracy: 0.2121 - val_loss: 2520965.0000 - val_accuracy: 0.1733\n",
      "Epoch 3/81\n",
      "2/2 [==============================] - 0s 298ms/step - loss: 3066989.0000 - accuracy: 0.3535 - val_loss: 573139.6875 - val_accuracy: 0.2400\n",
      "Epoch 4/81\n",
      "2/2 [==============================] - 0s 181ms/step - loss: 835718.5625 - accuracy: 0.3603 - val_loss: 216442.1875 - val_accuracy: 0.5067\n",
      "Epoch 5/81\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 252332.6406 - accuracy: 0.4175 - val_loss: 74533.8906 - val_accuracy: 0.5867\n",
      "Epoch 6/81\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 66843.7188 - accuracy: 0.4983 - val_loss: 7999.6333 - val_accuracy: 0.5600\n",
      "Epoch 7/81\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 14484.3906 - accuracy: 0.4545 - val_loss: 1859.6515 - val_accuracy: 0.6267\n",
      "Epoch 8/81\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 4850.8267 - accuracy: 0.4276 - val_loss: 1274.1667 - val_accuracy: 0.6133\n",
      "Epoch 9/81\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 2855.2471 - accuracy: 0.3502 - val_loss: 1461.4056 - val_accuracy: 0.6267\n",
      "Epoch 10/81\n",
      "2/2 [==============================] - 0s 122ms/step - loss: 3391.1687 - accuracy: 0.3838 - val_loss: 1081.7710 - val_accuracy: 0.6267\n",
      "Epoch 11/81\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 2423.5024 - accuracy: 0.4007 - val_loss: 788.9595 - val_accuracy: 0.3867\n",
      "Epoch 12/81\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 1924.1334 - accuracy: 0.4444 - val_loss: 1145.5027 - val_accuracy: 0.3733\n",
      "Epoch 13/81\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 2021.2744 - accuracy: 0.4411 - val_loss: 1083.8739 - val_accuracy: 0.3467\n",
      "Epoch 14/81\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 2043.0270 - accuracy: 0.3973 - val_loss: 1080.7102 - val_accuracy: 0.3467\n",
      "Epoch 15/81\n",
      "2/2 [==============================] - 0s 122ms/step - loss: 5822.3022 - accuracy: 0.4141 - val_loss: 599.0405 - val_accuracy: 0.3333\n",
      "Epoch 16/81\n",
      "2/2 [==============================] - 0s 137ms/step - loss: 1200.6389 - accuracy: 0.4411 - val_loss: 602.4982 - val_accuracy: 0.6267\n",
      "Epoch 17/81\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 969.9647 - accuracy: 0.4310 - val_loss: 956.4922 - val_accuracy: 0.3467\n",
      "Epoch 18/81\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 972.4169 - accuracy: 0.3670 - val_loss: 699.4423 - val_accuracy: 0.3467\n",
      "Epoch 19/81\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 741.3591 - accuracy: 0.4276 - val_loss: 671.0609 - val_accuracy: 0.3467\n",
      "Epoch 20/81\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 867.3225 - accuracy: 0.4377 - val_loss: 683.7448 - val_accuracy: 0.3467\n",
      "Epoch 21/81\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 857.6852 - accuracy: 0.3401 - val_loss: 220.4596 - val_accuracy: 0.6533\n",
      "Epoch 22/81\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 2017.8442 - accuracy: 0.3973 - val_loss: 342.7534 - val_accuracy: 0.6533\n",
      "Epoch 23/81\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 2046.8860 - accuracy: 0.4276 - val_loss: 262.3026 - val_accuracy: 0.3600\n",
      "Epoch 24/81\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 1436.7281 - accuracy: 0.4175 - val_loss: 223.3055 - val_accuracy: 0.6533\n",
      "Epoch 25/81\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 603.6769 - accuracy: 0.3771 - val_loss: 363.0740 - val_accuracy: 0.6533\n",
      "Epoch 26/81\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 1918.8329 - accuracy: 0.4209 - val_loss: 183.8481 - val_accuracy: 0.3333\n",
      "Epoch 27/81\n",
      "2/2 [==============================] - 0s 121ms/step - loss: 422.0063 - accuracy: 0.3670 - val_loss: 157.5293 - val_accuracy: 0.3333\n",
      "Epoch 28/81\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 443.1294 - accuracy: 0.4141 - val_loss: 129.2721 - val_accuracy: 0.3200\n",
      "Epoch 29/81\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 356.4778 - accuracy: 0.3805 - val_loss: 92.5936 - val_accuracy: 0.3200\n",
      "Epoch 30/81\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 284.0213 - accuracy: 0.3872 - val_loss: 70.2177 - val_accuracy: 0.6533\n",
      "Epoch 31/81\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 261.3653 - accuracy: 0.3535 - val_loss: 63.0673 - val_accuracy: 0.6533\n",
      "Epoch 32/81\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 342.8934 - accuracy: 0.4276 - val_loss: 76.8529 - val_accuracy: 0.6400\n",
      "Epoch 33/81\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 282.2978 - accuracy: 0.3670 - val_loss: 57.7304 - val_accuracy: 0.6533\n",
      "Epoch 34/81\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 205.8745 - accuracy: 0.4007 - val_loss: 39.5820 - val_accuracy: 0.1733\n",
      "Epoch 35/81\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 305.7375 - accuracy: 0.3266 - val_loss: 37.9158 - val_accuracy: 0.6533\n",
      "Epoch 36/81\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 161.3521 - accuracy: 0.4108 - val_loss: 55.6389 - val_accuracy: 0.6533\n",
      "Epoch 37/81\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 128.0709 - accuracy: 0.4444 - val_loss: 37.5267 - val_accuracy: 0.6533\n",
      "Epoch 38/81\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 126.4886 - accuracy: 0.3569 - val_loss: 27.6404 - val_accuracy: 0.6533\n",
      "Epoch 39/81\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 123.5641 - accuracy: 0.4108 - val_loss: 35.0189 - val_accuracy: 0.6533\n",
      "Epoch 40/81\n",
      "2/2 [==============================] - 0s 217ms/step - loss: 83.8908 - accuracy: 0.4377 - val_loss: 34.0279 - val_accuracy: 0.6533\n",
      "Epoch 41/81\n",
      "2/2 [==============================] - 0s 122ms/step - loss: 85.6672 - accuracy: 0.3704 - val_loss: 27.7194 - val_accuracy: 0.6533\n",
      "Epoch 42/81\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 76.3971 - accuracy: 0.4040 - val_loss: 30.4235 - val_accuracy: 0.1733\n",
      "Epoch 43/81\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 81.5800 - accuracy: 0.3670 - val_loss: 68.9744 - val_accuracy: 0.6533\n",
      "Epoch 44/81\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 95.0015 - accuracy: 0.3771 - val_loss: 82.4872 - val_accuracy: 0.6533\n",
      "Epoch 45/81\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 112.6665 - accuracy: 0.3333 - val_loss: 71.9329 - val_accuracy: 0.6533\n",
      "Epoch 46/81\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 77.2783 - accuracy: 0.4040 - val_loss: 27.7622 - val_accuracy: 0.6533\n",
      "Epoch 47/81\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 65.3061 - accuracy: 0.3468 - val_loss: 107.4339 - val_accuracy: 0.6533\n",
      "Epoch 48/81\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 218.6652 - accuracy: 0.4141 - val_loss: 1627.6345 - val_accuracy: 0.3200\n",
      "Epoch 49/81\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 25847.4180 - accuracy: 0.4141 - val_loss: 12694.5762 - val_accuracy: 0.4533\n",
      "Epoch 50/81\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 380867.0938 - accuracy: 0.3906 - val_loss: 2316195.7500 - val_accuracy: 0.2400\n",
      "Epoch 51/81\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 944050.3125 - accuracy: 0.2795 - val_loss: 774.7170 - val_accuracy: 0.1600\n",
      "Epoch 52/81\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 745.0815 - accuracy: 0.3300 - val_loss: 302.2328 - val_accuracy: 0.2400\n",
      "Epoch 53/81\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 438.1296 - accuracy: 0.3401 - val_loss: 101.6305 - val_accuracy: 0.2400\n",
      "Epoch 54/81\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 290.7376 - accuracy: 0.3165 - val_loss: 45.0728 - val_accuracy: 0.5867\n",
      "Epoch 55/81\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 191.4566 - accuracy: 0.3670 - val_loss: 88.3764 - val_accuracy: 0.5867\n",
      "Epoch 56/81\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 163.5031 - accuracy: 0.3737 - val_loss: 138.5032 - val_accuracy: 0.5867\n",
      "Epoch 57/81\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 233.1402 - accuracy: 0.2761 - val_loss: 70.4837 - val_accuracy: 0.2400\n",
      "Epoch 58/81\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 155.6513 - accuracy: 0.2525 - val_loss: 82.5468 - val_accuracy: 0.2400\n",
      "Epoch 59/81\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 192.3149 - accuracy: 0.2391 - val_loss: 91.8746 - val_accuracy: 0.2400\n",
      "Epoch 60/81\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 183.5701 - accuracy: 0.3131 - val_loss: 113.1392 - val_accuracy: 0.2400\n",
      "Epoch 61/81\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 152.1261 - accuracy: 0.4007 - val_loss: 102.6265 - val_accuracy: 0.2400\n",
      "Epoch 62/81\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 176.4326 - accuracy: 0.3300 - val_loss: 137.0312 - val_accuracy: 0.2400\n",
      "Epoch 63/81\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 158.6954 - accuracy: 0.3064 - val_loss: 120.8323 - val_accuracy: 0.2400\n",
      "Epoch 64/81\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 158.1187 - accuracy: 0.2963 - val_loss: 124.2081 - val_accuracy: 0.2400\n",
      "Epoch 65/81\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 154.7170 - accuracy: 0.2357 - val_loss: 86.0308 - val_accuracy: 0.2400\n",
      "Epoch 66/81\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 129.3806 - accuracy: 0.2559 - val_loss: 86.7598 - val_accuracy: 0.2400\n",
      "Epoch 67/81\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 128.7852 - accuracy: 0.3199 - val_loss: 87.1262 - val_accuracy: 0.2400\n",
      "Epoch 68/81\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 115.1852 - accuracy: 0.3300 - val_loss: 59.0382 - val_accuracy: 0.2400\n",
      "Epoch 69/81\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 105.2387 - accuracy: 0.2626 - val_loss: 81.2713 - val_accuracy: 0.5867\n",
      "Epoch 70/81\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 133.4364 - accuracy: 0.3434 - val_loss: 83.0887 - val_accuracy: 0.5867\n",
      "Epoch 71/81\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 125.1965 - accuracy: 0.2929 - val_loss: 38.9253 - val_accuracy: 0.5867\n",
      "Epoch 72/81\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 79.5128 - accuracy: 0.3367 - val_loss: 49.3522 - val_accuracy: 0.5867\n",
      "Epoch 73/81\n",
      "2/2 [==============================] - 0s 192ms/step - loss: 87.9867 - accuracy: 0.3434 - val_loss: 32.9600 - val_accuracy: 0.5867\n",
      "Epoch 74/81\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 81.8171 - accuracy: 0.3165 - val_loss: 21.3464 - val_accuracy: 0.5867\n",
      "Epoch 75/81\n",
      "2/2 [==============================] - 0s 140ms/step - loss: 84.5816 - accuracy: 0.3468 - val_loss: 48.0266 - val_accuracy: 0.2400\n",
      "Epoch 76/81\n",
      "2/2 [==============================] - 0s 121ms/step - loss: 88.9376 - accuracy: 0.3367 - val_loss: 14.1646 - val_accuracy: 0.5867\n",
      "Epoch 77/81\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 83.7898 - accuracy: 0.3401 - val_loss: 36.5224 - val_accuracy: 0.2400\n",
      "Epoch 78/81\n",
      "2/2 [==============================] - 0s 221ms/step - loss: 95.0000 - accuracy: 0.3670 - val_loss: 27.4624 - val_accuracy: 0.5867\n",
      "Epoch 79/81\n",
      "2/2 [==============================] - 0s 139ms/step - loss: 100.9909 - accuracy: 0.3266 - val_loss: 49.7143 - val_accuracy: 0.2400\n",
      "Epoch 80/81\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 104.9322 - accuracy: 0.3569 - val_loss: 14.8430 - val_accuracy: 0.5867\n",
      "Epoch 81/81\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 109.0896 - accuracy: 0.2727 - val_loss: 52.9895 - val_accuracy: 0.5867\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "| \u001b[0m17       \u001b[0m | \u001b[0m0.2043   \u001b[0m | \u001b[0m0.7013   \u001b[0m | \u001b[0m148.9    \u001b[0m | \u001b[0m80.99    \u001b[0m | \u001b[0m0.7627   \u001b[0m | \u001b[0m1.427    \u001b[0m |\n",
      "Epoch 1/58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/rmsprop.py:140: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adagrad.py:81: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 50ms/step - loss: 4367.6943 - accuracy: 0.3064 - val_loss: 3312.1038 - val_accuracy: 0.5867\n",
      "Epoch 2/58\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1217.3595 - accuracy: 0.3165 - val_loss: 49.5681 - val_accuracy: 0.5867\n",
      "Epoch 3/58\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 34.9852 - accuracy: 0.3771 - val_loss: 5.6418 - val_accuracy: 0.5867\n",
      "Epoch 4/58\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.2183 - accuracy: 0.4242 - val_loss: 1.4742 - val_accuracy: 0.5867\n",
      "Epoch 5/58\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 2.4679 - accuracy: 0.4108 - val_loss: 1.3022 - val_accuracy: 0.4000\n",
      "Epoch 6/58\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 2.5993 - accuracy: 0.4074 - val_loss: 1.3525 - val_accuracy: 0.5467\n",
      "Epoch 7/58\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 2.2069 - accuracy: 0.4141 - val_loss: 1.1372 - val_accuracy: 0.6000\n",
      "Epoch 8/58\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 2.5602 - accuracy: 0.3939 - val_loss: 1.1402 - val_accuracy: 0.5600\n",
      "Epoch 9/58\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 2.3743 - accuracy: 0.4411 - val_loss: 1.1198 - val_accuracy: 0.5600\n",
      "Epoch 10/58\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 2.5036 - accuracy: 0.4141 - val_loss: 1.1039 - val_accuracy: 0.5600\n",
      "Epoch 11/58\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 2.3390 - accuracy: 0.4444 - val_loss: 1.1219 - val_accuracy: 0.6000\n",
      "Epoch 12/58\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 2.0753 - accuracy: 0.4747 - val_loss: 1.0805 - val_accuracy: 0.6133\n",
      "Epoch 13/58\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 2.3200 - accuracy: 0.4343 - val_loss: 0.9703 - val_accuracy: 0.6000\n",
      "Epoch 14/58\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 2.2168 - accuracy: 0.4444 - val_loss: 1.0280 - val_accuracy: 0.5467\n",
      "Epoch 15/58\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 2.2667 - accuracy: 0.4579 - val_loss: 1.1324 - val_accuracy: 0.6133\n",
      "Epoch 16/58\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 2.2977 - accuracy: 0.4613 - val_loss: 1.0498 - val_accuracy: 0.6133\n",
      "Epoch 17/58\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 2.1675 - accuracy: 0.4209 - val_loss: 1.3024 - val_accuracy: 0.5733\n",
      "Epoch 18/58\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 2.0423 - accuracy: 0.4579 - val_loss: 1.0417 - val_accuracy: 0.5600\n",
      "Epoch 19/58\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 2.0136 - accuracy: 0.4781 - val_loss: 0.9998 - val_accuracy: 0.5867\n",
      "Epoch 20/58\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 1.9424 - accuracy: 0.5185 - val_loss: 0.9307 - val_accuracy: 0.6133\n",
      "Epoch 21/58\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 2.0643 - accuracy: 0.5084 - val_loss: 1.0472 - val_accuracy: 0.6000\n",
      "Epoch 22/58\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 1.8146 - accuracy: 0.5421 - val_loss: 1.0754 - val_accuracy: 0.6000\n",
      "Epoch 23/58\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 1.9490 - accuracy: 0.4983 - val_loss: 0.9602 - val_accuracy: 0.6267\n",
      "Epoch 24/58\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 2.2158 - accuracy: 0.4747 - val_loss: 0.9608 - val_accuracy: 0.6267\n",
      "Epoch 25/58\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 1.9202 - accuracy: 0.5421 - val_loss: 0.9765 - val_accuracy: 0.6533\n",
      "Epoch 26/58\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 1.7974 - accuracy: 0.5387 - val_loss: 1.0560 - val_accuracy: 0.6267\n",
      "Epoch 27/58\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 2.1240 - accuracy: 0.4377 - val_loss: 1.1106 - val_accuracy: 0.6267\n",
      "Epoch 28/58\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 1.8467 - accuracy: 0.5152 - val_loss: 0.9267 - val_accuracy: 0.6000\n",
      "Epoch 29/58\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 1.7266 - accuracy: 0.5118 - val_loss: 1.0408 - val_accuracy: 0.6133\n",
      "Epoch 30/58\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.9331 - accuracy: 0.5354 - val_loss: 0.9179 - val_accuracy: 0.6133\n",
      "Epoch 31/58\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 1.8392 - accuracy: 0.5219 - val_loss: 1.1501 - val_accuracy: 0.6000\n",
      "Epoch 32/58\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 2.0843 - accuracy: 0.5051 - val_loss: 1.3469 - val_accuracy: 0.6000\n",
      "Epoch 33/58\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 2.2135 - accuracy: 0.5017 - val_loss: 1.0825 - val_accuracy: 0.6267\n",
      "Epoch 34/58\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 2.0701 - accuracy: 0.5185 - val_loss: 2.2163 - val_accuracy: 0.5067\n",
      "Epoch 35/58\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.7669 - accuracy: 0.5960 - val_loss: 0.9139 - val_accuracy: 0.6133\n",
      "Epoch 36/58\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 1.7043 - accuracy: 0.5892 - val_loss: 1.4395 - val_accuracy: 0.6133\n",
      "Epoch 37/58\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 1.8653 - accuracy: 0.5455 - val_loss: 1.3578 - val_accuracy: 0.6133\n",
      "Epoch 38/58\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 1.7170 - accuracy: 0.5690 - val_loss: 1.0233 - val_accuracy: 0.6267\n",
      "Epoch 39/58\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 1.9525 - accuracy: 0.5589 - val_loss: 1.0037 - val_accuracy: 0.6533\n",
      "Epoch 40/58\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 1.9562 - accuracy: 0.5690 - val_loss: 0.9309 - val_accuracy: 0.6267\n",
      "Epoch 41/58\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 1.6297 - accuracy: 0.5589 - val_loss: 1.0569 - val_accuracy: 0.6667\n",
      "Epoch 42/58\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 1.7833 - accuracy: 0.5455 - val_loss: 1.3182 - val_accuracy: 0.6133\n",
      "Epoch 43/58\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 1.6940 - accuracy: 0.5926 - val_loss: 1.0801 - val_accuracy: 0.6400\n",
      "Epoch 44/58\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 1.7137 - accuracy: 0.6061 - val_loss: 1.0780 - val_accuracy: 0.6400\n",
      "Epoch 45/58\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 1.5371 - accuracy: 0.6162 - val_loss: 1.3552 - val_accuracy: 0.6000\n",
      "Epoch 46/58\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 1.6191 - accuracy: 0.6094 - val_loss: 1.0694 - val_accuracy: 0.6400\n",
      "Epoch 47/58\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 1.6777 - accuracy: 0.5657 - val_loss: 0.9399 - val_accuracy: 0.6267\n",
      "Epoch 48/58\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 1.5412 - accuracy: 0.6633 - val_loss: 1.0288 - val_accuracy: 0.6267\n",
      "Epoch 49/58\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 1.5325 - accuracy: 0.6229 - val_loss: 1.0997 - val_accuracy: 0.6533\n",
      "Epoch 50/58\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 1.5439 - accuracy: 0.6094 - val_loss: 1.0358 - val_accuracy: 0.6267\n",
      "Epoch 51/58\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 1.5012 - accuracy: 0.6094 - val_loss: 0.9843 - val_accuracy: 0.6400\n",
      "Epoch 52/58\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 1.3934 - accuracy: 0.6431 - val_loss: 1.1238 - val_accuracy: 0.6400\n",
      "Epoch 53/58\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 1.6476 - accuracy: 0.6229 - val_loss: 1.0179 - val_accuracy: 0.6400\n",
      "Epoch 54/58\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 1.6608 - accuracy: 0.5926 - val_loss: 1.1273 - val_accuracy: 0.6533\n",
      "Epoch 55/58\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 1.3870 - accuracy: 0.6532 - val_loss: 1.0802 - val_accuracy: 0.6400\n",
      "Epoch 56/58\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 1.6558 - accuracy: 0.6128 - val_loss: 0.8645 - val_accuracy: 0.6533\n",
      "Epoch 57/58\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 1.4413 - accuracy: 0.6397 - val_loss: 1.2058 - val_accuracy: 0.6267\n",
      "Epoch 58/58\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 1.5283 - accuracy: 0.6364 - val_loss: 1.2911 - val_accuracy: 0.6800\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "| \u001b[95m18       \u001b[0m | \u001b[95m0.7204   \u001b[0m | \u001b[95m1.101    \u001b[0m | \u001b[95m59.9     \u001b[0m | \u001b[95m58.08    \u001b[0m | \u001b[95m0.2457   \u001b[0m | \u001b[95m2.579    \u001b[0m |\n",
      "Epoch 1/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/rmsprop.py:140: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adagrad.py:81: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 3s 42ms/step - loss: 2.4765 - accuracy: 0.3906 - val_loss: 1.4874 - val_accuracy: 0.5867\n",
      "Epoch 2/32\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.6690 - accuracy: 0.3906 - val_loss: 4.0159 - val_accuracy: 0.2400\n",
      "Epoch 3/32\n",
      "8/8 [==============================] - 0s 31ms/step - loss: 2.1319 - accuracy: 0.3838 - val_loss: 1.2512 - val_accuracy: 0.5467\n",
      "Epoch 4/32\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.3576 - accuracy: 0.4276 - val_loss: 1.0111 - val_accuracy: 0.6533\n",
      "Epoch 5/32\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.0403 - accuracy: 0.4949 - val_loss: 0.8993 - val_accuracy: 0.5867\n",
      "Epoch 6/32\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.8838 - accuracy: 0.5960 - val_loss: 1.1279 - val_accuracy: 0.3333\n",
      "Epoch 7/32\n",
      "8/8 [==============================] - 0s 30ms/step - loss: 1.8576 - accuracy: 0.4141 - val_loss: 1.2533 - val_accuracy: 0.5867\n",
      "Epoch 8/32\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 2.2655 - accuracy: 0.4007 - val_loss: 1.6883 - val_accuracy: 0.2667\n",
      "Epoch 9/32\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1.9394 - accuracy: 0.4276 - val_loss: 1.6720 - val_accuracy: 0.5867\n",
      "Epoch 10/32\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.3442 - accuracy: 0.4680 - val_loss: 1.4931 - val_accuracy: 0.2400\n",
      "Epoch 11/32\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.9454 - accuracy: 0.5926 - val_loss: 1.3973 - val_accuracy: 0.5867\n",
      "Epoch 12/32\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.1636 - accuracy: 0.5219 - val_loss: 0.8080 - val_accuracy: 0.6533\n",
      "Epoch 13/32\n",
      "8/8 [==============================] - 0s 31ms/step - loss: 0.6292 - accuracy: 0.7172 - val_loss: 1.1699 - val_accuracy: 0.6667\n",
      "Epoch 14/32\n",
      "8/8 [==============================] - 0s 32ms/step - loss: 0.4667 - accuracy: 0.8215 - val_loss: 0.9121 - val_accuracy: 0.6933\n",
      "Epoch 15/32\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.6860 - accuracy: 0.7205 - val_loss: 0.7429 - val_accuracy: 0.7333\n",
      "Epoch 16/32\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.2664 - accuracy: 0.8855 - val_loss: 0.5058 - val_accuracy: 0.8133\n",
      "Epoch 17/32\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.1141 - accuracy: 0.9764 - val_loss: 0.6175 - val_accuracy: 0.8133\n",
      "Epoch 18/32\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.0706 - accuracy: 0.9933 - val_loss: 0.6628 - val_accuracy: 0.7600\n",
      "Epoch 19/32\n",
      "8/8 [==============================] - 0s 31ms/step - loss: 0.0719 - accuracy: 0.9899 - val_loss: 0.5633 - val_accuracy: 0.8133\n",
      "Epoch 20/32\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 0.0417 - accuracy: 0.9933 - val_loss: 0.6915 - val_accuracy: 0.8133\n",
      "Epoch 21/32\n",
      "8/8 [==============================] - 0s 38ms/step - loss: 0.0472 - accuracy: 0.9899 - val_loss: 0.5659 - val_accuracy: 0.8000\n",
      "Epoch 22/32\n",
      "8/8 [==============================] - 0s 42ms/step - loss: 0.0255 - accuracy: 0.9933 - val_loss: 0.5739 - val_accuracy: 0.8267\n",
      "Epoch 23/32\n",
      "8/8 [==============================] - 0s 31ms/step - loss: 0.0367 - accuracy: 0.9899 - val_loss: 0.5836 - val_accuracy: 0.8267\n",
      "Epoch 24/32\n",
      "8/8 [==============================] - 0s 36ms/step - loss: 0.0407 - accuracy: 0.9966 - val_loss: 0.5837 - val_accuracy: 0.8133\n",
      "Epoch 25/32\n",
      "8/8 [==============================] - 0s 30ms/step - loss: 0.0208 - accuracy: 0.9966 - val_loss: 0.6309 - val_accuracy: 0.8267\n",
      "Epoch 26/32\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.6784 - val_accuracy: 0.8133\n",
      "Epoch 27/32\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.0158 - accuracy: 0.9933 - val_loss: 0.6331 - val_accuracy: 0.8133\n",
      "Epoch 28/32\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.0317 - accuracy: 0.9899 - val_loss: 0.6912 - val_accuracy: 0.7600\n",
      "Epoch 29/32\n",
      "8/8 [==============================] - 0s 39ms/step - loss: 0.3212 - accuracy: 0.8788 - val_loss: 0.6660 - val_accuracy: 0.7867\n",
      "Epoch 30/32\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.0477 - accuracy: 0.9933 - val_loss: 0.8527 - val_accuracy: 0.7867\n",
      "Epoch 31/32\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.0660 - accuracy: 0.9966 - val_loss: 0.6458 - val_accuracy: 0.7733\n",
      "Epoch 32/32\n",
      "8/8 [==============================] - 0s 32ms/step - loss: 0.0597 - accuracy: 0.9899 - val_loss: 0.7688 - val_accuracy: 0.8000\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "| \u001b[95m19       \u001b[0m | \u001b[95m0.7957   \u001b[0m | \u001b[95m1.729    \u001b[0m | \u001b[95m41.53    \u001b[0m | \u001b[95m31.58    \u001b[0m | \u001b[95m0.1809   \u001b[0m | \u001b[95m0.002741 \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/rmsprop.py:140: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adagrad.py:81: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/21\n",
      "3/3 [==============================] - 1s 104ms/step - loss: 21.8026 - accuracy: 0.2121 - val_loss: 43.7641 - val_accuracy: 0.2400\n",
      "Epoch 2/21\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 46.7248 - accuracy: 0.3333 - val_loss: 42.9986 - val_accuracy: 0.2400\n",
      "Epoch 3/21\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 45.5703 - accuracy: 0.3300 - val_loss: 10.2116 - val_accuracy: 0.2400\n",
      "Epoch 4/21\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 28.3934 - accuracy: 0.3805 - val_loss: 27.2180 - val_accuracy: 0.5867\n",
      "Epoch 5/21\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 38.3197 - accuracy: 0.4141 - val_loss: 11.6930 - val_accuracy: 0.1600\n",
      "Epoch 6/21\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 23.2463 - accuracy: 0.3737 - val_loss: 29.0431 - val_accuracy: 0.2400\n",
      "Epoch 7/21\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 28.2239 - accuracy: 0.3737 - val_loss: 32.2414 - val_accuracy: 0.5867\n",
      "Epoch 8/21\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 42.0839 - accuracy: 0.4108 - val_loss: 9.6151 - val_accuracy: 0.2400\n",
      "Epoch 9/21\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 15.3184 - accuracy: 0.4141 - val_loss: 21.6049 - val_accuracy: 0.5867\n",
      "Epoch 10/21\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 29.6487 - accuracy: 0.4007 - val_loss: 12.1005 - val_accuracy: 0.5867\n",
      "Epoch 11/21\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 24.0335 - accuracy: 0.3737 - val_loss: 2.2828 - val_accuracy: 0.5867\n",
      "Epoch 12/21\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 13.1990 - accuracy: 0.3603 - val_loss: 38.3400 - val_accuracy: 0.2400\n",
      "Epoch 13/21\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 27.8554 - accuracy: 0.3603 - val_loss: 33.4135 - val_accuracy: 0.2400\n",
      "Epoch 14/21\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 20.7924 - accuracy: 0.3603 - val_loss: 13.8191 - val_accuracy: 0.5867\n",
      "Epoch 15/21\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 21.7484 - accuracy: 0.4310 - val_loss: 50.9984 - val_accuracy: 0.1600\n",
      "Epoch 16/21\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 42.7427 - accuracy: 0.3367 - val_loss: 30.1577 - val_accuracy: 0.5867\n",
      "Epoch 17/21\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 27.8440 - accuracy: 0.3704 - val_loss: 39.7007 - val_accuracy: 0.2400\n",
      "Epoch 18/21\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 32.4698 - accuracy: 0.3704 - val_loss: 26.0642 - val_accuracy: 0.5867\n",
      "Epoch 19/21\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 39.6113 - accuracy: 0.4209 - val_loss: 10.0724 - val_accuracy: 0.2400\n",
      "Epoch 20/21\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 18.9775 - accuracy: 0.4343 - val_loss: 15.7925 - val_accuracy: 0.2400\n",
      "Epoch 21/21\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 27.7023 - accuracy: 0.3838 - val_loss: 26.8137 - val_accuracy: 0.5867\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "| \u001b[0m20       \u001b[0m | \u001b[0m0.2043   \u001b[0m | \u001b[0m2.463    \u001b[0m | \u001b[0m117.3    \u001b[0m | \u001b[0m21.16    \u001b[0m | \u001b[0m0.3449   \u001b[0m | \u001b[0m0.6785   \u001b[0m |\n",
      "Epoch 1/51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/rmsprop.py:140: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adagrad.py:81: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 89ms/step - loss: 21.6409 - accuracy: 0.2088 - val_loss: 76.9496 - val_accuracy: 0.1600\n",
      "Epoch 2/51\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 127.4009 - accuracy: 0.3569 - val_loss: 95.0955 - val_accuracy: 0.5867\n",
      "Epoch 3/51\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 91.0929 - accuracy: 0.4579 - val_loss: 48.6155 - val_accuracy: 0.2800\n",
      "Epoch 4/51\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 60.6456 - accuracy: 0.3771 - val_loss: 40.1606 - val_accuracy: 0.5867\n",
      "Epoch 5/51\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 53.8395 - accuracy: 0.3098 - val_loss: 57.5164 - val_accuracy: 0.2800\n",
      "Epoch 6/51\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 60.3898 - accuracy: 0.3838 - val_loss: 36.6756 - val_accuracy: 0.5867\n",
      "Epoch 7/51\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 43.9520 - accuracy: 0.3704 - val_loss: 52.7337 - val_accuracy: 0.2400\n",
      "Epoch 8/51\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 48.3853 - accuracy: 0.4781 - val_loss: 40.2667 - val_accuracy: 0.5867\n",
      "Epoch 9/51\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 59.1004 - accuracy: 0.4007 - val_loss: 26.9531 - val_accuracy: 0.3067\n",
      "Epoch 10/51\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 38.0288 - accuracy: 0.4343 - val_loss: 31.1490 - val_accuracy: 0.1733\n",
      "Epoch 11/51\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 48.9625 - accuracy: 0.3939 - val_loss: 25.5454 - val_accuracy: 0.5067\n",
      "Epoch 12/51\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 43.6031 - accuracy: 0.3636 - val_loss: 28.8518 - val_accuracy: 0.2933\n",
      "Epoch 13/51\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 43.0579 - accuracy: 0.3939 - val_loss: 42.0541 - val_accuracy: 0.5867\n",
      "Epoch 14/51\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 45.2308 - accuracy: 0.4512 - val_loss: 10.6998 - val_accuracy: 0.5600\n",
      "Epoch 15/51\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 30.1489 - accuracy: 0.3906 - val_loss: 21.4652 - val_accuracy: 0.6000\n",
      "Epoch 16/51\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 35.6758 - accuracy: 0.3805 - val_loss: 22.0123 - val_accuracy: 0.3733\n",
      "Epoch 17/51\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 29.2211 - accuracy: 0.4074 - val_loss: 20.2169 - val_accuracy: 0.2667\n",
      "Epoch 18/51\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 37.9115 - accuracy: 0.4545 - val_loss: 56.8027 - val_accuracy: 0.5867\n",
      "Epoch 19/51\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 70.5246 - accuracy: 0.3872 - val_loss: 103.9301 - val_accuracy: 0.2400\n",
      "Epoch 20/51\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 69.9051 - accuracy: 0.3973 - val_loss: 41.3922 - val_accuracy: 0.5867\n",
      "Epoch 21/51\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 40.1022 - accuracy: 0.4444 - val_loss: 42.0513 - val_accuracy: 0.3067\n",
      "Epoch 22/51\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 54.5253 - accuracy: 0.3838 - val_loss: 44.2676 - val_accuracy: 0.3067\n",
      "Epoch 23/51\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 57.9366 - accuracy: 0.4242 - val_loss: 33.7962 - val_accuracy: 0.5067\n",
      "Epoch 24/51\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 33.9012 - accuracy: 0.4141 - val_loss: 76.3051 - val_accuracy: 0.5867\n",
      "Epoch 25/51\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 57.1230 - accuracy: 0.4545 - val_loss: 46.6798 - val_accuracy: 0.1867\n",
      "Epoch 26/51\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 53.1599 - accuracy: 0.3805 - val_loss: 26.1812 - val_accuracy: 0.5867\n",
      "Epoch 27/51\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 48.2352 - accuracy: 0.3636 - val_loss: 21.4689 - val_accuracy: 0.5867\n",
      "Epoch 28/51\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 37.0777 - accuracy: 0.3737 - val_loss: 44.4342 - val_accuracy: 0.2400\n",
      "Epoch 29/51\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 49.6845 - accuracy: 0.3502 - val_loss: 27.8228 - val_accuracy: 0.5867\n",
      "Epoch 30/51\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 30.0128 - accuracy: 0.4310 - val_loss: 85.0590 - val_accuracy: 0.1600\n",
      "Epoch 31/51\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 67.0044 - accuracy: 0.2761 - val_loss: 36.3901 - val_accuracy: 0.2400\n",
      "Epoch 32/51\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 60.7647 - accuracy: 0.4108 - val_loss: 49.3765 - val_accuracy: 0.5867\n",
      "Epoch 33/51\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 61.4280 - accuracy: 0.4377 - val_loss: 37.3558 - val_accuracy: 0.3067\n",
      "Epoch 34/51\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 49.3610 - accuracy: 0.4074 - val_loss: 52.5584 - val_accuracy: 0.4000\n",
      "Epoch 35/51\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 51.5710 - accuracy: 0.4209 - val_loss: 43.8276 - val_accuracy: 0.5867\n",
      "Epoch 36/51\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 46.8124 - accuracy: 0.3838 - val_loss: 63.5052 - val_accuracy: 0.2800\n",
      "Epoch 37/51\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 57.8559 - accuracy: 0.3569 - val_loss: 14.2786 - val_accuracy: 0.4267\n",
      "Epoch 38/51\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 34.1007 - accuracy: 0.4209 - val_loss: 33.4726 - val_accuracy: 0.5867\n",
      "Epoch 39/51\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 49.0397 - accuracy: 0.4242 - val_loss: 33.5059 - val_accuracy: 0.2400\n",
      "Epoch 40/51\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 60.9479 - accuracy: 0.3401 - val_loss: 92.0875 - val_accuracy: 0.2400\n",
      "Epoch 41/51\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 111.8626 - accuracy: 0.3939 - val_loss: 85.9604 - val_accuracy: 0.2400\n",
      "Epoch 42/51\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 74.7092 - accuracy: 0.3569 - val_loss: 41.9181 - val_accuracy: 0.5867\n",
      "Epoch 43/51\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 65.8058 - accuracy: 0.4007 - val_loss: 85.9521 - val_accuracy: 0.1600\n",
      "Epoch 44/51\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 67.0376 - accuracy: 0.2963 - val_loss: 105.6947 - val_accuracy: 0.2400\n",
      "Epoch 45/51\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 74.1517 - accuracy: 0.3973 - val_loss: 43.7085 - val_accuracy: 0.5867\n",
      "Epoch 46/51\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 51.1688 - accuracy: 0.4411 - val_loss: 91.7630 - val_accuracy: 0.1600\n",
      "Epoch 47/51\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 68.4060 - accuracy: 0.2727 - val_loss: 133.8184 - val_accuracy: 0.2400\n",
      "Epoch 48/51\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 84.0269 - accuracy: 0.3199 - val_loss: 67.2083 - val_accuracy: 0.5867\n",
      "Epoch 49/51\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 54.0044 - accuracy: 0.4276 - val_loss: 76.1213 - val_accuracy: 0.1600\n",
      "Epoch 50/51\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 82.8278 - accuracy: 0.3199 - val_loss: 62.9959 - val_accuracy: 0.5867\n",
      "Epoch 51/51\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 63.0581 - accuracy: 0.3367 - val_loss: 67.0497 - val_accuracy: 0.1600\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "| \u001b[0m21       \u001b[0m | \u001b[0m0.2043   \u001b[0m | \u001b[0m2.386    \u001b[0m | \u001b[0m142.0    \u001b[0m | \u001b[0m51.39    \u001b[0m | \u001b[0m0.8044   \u001b[0m | \u001b[0m0.6645   \u001b[0m |\n",
      "Epoch 1/22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/rmsprop.py:140: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adagrad.py:81: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 164ms/step - loss: 9.2571 - accuracy: 0.2761 - val_loss: 65.7442 - val_accuracy: 0.1600\n",
      "Epoch 2/22\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 46.4531 - accuracy: 0.3502 - val_loss: 49.0301 - val_accuracy: 0.2400\n",
      "Epoch 3/22\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 41.3655 - accuracy: 0.3401 - val_loss: 25.0673 - val_accuracy: 0.5867\n",
      "Epoch 4/22\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 21.7583 - accuracy: 0.4949 - val_loss: 23.0524 - val_accuracy: 0.1600\n",
      "Epoch 5/22\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 27.2776 - accuracy: 0.2525 - val_loss: 17.8525 - val_accuracy: 0.5867\n",
      "Epoch 6/22\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 21.2857 - accuracy: 0.5118 - val_loss: 12.9720 - val_accuracy: 0.5867\n",
      "Epoch 7/22\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 17.4052 - accuracy: 0.3771 - val_loss: 14.3943 - val_accuracy: 0.1600\n",
      "Epoch 8/22\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 17.0790 - accuracy: 0.3704 - val_loss: 18.5915 - val_accuracy: 0.5867\n",
      "Epoch 9/22\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 16.2816 - accuracy: 0.4714 - val_loss: 16.3485 - val_accuracy: 0.2400\n",
      "Epoch 10/22\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 14.5530 - accuracy: 0.3737 - val_loss: 13.9299 - val_accuracy: 0.5867\n",
      "Epoch 11/22\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 14.1956 - accuracy: 0.4512 - val_loss: 19.1734 - val_accuracy: 0.2400\n",
      "Epoch 12/22\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 14.5561 - accuracy: 0.3636 - val_loss: 12.8488 - val_accuracy: 0.5867\n",
      "Epoch 13/22\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 12.5787 - accuracy: 0.4613 - val_loss: 13.9814 - val_accuracy: 0.2400\n",
      "Epoch 14/22\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 12.6947 - accuracy: 0.3704 - val_loss: 9.0501 - val_accuracy: 0.5867\n",
      "Epoch 15/22\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 8.7660 - accuracy: 0.4141 - val_loss: 5.3750 - val_accuracy: 0.2400\n",
      "Epoch 16/22\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 8.1071 - accuracy: 0.4209 - val_loss: 7.5390 - val_accuracy: 0.1600\n",
      "Epoch 17/22\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 7.8186 - accuracy: 0.3771 - val_loss: 6.5329 - val_accuracy: 0.2400\n",
      "Epoch 18/22\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 8.1442 - accuracy: 0.3098 - val_loss: 5.0519 - val_accuracy: 0.1600\n",
      "Epoch 19/22\n",
      "3/3 [==============================] - 0s 171ms/step - loss: 6.7241 - accuracy: 0.2929 - val_loss: 4.2765 - val_accuracy: 0.2400\n",
      "Epoch 20/22\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 6.1466 - accuracy: 0.4007 - val_loss: 5.0946 - val_accuracy: 0.5867\n",
      "Epoch 21/22\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 6.1861 - accuracy: 0.4141 - val_loss: 5.6560 - val_accuracy: 0.5867\n",
      "Epoch 22/22\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 6.1255 - accuracy: 0.4175 - val_loss: 3.7817 - val_accuracy: 0.5867\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "| \u001b[0m22       \u001b[0m | \u001b[0m0.2043   \u001b[0m | \u001b[0m1.535    \u001b[0m | \u001b[0m130.1    \u001b[0m | \u001b[0m22.25    \u001b[0m | \u001b[0m0.7027   \u001b[0m | \u001b[0m2.238    \u001b[0m |\n",
      "Epoch 1/38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/rmsprop.py:140: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adagrad.py:81: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 100ms/step - loss: 191236.2344 - accuracy: 0.1818 - val_loss: 6236295.5000 - val_accuracy: 0.1600\n",
      "Epoch 2/38\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 2973228.5000 - accuracy: 0.3670 - val_loss: 67458.9297 - val_accuracy: 0.5867\n",
      "Epoch 3/38\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 90796.4141 - accuracy: 0.4983 - val_loss: 115861.8438 - val_accuracy: 0.2400\n",
      "Epoch 4/38\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 96882.4141 - accuracy: 0.3401 - val_loss: 35739.7227 - val_accuracy: 0.4000\n",
      "Epoch 5/38\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 31504.4180 - accuracy: 0.3838 - val_loss: 4147.0640 - val_accuracy: 0.5600\n",
      "Epoch 6/38\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 6855.3823 - accuracy: 0.4714 - val_loss: 1923.3275 - val_accuracy: 0.5333\n",
      "Epoch 7/38\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 5739.5522 - accuracy: 0.3165 - val_loss: 2465.7073 - val_accuracy: 0.1867\n",
      "Epoch 8/38\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 3064.8367 - accuracy: 0.3266 - val_loss: 1420.0961 - val_accuracy: 0.2400\n",
      "Epoch 9/38\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 1866.5284 - accuracy: 0.2020 - val_loss: 863.7371 - val_accuracy: 0.1867\n",
      "Epoch 10/38\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 2408.3633 - accuracy: 0.1818 - val_loss: 780.1167 - val_accuracy: 0.1467\n",
      "Epoch 11/38\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 573.2263 - accuracy: 0.1246 - val_loss: 735.6233 - val_accuracy: 0.0933\n",
      "Epoch 12/38\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 533.5719 - accuracy: 0.1010 - val_loss: 692.7002 - val_accuracy: 0.0667\n",
      "Epoch 13/38\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 558.2908 - accuracy: 0.0909 - val_loss: 651.7558 - val_accuracy: 0.0667\n",
      "Epoch 14/38\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 555.6302 - accuracy: 0.0673 - val_loss: 637.8693 - val_accuracy: 0.0667\n",
      "Epoch 15/38\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 537.1600 - accuracy: 0.0741 - val_loss: 623.2399 - val_accuracy: 0.0533\n",
      "Epoch 16/38\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 534.3979 - accuracy: 0.0572 - val_loss: 611.8139 - val_accuracy: 0.0400\n",
      "Epoch 17/38\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 522.9871 - accuracy: 0.0707 - val_loss: 601.0602 - val_accuracy: 0.0267\n",
      "Epoch 18/38\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 517.2640 - accuracy: 0.0640 - val_loss: 568.2573 - val_accuracy: 0.0400\n",
      "Epoch 19/38\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 511.5398 - accuracy: 0.0741 - val_loss: 546.1483 - val_accuracy: 0.0800\n",
      "Epoch 20/38\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 532.0794 - accuracy: 0.0741 - val_loss: 577.8056 - val_accuracy: 0.0267\n",
      "Epoch 21/38\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 501.3488 - accuracy: 0.0640 - val_loss: 574.1298 - val_accuracy: 0.0267\n",
      "Epoch 22/38\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 517.9171 - accuracy: 0.0438 - val_loss: 566.3709 - val_accuracy: 0.0267\n",
      "Epoch 23/38\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 512.1164 - accuracy: 0.0471 - val_loss: 558.0123 - val_accuracy: 0.0267\n",
      "Epoch 24/38\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 506.3987 - accuracy: 0.0505 - val_loss: 551.0729 - val_accuracy: 0.0267\n",
      "Epoch 25/38\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 505.0245 - accuracy: 0.0438 - val_loss: 542.7168 - val_accuracy: 0.0267\n",
      "Epoch 26/38\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 494.1342 - accuracy: 0.0404 - val_loss: 537.7437 - val_accuracy: 0.0267\n",
      "Epoch 27/38\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 487.8351 - accuracy: 0.0505 - val_loss: 533.6707 - val_accuracy: 0.0267\n",
      "Epoch 28/38\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 486.1051 - accuracy: 0.0606 - val_loss: 528.9998 - val_accuracy: 0.0267\n",
      "Epoch 29/38\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 477.8302 - accuracy: 0.0471 - val_loss: 523.7932 - val_accuracy: 0.0267\n",
      "Epoch 30/38\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 473.3393 - accuracy: 0.0572 - val_loss: 518.1320 - val_accuracy: 0.0267\n",
      "Epoch 31/38\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 461.3600 - accuracy: 0.0404 - val_loss: 513.8719 - val_accuracy: 0.0267\n",
      "Epoch 32/38\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 457.6878 - accuracy: 0.0471 - val_loss: 509.6416 - val_accuracy: 0.0267\n",
      "Epoch 33/38\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 452.9453 - accuracy: 0.0505 - val_loss: 500.4650 - val_accuracy: 0.0267\n",
      "Epoch 34/38\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 424.4995 - accuracy: 0.0808 - val_loss: 473.9527 - val_accuracy: 0.0533\n",
      "Epoch 35/38\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 419.1353 - accuracy: 0.0774 - val_loss: 455.3951 - val_accuracy: 0.0933\n",
      "Epoch 36/38\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 428.8622 - accuracy: 0.0875 - val_loss: 469.9050 - val_accuracy: 0.0533\n",
      "Epoch 37/38\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 413.4095 - accuracy: 0.0808 - val_loss: 473.1175 - val_accuracy: 0.0667\n",
      "Epoch 38/38\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 424.4261 - accuracy: 0.0269 - val_loss: 470.6712 - val_accuracy: 0.0667\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "| \u001b[0m23       \u001b[0m | \u001b[0m0.1613   \u001b[0m | \u001b[0m1.385    \u001b[0m | \u001b[0m113.7    \u001b[0m | \u001b[0m38.03    \u001b[0m | \u001b[0m0.6761   \u001b[0m | \u001b[0m2.052    \u001b[0m |\n",
      "Epoch 1/75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/rmsprop.py:140: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adagrad.py:81: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 99ms/step - loss: 3.0974 - accuracy: 0.2391 - val_loss: 5.1398 - val_accuracy: 0.1733\n",
      "Epoch 2/75\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 5.3509 - accuracy: 0.4209 - val_loss: 3.1112 - val_accuracy: 0.5867\n",
      "Epoch 3/75\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 4.0196 - accuracy: 0.3939 - val_loss: 1.3906 - val_accuracy: 0.2400\n",
      "Epoch 4/75\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 3.1073 - accuracy: 0.4074 - val_loss: 2.8090 - val_accuracy: 0.5867\n",
      "Epoch 5/75\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 3.2701 - accuracy: 0.4646 - val_loss: 1.6413 - val_accuracy: 0.3867\n",
      "Epoch 6/75\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 2.3265 - accuracy: 0.3771 - val_loss: 1.3596 - val_accuracy: 0.6000\n",
      "Epoch 7/75\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 2.2941 - accuracy: 0.4478 - val_loss: 1.6417 - val_accuracy: 0.4267\n",
      "Epoch 8/75\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 2.3567 - accuracy: 0.4074 - val_loss: 1.4544 - val_accuracy: 0.4000\n",
      "Epoch 9/75\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 1.8766 - accuracy: 0.4040 - val_loss: 1.5048 - val_accuracy: 0.5867\n",
      "Epoch 10/75\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 2.0124 - accuracy: 0.4444 - val_loss: 1.1535 - val_accuracy: 0.5600\n",
      "Epoch 11/75\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 2.0080 - accuracy: 0.3872 - val_loss: 1.3693 - val_accuracy: 0.5600\n",
      "Epoch 12/75\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 1.9123 - accuracy: 0.3502 - val_loss: 1.2132 - val_accuracy: 0.4267\n",
      "Epoch 13/75\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 1.5688 - accuracy: 0.4613 - val_loss: 1.8487 - val_accuracy: 0.2533\n",
      "Epoch 14/75\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 1.7443 - accuracy: 0.3872 - val_loss: 1.6086 - val_accuracy: 0.4933\n",
      "Epoch 15/75\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 1.7949 - accuracy: 0.4613 - val_loss: 1.5267 - val_accuracy: 0.2533\n",
      "Epoch 16/75\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 1.5280 - accuracy: 0.3333 - val_loss: 1.3055 - val_accuracy: 0.5867\n",
      "Epoch 17/75\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 1.5813 - accuracy: 0.4209 - val_loss: 1.3433 - val_accuracy: 0.2800\n",
      "Epoch 18/75\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 1.5322 - accuracy: 0.4377 - val_loss: 1.1004 - val_accuracy: 0.5867\n",
      "Epoch 19/75\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 1.3480 - accuracy: 0.4108 - val_loss: 1.0772 - val_accuracy: 0.5867\n",
      "Epoch 20/75\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 1.3056 - accuracy: 0.4478 - val_loss: 1.0586 - val_accuracy: 0.5867\n",
      "Epoch 21/75\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 1.2876 - accuracy: 0.4377 - val_loss: 1.0376 - val_accuracy: 0.5867\n",
      "Epoch 22/75\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 1.3350 - accuracy: 0.4613 - val_loss: 1.2521 - val_accuracy: 0.2400\n",
      "Epoch 23/75\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 1.2998 - accuracy: 0.4377 - val_loss: 1.0879 - val_accuracy: 0.5867\n",
      "Epoch 24/75\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 1.3305 - accuracy: 0.3636 - val_loss: 1.0823 - val_accuracy: 0.5867\n",
      "Epoch 25/75\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 1.1907 - accuracy: 0.4714 - val_loss: 1.1192 - val_accuracy: 0.3867\n",
      "Epoch 26/75\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 1.1903 - accuracy: 0.4680 - val_loss: 1.0795 - val_accuracy: 0.5867\n",
      "Epoch 27/75\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 1.2161 - accuracy: 0.4478 - val_loss: 1.0902 - val_accuracy: 0.5600\n",
      "Epoch 28/75\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 1.2866 - accuracy: 0.4175 - val_loss: 1.0410 - val_accuracy: 0.4933\n",
      "Epoch 29/75\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 1.3055 - accuracy: 0.4108 - val_loss: 1.1029 - val_accuracy: 0.5867\n",
      "Epoch 30/75\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 1.2493 - accuracy: 0.4444 - val_loss: 1.0168 - val_accuracy: 0.5867\n",
      "Epoch 31/75\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 1.3105 - accuracy: 0.4512 - val_loss: 1.0465 - val_accuracy: 0.5867\n",
      "Epoch 32/75\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 1.3113 - accuracy: 0.4175 - val_loss: 1.0469 - val_accuracy: 0.5867\n",
      "Epoch 33/75\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 1.1773 - accuracy: 0.4747 - val_loss: 0.9766 - val_accuracy: 0.5867\n",
      "Epoch 34/75\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 1.2531 - accuracy: 0.4209 - val_loss: 1.0677 - val_accuracy: 0.4933\n",
      "Epoch 35/75\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 1.2481 - accuracy: 0.4377 - val_loss: 1.3330 - val_accuracy: 0.5867\n",
      "Epoch 36/75\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 1.3860 - accuracy: 0.4444 - val_loss: 1.3721 - val_accuracy: 0.2933\n",
      "Epoch 37/75\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 1.5033 - accuracy: 0.4478 - val_loss: 1.3258 - val_accuracy: 0.2400\n",
      "Epoch 38/75\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 1.4130 - accuracy: 0.3636 - val_loss: 1.3514 - val_accuracy: 0.4267\n",
      "Epoch 39/75\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 1.4791 - accuracy: 0.3468 - val_loss: 1.4586 - val_accuracy: 0.5867\n",
      "Epoch 40/75\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 1.5106 - accuracy: 0.4882 - val_loss: 1.6353 - val_accuracy: 0.3733\n",
      "Epoch 41/75\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 1.6551 - accuracy: 0.3603 - val_loss: 1.2380 - val_accuracy: 0.5867\n",
      "Epoch 42/75\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 1.3888 - accuracy: 0.4242 - val_loss: 1.2176 - val_accuracy: 0.3733\n",
      "Epoch 43/75\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 1.2969 - accuracy: 0.4512 - val_loss: 1.2616 - val_accuracy: 0.5867\n",
      "Epoch 44/75\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 1.3715 - accuracy: 0.4310 - val_loss: 1.0820 - val_accuracy: 0.5200\n",
      "Epoch 45/75\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 1.3891 - accuracy: 0.4310 - val_loss: 1.1550 - val_accuracy: 0.5867\n",
      "Epoch 46/75\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 1.3147 - accuracy: 0.4310 - val_loss: 1.1490 - val_accuracy: 0.5867\n",
      "Epoch 47/75\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 1.3882 - accuracy: 0.4209 - val_loss: 1.2005 - val_accuracy: 0.3733\n",
      "Epoch 48/75\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 1.4248 - accuracy: 0.3401 - val_loss: 1.0272 - val_accuracy: 0.5867\n",
      "Epoch 49/75\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 1.3616 - accuracy: 0.4209 - val_loss: 1.0289 - val_accuracy: 0.5867\n",
      "Epoch 50/75\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 1.3570 - accuracy: 0.4848 - val_loss: 1.0349 - val_accuracy: 0.5600\n",
      "Epoch 51/75\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 1.4237 - accuracy: 0.4411 - val_loss: 1.1368 - val_accuracy: 0.3867\n",
      "Epoch 52/75\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 1.3584 - accuracy: 0.4074 - val_loss: 0.9668 - val_accuracy: 0.5867\n",
      "Epoch 53/75\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 1.3151 - accuracy: 0.4175 - val_loss: 1.3392 - val_accuracy: 0.4133\n",
      "Epoch 54/75\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 1.3777 - accuracy: 0.4680 - val_loss: 1.3479 - val_accuracy: 0.2933\n",
      "Epoch 55/75\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 1.4910 - accuracy: 0.3502 - val_loss: 1.2066 - val_accuracy: 0.5867\n",
      "Epoch 56/75\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 1.3200 - accuracy: 0.4377 - val_loss: 1.0298 - val_accuracy: 0.5867\n",
      "Epoch 57/75\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 1.3890 - accuracy: 0.4680 - val_loss: 1.4580 - val_accuracy: 0.2400\n",
      "Epoch 58/75\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 1.5459 - accuracy: 0.3670 - val_loss: 1.6639 - val_accuracy: 0.5867\n",
      "Epoch 59/75\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 1.5842 - accuracy: 0.4680 - val_loss: 1.0946 - val_accuracy: 0.5733\n",
      "Epoch 60/75\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 1.3508 - accuracy: 0.4680 - val_loss: 1.1647 - val_accuracy: 0.3600\n",
      "Epoch 61/75\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 1.3112 - accuracy: 0.4444 - val_loss: 1.0509 - val_accuracy: 0.5867\n",
      "Epoch 62/75\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 1.3480 - accuracy: 0.4377 - val_loss: 1.0397 - val_accuracy: 0.5867\n",
      "Epoch 63/75\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 1.2620 - accuracy: 0.4141 - val_loss: 1.0148 - val_accuracy: 0.5867\n",
      "Epoch 64/75\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 1.1958 - accuracy: 0.4512 - val_loss: 1.0259 - val_accuracy: 0.5867\n",
      "Epoch 65/75\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 1.2058 - accuracy: 0.4680 - val_loss: 1.1387 - val_accuracy: 0.2400\n",
      "Epoch 66/75\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 1.4532 - accuracy: 0.3872 - val_loss: 1.1218 - val_accuracy: 0.3867\n",
      "Epoch 67/75\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 1.3626 - accuracy: 0.3805 - val_loss: 1.0923 - val_accuracy: 0.5867\n",
      "Epoch 68/75\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 1.3019 - accuracy: 0.4478 - val_loss: 1.0136 - val_accuracy: 0.5200\n",
      "Epoch 69/75\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 1.2142 - accuracy: 0.4747 - val_loss: 1.2424 - val_accuracy: 0.2400\n",
      "Epoch 70/75\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 1.2221 - accuracy: 0.4108 - val_loss: 1.0889 - val_accuracy: 0.5867\n",
      "Epoch 71/75\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 1.2155 - accuracy: 0.4040 - val_loss: 1.0961 - val_accuracy: 0.5867\n",
      "Epoch 72/75\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 1.3274 - accuracy: 0.4545 - val_loss: 1.2028 - val_accuracy: 0.3200\n",
      "Epoch 73/75\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 1.3863 - accuracy: 0.4209 - val_loss: 1.0852 - val_accuracy: 0.6133\n",
      "Epoch 74/75\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 1.2672 - accuracy: 0.3973 - val_loss: 1.0349 - val_accuracy: 0.5867\n",
      "Epoch 75/75\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 1.3096 - accuracy: 0.4377 - val_loss: 1.2149 - val_accuracy: 0.5867\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "| \u001b[0m24       \u001b[0m | \u001b[0m0.5376   \u001b[0m | \u001b[0m1.98     \u001b[0m | \u001b[0m108.4    \u001b[0m | \u001b[0m74.66    \u001b[0m | \u001b[0m0.09537  \u001b[0m | \u001b[0m2.132    \u001b[0m |\n",
      "Epoch 1/70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/rmsprop.py:140: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adagrad.py:81: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 1s 52ms/step - loss: 541685363568981961189356591537717248.0000 - accuracy: 0.3468 - val_loss: nan - val_accuracy: 0.5867\n",
      "Epoch 2/70\n",
      "7/7 [==============================] - 0s 49ms/step - loss: nan - accuracy: 0.2054 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 3/70\n",
      "7/7 [==============================] - 0s 30ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 4/70\n",
      "7/7 [==============================] - 0s 22ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 5/70\n",
      "7/7 [==============================] - 0s 22ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 6/70\n",
      "7/7 [==============================] - 0s 20ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 7/70\n",
      "7/7 [==============================] - 0s 19ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 8/70\n",
      "7/7 [==============================] - 0s 22ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 9/70\n",
      "7/7 [==============================] - 0s 30ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 10/70\n",
      "7/7 [==============================] - 0s 32ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 11/70\n",
      "7/7 [==============================] - 0s 31ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 12/70\n",
      "7/7 [==============================] - 0s 24ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 13/70\n",
      "7/7 [==============================] - 0s 25ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 14/70\n",
      "7/7 [==============================] - 0s 21ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 15/70\n",
      "7/7 [==============================] - 0s 26ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 16/70\n",
      "7/7 [==============================] - 0s 22ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 17/70\n",
      "7/7 [==============================] - 0s 24ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 18/70\n",
      "7/7 [==============================] - 0s 36ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 19/70\n",
      "7/7 [==============================] - 0s 23ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 20/70\n",
      "7/7 [==============================] - 0s 18ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 21/70\n",
      "7/7 [==============================] - 0s 20ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 22/70\n",
      "7/7 [==============================] - 0s 25ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 23/70\n",
      "7/7 [==============================] - 0s 35ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 24/70\n",
      "7/7 [==============================] - 0s 27ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 25/70\n",
      "7/7 [==============================] - 0s 23ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 26/70\n",
      "7/7 [==============================] - 0s 22ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 27/70\n",
      "7/7 [==============================] - 0s 17ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 28/70\n",
      "7/7 [==============================] - 0s 19ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 29/70\n",
      "7/7 [==============================] - 0s 26ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 30/70\n",
      "7/7 [==============================] - 0s 24ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 31/70\n",
      "7/7 [==============================] - 0s 22ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 32/70\n",
      "7/7 [==============================] - 0s 20ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 33/70\n",
      "7/7 [==============================] - 0s 18ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 34/70\n",
      "7/7 [==============================] - 0s 37ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 35/70\n",
      "7/7 [==============================] - 0s 36ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 36/70\n",
      "7/7 [==============================] - 0s 24ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 37/70\n",
      "7/7 [==============================] - 0s 18ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 38/70\n",
      "7/7 [==============================] - 0s 19ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 39/70\n",
      "7/7 [==============================] - 0s 30ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 40/70\n",
      "7/7 [==============================] - 0s 27ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 41/70\n",
      "7/7 [==============================] - 0s 19ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 42/70\n",
      "7/7 [==============================] - 0s 19ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 43/70\n",
      "7/7 [==============================] - 0s 28ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 44/70\n",
      "7/7 [==============================] - 0s 24ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 45/70\n",
      "7/7 [==============================] - 0s 21ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 46/70\n",
      "7/7 [==============================] - 0s 24ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 47/70\n",
      "7/7 [==============================] - 0s 23ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 48/70\n",
      "7/7 [==============================] - 0s 22ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 49/70\n",
      "7/7 [==============================] - 0s 25ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 50/70\n",
      "7/7 [==============================] - 0s 45ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 51/70\n",
      "7/7 [==============================] - 0s 20ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 52/70\n",
      "7/7 [==============================] - 0s 23ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 53/70\n",
      "7/7 [==============================] - 0s 27ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 54/70\n",
      "7/7 [==============================] - 0s 21ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 55/70\n",
      "7/7 [==============================] - 0s 23ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 56/70\n",
      "7/7 [==============================] - 0s 20ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 57/70\n",
      "7/7 [==============================] - 0s 25ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 58/70\n",
      "7/7 [==============================] - 0s 20ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 59/70\n",
      "7/7 [==============================] - 0s 23ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 60/70\n",
      "7/7 [==============================] - 0s 22ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 61/70\n",
      "7/7 [==============================] - 0s 23ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 62/70\n",
      "7/7 [==============================] - 0s 22ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 63/70\n",
      "7/7 [==============================] - 0s 17ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 64/70\n",
      "7/7 [==============================] - 0s 18ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 65/70\n",
      "7/7 [==============================] - 0s 42ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 66/70\n",
      "7/7 [==============================] - 0s 22ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 67/70\n",
      "7/7 [==============================] - 0s 17ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 68/70\n",
      "7/7 [==============================] - 0s 16ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 69/70\n",
      "7/7 [==============================] - 0s 23ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "Epoch 70/70\n",
      "7/7 [==============================] - 0s 27ms/step - loss: nan - accuracy: 0.1785 - val_loss: nan - val_accuracy: 0.1600\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "| \u001b[0m25       \u001b[0m | \u001b[0m0.2043   \u001b[0m | \u001b[0m1.499    \u001b[0m | \u001b[0m46.86    \u001b[0m | \u001b[0m69.64    \u001b[0m | \u001b[0m0.4334   \u001b[0m | \u001b[0m0.2741   \u001b[0m |\n",
      "Epoch 1/79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/rmsprop.py:140: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adagrad.py:81: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 66ms/step - loss: 49496.8164 - accuracy: 0.3300 - val_loss: 62.1040 - val_accuracy: 0.5467\n",
      "Epoch 2/79\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 45.1103 - accuracy: 0.3603 - val_loss: 8.4351 - val_accuracy: 0.5733\n",
      "Epoch 3/79\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 17.2561 - accuracy: 0.3704 - val_loss: 3.5352 - val_accuracy: 0.5733\n",
      "Epoch 4/79\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 5.5494 - accuracy: 0.4444 - val_loss: 7.8833 - val_accuracy: 0.5867\n",
      "Epoch 5/79\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 8.4505 - accuracy: 0.5051 - val_loss: 17.0673 - val_accuracy: 0.5867\n",
      "Epoch 6/79\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 15.4457 - accuracy: 0.5185 - val_loss: 121.5689 - val_accuracy: 0.5733\n",
      "Epoch 7/79\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 2.1113 - accuracy: 0.4276 - val_loss: 172.6885 - val_accuracy: 0.5733\n",
      "Epoch 8/79\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 86.5863 - accuracy: 0.5219 - val_loss: 19.8740 - val_accuracy: 0.5867\n",
      "Epoch 9/79\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 43.3167 - accuracy: 0.5219 - val_loss: 2.8122 - val_accuracy: 0.6000\n",
      "Epoch 10/79\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 148.4172 - accuracy: 0.5152 - val_loss: 300.2761 - val_accuracy: 0.6133\n",
      "Epoch 11/79\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 145.6821 - accuracy: 0.5185 - val_loss: 708.7256 - val_accuracy: 0.6133\n",
      "Epoch 12/79\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 88.8715 - accuracy: 0.5185 - val_loss: 359.0773 - val_accuracy: 0.6133\n",
      "Epoch 13/79\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 53.6699 - accuracy: 0.5185 - val_loss: 135.4693 - val_accuracy: 0.6133\n",
      "Epoch 14/79\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 187.7577 - accuracy: 0.5152 - val_loss: 181.4977 - val_accuracy: 0.6133\n",
      "Epoch 15/79\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 259.0842 - accuracy: 0.5051 - val_loss: 114.0496 - val_accuracy: 0.6000\n",
      "Epoch 16/79\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 3.8940 - accuracy: 0.5354 - val_loss: 129.4749 - val_accuracy: 0.6000\n",
      "Epoch 17/79\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 12.1187 - accuracy: 0.5387 - val_loss: 129.0486 - val_accuracy: 0.6000\n",
      "Epoch 18/79\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 5.6565 - accuracy: 0.5253 - val_loss: 123.9717 - val_accuracy: 0.6000\n",
      "Epoch 19/79\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 104.5956 - accuracy: 0.5219 - val_loss: 119.8414 - val_accuracy: 0.5867\n",
      "Epoch 20/79\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 56.6325 - accuracy: 0.5152 - val_loss: 706.7645 - val_accuracy: 0.2800\n",
      "Epoch 21/79\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 82.7971 - accuracy: 0.4646 - val_loss: 105.0327 - val_accuracy: 0.6000\n",
      "Epoch 22/79\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 30.9692 - accuracy: 0.5152 - val_loss: 96.5843 - val_accuracy: 0.6000\n",
      "Epoch 23/79\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 1.0194 - accuracy: 0.5219 - val_loss: 133.0034 - val_accuracy: 0.5867\n",
      "Epoch 24/79\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 11.3688 - accuracy: 0.5185 - val_loss: 85.5864 - val_accuracy: 0.6000\n",
      "Epoch 25/79\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 2.1729 - accuracy: 0.5219 - val_loss: 83.3678 - val_accuracy: 0.6000\n",
      "Epoch 26/79\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 40.2556 - accuracy: 0.5185 - val_loss: 83.0873 - val_accuracy: 0.6000\n",
      "Epoch 27/79\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 5.1840 - accuracy: 0.5219 - val_loss: 82.7192 - val_accuracy: 0.6000\n",
      "Epoch 28/79\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 1.0162 - accuracy: 0.5253 - val_loss: 82.4470 - val_accuracy: 0.6000\n",
      "Epoch 29/79\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 10.6366 - accuracy: 0.5219 - val_loss: 82.2590 - val_accuracy: 0.6000\n",
      "Epoch 30/79\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1.0215 - accuracy: 0.5253 - val_loss: 82.1292 - val_accuracy: 0.6000\n",
      "Epoch 31/79\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 1.0225 - accuracy: 0.5253 - val_loss: 82.0686 - val_accuracy: 0.6000\n",
      "Epoch 32/79\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 1.0218 - accuracy: 0.5253 - val_loss: 81.9780 - val_accuracy: 0.6000\n",
      "Epoch 33/79\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 1.2268 - accuracy: 0.5219 - val_loss: 82.0283 - val_accuracy: 0.6000\n",
      "Epoch 34/79\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 1.0248 - accuracy: 0.5253 - val_loss: 82.1005 - val_accuracy: 0.6000\n",
      "Epoch 35/79\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 1.0410 - accuracy: 0.5253 - val_loss: 82.0945 - val_accuracy: 0.6000\n",
      "Epoch 36/79\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 1.0280 - accuracy: 0.5253 - val_loss: 82.0934 - val_accuracy: 0.6000\n",
      "Epoch 37/79\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 1.0393 - accuracy: 0.5253 - val_loss: 82.1130 - val_accuracy: 0.6000\n",
      "Epoch 38/79\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 1.0339 - accuracy: 0.5253 - val_loss: 82.1167 - val_accuracy: 0.6000\n",
      "Epoch 39/79\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 10.1280 - accuracy: 0.5219 - val_loss: 91.2980 - val_accuracy: 0.6000\n",
      "Epoch 40/79\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 17.9163 - accuracy: 0.5185 - val_loss: 97.3898 - val_accuracy: 0.6000\n",
      "Epoch 41/79\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 2.1695 - accuracy: 0.5185 - val_loss: 101.4514 - val_accuracy: 0.6000\n",
      "Epoch 42/79\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 1.0331 - accuracy: 0.5219 - val_loss: 104.1484 - val_accuracy: 0.5867\n",
      "Epoch 43/79\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 23.5893 - accuracy: 0.5152 - val_loss: 105.9613 - val_accuracy: 0.5867\n",
      "Epoch 44/79\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 2.2488 - accuracy: 0.5152 - val_loss: 107.3267 - val_accuracy: 0.2400\n",
      "Epoch 45/79\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 1.1269 - accuracy: 0.4478 - val_loss: 107.8846 - val_accuracy: 0.5867\n",
      "Epoch 46/79\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1.0383 - accuracy: 0.5152 - val_loss: 108.3984 - val_accuracy: 0.5867\n",
      "Epoch 47/79\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1.0424 - accuracy: 0.5152 - val_loss: 108.7472 - val_accuracy: 0.5867\n",
      "Epoch 48/79\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1.0550 - accuracy: 0.5118 - val_loss: 108.9666 - val_accuracy: 0.5867\n",
      "Epoch 49/79\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 1.0414 - accuracy: 0.5152 - val_loss: 109.3653 - val_accuracy: 0.2400\n",
      "Epoch 50/79\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 1.1600 - accuracy: 0.4512 - val_loss: 109.2212 - val_accuracy: 0.5867\n",
      "Epoch 51/79\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 1.0468 - accuracy: 0.5152 - val_loss: 109.2965 - val_accuracy: 0.5867\n",
      "Epoch 52/79\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 1.0413 - accuracy: 0.5152 - val_loss: 109.3529 - val_accuracy: 0.5867\n",
      "Epoch 53/79\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1.0439 - accuracy: 0.5152 - val_loss: 109.3635 - val_accuracy: 0.5867\n",
      "Epoch 54/79\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 1.0473 - accuracy: 0.5152 - val_loss: 109.3852 - val_accuracy: 0.5867\n",
      "Epoch 55/79\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 1.0447 - accuracy: 0.5152 - val_loss: 109.4008 - val_accuracy: 0.5867\n",
      "Epoch 56/79\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 27.0392 - accuracy: 0.5118 - val_loss: 109.4421 - val_accuracy: 0.5867\n",
      "Epoch 57/79\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 1.0433 - accuracy: 0.5152 - val_loss: 109.4256 - val_accuracy: 0.5867\n",
      "Epoch 58/79\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 1.0423 - accuracy: 0.5152 - val_loss: 109.4355 - val_accuracy: 0.5867\n",
      "Epoch 59/79\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 1.0405 - accuracy: 0.5152 - val_loss: 109.4677 - val_accuracy: 0.5867\n",
      "Epoch 60/79\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 1.0441 - accuracy: 0.5152 - val_loss: 109.4594 - val_accuracy: 0.5867\n",
      "Epoch 61/79\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 1.0350 - accuracy: 0.5152 - val_loss: 109.4505 - val_accuracy: 0.5867\n",
      "Epoch 62/79\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 1.0410 - accuracy: 0.5152 - val_loss: 109.4542 - val_accuracy: 0.5867\n",
      "Epoch 63/79\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1.0405 - accuracy: 0.5152 - val_loss: 109.4599 - val_accuracy: 0.5867\n",
      "Epoch 64/79\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 1.0374 - accuracy: 0.5152 - val_loss: 109.4714 - val_accuracy: 0.5867\n",
      "Epoch 65/79\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 1.0382 - accuracy: 0.5152 - val_loss: 109.4625 - val_accuracy: 0.5867\n",
      "Epoch 66/79\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1.0384 - accuracy: 0.5152 - val_loss: 109.4552 - val_accuracy: 0.5867\n",
      "Epoch 67/79\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 1.0381 - accuracy: 0.5152 - val_loss: 109.4872 - val_accuracy: 0.5867\n",
      "Epoch 68/79\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 1.0544 - accuracy: 0.5152 - val_loss: 109.4811 - val_accuracy: 0.5867\n",
      "Epoch 69/79\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 1.0484 - accuracy: 0.5152 - val_loss: 109.4601 - val_accuracy: 0.5867\n",
      "Epoch 70/79\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 1.0466 - accuracy: 0.5152 - val_loss: 109.4599 - val_accuracy: 0.5867\n",
      "Epoch 71/79\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 1.0456 - accuracy: 0.5152 - val_loss: 109.4854 - val_accuracy: 0.5867\n",
      "Epoch 72/79\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 1.0523 - accuracy: 0.5152 - val_loss: 109.4642 - val_accuracy: 0.5867\n",
      "Epoch 73/79\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 1.0384 - accuracy: 0.5152 - val_loss: 109.4683 - val_accuracy: 0.5867\n",
      "Epoch 74/79\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 1.0484 - accuracy: 0.5152 - val_loss: 109.4568 - val_accuracy: 0.5867\n",
      "Epoch 75/79\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.0370 - accuracy: 0.5152 - val_loss: 109.4853 - val_accuracy: 0.5867\n",
      "Epoch 76/79\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 1.0472 - accuracy: 0.5152 - val_loss: 109.4738 - val_accuracy: 0.5867\n",
      "Epoch 77/79\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 1.0422 - accuracy: 0.5152 - val_loss: 109.4610 - val_accuracy: 0.5867\n",
      "Epoch 78/79\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 1.0405 - accuracy: 0.5152 - val_loss: 109.4728 - val_accuracy: 0.5867\n",
      "Epoch 79/79\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 1.0371 - accuracy: 0.5152 - val_loss: 109.4781 - val_accuracy: 0.5867\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "| \u001b[0m26       \u001b[0m | \u001b[0m0.5376   \u001b[0m | \u001b[0m0.03732  \u001b[0m | \u001b[0m91.36    \u001b[0m | \u001b[0m78.69    \u001b[0m | \u001b[0m0.4661   \u001b[0m | \u001b[0m1.906    \u001b[0m |\n",
      "Epoch 1/59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/rmsprop.py:140: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adagrad.py:81: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 69ms/step - loss: 8.5058 - accuracy: 0.4343 - val_loss: 1.2427 - val_accuracy: 0.5867\n",
      "Epoch 2/59\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1.3480 - accuracy: 0.4512 - val_loss: 1.1734 - val_accuracy: 0.2533\n",
      "Epoch 3/59\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.1691 - accuracy: 0.4242 - val_loss: 1.0602 - val_accuracy: 0.5867\n",
      "Epoch 4/59\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1.1956 - accuracy: 0.5185 - val_loss: 1.0511 - val_accuracy: 0.5867\n",
      "Epoch 5/59\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 1.1782 - accuracy: 0.4310 - val_loss: 1.0738 - val_accuracy: 0.4667\n",
      "Epoch 6/59\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 1.0083 - accuracy: 0.4714 - val_loss: 0.9364 - val_accuracy: 0.5867\n",
      "Epoch 7/59\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 1.0150 - accuracy: 0.5825 - val_loss: 0.8683 - val_accuracy: 0.6667\n",
      "Epoch 8/59\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.9416 - accuracy: 0.5253 - val_loss: 0.9051 - val_accuracy: 0.6267\n",
      "Epoch 9/59\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.9213 - accuracy: 0.4680 - val_loss: 0.9231 - val_accuracy: 0.6667\n",
      "Epoch 10/59\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.8428 - accuracy: 0.5993 - val_loss: 0.8200 - val_accuracy: 0.6667\n",
      "Epoch 11/59\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.8564 - accuracy: 0.6431 - val_loss: 0.8165 - val_accuracy: 0.6533\n",
      "Epoch 12/59\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.7764 - accuracy: 0.6296 - val_loss: 0.8900 - val_accuracy: 0.6667\n",
      "Epoch 13/59\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7284 - accuracy: 0.6330 - val_loss: 0.8477 - val_accuracy: 0.6533\n",
      "Epoch 14/59\n",
      "4/4 [==============================] - 0s 89ms/step - loss: 0.6737 - accuracy: 0.6633 - val_loss: 0.8411 - val_accuracy: 0.6400\n",
      "Epoch 15/59\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 0.6294 - accuracy: 0.7172 - val_loss: 0.9160 - val_accuracy: 0.6933\n",
      "Epoch 16/59\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.5664 - accuracy: 0.7542 - val_loss: 0.8451 - val_accuracy: 0.6400\n",
      "Epoch 17/59\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 0.5521 - accuracy: 0.7542 - val_loss: 0.8513 - val_accuracy: 0.7333\n",
      "Epoch 18/59\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.4766 - accuracy: 0.8081 - val_loss: 0.8736 - val_accuracy: 0.7467\n",
      "Epoch 19/59\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.4816 - accuracy: 0.7946 - val_loss: 0.8136 - val_accuracy: 0.6800\n",
      "Epoch 20/59\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.4193 - accuracy: 0.8418 - val_loss: 1.0760 - val_accuracy: 0.7467\n",
      "Epoch 21/59\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.4252 - accuracy: 0.8384 - val_loss: 0.8303 - val_accuracy: 0.7333\n",
      "Epoch 22/59\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.3888 - accuracy: 0.8485 - val_loss: 0.8593 - val_accuracy: 0.7867\n",
      "Epoch 23/59\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.3190 - accuracy: 0.8990 - val_loss: 0.7983 - val_accuracy: 0.7867\n",
      "Epoch 24/59\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.2780 - accuracy: 0.9125 - val_loss: 0.7455 - val_accuracy: 0.7600\n",
      "Epoch 25/59\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.3025 - accuracy: 0.8889 - val_loss: 0.7813 - val_accuracy: 0.8400\n",
      "Epoch 26/59\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.2449 - accuracy: 0.9360 - val_loss: 0.7539 - val_accuracy: 0.8267\n",
      "Epoch 27/59\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.2053 - accuracy: 0.9360 - val_loss: 0.8122 - val_accuracy: 0.8533\n",
      "Epoch 28/59\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.1987 - accuracy: 0.9529 - val_loss: 0.8508 - val_accuracy: 0.8400\n",
      "Epoch 29/59\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.2031 - accuracy: 0.9562 - val_loss: 0.8718 - val_accuracy: 0.8400\n",
      "Epoch 30/59\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.1770 - accuracy: 0.9428 - val_loss: 0.8632 - val_accuracy: 0.7333\n",
      "Epoch 31/59\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.1628 - accuracy: 0.9428 - val_loss: 0.9302 - val_accuracy: 0.8400\n",
      "Epoch 32/59\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.1781 - accuracy: 0.9428 - val_loss: 0.9662 - val_accuracy: 0.8400\n",
      "Epoch 33/59\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.1641 - accuracy: 0.9495 - val_loss: 0.8771 - val_accuracy: 0.7467\n",
      "Epoch 34/59\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.1738 - accuracy: 0.9461 - val_loss: 1.0963 - val_accuracy: 0.8400\n",
      "Epoch 35/59\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.1168 - accuracy: 0.9663 - val_loss: 0.9081 - val_accuracy: 0.7600\n",
      "Epoch 36/59\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.1372 - accuracy: 0.9529 - val_loss: 1.2770 - val_accuracy: 0.8267\n",
      "Epoch 37/59\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.1462 - accuracy: 0.9562 - val_loss: 0.9084 - val_accuracy: 0.7733\n",
      "Epoch 38/59\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.0979 - accuracy: 0.9663 - val_loss: 1.1463 - val_accuracy: 0.8400\n",
      "Epoch 39/59\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.0803 - accuracy: 0.9764 - val_loss: 1.0023 - val_accuracy: 0.8133\n",
      "Epoch 40/59\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.0789 - accuracy: 0.9764 - val_loss: 1.0382 - val_accuracy: 0.8267\n",
      "Epoch 41/59\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0737 - accuracy: 0.9731 - val_loss: 1.0185 - val_accuracy: 0.8133\n",
      "Epoch 42/59\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.0551 - accuracy: 0.9865 - val_loss: 1.0069 - val_accuracy: 0.8133\n",
      "Epoch 43/59\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.0515 - accuracy: 0.9899 - val_loss: 1.0793 - val_accuracy: 0.8667\n",
      "Epoch 44/59\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0553 - accuracy: 0.9832 - val_loss: 0.9690 - val_accuracy: 0.8400\n",
      "Epoch 45/59\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.0521 - accuracy: 0.9798 - val_loss: 1.2882 - val_accuracy: 0.8533\n",
      "Epoch 46/59\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.0484 - accuracy: 0.9865 - val_loss: 1.1617 - val_accuracy: 0.8267\n",
      "Epoch 47/59\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.0435 - accuracy: 0.9865 - val_loss: 1.2124 - val_accuracy: 0.8400\n",
      "Epoch 48/59\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.0439 - accuracy: 0.9933 - val_loss: 1.2200 - val_accuracy: 0.8267\n",
      "Epoch 49/59\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.0299 - accuracy: 0.9933 - val_loss: 1.3937 - val_accuracy: 0.8267\n",
      "Epoch 50/59\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0375 - accuracy: 0.9933 - val_loss: 1.3841 - val_accuracy: 0.8533\n",
      "Epoch 51/59\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.0285 - accuracy: 0.9933 - val_loss: 1.1843 - val_accuracy: 0.8400\n",
      "Epoch 52/59\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.0233 - accuracy: 0.9966 - val_loss: 1.1695 - val_accuracy: 0.8533\n",
      "Epoch 53/59\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.0208 - accuracy: 0.9933 - val_loss: 1.2772 - val_accuracy: 0.8533\n",
      "Epoch 54/59\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.0216 - accuracy: 0.9933 - val_loss: 1.1425 - val_accuracy: 0.8133\n",
      "Epoch 55/59\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.0236 - accuracy: 0.9933 - val_loss: 1.2908 - val_accuracy: 0.8667\n",
      "Epoch 56/59\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.0319 - accuracy: 0.9832 - val_loss: 1.5220 - val_accuracy: 0.8533\n",
      "Epoch 57/59\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.0215 - accuracy: 0.9899 - val_loss: 1.2844 - val_accuracy: 0.8400\n",
      "Epoch 58/59\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.0381 - accuracy: 0.9865 - val_loss: 1.3244 - val_accuracy: 0.8400\n",
      "Epoch 59/59\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.0395 - accuracy: 0.9899 - val_loss: 1.3174 - val_accuracy: 0.8400\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "| \u001b[95m27       \u001b[0m | \u001b[95m0.8065   \u001b[0m | \u001b[95m2.93     \u001b[0m | \u001b[95m90.04    \u001b[0m | \u001b[95m58.65    \u001b[0m | \u001b[95m0.02253  \u001b[0m | \u001b[95m2.231    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/rmsprop.py:140: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adagrad.py:81: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/94\n",
      "3/3 [==============================] - 1s 249ms/step - loss: 2.1721 - accuracy: 0.4411 - val_loss: 14.1664 - val_accuracy: 0.5867\n",
      "Epoch 2/94\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 21.5822 - accuracy: 0.3704 - val_loss: 4.0482 - val_accuracy: 0.5200\n",
      "Epoch 3/94\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 7.7694 - accuracy: 0.3771 - val_loss: 6.8873 - val_accuracy: 0.2667\n",
      "Epoch 4/94\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 8.3523 - accuracy: 0.4175 - val_loss: 6.7256 - val_accuracy: 0.2400\n",
      "Epoch 5/94\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 8.3607 - accuracy: 0.4377 - val_loss: 5.8153 - val_accuracy: 0.5867\n",
      "Epoch 6/94\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 5.2734 - accuracy: 0.4411 - val_loss: 5.5563 - val_accuracy: 0.2267\n",
      "Epoch 7/94\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 5.1703 - accuracy: 0.3838 - val_loss: 4.8315 - val_accuracy: 0.5867\n",
      "Epoch 8/94\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 4.2863 - accuracy: 0.4781 - val_loss: 2.8813 - val_accuracy: 0.4000\n",
      "Epoch 9/94\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 3.2225 - accuracy: 0.4040 - val_loss: 6.2327 - val_accuracy: 0.5867\n",
      "Epoch 10/94\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 5.4496 - accuracy: 0.4343 - val_loss: 1.7113 - val_accuracy: 0.5867\n",
      "Epoch 11/94\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 2.8264 - accuracy: 0.4276 - val_loss: 2.2628 - val_accuracy: 0.4133\n",
      "Epoch 12/94\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 3.1430 - accuracy: 0.4310 - val_loss: 6.7956 - val_accuracy: 0.5867\n",
      "Epoch 13/94\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 5.2653 - accuracy: 0.4916 - val_loss: 2.9813 - val_accuracy: 0.5867\n",
      "Epoch 14/94\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 3.3324 - accuracy: 0.4242 - val_loss: 4.5720 - val_accuracy: 0.2400\n",
      "Epoch 15/94\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 4.1961 - accuracy: 0.3838 - val_loss: 3.8528 - val_accuracy: 0.2400\n",
      "Epoch 16/94\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 4.7369 - accuracy: 0.4175 - val_loss: 5.3876 - val_accuracy: 0.5867\n",
      "Epoch 17/94\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 5.7135 - accuracy: 0.4343 - val_loss: 1.6157 - val_accuracy: 0.3200\n",
      "Epoch 18/94\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 2.1398 - accuracy: 0.4242 - val_loss: 5.9256 - val_accuracy: 0.5867\n",
      "Epoch 19/94\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 4.9132 - accuracy: 0.4512 - val_loss: 1.8440 - val_accuracy: 0.5600\n",
      "Epoch 20/94\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 2.2328 - accuracy: 0.4343 - val_loss: 1.3673 - val_accuracy: 0.4533\n",
      "Epoch 21/94\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 2.3906 - accuracy: 0.3906 - val_loss: 1.2681 - val_accuracy: 0.4133\n",
      "Epoch 22/94\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 1.9880 - accuracy: 0.3939 - val_loss: 2.8132 - val_accuracy: 0.5867\n",
      "Epoch 23/94\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 2.8487 - accuracy: 0.4343 - val_loss: 1.9601 - val_accuracy: 0.5867\n",
      "Epoch 24/94\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 2.7978 - accuracy: 0.3973 - val_loss: 1.1801 - val_accuracy: 0.4667\n",
      "Epoch 25/94\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 1.8723 - accuracy: 0.4276 - val_loss: 6.4523 - val_accuracy: 0.2533\n",
      "Epoch 26/94\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 4.2544 - accuracy: 0.3636 - val_loss: 2.9210 - val_accuracy: 0.2400\n",
      "Epoch 27/94\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 3.1601 - accuracy: 0.4007 - val_loss: 1.4290 - val_accuracy: 0.5867\n",
      "Epoch 28/94\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 1.8484 - accuracy: 0.4108 - val_loss: 4.0790 - val_accuracy: 0.2533\n",
      "Epoch 29/94\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 2.9894 - accuracy: 0.3973 - val_loss: 3.5972 - val_accuracy: 0.5867\n",
      "Epoch 30/94\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 3.8001 - accuracy: 0.4377 - val_loss: 2.6497 - val_accuracy: 0.2933\n",
      "Epoch 31/94\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 2.8829 - accuracy: 0.4579 - val_loss: 1.2649 - val_accuracy: 0.5867\n",
      "Epoch 32/94\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 2.2269 - accuracy: 0.4074 - val_loss: 3.0821 - val_accuracy: 0.2933\n",
      "Epoch 33/94\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 2.6344 - accuracy: 0.4209 - val_loss: 2.6181 - val_accuracy: 0.3333\n",
      "Epoch 34/94\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 2.4616 - accuracy: 0.3704 - val_loss: 3.5790 - val_accuracy: 0.5867\n",
      "Epoch 35/94\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 3.5043 - accuracy: 0.4343 - val_loss: 1.4930 - val_accuracy: 0.5867\n",
      "Epoch 36/94\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 1.8267 - accuracy: 0.3872 - val_loss: 1.9992 - val_accuracy: 0.3067\n",
      "Epoch 37/94\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 1.9594 - accuracy: 0.4579 - val_loss: 2.5131 - val_accuracy: 0.5867\n",
      "Epoch 38/94\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 2.5725 - accuracy: 0.4108 - val_loss: 3.3872 - val_accuracy: 0.2400\n",
      "Epoch 39/94\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 3.3057 - accuracy: 0.4209 - val_loss: 3.7505 - val_accuracy: 0.2400\n",
      "Epoch 40/94\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 3.4096 - accuracy: 0.4074 - val_loss: 2.1749 - val_accuracy: 0.4533\n",
      "Epoch 41/94\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 2.1726 - accuracy: 0.4747 - val_loss: 2.5844 - val_accuracy: 0.5867\n",
      "Epoch 42/94\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 2.9376 - accuracy: 0.4209 - val_loss: 1.6998 - val_accuracy: 0.5733\n",
      "Epoch 43/94\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 2.5010 - accuracy: 0.3468 - val_loss: 3.2090 - val_accuracy: 0.4000\n",
      "Epoch 44/94\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 2.4557 - accuracy: 0.4343 - val_loss: 1.9222 - val_accuracy: 0.4533\n",
      "Epoch 45/94\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 2.0667 - accuracy: 0.4141 - val_loss: 1.8668 - val_accuracy: 0.5467\n",
      "Epoch 46/94\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 1.9781 - accuracy: 0.4310 - val_loss: 2.5273 - val_accuracy: 0.2400\n",
      "Epoch 47/94\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 2.2930 - accuracy: 0.4108 - val_loss: 1.3867 - val_accuracy: 0.5867\n",
      "Epoch 48/94\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 1.7308 - accuracy: 0.3771 - val_loss: 3.9961 - val_accuracy: 0.2400\n",
      "Epoch 49/94\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 3.1881 - accuracy: 0.3704 - val_loss: 1.3304 - val_accuracy: 0.3467\n",
      "Epoch 50/94\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 1.6305 - accuracy: 0.3939 - val_loss: 1.1547 - val_accuracy: 0.5867\n",
      "Epoch 51/94\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 1.3475 - accuracy: 0.4411 - val_loss: 1.3847 - val_accuracy: 0.4133\n",
      "Epoch 52/94\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 1.8102 - accuracy: 0.4242 - val_loss: 1.6569 - val_accuracy: 0.5733\n",
      "Epoch 53/94\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 1.6799 - accuracy: 0.4310 - val_loss: 4.2255 - val_accuracy: 0.2400\n",
      "Epoch 54/94\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 2.9037 - accuracy: 0.4007 - val_loss: 1.8370 - val_accuracy: 0.3467\n",
      "Epoch 55/94\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 1.8897 - accuracy: 0.4411 - val_loss: 1.6749 - val_accuracy: 0.4133\n",
      "Epoch 56/94\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 1.8788 - accuracy: 0.3805 - val_loss: 1.8864 - val_accuracy: 0.5867\n",
      "Epoch 57/94\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 1.8834 - accuracy: 0.4512 - val_loss: 1.3622 - val_accuracy: 0.4133\n",
      "Epoch 58/94\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 1.6691 - accuracy: 0.4310 - val_loss: 2.6490 - val_accuracy: 0.5867\n",
      "Epoch 59/94\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 2.1314 - accuracy: 0.5017 - val_loss: 2.1058 - val_accuracy: 0.2933\n",
      "Epoch 60/94\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 2.1744 - accuracy: 0.4377 - val_loss: 1.2638 - val_accuracy: 0.5733\n",
      "Epoch 61/94\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 1.4738 - accuracy: 0.4343 - val_loss: 1.1372 - val_accuracy: 0.4800\n",
      "Epoch 62/94\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 1.1281 - accuracy: 0.4983 - val_loss: 1.1918 - val_accuracy: 0.6133\n",
      "Epoch 63/94\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 1.3533 - accuracy: 0.4680 - val_loss: 1.0573 - val_accuracy: 0.5600\n",
      "Epoch 64/94\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 1.3024 - accuracy: 0.4411 - val_loss: 3.1226 - val_accuracy: 0.2400\n",
      "Epoch 65/94\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 2.3240 - accuracy: 0.4074 - val_loss: 1.4479 - val_accuracy: 0.4800\n",
      "Epoch 66/94\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 1.4815 - accuracy: 0.4781 - val_loss: 1.2776 - val_accuracy: 0.5867\n",
      "Epoch 67/94\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 1.5823 - accuracy: 0.4343 - val_loss: 1.5026 - val_accuracy: 0.4667\n",
      "Epoch 68/94\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 1.4177 - accuracy: 0.4882 - val_loss: 1.4837 - val_accuracy: 0.5867\n",
      "Epoch 69/94\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 1.4831 - accuracy: 0.4680 - val_loss: 2.0999 - val_accuracy: 0.2400\n",
      "Epoch 70/94\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 1.8388 - accuracy: 0.4276 - val_loss: 1.9319 - val_accuracy: 0.2400\n",
      "Epoch 71/94\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 1.6866 - accuracy: 0.4646 - val_loss: 1.6430 - val_accuracy: 0.5867\n",
      "Epoch 72/94\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 1.9620 - accuracy: 0.4310 - val_loss: 1.7442 - val_accuracy: 0.2400\n",
      "Epoch 73/94\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 1.6168 - accuracy: 0.4747 - val_loss: 1.3443 - val_accuracy: 0.5733\n",
      "Epoch 74/94\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 1.5316 - accuracy: 0.4478 - val_loss: 2.5694 - val_accuracy: 0.2400\n",
      "Epoch 75/94\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 2.1460 - accuracy: 0.4209 - val_loss: 2.3517 - val_accuracy: 0.2133\n",
      "Epoch 76/94\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 1.8584 - accuracy: 0.3872 - val_loss: 1.9640 - val_accuracy: 0.2400\n",
      "Epoch 77/94\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 1.7057 - accuracy: 0.4242 - val_loss: 1.2945 - val_accuracy: 0.4400\n",
      "Epoch 78/94\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 1.3792 - accuracy: 0.4343 - val_loss: 2.5131 - val_accuracy: 0.5733\n",
      "Epoch 79/94\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 2.0540 - accuracy: 0.4983 - val_loss: 3.3618 - val_accuracy: 0.3200\n",
      "Epoch 80/94\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 2.5852 - accuracy: 0.3704 - val_loss: 1.6328 - val_accuracy: 0.2533\n",
      "Epoch 81/94\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 1.6259 - accuracy: 0.4512 - val_loss: 1.2523 - val_accuracy: 0.5733\n",
      "Epoch 82/94\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 1.6725 - accuracy: 0.3973 - val_loss: 2.0376 - val_accuracy: 0.3200\n",
      "Epoch 83/94\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 1.8449 - accuracy: 0.4209 - val_loss: 2.1657 - val_accuracy: 0.4267\n",
      "Epoch 84/94\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 1.8656 - accuracy: 0.4714 - val_loss: 1.4737 - val_accuracy: 0.3867\n",
      "Epoch 85/94\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 1.7568 - accuracy: 0.4141 - val_loss: 1.5833 - val_accuracy: 0.5733\n",
      "Epoch 86/94\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 1.6903 - accuracy: 0.4613 - val_loss: 1.5586 - val_accuracy: 0.4133\n",
      "Epoch 87/94\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 1.4135 - accuracy: 0.4882 - val_loss: 1.2185 - val_accuracy: 0.4667\n",
      "Epoch 88/94\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 1.4690 - accuracy: 0.4646 - val_loss: 2.5242 - val_accuracy: 0.4133\n",
      "Epoch 89/94\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 2.5431 - accuracy: 0.4007 - val_loss: 1.4811 - val_accuracy: 0.4267\n",
      "Epoch 90/94\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 1.5708 - accuracy: 0.3872 - val_loss: 1.2622 - val_accuracy: 0.5200\n",
      "Epoch 91/94\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 1.3715 - accuracy: 0.4545 - val_loss: 1.3214 - val_accuracy: 0.5867\n",
      "Epoch 92/94\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 1.5097 - accuracy: 0.4478 - val_loss: 2.0881 - val_accuracy: 0.3067\n",
      "Epoch 93/94\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 1.9672 - accuracy: 0.3737 - val_loss: 2.3461 - val_accuracy: 0.5867\n",
      "Epoch 94/94\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 2.1689 - accuracy: 0.4747 - val_loss: 2.6905 - val_accuracy: 0.2800\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "| \u001b[0m28       \u001b[0m | \u001b[0m0.3011   \u001b[0m | \u001b[0m1.796    \u001b[0m | \u001b[0m142.9    \u001b[0m | \u001b[0m93.91    \u001b[0m | \u001b[0m0.3884   \u001b[0m | \u001b[0m2.714    \u001b[0m |\n",
      "=====================================================================================\n"
     ]
    }
   ],
   "source": [
    "params_rnn ={\n",
    "    'optimizer_index':(0,3),\n",
    "    'activation_index':(0, 3),\n",
    "    'learning_rate':learning_rates,\n",
    "    'epoch':epochs,\n",
    "    'batch_size':batch_sizes\n",
    "    \n",
    "}\n",
    "\n",
    "nn_bo = BayesianOptimization(objective_func1, params_rnn, random_state=110)\n",
    "nn_bo.maximize(init_points=25, n_iter=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'softplus',\n",
       " 'optimizer': 'Adam',\n",
       " 'batch_size': 90,\n",
       " 'epoch': 59,\n",
       " 'learning_rate': 0.022531078608418083}"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_rnn_ = nn_bo.max['params']\n",
    "\n",
    "best_params_rnn = {}\n",
    "\n",
    "best_params_rnn['activation'] = activations_list[round(params_rnn_['activation_index'])]\n",
    "best_params_rnn['optimizer'] = optimizers_list[round(params_rnn_['optimizer_index'])]\n",
    "best_params_rnn['batch_size'] = round(params_rnn_['batch_size'])\n",
    "best_params_rnn['epoch'] = round(params_rnn_['epoch'])\n",
    "best_params_rnn['learning_rate'] = params_rnn_['learning_rate']\n",
    "\n",
    "best_params_rnn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN GRU Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_GRU_model():\n",
    "    RNN = Sequential()\n",
    "    RNN.add(Embedding(len(word_index) + 1, word_dimension, weights=[embedding_matrix], input_length = maxlen, trainable=False))\n",
    "\n",
    "    RNN.add(Bidirectional(GRU(word_dimension)))\n",
    "    RNN.add(Dense(word_dimension, activation='relu'))\n",
    "    RNN.add(Dense(4, activation='sigmoid'))\n",
    "    RNN.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "    #RNN.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "    \n",
    "    return RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "19/19 [==============================] - 61s 96ms/step - loss: 1.2263 - accuracy: 0.5051 - val_loss: 1.0383 - val_accuracy: 0.6000\n",
      "Epoch 2/50\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 0.9553 - accuracy: 0.5758 - val_loss: 0.9246 - val_accuracy: 0.5867\n",
      "Epoch 3/50\n",
      "19/19 [==============================] - 1s 39ms/step - loss: 0.8130 - accuracy: 0.6566 - val_loss: 0.8448 - val_accuracy: 0.7200\n",
      "Epoch 4/50\n",
      "19/19 [==============================] - 1s 38ms/step - loss: 0.7174 - accuracy: 0.7138 - val_loss: 0.8065 - val_accuracy: 0.6533\n",
      "Epoch 5/50\n",
      "19/19 [==============================] - 1s 36ms/step - loss: 0.6305 - accuracy: 0.7744 - val_loss: 0.7877 - val_accuracy: 0.7067\n",
      "Epoch 6/50\n",
      "19/19 [==============================] - 1s 38ms/step - loss: 0.5783 - accuracy: 0.8081 - val_loss: 0.7721 - val_accuracy: 0.7067\n",
      "Epoch 7/50\n",
      "19/19 [==============================] - 1s 51ms/step - loss: 0.5258 - accuracy: 0.8283 - val_loss: 0.7963 - val_accuracy: 0.6533\n",
      "Epoch 8/50\n",
      "19/19 [==============================] - 1s 46ms/step - loss: 0.4710 - accuracy: 0.8485 - val_loss: 0.7537 - val_accuracy: 0.7333\n",
      "Epoch 9/50\n",
      "19/19 [==============================] - 1s 38ms/step - loss: 0.4031 - accuracy: 0.8855 - val_loss: 0.7608 - val_accuracy: 0.7200\n",
      "Epoch 10/50\n",
      "19/19 [==============================] - 1s 38ms/step - loss: 0.3706 - accuracy: 0.8855 - val_loss: 0.7301 - val_accuracy: 0.7333\n",
      "Epoch 11/50\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 0.3195 - accuracy: 0.9158 - val_loss: 0.7924 - val_accuracy: 0.6933\n",
      "Epoch 12/50\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 0.2931 - accuracy: 0.9192 - val_loss: 0.7505 - val_accuracy: 0.7333\n",
      "Epoch 13/50\n",
      "19/19 [==============================] - 1s 55ms/step - loss: 0.2507 - accuracy: 0.9226 - val_loss: 0.7646 - val_accuracy: 0.7333\n",
      "Epoch 14/50\n",
      "19/19 [==============================] - 1s 49ms/step - loss: 0.2628 - accuracy: 0.9158 - val_loss: 0.8406 - val_accuracy: 0.7333\n",
      "Epoch 15/50\n",
      "19/19 [==============================] - 1s 51ms/step - loss: 0.2288 - accuracy: 0.9360 - val_loss: 0.6763 - val_accuracy: 0.7867\n",
      "Epoch 16/50\n",
      "19/19 [==============================] - 1s 52ms/step - loss: 0.1877 - accuracy: 0.9327 - val_loss: 0.6950 - val_accuracy: 0.8267\n",
      "Epoch 17/50\n",
      "19/19 [==============================] - 1s 45ms/step - loss: 0.1881 - accuracy: 0.9327 - val_loss: 0.6959 - val_accuracy: 0.8000\n",
      "Epoch 18/50\n",
      "19/19 [==============================] - 1s 73ms/step - loss: 0.1679 - accuracy: 0.9428 - val_loss: 0.7984 - val_accuracy: 0.7333\n",
      "Epoch 19/50\n",
      "19/19 [==============================] - 1s 69ms/step - loss: 0.1904 - accuracy: 0.9360 - val_loss: 0.6801 - val_accuracy: 0.8133\n",
      "Epoch 20/50\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.1652 - accuracy: 0.9394 - val_loss: 0.6903 - val_accuracy: 0.8133\n",
      "Epoch 21/50\n",
      "19/19 [==============================] - 1s 72ms/step - loss: 0.1541 - accuracy: 0.9495 - val_loss: 0.7029 - val_accuracy: 0.8133\n",
      "Epoch 22/50\n",
      "19/19 [==============================] - 1s 57ms/step - loss: 0.1297 - accuracy: 0.9596 - val_loss: 0.7564 - val_accuracy: 0.7733\n",
      "Epoch 23/50\n",
      "19/19 [==============================] - 1s 37ms/step - loss: 0.1199 - accuracy: 0.9529 - val_loss: 0.7850 - val_accuracy: 0.7867\n",
      "Epoch 24/50\n",
      "19/19 [==============================] - 1s 37ms/step - loss: 0.1224 - accuracy: 0.9596 - val_loss: 0.7600 - val_accuracy: 0.7733\n",
      "Epoch 25/50\n",
      "19/19 [==============================] - 1s 37ms/step - loss: 0.1058 - accuracy: 0.9562 - val_loss: 0.8604 - val_accuracy: 0.7733\n",
      "Epoch 26/50\n",
      "19/19 [==============================] - 1s 38ms/step - loss: 0.1100 - accuracy: 0.9697 - val_loss: 0.8376 - val_accuracy: 0.7733\n",
      "Epoch 27/50\n",
      "19/19 [==============================] - 1s 81ms/step - loss: 0.1182 - accuracy: 0.9630 - val_loss: 0.8549 - val_accuracy: 0.7600\n",
      "Epoch 28/50\n",
      "19/19 [==============================] - 1s 66ms/step - loss: 0.1010 - accuracy: 0.9562 - val_loss: 0.7748 - val_accuracy: 0.8000\n",
      "Epoch 29/50\n",
      "19/19 [==============================] - 1s 45ms/step - loss: 0.0926 - accuracy: 0.9731 - val_loss: 0.7857 - val_accuracy: 0.8267\n",
      "Epoch 30/50\n",
      "19/19 [==============================] - 1s 46ms/step - loss: 0.1027 - accuracy: 0.9562 - val_loss: 0.8945 - val_accuracy: 0.8133\n",
      "Epoch 31/50\n",
      "19/19 [==============================] - 1s 46ms/step - loss: 0.1224 - accuracy: 0.9495 - val_loss: 0.8399 - val_accuracy: 0.8400\n",
      "Epoch 32/50\n",
      "19/19 [==============================] - 1s 45ms/step - loss: 0.1179 - accuracy: 0.9495 - val_loss: 0.8538 - val_accuracy: 0.7733\n",
      "Epoch 33/50\n",
      "19/19 [==============================] - 1s 43ms/step - loss: 0.0929 - accuracy: 0.9529 - val_loss: 0.8031 - val_accuracy: 0.8000\n",
      "Epoch 34/50\n",
      "19/19 [==============================] - 1s 47ms/step - loss: 0.0848 - accuracy: 0.9697 - val_loss: 0.8425 - val_accuracy: 0.7867\n",
      "Epoch 35/50\n",
      "19/19 [==============================] - 1s 65ms/step - loss: 0.0698 - accuracy: 0.9731 - val_loss: 0.8135 - val_accuracy: 0.8133\n",
      "Epoch 36/50\n",
      "19/19 [==============================] - 1s 43ms/step - loss: 0.0726 - accuracy: 0.9697 - val_loss: 0.8545 - val_accuracy: 0.8000\n",
      "Epoch 37/50\n",
      "19/19 [==============================] - 1s 42ms/step - loss: 0.0643 - accuracy: 0.9731 - val_loss: 0.8792 - val_accuracy: 0.8133\n",
      "Epoch 38/50\n",
      "19/19 [==============================] - 1s 38ms/step - loss: 0.0695 - accuracy: 0.9764 - val_loss: 0.8761 - val_accuracy: 0.7600\n",
      "Epoch 39/50\n",
      "19/19 [==============================] - 1s 51ms/step - loss: 0.0552 - accuracy: 0.9832 - val_loss: 0.8796 - val_accuracy: 0.8000\n",
      "Epoch 40/50\n",
      "19/19 [==============================] - 1s 39ms/step - loss: 0.0525 - accuracy: 0.9832 - val_loss: 0.8766 - val_accuracy: 0.8000\n",
      "Epoch 41/50\n",
      "19/19 [==============================] - 1s 37ms/step - loss: 0.0599 - accuracy: 0.9764 - val_loss: 0.9148 - val_accuracy: 0.7867\n",
      "Epoch 42/50\n",
      "19/19 [==============================] - 1s 39ms/step - loss: 0.0603 - accuracy: 0.9764 - val_loss: 0.9461 - val_accuracy: 0.8400\n",
      "Epoch 43/50\n",
      "19/19 [==============================] - 1s 39ms/step - loss: 0.0656 - accuracy: 0.9832 - val_loss: 0.9490 - val_accuracy: 0.8133\n",
      "Epoch 44/50\n",
      "19/19 [==============================] - 1s 38ms/step - loss: 0.0559 - accuracy: 0.9798 - val_loss: 1.0646 - val_accuracy: 0.7733\n",
      "Epoch 45/50\n",
      "19/19 [==============================] - 1s 45ms/step - loss: 0.0472 - accuracy: 0.9865 - val_loss: 0.9670 - val_accuracy: 0.8400\n",
      "Epoch 46/50\n",
      "19/19 [==============================] - 1s 74ms/step - loss: 0.0581 - accuracy: 0.9798 - val_loss: 1.0219 - val_accuracy: 0.8000\n",
      "Epoch 47/50\n",
      "19/19 [==============================] - 1s 47ms/step - loss: 0.0449 - accuracy: 0.9865 - val_loss: 1.0022 - val_accuracy: 0.8000\n",
      "Epoch 48/50\n",
      "19/19 [==============================] - 1s 46ms/step - loss: 0.0413 - accuracy: 0.9899 - val_loss: 0.9759 - val_accuracy: 0.8267\n",
      "Epoch 49/50\n",
      "19/19 [==============================] - 1s 44ms/step - loss: 0.0428 - accuracy: 0.9899 - val_loss: 0.9790 - val_accuracy: 0.8133\n",
      "Epoch 50/50\n",
      "19/19 [==============================] - 1s 58ms/step - loss: 0.0416 - accuracy: 0.9865 - val_loss: 1.0590 - val_accuracy: 0.8133\n"
     ]
    }
   ],
   "source": [
    "GRU_model = create_GRU_model()\n",
    "GRU_history = GRU_model.fit(feature_train, y_train, epochs=50, batch_size=16, validation_data=(feature_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAikAAAGDCAYAAADu/IALAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABd2klEQVR4nO3dd3yUVdr/8c9JDxCS0EsSCEU6JIiACHYUu+vacW24rm5zn226+9v67LO9F3fdtawF7K4r1hVdGyogkNCRFkgCCSWkQ/r5/XEmEELKJJk7M0m+79eLVzL33DP3mRGZa865rusYay0iIiIioSYs2AMQERERaYqCFBEREQlJClJEREQkJClIERERkZCkIEVERERCkoIUERERCUkKUkSkzYwxI40x1hgT4ce5txpjlnfGuESke1GQItLNGWN2G2OqjDEDGh3P9AUaI4M0NBGRFilIEekZsoAb6m8YY6YAscEbTmjwZyZIRIJHQYpIz/AEcHOD27cAjzc8wRgTb4x53Bhz0BizxxjzPWNMmO++cGPMb4wxh4wxu4BLmnjsw8aYPGPMXmPM/xljwv0ZmDHmOWNMvjGm2BjzvjFmUoP7Yo0xv/WNp9gYs9wYE+u7b64x5iNjTJExJscYc6vv+LvGmDsaPMcJy02+2aMvGWO2A9t9x/7oe44SY8waY8y8BueHG2O+a4zZaYwp9d2fbIy53xjz20av5WVjzNf8ed0i0joFKSI9wwqgrzFmgi94uA5Y3OicPwPxwCjgLFxQc5vvvs8DlwLpwAzg6kaPfQyoAcb4zrkAuAP/vA6MBQYBa4ElDe77DXAqMAfoB3wbqDPGpPge92dgIJAGZPp5PYArgVnARN/tT3zP0Q94EnjOGBPju+/ruFmoi4G+wO3AEdxrvqFBIDcAOA94qg3jEJEWKEgR6TnqZ1PmA1uBvfV3NAhcvmOtLbXW7gZ+C3zOd8q1wB+stTnW2sPAzxs8djBwEfA1a225tfYA8Hvgen8GZa19xHfNSuBHwDTfzEwYLiC4x1q711pba639yHfeQuAta+1T1tpqa22BtTazDe/Fz621h621R31jWOx7jhpr7W+BaGCc79w7gO9Zaz+1zjrfuauAYlxggu/1vmut3d+GcYhIC7QeK9JzPAG8D6TSaKkHGABEAXsaHNsDDPf9PgzIaXRfvRFAJJBnjKk/Ftbo/Cb5gqOfAtfgZkTqGownGogBdjbx0ORmjvvrhLEZY76BC0aGARY3Y1KfaNzStR4DbgKW+X7+sQNjEpFGNJMi0kNYa/fgEmgvBv7V6O5DQDUu4KiXwvHZljzch3XD++rlAJXAAGttgu9PX2vtJFp3I3AFcD5uqWmk77jxjakCGN3E43KaOQ5QDvRqcHtIE+cc2/7dl39yL262KNFam4CbIamPuFq61mLgCmPMNGAC8O9mzhORdlCQItKzLALOtdaWNzxora0FngV+aoyJM8aMwOVi1OetPAt81RiTZIxJBO5r8Ng84E3gt8aYvsaYMGPMaGPMWX6MJw4X4BTgAoufNXjeOuAR4HfGmGG+BNbTjTHRuLyV840x1xpjIowx/Y0xab6HZgJXGWN6GWPG+F5za2OoAQ4CEcaYH+BmUuo9BPzEGDPWOFONMf19Y8zF5bM8AbxQv3wkIoGhIEWkB7HW7rTWrm7m7q/gZiF2ActxCaSP+O57EPgPsA6X3Np4JuZm3HLRZqAQeB4Y6seQHsctHe31PXZFo/u/CWzABQKHgV8CYdbabNyM0Dd8xzOBab7H/B6oAvbjlmOW0LL/4JJwt/nGUsGJy0G/wwVpbwIlwMOcWL79GDAFF6iISAAZa23rZ4mISJOMMWfiZpxG+mZ/RCRANJMiItJOxphI4B7gIQUoIoGnIEVEpB2MMROAItyy1h+COhiRbkrLPSIiIhKSNJMiIiIiIUlBioiIiISkLtdxdsCAAXbkyJHBHoaIiIgEwJo1aw5Zawc2dV+XC1JGjhzJ6tXNtXkQERGRrsQYs6e5+7TcIyIiIiFJQYqIiIiEJAUpIiIiEpI8y0kxxjwCXAocsNZObuJ+g9vW/GLgCHCrtXZte65VXV1Nbm4uFRUVHRlylxATE0NSUhKRkZHBHoqIiIinvEycfRT4C24DsaZcBIz1/ZkF/M33s81yc3OJi4tj5MiRuNine7LWUlBQQG5uLqmpqcEejoiIiKc8W+6x1r6P2520OVcAj1tnBZBgjPFn19STVFRU0L9//24doAAYY+jfv3+PmDESEREJZk7KcE7cDj3Xd+wkxpg7jTGrjTGrDx482OSTdfcApV5PeZ0iIiLBDFKa+rRtciMha+0/rLUzrLUzBg5sst9LUBUUFJCWlkZaWhpDhgxh+PDhx25XVVW1+NjVq1fz1a9+tZNGKiIi0nUEs5lbLpDc4HYSsC9IY+mQ/v37k5mZCcCPfvQj+vTpwze/+c1j99fU1BAR0fRbPWPGDGbMmNEZwxQREelSgjmTshS42TizgWJrbV4QxxNQt956K1//+tc555xzuPfee1m1ahVz5swhPT2dOXPm8OmnnwLw7rvvcumllwIuwLn99ts5++yzGTVqFH/605+C+RJERESCyssS5KeAs4EBxphc4IdAJIC19gHgNVz58Q5cCfJtgbjuj1/exOZ9JYF4qmMmDuvLDy+b1ObHbdu2jbfeeovw8HBKSkp4//33iYiI4K233uK73/0uL7zwwkmP2bp1K++88w6lpaWMGzeOu+++W+XGIiLSI3kWpFhrb2jlfgt8yavrh4JrrrmG8PBwAIqLi7nlllvYvn07xhiqq6ubfMwll1xCdHQ00dHRDBo0iP3795OUlNSZwxYRkS6uqqaOrfklFJS3nBcJ0DsqgknD+tI7OvS28wu9EXVQe2Y8vNK7d+9jv3//+9/nnHPO4cUXX2T37t2cffbZTT4mOjr62O/h4eHU1NR4PUwREeni9pdUsHZPIRk5RazdU8iGvcVU1tT5/fgwA+OH9CU9JYHpKYlMH5HIyP69gl5R2u2ClFBVXFzM8OGuwvrRRx8N7mBERKTTFZRVYoyhX++oDj2PtZYNe4tZlXWYjJwiMvYUsq/Y9c+KighjyvB4Pjd7BNNHJDIkPqbJUtqGCo9UkZldxNrsIl7K3MeSldkAJPaKJD0lkfTkBKaPSCQtOaHTZ1sUpHSSb3/729xyyy387ne/49xzzw32cEREpJNsyC3m4eW7eGV9HsbAZdOGsWhuKpOGxbfpeapq6nh1wz4e+iCLTb7cy+EJsUwfkcgdKYmkpyQwcVhfoiPC2zzGc8cPBqC2zrLjQBkZ2YWszS4kI7uI/249AMAfr0/jirQm25l5xrjUkK5jxowZdvXq1Scc27JlCxMmTAjSiDpfT3u9ItIzHKmqIbfwaKvn9YoKJymxVyeMCOrqLPtLKxgcF0NYmP9LH7V1lmWb9/PI8ixW7T5Mn+gIrp2RTJ21PLs6hyNVtcwe1Y875o7i3PGDWnzuwvIqnlyVzWMf7eZAaSVjBvXhtjNGcv6EwQzuGxOIl9mi4qPVrMspYvLw+A7PAjXFGLPGWttkLw7NpIiISFDtKzrKYx/t5qlV2ZRU+JeHNyu1H4vmpnLehMGEtyF48Fd5ZQ3Pr8nlnx9msbvgCPGxkaQl1+drJDAtOYG+MSdXXpZV1vDsJzk8+tFusg8fISkxlu9dMoHrTksmznf+/8w/had9Qccdj68mdUBvbjtjJFefmkSvqOMfyzsOlPHIh1n8a20uFdV1zBs7gF9dPZUzxw5sU8DUUfGxkZx5SnAaqWompQvqaa9XRLqnjOxCHl6exesb8wFYMHkIF0wcTERYyy28cgqP8MTHe9hbdJQR/Xtx25yRXDMjOSD5Eo0DpvSUBC6ZMpSdB8tYu6eIbQdKsRaMgbGD+pCe7IKWMYPieH1DHs98kkNpZQ2njkjkjrmpzJ84mIjwpl9PdW0db2zM5+HlWWTmFNE3JoIbZqUwY0Q/nly5h3c+PUhURBhXpQ/n9rmpnDI4rsOvLxS1NJOiIKUL6mmvV0S6j5raOv6zaT8PL9/F2uwi4mIiuGFmCrfMGcnwhNhOf556mTlFPLw8i9c2uJ6iCyYPYdHcVKanJJ5wXklFNetzilnbIGej+KhrKREeZrh4ylAWzU0lLTmhTddfs6eQR5Zn8frGPOosDOgTzc2nj2DhrBT694lu/Qm6MAUp3UxPe70i0vWVVFTzzCq3DLK36Cgp/Xpx2xluBqRPB2dAmpqRWTQ3lXGtzDxY4P1tB3l4eRZr9hQSFx3B9TOTuWXOSL9zXqy17DpUzpa8EqanJDKsHQFSQzmHj7Btfylzxw5oVwJsV6ScFBER6TTWWnILjx6baVibXcjmfSXU1FlmpvbjB5dN5PwA5pKkpyTylxsT2dtgqebV9f7vspLSrxc/vGxiuwImYwyjB/Zh9MA+bR12k5L79SK5X+ckBXcFClJERKRDjlTVsD63+FhAkpFdxKGySgBiI8OZlhzP588cxcWThzIlqW1lt20xPCGW7148gXvOG8urG/IoOtJ6t9XUAX04d/wgT5JvpeMUpARAQUEB5513HgD5+fmEh4czcKDLhF61ahVRUS2XbL377rtERUUxZ84cz8cqIq0rqahm0aOfkJzYi19fM61bfIAVH6kmM9d1I12bXcj63GISekUea9Q1PSWRcUPiiGwmybOetZY9BUfIyClk7Z4iMnIK2ZJXSm2dSx1IHdCbM8cOIH1EItNTEhg3OK7ZxFGv9PaV+0rXpyAlAPr3709mZibgdjLu06cP3/zmN/1+/LvvvkufPn0UpIiEgIrqWu58fDVr9hTyye5CYqPC+b8rJwe9PXhb1NZZth8odTMbvlbpOw6UAa79+SmD47ho8hAKj1Tx4c4C/p25D4CYyDCmJiUca42enpJA76gI1uUWnfBch337wfSOCictJYG7zxrN9BEJpCUnetJHQ3ouBSkeWbNmDV//+tcpKytjwIABPProowwdOpQ//elPPPDAA0RERDBx4kR+8Ytf8MADDxAeHs7ixYv585//zLx584I9fJGQUnykmnueyeBIVS23nzGS+ROHeDK7UVtn+fqzmazYdZg/XJfG1vxSHnhvJ4PiYrjn/LEBv54XPtp5iC8tWUvhEVdxktgrkukpiVyZNozpKYlMTU44Ie/CWsveoqOszS7ydRkt4pHlWfy9dhfgSm3r6ytGD+zNueMHHQtgThkc1y1mmSR0db8g5fX7IH9DYJ9zyBS46Bd+n26t5Stf+QovvfQSAwcO5JlnnuH//b//xyOPPMIvfvELsrKyiI6OpqioiISEBO666642z76I9BR7i45y6yOr2FNwhIFx0dy1eC3J/WK5dU4q185IOtYgq6Ostfxo6SZe25DP9y6ZwJXpw7HWcrC0kt+/tY0BcVEsnDUiINfyysa9xdz5+BqGxsfw/Usnkp7S+iZxxhiSEnuRlNiLy6cNA9xs0qZ9xazdU0R5VQ1pyQmkJSeQ0EuzJNK5ul+QEgIqKyvZuHEj8+fPB6C2tpahQ4cCMHXqVBYuXMiVV17JlVdeGcRRioS+TfuKue2fn3C0upbHbp/JzNR+LNvsml/95JXN/GHZNq49LZlb54zscEXEX/67gydW7OELZ43ijnmjAPcB/ovPTqHwSBXf//dG+veOZsHkIYF4aQGXXXCEW//5CfGxkTyxaBZD4tvfLj0mMpxTR/Tj1BH9AjhCkbbrfkFKG2Y8vGKtZdKkSXz88ccn3ffqq6/y/vvvs3TpUn7yk5+wadOmIIxQJPR9sP0gdy9eS1xMBM/fNYdxQ1zPiwWTh7Jg8lDW+ZpvPfbRbv75YdYJzbfamj/y1KpsfrtsG1dNH859C8afcF9keBj33zidGx9awVefzuCJ22cya1T/gL3OQDhYWsnnHllJTV0dT98+u0MBikgo6dyU6x4iOjqagwcPHgtSqqur2bRpE3V1deTk5HDOOefwq1/9iqKiIsrKyoiLi6O0tDTIoxYJHf9am8tt//yEpMRYXvziGccClIamJSfwpxvS+eDec7jzzNEs336Iz/7tY67860csXbeP6to6v671n035/L8XN3D2uIH88rNTmwxwYqPCeeSW00hOjOWOx1ezJa+kw68xUMoqa7jt0VXsL6ngkVtPY8ygwPTrEAkFClI8EBYWxvPPP8+9997LtGnTSEtL46OPPqK2tpabbrqJKVOmkJ6ezv/8z/+QkJDAZZddxosvvkhaWhoffPBBsIcvEjTWWu5/Zwdff3YdM1P78exdp7c6KzA0Ppb7LhrPiu+ex0+umETJ0Wq++lQGZ/3qHf7+3s5jLcubsirrMF99KoOpSQn8deH0FstvE3tH8fiiWfSOiuCWR1aRc/hIu19noFTV1HHXE2vYklfK3xaeelILd5GuTm3xu6Ce9nqlc+08WMb97+xg7KA4bpyZQnyv9iWmFh+p5qlPslm9+zAThvYlPSWB9OREEpspUa2preOHSzexZGU2V6YN41dXTyMqou3fo+rqLP/deoCHl2fx8a4CekWFc82pSdx2RiojB/Q+dt7W/BKufeBjBsZF8/xdc5odV2Pb9pdy9d8+YkCfaJ676/Sg7atSV2e555lMXl63j99eM43PnpoUlHGIdJT27ulmetrrlc5RW2d56INd/HbZNsIMVFTXERsZztWnJnHbGSMZ5Wfb76xD5fzzwyyeW53L0epaRvbvRU7h0WPNvkYN6E1agz4c4wbHUVVbx1efyuCtLQe4++zRfPvCcQHpS7JpXzGPLN/N0nV7qamznDd+MIvmppLcL5bP/u0jAP71xTPavCHd6t2HWfjQSsYP7cuTd8wKyO67bWGt5ccvb+bRj3Zz30Xjueus0Z16fZFAUpDSzfS01yve23GglG8+t57MnCIumDiY//vMZArKqnhkeRYvZe6juq6Oc8cNYtG8VE4f1f+kAMJay8e7CnhkeRZvbz1AZFgYl6cN4/YzUpk4rG8TbdMLOVTmGoL1igonPjaS/SUV/PjySXzu9JEBf30HSip4YsUelqzM5nB5FdERYURHhPFcg4Tctlq2eT9feGI1M0b243uXTGBqUkJgB92Cv767g1+98SmL5qbyvUsmdKlGcyKNKUjpZnra6xXv1NTW8eAHWfz+rW30jgrnx1dM5rKpQ0/40DtYWsniFXtYvGIPBeVVTBjal0VzU7ls2lAMhpfX7ePh5Vlsziuhf+8oFs4ewU2zUxgU13wuSeMN6HYcKOOWOSOZP3Gwp6+3orqWFzP28ur6PL52/lhmjOxYie2/1ubyg5c2UVZZw2kjE1k0N9WzRnP1nl2dw7efX88VacP4/bVphKmZmnRxPSJIGT9+fI/4NmGtZevWrQpSpMO27S/lW8+tY11uMQsmDeEnV05mYFzz+RUV1bW8lLmXh5dnsW1/GQP6RGOMC2JOGdyHRXNTuSJtODGRPWN7+XqlFdU8uzqXf36YRW7hUZL7xXLbnFSuPa3tO+o2p+hIFRk5RazKOsw/3t/FnNH9efiW09qVsyMSarp9kJKVlUVcXBz9+588Dd2dWGspKCigtLSU1NTUYA9Huqia2jr+/v4u/vjWdvrERPC/V0zikilD/f5/x1rL8h2HeOyjPYDl5tNHMm/sgG79/54/aussb25yjeZW7ykkLjqC605L5pY2NpqrrbNs2196bJZpbXYhuw6WA27fnXljB/LXhdM7PQ9GxCvdPkiprq4mNzeXioqKII2q88TExJCUlERkZGBagUvPsjW/hG89t54Ne4u5ZOpQ/vfySUGrTunO6hvNvbYhjzprOW/CYIa1UkpdZ11l1bqcIsqragHo1zuK6SkJpPuSjKclJSg4kW6n2wcpItKy6to6/vbuTv783+30jYnkJ1dO5uIpQ4M9rG4vr/goj320h5cy93K0urbV85MSY49VPU1PSSSlX8v77oh0BwpSRHqwzftK+Nbz69i0r4TLpg3jx5dPop+fPUFERLzWUpCieUORbqqqpo7739nB/e/sIKFXFA/cdGrIbo4nItIUBSkiQVRQVskH2w8xd+wABgQwN2Tj3mK++dw6tuaX8pn04fzg0ol+d1QVEQkVClJEgsBay6sb8vjBS5s4XF5FVEQYV6YNY9HcUe1uLgZQWVPLX/67g7++u5N+vaN48OYZnvceERHxioIUkU52sLSSH7y0kdc35jMtKZ7fXTuNZZv388LaXJ5dncu8sQO4fW4qZ40d6HejroKySlbvKeR3b27j0/2lXDXdzZ4k9NLsiYh0XUqcFekk1lqWrtvHj5Zuoryqlq/PP4U75qYS4dt5t7C8iidXZfPYR7s5UFrJ6IG9uX1uKlelJxEbdbxBWk1tHVvzS8nILmRtdhEZ2YXsLnA78g7uG83Pr5rCueM1eyIiXYOqe0T8VFNbx/Idhxg1oA/J/WIDVv55oLSC7724kTc37yctOYHfXDOVMYOaXtapqqnj1Q2u1fzGvSUk9ork+pkpWAsZ2YWszy0+Vs46oE/0sT4a01MSmJac0OM6vopI16YgRcRPP39tC39/fxcAA/pEHWuiNT0lkalJ8fSKatsKqbWWf2fu5UdLN1NRXcs3LjiFRXNH+bW3i7WWVVmHeXh5Fsu27CfcGCYN63vCmJISAxdIiYgEg0qQRfzw9pb9/P39XXx2ehLpKQlk+JZSlm3eD0B4mGH8kDjSUxJIT06kf5+W8z2shSUr9/DWlgOcOiKRX109ldED+/g9HmMMs0b1Z9ao/hSUVdI7OkKzJCLSo2gmRQTILTzCJX9aTlJiLC/cPeeEYKCwvIrMHLeHytrsQtblFFNWWePX80ZHhPGtC8dx2xmpnu6MKyLSVWkmRaQFVTV1fPnJDOrqLH9dOP2k2YrE3lGcM34Q54wfBLgN4HYdLKPUj0AlKSGWQX1b3rNFRESapiBFerxfvL6VzJwi/rZwOiP69271/PAww9jB7e9lIiIi/gkL9gBEgumNjfk88mEWt84ZyUXacE9EJKQoSJEeK7vgCN96fh3TkuL5zsXjgz0cERFpREGKdAtHqmqorfM/CbyyppYvPbkWA/zlxulER6hqRkQk1CgnRbqcujrLjoNlrN1TSEa2q7rZcbCM4Qmx3HZGKtfOSCIuJrLF5/jZq1vYsLeYv3/uVJL79eqkkYuISFsoSJGQV3ykmrU5hcf6lmRmFx2rrImPjSQ9JYEFk4ewYlcBP3llM79fto3rTkvm1jkjmwxAXl2fx2Mf72HR3FQunDSks1+OiIj4SUGKhJTaOsu2/aXHZkgysgvZebAcgDAD44b05bK0YUz3dV0dNaD3CR1X1+UU8fDyLB77aDf//DCLCycN4Y55qUxPScQYw+5D5dz7wnrSkhO4d4HyUEREQpmauUlQHS6vIiP7+LLNupwiyqvcvjT9ekeRnpzA9BEuIJmalECfaP/i6rziozz20R6eXLmHkooapiUncPsZI/n7e7vYW3SUV786l6RELfOIiASb9u6RkPTw8ix+8spm4HjL+ekN9qUZ0b9Xh/elOVJVwwtrcnnkw91kHXIzMg/fMoPzJmiXYBGRUKCOsxJyio5U8ftl2zh9VH/uOX9suzbv80evqAg+d/pIFs4awTufHqCypk4BiohIF6EgRYLi4eVZlFXW8MPLJzJ+SF/PrxcWZhSciIh0MeqTIp2u6EgV//xwN5dMGdopAYqIiHRNClKk0z34wS7Kq2r46nljgz0UEREJYQpSpFMVllfx6Ie7uXjKUMYN0SZ9IiLSPAUp0qke/GAXR6pr+ZpmUUREpBWeBinGmAXGmE+NMTuMMfc1cX+iMeZFY8x6Y8wqY8xkL8cjwXW4vIrHPtrNpVOHMXawZlFERKRlngUpxphw4H7gImAicIMxZmKj074LZFprpwI3A3/0ajwSfP94382i3HPemGAPRUREugAvZ1JmAjustbustVXA08AVjc6ZCLwNYK3dCow0xqhOtBsqKKvk8Y93c9nUYYwZpFkUERFpnZdBynAgp8HtXN+xhtYBVwEYY2YCI4Ckxk9kjLnTGLPaGLP64MGDHg1XvPSPD3ZRUV2rih4REfGbl0FKU/3MG/fg/wWQaIzJBL4CZAA1Jz3I2n9Ya2dYa2cMHDgw4AMVbx0qq+Txj/Zw+bRhjBnUJ9jDERGRLsLLjrO5QHKD20nAvoYnWGtLgNsAjNukJcv3R7qRf7y/i8qaWr6iWRQREWkDL2dSPgHGGmNSjTFRwPXA0oYnGGMSfPcB3AG87wtcpJs45MtFuSJtOKMHahZFRET859lMirW2xhjzZeA/QDjwiLV2kzHmLt/9DwATgMeNMbXAZmCRV+OR4Pj7ezupqqnjK+eqokdERNrG0w0GrbWvAa81OvZAg98/BrQG0E0dKK3giRV7uDJ9OKM0iyIiIm2kjrPimX+8t4vqWstXz1UcKiIibacgRTxxoLSCxSv3cGXacEYO6B3s4YiISBfk6XKPdD+1dZZnV+dQWlHd4nmrsg67WRR1lxURkXZSkCJt8sbGfL7zrw1+nXvT7BRG9NcsioiItI+CFGmTJ1bsJikxltfvmUeYaapf33G9osI7aVQiItIdKUgRv+04UMqKXYf59oJxxMVEBns4IiLSzSlxVvy2eEU2keGGa2ckt36yiIhIBylIEb8cqarhhbW5XDxlKAP6RAd7OCIi0gMoSBG/LM3cR2lFDTfNHhHsoYiISA+hIEVaZa1l8co9jBscx4wRicEejoiI9BAKUqRV63KL2bi3hJtOH4FppaJHREQkUBSkSKue+HgPvaPC+Uz68GAPRUREehAFKdKioiNVvLJ+H1emD6dPtCrWRUSk8yhIkRY9vyaXypo6JcyKiEinU5AizaqrsyxesYcZIxKZMLRvsIcjIiI9jIIUadaHOw+xu+CIZlFERCQoFKRIsxav2EO/3lFcNGVIsIciIiI9kIIUaVJe8VGWbd7PtTOSiY7QRoEiItL5FKRIk55alYMFFs5KCfZQRESkh1KQIieprq3j6VXZnHXKQJL79Qr2cEREpIdSkCIneWvzfg6UVnLTLCXMiohI8ChIkZM8sWIPwxNiOWf8oGAPRUREejAFKXKCnQfL+GhnATfOSiE8TPv0iIhI8ChIkRMsWZFNZLjh2hnJwR6KiIj0cApS5JijVbU8vyaHBZOHMjAuOtjDERGRHk5Bihzz/JocSipquEllxyIiEgIUpAgAOw6U8rPXtjIrtR8zU/sFezgiIiIKUgSOVNXwxSVr6RUVzp9uSMcYJcyKiEjwRQR7ABJ8P3hpE9sPlPH47TMZ3Dcm2MMREREBNJPS4z23Oofn1+TylXPGMG/swGAPR0RE5BgFKT3Yp/mlfP+ljZw+qj/3nH9KsIcj0j1VlsF/fwpHi4I9Emls+zLY+K/Ou97W1+DTNzrvet2Alnt6qPLKGr64ZA19oiP54w1patwm4pUPfgPLfw99h8GM24I9Gmno9W9DcS4MS4N+o7y/3hv3QvVR+PoWCI/0/nrdgGZSeiBrLd/790ayDpXzp+vTGBSnPBQRTxTuho/vd7/nrArqUKSRgp1weBfUVsGyH3h/vZI8KMqG8oOw/U3vr9dNKEjpgZ75JIcXM/Zyz3mnMGfMgGAPR6T7evP7EBYBSadBzopgj0Ya2vGW+5l2E2x5GbI+8PZ6OSvdz7BIyFji7bW6EQUpPcyWvBJ+uHQTc8cM4Mvnjgn2cES6r93LYctSmPs/MOEy96297GCwRyX1ti+DfqPhkt9AfDK88R2oq/XuejmrICIGZn4etr0BZQe8u1Y3oiClBymrrOFLS9YSHxvJH65XHoqIZ+pq3Yde3ySY8xVInuWO13+bluCqPgq7P4Cx8yEyFub/GPZvgIzF3l0zZwUMmw6n3ga2FtY/4921uhEFKT2EtZbv/GsDuwvK+dMN6Qzoo715RDyT+STkr3cffpGxMDQNwqMUpISK3R9CTQWMme9uT7oKkmfDf38CFSWBv171UchbB8kzYeApkDTTBUTWBv5a3YyClB5iycpsXl63j29cMI7Zo/oHezgi3VdFCbz9v272ZPJn3bHIGBeoKEgJDTuWuaWXkWe428bAgp+7pNYPfhP46+1dC3U1kDLb3U5fCAe3uuPSIgUpPcDGvcX87yubOfOUgdx91uhgD6d72PYmFOUEexTipT0fQ/7Gtj9u+e+g/ID70Gu4xUTKLNiXATWVgRujtM/2N2HkPDfLVW/4dJh2I6z4m8sfCqT64DRppvs56SqIiIWMJwJ7nZOuu8rN4HRhClK6uZKKar705Fr69YriD9elEaY8lI4r3gtPXQcv3KHp2u6qKAeeuBIePBc2v+T/4+pLjqfdAMNPPfG+5Fmu3HVfZgAHKm1WX3o8dv7J9533A1d9E+iS5JyV0H8s9PbNYsf0hYlXwMYXoOpIYK9VryQPHr8SHjofNjzvzTU6gYKUbsxay30vrCe38Ch/uTGdfr2jgj2k7mHdk2DrXCLcpk7sVimd560fuZ9DJsOztxzvddKa+pLj85r4kFPybGioLz0ec/7J9/UdCvP+J7Alyda6/+b1//3rpd8ElSWw9ZXAXKex//4E6qph6DR4YZFrKNgFv1QpSOnGHv94D69tyOdbF45jxsh+wR5O92Ct63Ew4gwYMgWW/dAlxUn3kb0SNj4Pc74Kt77qyof/8114/d6WS1Qblhz3HXby/X0GQWKqgpRgqy897t/M0vfpXw5sSfKh7XC00C33NTTiDEgY4U1F0b4MyFwCs+92f4cnf9YF3q9+HWprAn89DylI6abW5RTxf69u5tzxg7hzXie0e+4p9nwEhVkw/Wa48OdQnAMf/yXYo5JAqauD/3wH4obCGfe4nIVrHoPZX4KVD8CzNzc9Pd+45Lg5KbNdkNIFv9F2Cw1Lj5sT6JLk+qC08UxKWJibTcl6Dwr3dPw69ax1fxd7D4R534SIaLjqITjja7D6EXj6RrefVBehIKUbKj7i8lAGxcXw22umKQ8lkDKXQFQcTLgcUue5b9kf/N6t/0rXt+FZ2LsGzvshRPdxx8LCYMHPYMEvYeur8NhlUH7oxMc1LjluTvJMV0ES6MRM8U/j0uPmBLIkOWcFxCa6nJTGpt0AGFj3VMeu0dCmFyH7Yzj3ey73Bdzf4fk/hkt+5yqbHr0ESvcH7poeUpDSzVhr+ebz68gvruDPN6aTqDyUwKksdf8ATL4Konq5Y/N9675v/29wxyYdV1XupsSHTYep1518/+y74LonYP9Gl4xYsNMdb6rkuDnJvhJU7eMTHI1Lj5sTyJLknFWuqiesiY/bhGQYdbZbQq6r69h1wM0ULfshDJ4C6Z87+f7TFsH1T8Ghbe7v8MFPO35NjylI6WYeXp7Fss37ue+i8UxPSQz2cLqXTf+G6iNuirZev1SY/UWXTKueB13bh3+E0jxY8IumP1DAzZzd8opLeHzofPcB1FzJcVMGjofoeO3jEyzbl51cetycQJQkHznsAoLG+SgNpd8ExdluGaqjPr7fPdeCn0FYeNPnjFvg8lRqKuDh+W52KYRFBHsAEjhrswv5xetbuWDiYBbNTQ32cLqfjMUw4BS3WVxD877hloHe+A7c/kbrH1TtkbfOlT4HQq/+Lf+j2RMV5bggZfJnW39vkk+DRctgyTVu6cfWNV1y3JSwMPf4UJhJKdjp/i7EJnTseWpr3Afx4IkBGZZnCnbC4Z0w6wv+P+a8H7gS9GU/gOvakZ9S/9+5cT5KQ+MvgZh49+/LqLPafo16pfnwwe9g/KWQembL5w6fDne8BUuudqX28//XJfG2Zli6q4DqRApSuomiI1V85ckMhsTH8Ourp2G8+KDsyQ7tcN9+z//xyUFITF849/vw8lddSXJrU/5tVVkGD57nlpUC5c73YFha4J6vq6svOT7/x/6d33+0C1Seut51Dm2q5Lg5ybPgnZ/B0aKOBwjtVZQNf5sDfQbDTS/AgCbyJfxRWQrP3erKem9/M7SD35ZKj5vTdyjM/Rq881PX2G/I5LZdM2eFK0kfNr35cyJjYfLV7otOxW9cwNIeb//E9eG54Cf+nZ84Aha9CU8vhDfu8+8x1z7u+rt0IgUp3UBdneUbz67jQGkFz981h/hekcEeUveTuRhMOEy7vun702+CTx5068HjLvZvOtlf+ze6AOWiX7vEy46oqXTf/jMWK0ipV19yfOa3XY6Av3r3h9ted0s/vdpQ4p88C7CQuxrGtuEDM5CW/dD9rCp3U/7XPwUjTm/bc5TkwZPXwv5N7v+Nba+HdpDSWulxc2Ysgvd+5YKIBT9v22NzVrk+JfU5bM1JXwirH3bN3Wbc3rZrwPGS4zlfgX5tqOaMTYSbl8LBLf6VWyf6MdsSYApSuoEHP9jF21sP8KPLJjItOSHYw+l+amtg3dOubDFuSNPnhIW7kuTHLnUlyWd+K3DXz1vvfo6/BOKHd/z5JlwKG56DC/7P7SnTkzUuOW6r8Ii2BSjgloVMuPuWHYwgJdvXhPCse90y1ZKr4fEr4DMPuKRwfxzY4pa7jhyGG5+B5X+A7W/B+T/ycuTtV196fOqtbX9s7/4w7iK3a/H5P4YIP4sRaqpcpZg/Qcew6TBookugbWuQcqzkeED7/t0Jj3A9n0KUEme7uF0Hy/jVfz7l4ilDuGXOyGAPp3va+V+XUNkwYbYpXpUk569zuQNNNQhrj/SboKIIPn01MM/XlW147uSSY69F93HLBsFo6lZX56b244a5oKxfqlu2GpYOz98GH/6p9R4uWe/Dwxe6pYXbXnPB+9jzXV+Rkn2d8zrayt/S4+akfw6OFMC2N/x/TP4Gd82W8lHqGQNpC2HvajiwtW1j2/zvk0uOuxEFKV3cQ8uzCA8z/PjyycpD8UrmYhckjL2w9XO9KEnO3+C+6QTqv2/qWa6jZsaSwDxfV9VaybGXkmdB7prO7/65/mm3NHD+jyCqtzvWqx/c/BJMvBKWfR9e+1bzU//rn4UnrnK5Gne8dXzJsP7Dvz7vI9T4W3rcnNHnQp8hbknFX/UVXP4EKeD+DoZFuH9v/FVdAW/+AAZPbrrkuBvwNEgxxiwwxnxqjNlhjDkpM8cYE2+MedkYs84Ys8kYc5uX4+luDpVV8sKaXD47fTgD46KDPZzuqbwAtr4GU6/3b5o30CXJtdVuan3I1I4/V72wcDfNv/O/UJwbuOftaj78I5Tua7nk2CvJs6C63OUbdZbKMnjrx265aco1J94XGQNX/9PlNHzyoEumrCo/fr+18P5v4F+fd11zb38DElKO3z94kpud2b6sc15LW7Wl9Lgp4RGQdoPbPbk037/H5Kx075G/1TB9BsIpC9zScq2fSfIr6kuOf958yXEX59n/mcaYcOB+4CJgInCDMaZxjdqXgM3W2mnA2cBvjTHqPuanJz7eQ2VNHYvmqu29ZzY852ZG0hf6/5h533Atqd/4Tsfbnx/c6qbVh07r2PM0lnYjYAPb6bIraUvJsReCsdngh3+Asvzmg7KwMJendNGvYft/4NFLoeyAm+15+R7XfXXKNa4aKLZRDyZj3JLPrnf9/4DtLPWlxy21wvdH2k2u3Hzd062fa61LyPZ3FqVe+k2ugZw/wV5pPrz/W/9KjrswLxNnZwI7rLW7AIwxTwNXAJsbnGOBOOPWKfoAh4GutftRkFRU1/LEij2cP2EQYwZ10lp6T5Sx2K3XD57k/2NOKEl+0f9kxKbUJ80GciYF3IzPyHluyWfeN73p7RLK3vaVGgcr0TMhGfoOd0FKW/p21NW6PIf6pRp/FWXDR392pa6tVYjNutMlaD+/yDWs6z/azbrN+4b7e93c35Ux82Ht466ipb3LKjWVbqytie4LcYP9e872lB43ZcAY1zE4Y7HL52np/5mibBcQtjVIGTMfeg9ye+y0Vhb+3q/aVnLcRXkZpAwHchrczgUa/xf7C7AU2AfEAddZawPQG7j7e2FtLofLq/i8Ng/0Tt46lwx4cTvaYqffBKsehPd+2bEgJX8DRPZqe9mkP9Jvghe/4DZNbO+HSle0f7ObIZv3zROXLDpb8kz3bbstXr7HNRe79nEYfY7/j1v2Q8C4/Vv8Mf4S15X0yWth13tw6R9gRiur8aPOdjkVO5a1/+/Tv+50iaCtMnDhz+D0L7Z+antLj5uSvhCWfgVyP2k52GtuU8HW1C8rffhH+IsfsyltLTnugrwMUpoKMxvPfV8IZALnAqOBZcaYD6y1J+zoZIy5E7gTICUliP+ohIi6OstDH2QxNSmemaltLH8U/2UshvBomHJ12x8bFu4e99YP3WZ0vQe0bwz5690sjhfrzRMuh1e/6V5nTwpSMp6AsEiXOxRMybPdTFtxLsQntX5+7ho39sjermz48j/7lu1a0bDk2J/r1Es6Fe5a7pYfhvoxkxfT172m9pYilx2Era/ApM+4JYyWbHrRlY4XZcOFP23+/4+OlB43ZdJn4PV73X+H1oKUqD5tm4Gtd+a3YWiaW1pqSWSsf8n8XZyXQUou0LAzUhJuxqSh24BfWGstsMMYkwWMB07oGW2t/QfwD4AZM2b0+D3O39qyn6xD5fz5hnRV9HilusJVMky47OT1d381zDsYf0nbH19X52ZSGic5BkpULzfLs+E5uPhXEB3nzXVCSU2V63cx7iLX/yKY6j/kcla2HjxY60qHew+CO9+Fl74I/77b5dac9e3mlx4alxy3Vd+hbWuDPvZ8VzFVsq/tJfPrn4G6GjjrPhg0vuVzJ30G3vwerPgrlOTCVQ82nRTb0dLjxqLj3LU3vuhye5pbdsteCUkz2vflIrpPx2ZfuxkvU9o/AcYaY1J9ybDX45Z2GsoGzgMwxgwGxgHaw7wVD36wi+EJsVw0uZnGYtJxn77meom0JWG2sWHp7ht7e5Mji3a7bqb+fIttr/Sb3KaJm1707hqhZNsbrt9FKJRrDpnilvL82cdn4wuQu8q1348fDjc+5za/e/dn8NKXm09Wbark2EvtLUW21s3oDZ/ReoAC7sN/wc9dA8Utr7guyuWHTj6vo6XHTUlbCFWlsOXlpu+vKIEDm47veC0d4lmQYq2tAb4M/AfYAjxrrd1kjLnLGHOX77SfAHOMMRuAt4F7rbVN/E2TemuzC/lkdyGL5qYSEa42N57JXOJ6iaR2YMOvyBjXR6KteQf18je4n152g0w6zW2a2FN6pmQucf0uRp8b7JFAeKQrB85uZUfkqiMup2TI1OPLOxFRcOVf3axD5mLX/bWi5MTHtVRy7JX2liLvW+tas7fWMLGx07/o8nPyN7j2/gU7T7y/o6XHTRkxx+WBZDTTz2TvardU09EtLATwuE+KtfY1a+0p1trR1tqf+o49YK19wPf7PmvtBdbaKdbaydbadmwz2bM89MEu+sZEcO1pbdhjRNqmeC/seNv1EuloLkjyLPdNtqay7Y/NW+/apw9qx7q2v+o7XeasgEPbvbtOKCjNd30u0m5wCYqhIHmW+4Bt2JOksY//4pY0FvzixL+PxsA534Er7nd5F/+86MSOr62VHHuhvaXIGYshIrZ9yxwTL4dbXnYbNj48//jM1OFdgSk9bswYFyzu/gAOZ518f84qwJy8W7q0i76KdyHZBUd4Y2M+C2ePoE90iPwj2x2tewqw/iUltiZ5FtRWukqhtspfDwPHeb+/zrTrXTDUlm6aXdG6p9033LQ2flv3UvIssLWuNX9TSvbB8t+7nWebW7JIvwlufBYK97iS4f2b2lZyHGhj5rtlSn+WscAlt254wQUb7d0BOHmm64AbE++WfjYvdQm80PHS46ZMuxEwkPnkyfdlr3AzSt2wRX0wKEjpQh750LXAv1V79HjHWvdhPXKe6yXSUR1p2pW/IfD9UZoSN8R928x8qvPbtHeW+pyH5Nmu30WoSPZ9227u78dbP3bJpPNb2WZhzHlw++suCHv4QnjhDtpUchxIDUuR/bHlFagsdjN6HdF/tNuHaMgUePZmF9wFqvS4sfjhbskw88kTtxCoq3W7W7e19FiapSCliyg6UsUzn+Rw+bThDO7bw3eu9VLOKjdN3NF/MOvFDYbEka3nHTRWdtBtathZu5Om3+SWBnb+17/zywtcR9J/XtJ0wmKoyf0ECra3PefBa7GJMHBC03lLuWtc4uvpX3J/h1ozZIqbTUhIcUHPGV9tW8lxoDQsRfZH5mI35pHzOn7t3gPc0s/4S9yWB4Fe6mko/Sa3DJf13vFjBza7pFoFKQGjIKWLWLIym6PVtXz+zAB8u5fmbXvdfQtsT8lwc5Jnu+CnLS3y833LQ15W9jQ09kK3iWLGE62fW7ATHj7fvaa9q90SQ+OExVCT8YSrpJl0ZbBHcrLkma5yp65BX4yGJcfzvuH/c8UnuRmVy/4Ec78e+LH6y99dkYuyXbO4tIWBy5uJjHXJtJ/5B5z5rcA8Z1PGXQwxCScmndfPiAVjq4VuSkFKF1BZU8s/P9zNmacMZPwQrXN6avtbkHJ6YNeTk2dC+QEobCLJrjnH2uF30kxKRJTbRPHT190sSXNyPnHJiUeL3DfWW15x+QcPne9/DkJnqyp3fS0mfSY0e8GkzIaKYjj06fFjDUuO2zrmmHg49Rbvc5la4m8pcqZv76hA5H81FBYO065rfxNFf0TGwNRrXSny0UJ3LHsl9BkMCSO8u24PoyClC3gpYx+Hyiq5Uy3wvVWS5779BTrRLsXXL6EtH+L5G9wUeHsbybVH+kK3meKGZ5u+f8vL8Nil7kNz0TL3bTH5NPd7bIIvYfGlzhuvvzYvdVPwgVrCC7TGeUtNlRx3Nf6UItfVuaWeUWcFd3uCjkhb6BLjN77gbuf4NhVUk82AaTVIMcZcaoxRMBMk1loe/GAXE4b25YwxQe6Q2d3Vf+sL9Dr2wPFuQ7S25KXkr++cpNmGBk9yDegyFp+8NLXiAXjmczB4Mtzx9onJp/1Hw6K33HifvQU+/mvnjrs1mUtcX4sRc4I9kqb1GwW9BhzPS2mu5LgrMcYl87ZUirxnuVvuCaVqq7YaOg0GT3H/z5TmQ9Ge419KJCD8CT6uB7YbY35ljJng9YDkRO9uO8j2A2V8fl6qWuB7bccy9+1v0MTAPm9YuOuZ4O9MSmWZy/Ho7CAF3DfD/RuPl0zX1cEb34U37nV5Ore83PQUeu/+cMtSmHCp21Pl9ftOrHoIlsNZrp9F2o2h++3WGPftO2elfyXHXcXYC1ouRc5YDNHx7u9MV2WMm4HclwGr/+mOKWk2oFoNUqy1NwHpwE7gn8aYj40xdxpjQnBxt/t58P1dDOkbw6VT27gPhrRNbTXsfMcl/HnxYZY8y2X+Hy1q/dz9GwHbeUmzDU252m2qmLnE9a947hZYcT/MusslI0b1av6xkbFwzWMw+0uw8m+uDLT6aOeNvSmZTwLG19cihKXMco3HXr7Hv5LjrqClUuSKYrcMN+Wzge0GGwxTrnXbXyz/vWvBH4wvF92YX8s4vl2JXwCeBoYCnwHWGmO+4uHYeryNe4v5aGcBt50xkqgIrbh5KmeV+9YXqI3IGkuZBVhXDdOaY+3wg/CPXWyi+2a7/ll4/AqXh3Lhz+GiX/q39BAWDgt+Bgt+CVtfbX5Plc5QV+uClNHnur4Woaz+2/f2N/0vOQ51LZUib/wX1BwNvZLw9ujd321YWVsJw6a7JHQJmFbblhpjLgNuB0YDTwAzrbUHjDG9cHvy/NnbIfZcS9ftIyo8jOtndtGksq5kxzL3rW/U2d48//BTwYS5vIPWEnPz1rly4LbuIhso6Te5RMC8dXDtY27poa1m3+UCgxfugL/McDkXgTD6XLjwp27fm9ZkvedyOy74SWCu7aWhaRAe5Upa21JyHOqa2xU5c4nrDzNsetCGFlDpn4MtS1V67AF/eqtfA/zeWvt+w4PW2iPGmNu9GZYArNhVQFpKAvGxfvyDLB3jRelxQ9FxLunUn86z+etd6XGwcihSz4Zz/h+MOud4R9T2mHAZ3PoarPp72/ZxaU5VuXuuQ9vc0lNr/60yFrsP/XEXd/zaXouMgQt/Bv3HhGaZdHuNme+ClB1vwfSb3bGDn7rmehf8NHTzhNpqzHkw75sd2zVdmuRPkPJDIK/+hjEmFhhsrd1trX3bs5H1cCUV1WzcW8yXzx0b7KF0f/Wlx+d73EI8eZZbfqitaX6Du9pqOLDF5YAES1gYnPXtwDxX0qmQ9I/APBfA2ifgla+5zfQWPtf8bNPRQtduPdj9Qtpi5ueDPYLAa1iKXB+kZCx2s5ZTrwvu2AIpLBzO+36wR9Et+ZPo8BzQoBUitb5j4qFPsg5TZ+H0USo79pxXpceNpcyG6nI4sKn5cw5+CrVVrrRRTjb9c77N9HYf30yvKRuedzkCodobpadoXIpcW+02ejxlAfQZGOzRSRfgT5ASYa2tqr/h+12ZQR5bsauAqIgw0lMSgj2U7s+r0uPG6nejbWqflnr59Z1mVSHQrDHnwW2+zfQeWeCqshrLXOL6VyjYC76Gpcg73nLdlxU8ip/8CVIOGmMur79hjLkC6AI7inVtH+8qID05gZjILtrMqavwuvS4ofhkFwy1lJeSt97tMePFzq3dydCpbjO9+CRYcrWv1Nhn/ybXtyJ9YffJeejKGpYiZyx2+xF5PWsp3YY/QcpdwHeNMdnGmBzgXuAL3g6rZys+Ws2mfSWcPlpLPZ7zuvS4IWPcbEpLQUr+ereO31U7jXam+CS4/Q0YcQb8+25495euU27GEte3Ysq1wR6hwPFS5I3/gm1vuD11/KnOEsG/Zm47rbWzgYnARGvtHGvtDu+H1nN9knUYa2G28lG853XpcWPJs6A4B4r3nnyfta5HipZ6/BcTDwufh2k3wLs/g5e+DOufdn0reuv/n5Ax9nzXMr6upmu3wZdO5091D8aYS4BJQEx9a3ZrbTdoiRiaPvblo6QlJwR7KN3f9rfctzyvSo8bS2mwmVz8VSfeV7jbzeoEo9NsVxYRBVf+zW1S994v3bH0zwV3THKi+lLk4TNg0Phgj0a6EH+auT0A9ALOAR4CrgZCdE/27mHFrgJOTUlUPorXOqv0uKEhUyEi1i0zTW4UpBxLmp3SeePpLoyBc74LiamukmT0ucEekTQ0eJLbmmDyZ4M9Euli/MlJmWOtvRkotNb+GDgdSPZ2WD1X8ZFqNueVaKmnM3RW6XFD4ZGu+2xOEzsi528AEw6DJnXeeLqbtBvgqr8334dGgsMY+Mzf3LKPSBv4E6RU+H4eMcYMA6qBVO+G1LOtzCrw5aP0C/ZQur/OKj1uLHmmq+KpKj/xeN56GDiu6zQfExHxmD9BysvGmATg18BaYDfwlIdj6tFW7DpMdEQYaeqP4q3OLD1uLGU22FrYu/bE4/nrlTQrItJAi3Oixpgw4G1rbRHwgjHmFSDGWlvcGYPriVbsKuDUEYlERygfxVOdWXrcWJJvP5yclZA6z/1edhBK85Q0KyLSQIszKdbaOuC3DW5XKkDxTtGRKrbkKx+lU3R26XFDvfrBgHEn9ktR0qyIyEn8We550xjzWWPUutFrK339UdTErRN0dulxY8kz3WxOnW9bLAUpIiIn8SdI+TpuQ8FKY0yJMabUGFPi8bh6pI93FhATGcbUpPhgD6V7qy89DmalQcpsqCiCQ9vc7bz1rs9HbGLwxiQiEmJardOz1sZ1xkBE+Sid5ljp8QXBG0Nyg6Zug8YraVZEpAmtzqQYY85s6k9nDK4nKSyvYmt+KacrH8V7wSo9bqj/GIjt54KUyjIo2KkgRUSkEX86Hn2rwe8xwExgDaCWjgG0MqsA0H49nqsvPZ50ZXB3yDXGzabkrHS79mJV2SMi0og/yz2XNbxtjEkGfuXZiHqoFbsOExsZztSkhGAPpXsLZulxYymzYNvrsOsdd1szKSIiJ/AncbaxXGByoAfS063YVcCMkYlERbTnP4n4LZilx43V56WseRR69Ye+w4I6HBGRUOPPBoN/BqzvZhiQBqzzcEw9TkFZJVvzS7lsmj6kPBfs0uOGhqVDWKRr4jbq7OAuP4mIhCB/clJWN/i9BnjKWvuhR+PpkVZlHQaUj+K5Y7se/yjYI3EiY2HoNNi7Wks9IiJN8CdIeR6osNbWAhhjwo0xvay1R7wdWs+xYleBLx8lyP1RKkvhwBbXaKyj8tZBn8EQN6Rjz1NXB5tfhKoA/HXbl+F+BrP0uLGU2S5IGTot2CMREQk5/gQpbwPnA2W+27HAm8AcrwbV03zsy0eJDA9yPsoHv4Xlv4cz7oHzfgRh7RzPyr/D6/fCqLPg5pc6NqbN/4bnb+/YczTUb1RwS48bGzsfVj0YmMBQRKSb8SdIibHW1gcoWGvLjDG9PBxTj3KorJJt+8u4Mn14sIfiduUNj4IP/wjFuXDl3yAi2v/H19XBsu/Dx39xsyi73oPCPZA4ov1jylgMfZPg9teBAORs9OofWrkfo86G+7IhMibYIxERCTn+BCnlxpjp1tq1AMaYU4Gj3g6r5wiZfBRrXdfTaddDv9Hw1g+hNB+uW+w2xGtNdQW8+AU38zHzTjj9S/DHNFj3FJx9X/vGVJwLO/8LZ37LtYzvrhSgiIg0yZ/5/K8BzxljPjDGfAA8A3zZ01H1IB/vLKBXVDhThgc5H6VkLxwtdAmcc78Gn30Ycj+BRy6Ewt0tP/bIYXj8ChegXPBTuOhXkDjSzRJkLjm+iV5brXsKsJB2Y/seLyIiXVqrQYq19hNgPHA38EVggrV2jdcD6ylW7CrgtJH9gp+Pkufbhbc+gXPK1fC5f0PZfnhovlsKasrhXfDwfJeUes2jMOfLx5dT0m+ComzY/UHbx2MtZCyBkfOgX2rbHy8iIl2eP3v3fAnoba3daK3dAPQxxnzR+6F1fwdLK9l+oCz4Sz3glnowMHjS8WMjz4BFyyAiBh69BD5948TH5K5xAcyRArhlKUz6zIn3j78EYuLdbEpb7fkICrNcoCMiIj2SP1/fP2+tLaq/Ya0tBD7v2Yh6kOP79fiR8+G1vPVu07uo3iceHzgO7ngLBpwCT98Anzzsjm99zQUu0X1g0VuulLaxyFiYfDVsfgkqits2nozFEBUHEy5v3+sREZEuz58gJcyY4+UQxphwIMq7IXUDxbl+5WGs2FVA71DIRwHI39D8Bndxg+HWV11/kVe/Dk9eB88shMETXYAyYEzzz5t+E9RUwMZ/+T+WylKX3zL5KohSIZmISE/lT5DyH+BZY8x5xphzgaeA170dVhd25DD8aTpkPNHqqR/vLOC01H5EBDsf5chhKM5uuetpdB+4bgnMuB22vQGnXAS3vAJ9Brb83MPSXV+SjMX+j2fTi1B9REs9IiI9nD+fjvfiGrrdDXwJWI9r6CZNKcyC2krY9W6Lpx0orWDnwfIQyUfZ4H42N5NSLzwCLvkd3P0RXPeEf7McxrhgY+9qOLDVv/FkLHHLS0mn+Xe+iIh0S/5U99QBK4BdwAzgPGCLx+Pquor3up85q1o8beUu1x/l9JAIUnyVPf7sH2N8ybVh4f4//9Tr3M7DmX7MphzaDjkrIG1haDVdExGRTtdskGKMOcUY8wNjzBbgL0AOgLX2HGvtXzprgF1OiS9IKcl1uSnN+HhXAX2iI5g0LAR2483fAHHDoPcAb56/9wA4ZQGsewZqq1s+N3MJmHDXVE5ERHq0lmZStuJmTS6z1s611v4ZqO2cYXVhDQOTnJXNnrZiZwGnjUwMfj4KuMqe1pZ6Oir9Jig/ANuXNX9ObQ1kPuX2s+noxoQiItLltfQJ+VkgH3jHGPOgMeY8ArJ5SjdXnAsJIyCyF2Q3HaTsLTrKrkPlzB3bStJpZ6g+Coe2+bfU0xFj5rv9fFrqmbLzv1CWr4RZEREBWghSrLUvWmuvw3WbfRf4H2CwMeZvxpgQ2us+xJTsdS3hh5/a7EzKh9sPATB3jEfLK22xfzPYWhgyxdvrhEe43JRtb0DZwabPyXjCbQA49kJvxyIiIl2CP4mz5dbaJdbaS4EkIBNo545xPUDxXohPguRZLtejsuykU5bvOMSAPtGcMrhP6893tMiVCLf0p6Kk/eOtT5r1erkH3AxJXQ2sf+bk+8oL4NPXYer1EKE2PCIi4t8uyMdYaw8Df/f9kcZqq6E0D/oOh+SZboZi31pIPfPYKXV1lg93HGLe2AGY1qpX1j4OS7/i37VveBrGXdT2Meevd63rE0a0/bFtNXCcKyvOWOx2SW74+jc8C3XVkL7Q+3GIiEiX0KYgpa2MMQuAPwLhwEPW2l80uv9bQP2nUgQwARjoC4a6ntI8wLqZlKQZ7lj2yhOClE/3l1JQXsUZ/iz1bHoR4lPcpn0teednrvV8e4KUvPUuH6Wzyn3TFsIrX3PB2/BT3TFrXeAyLP3EvYNERKRH8yxI8bXPvx+YD+QCnxhjllprN9efY639NfBr3/mXAf/TZQMUON4jJX44xCbCwAkn5aV8uMPlo7QapFSVw+4P4bQ7YNYXWj43ZxXseMu14g9rQ7VQXS3s3wQzbvP/MR01+Sp44zsuKKkPUvLWwf6NcPFvOm8cIiIS8rysf50J7LDW7rLWVgFPA1e0cP4NuJb7XVd9+XHfJPczeSbkrjphH5/lOw4xamBvhiW00rQ36wPXuXbs+a1fd+x8KD8IeZltG2/BDqg56n1lT0Mx8TDxctjwgqssAlfxEx4NU67uvHGIiEjI8zJIGY6vAZxPru/YSYwxvYAFwAsejsd7Jb4gJd73MlNmu91/D30KQGVNLSt3HWaeP0s9O5a5MuYRZ7R+7ujzfI95q23jzevEpNmG0m+CymLY8gpUV8D6Z2HCpW72SURExMfLIKWpJAfbzLmXAR82t9RjjLnTGLPaGLP64MFmyldDQfFeN1MQHeduJ89yP7NXAJCRXcTR6trWl3qsdU3PUs+EiOjWr9tnoMvnaKlRWlPy17kZjAGntO1xHTViLiSkuJLjT1+FiiKXqyIiItKAl0FKLpDc4HYSsK+Zc6+nhaUea+0/rLUzrLUzBg4MgQZozSnZe3ypB6DfKOg14Ng+Ph/uOESYgdmjW9mvp2AHFO2BMX4s9dQbM99t4nekDSk9eeth0AQIj/T/MYEQFgZpN0HW+/DB7917Nurszh2DiIiEPC+DlE+AscaYVGNMFC4QWdr4JGNMPHAW8JKHY+kcxTnHl3rAVcwkz3Ib5uHyUaYlJ9A3ppWgoH5GZOx8/689dj7YOte11R/Wuj4unb3UUy/tBvdz/wb3e1s2LBQRkR7BsyDFWlsDfBn4D27X5GettZuMMXcZY+5qcOpngDetteVejaXTFO91PVIaSpkFh3dRWrCPdTlF/nWZ3bEM+o91nWv9NfxUl9Phb15KyV44erhzk2YbSkiBUWe539NuDM4YREQkpHnaJ8Va+xrwWqNjDzS6/SjwqJfj6BRVR9yHfnzSicd9eSk71vyXOpvYttLjtggLdwm0/pYiH0uanda26wTSBT91/VL6jQreGEREJGSFwBa83USJL92mcZAyNA3Coyjf8SGxkeFMT2mlgqUtpceN1Zci569r/dz89YCBQRPbfp1AGTIZpt8cvOuLiEhIU5ASKMW+auvGyz2RMTA0jfiCDGaN6kdURCtveVtKjxurL0X2p8onfwP0HwPRfuwfJCIiEgQKUgKlpL7bbNJJd5UNPpVTanZw5qi+LT9HW0uPG2tLKXLe+uAlzYqIiPhBQUqg1LfE7zvspLvWMY5oU825ffNafo72lB435k8p8pHDUJwNQ6a0/zoiIiIeU5ASKCW50HtQkzMgrxenAJBSvqHl52hP6XFj/pQi5/vGEazKHhERET8oSAmU4twTe6T4WGt5Y7flYOQwwnJXNvHABtpTetyYP6XI+SFQ2SMiItIKBSmBUry3yXyUbfvLOFRWSfmgU92OyLaZnQGqjrjS47EXdGwcjUuRm5K/AeKGQW8/eraIiIgEiYKUQLD25Jb4Pst3HAIgftw8Vx5cmNX0c+zuQOlxY62VIuetVz6KiIiEPAUpgVBRDFVlTS73LN9+kFEDepM4bq47kN3Mks/2N9tfetzYsVLkJpZ8qo/CoW2q7BERkZCnICUQinPdz0Y9Uqpq6liZddh1mR04AaL7uiWfxjpaetxYfSnyjiZKkfdvBlurpFkREQl5ClIC4ViPlOQTDmfmFHGkqtYFKWFhkHRa00FKIEqPGxszH3I/ObkU+VjSrIIUEREJbQpSAqF+JqXRcs/yHYcIM3D6qP7uQMpsOLAFjhad+PhAlB431lwpcv56iI6HhBGBu5aIiIgHFKQEQsleCIuAPoNPOPzhjkNMSUogvlekO5A8E7CQu/rExwei9Lix5kqR65NmjQnctURERDygICUQinMhbqgr//UpragmM6eIeQ13PR4+A0zYiUs+gSo9bqypUuS6Wti/SUs9IiLSJShICYQmeqSs2HWY2jrr8lHqRfeBwZMhZ8XxY4EsPW6scSlywQ6oOaqkWRER6RIUpARCSe5JlT0f7jhETGQY00cknHhuymzIXQO1Ne52IEuPG2tcipznS5pVjxQREekCFKR0VF0dlOxrMml2Zmp/oiPCTzw/eRZUl8P+jYEvPW6scSly/joIj4aB4wJ/LRERkQBTkNJR5QehtuqEbrP5xRXsOFDG3DH9Tz4/eZb7mbPKm9LjxhqWIueth0ETIDzSu+uJiIgEiIKUjiqpLz8+HqR86GuFf0I+Sr34JLdvTs4Kb0qPG2tYipy/QUmzIiLSZUQEewBdXnF9I7fjyz0f7jhE/95RTBjS9+TzjYGUWW4m5Whh4EuPG6svRV77GBw9rKRZERHpMjST0lH13WZ9yz3WWpbvOMScMQMIC2umF0nyLCjOgaz3A1963Fh9KXLW++62ghQREekiFKR0VHEuRMRAr34A7Ck4woHSyuNdZptSn5dSV+NN6XFjx5aTDAye5P31REREAkDLPR1VnOvyTHwdXDfnlQAwZXh8848ZMsWVHYM3pceN1Zci9x/jerWIiIh0AQpSOqpk7wk9UjbvKyE8zDB2cAvBQHgkjLvIzcB4UXrcWJ+Bblmp/xjvryUiIhIgClI6qngvjD7n2M3NeSWMGdiHmMjwFh4EXP2IxwNrZOFznXs9ERGRDlJOSkfUVkNp3gkzKZv2FTNxWBNVPSIiItImClI6ojQPsMd6pBwqq2R/SSWTFKSIiIh0mIKUjmjUI2WLL2l24lAFKSIiIh2lIKUjin3dZn09Ujbv8wUpmkkRERHpMAUpHXGsJb6bSdm0r4ThCbEk9IoK4qBERES6BwUpHVG8F2LiIToOcJU9E7TUIyIiEhAKUjqiZO+xpZ6jVbXsOlimpR4REZEAUZDSEcU5x5Z6Pt1fSp1V0qyIiEigKEjpiOLj3WY37SsGUPmxiIhIgChIaa+qI3D08LEeKZv3lRAXE0FSYmyQByYiItI9KEhpr5J97md9kJJXwsShfTG+jQZFRESkYxSktFdxjvvZdzi1dZateaVKmhUREQkgBSntVXK822zWoXKOVtcyaVh8cMckIiLSjShIaa/6lvh9h7NZ7fBFREQCTkFKe5XkQu9BEBHN5n0lRIYbxgzqE+xRiYiIdBsKUtqrOLdBO/xiThkcR1SE3k4REZFA0adqexXvhfgkrLVs3leipR4REZEAU5DSHtYea4l/sLSSgvIqVfaIiIgEmIKU9qgohqoyiB/OJiXNioiIeEJBSnsU57qffYezeZ8LUiZoJkVERCSgFKS0x7EeKcls3ldCSr9e9I2JDO6YREREuhkFKe1RP5MSP/xYO3wREREJLAUp7VGyF8IiKIvsz+6Ccu18LCIi4gEFKe1RnAtxQ9m6vxxrUWWPiIiIBxSktIevR8qxdvgKUkRERAJOQUp7lOQeq+xJ7BXJkL4xwR6RiIhIt6Mgpa3q6qBk37Gk2UnD4jHGBHtUIiIi3Y6nQYoxZoEx5lNjzA5jzH3NnHO2MSbTGLPJGPOel+MJiPKDUFtFbdwwtuaXaqlHRETEIxFePbExJhy4H5gP5AKfGGOWWms3NzgnAfgrsMBam22MGeTVeAKmxJUf5zGQqpo6lR+LiIh4xMuZlJnADmvtLmttFfA0cEWjc24E/mWtzQaw1h7wcDwtq61xSzmtKXaN3LYddcGJZlJERES84WWQMhzIaXA713esoVOARGPMu8aYNcaYmz0cT/OshVfugedvheqjLZ/r6zabUdSb6IgwRg3o7f34REREeiAvg5Smsklto9sRwKnAJcCFwPeNMaec9ETG3GmMWW2MWX3w4MHAjxRg4ATY/BI8fgWUFzR/XnEuRMSw5qBh/JA4IsKVeywiIuIFLz9hc4HkBreTgH1NnPOGtbbcWnsIeB+Y1viJrLX/sNbOsNbOGDhwYOBHagzM+TJc8xjsy4SH58PhXU2fW5yLjU9is5JmRUREPOVlkPIJMNYYk2qMiQKuB5Y2OuclYJ4xJsIY0wuYBWzxcEwtm3Ql3LIUjh6Gh+ZD7uqTzynZS1WvoRQdqWbisPhOH6KIiEhP4VmQYq2tAb4M/AcXeDxrrd1kjLnLGHOX75wtwBvAemAV8JC1dqNXY/JLymxY9BZE94FHL4Wtr554f/FeDoW72RxV9oiIiHjHsxJkAGvta8BrjY490Oj2r4FfezmONhswxgUqT10PTy+Ei34Js74AtdVQmkduQj+MgfFD4oI9UhERkW5LWZ/N6TMQbnkZxl0Mr38b/vP/fJU9lk8r+pLavze9oz2N8URERHo0fcq2JKoXXPcEvPEd+PgvkOUa4q4r6cPEEVrqERER8ZJmUloTFu6Wey78GeS7dJl1JX1U2SMiIuIxzaT4wxg4/UsQn8zhjx5jz44hSpoVERHxmIKUtph4Of8+PIXqHZs1kyIiIuIxLfe00ea8EgbGRTMoLibYQxEREenWFKS00aZ9JVrqERER6QQKUtqgqqaOHQfUDl9ERKQzKEhpg+0HSqmutUxSkCIiIuI5BSltsGlfCQATtNwjIiLiOQUpbbAup4i4mAhS+/cO9lBERES6PQUpbZCZU8S0pATCwkywhyIiItLtKUjx09GqWrbml5KWnBDsoYiIiPQIClL8tGFvMbV1lvSUhGAPRUREpEdQkOKnzJxCAM2kiIiIdBIFKX7KzCkiuV8s/ftEB3soIiIiPYKCFD9lZheRlpwY7GGIiIj0GApS/LC/pIJ9xRVa6hEREelEClL8kJFdBCgfRUREpDMpSPFDZk4RkeFG7fBFREQ6kYIUP2TmFDJxaF9iIsODPRQREZEeQ0FKK2rrLBtyi7XUIyIi0skUpLRi+4FSyqtqSVMTNxERkU6lIKUVmceSZlV+LCIi0pkUpLQiI7uIhF6RjOzfK9hDERER6VEUpLSifudjY7TzsYiISGdSkNKCssoath0o1aaCIiIiQaAgpQXrc4uwVk3cREREgkFBSgsyc4oABSkiIiLBoCClBZnZRaQO6E1Cr6hgD0VERKTHUZDSDGstGTlFmkUREREJEgUpzdhXXMHB0koFKSIiIkGiIKUZ9U3cVNkjIiISHApSmpGZU0hURBjjh2jnYxERkWBQkNKMzJwiJg/rS1SE3iIREZFg0CdwE6pr69iwt1j79YiIiASRgpQmfJpfSkV1nXY+FhERCSIFKU3I8DVxS1dlj4iISNAoSGlCZnYR/XtHkZQYG+yhiIiI9FgKUpqQmVNIeop2PhYREQkmBSmNFB+tZufBcjVxExERCTIFKY2szy0CUGWPiIhIkClIaSQzuwhjYGpyfLCHIiIi0qMpSGkkI6eI0QP70DcmMthDERER6dEUpDRgrSVTOx+LiIiEBAUpDeQcPsrh8iptKigiIhICFKQ0kJFTCKCZFBERkRCgIKWBzJwiYiPDGTc4LthDERER6fEUpDSQmVPElOHxRITrbREREQk2fRr7VNbUsmlfiTYVFBERCREKUny25JVSVVOnfBQREZEQoSDFJzPbJc2qskdERCQ0KEjxycwpYnDfaIbGa+djERGRUOBpkGKMWWCM+dQYs8MYc18T959tjCk2xmT6/vzAy/G0ZFhCLBdPGRqsy4uIiEgjEV49sTEmHLgfmA/kAp8YY5Zaazc3OvUDa+2lXo3DX99eMD7YQxAREZEGvJxJmQnssNbustZWAU8DV3h4PREREelGvAxShgM5DW7n+o41droxZp0x5nVjzKSmnsgYc6cxZrUxZvXBgwe9GKuIiIiEGC+DFNPEMdvo9lpghLV2GvBn4N9NPZG19h/W2hnW2hkDBw4M7ChFREQkJHkZpOQCyQ1uJwH7Gp5grS2x1pb5fn8NiDTGDPBwTCIiItJFeBmkfAKMNcakGmOigOuBpQ1PMMYMMcYY3+8zfeMp8HBMIiIi0kV4Vt1jra0xxnwZ+A8QDjxird1kjLnLd/8DwNXA3caYGuAocL21tvGSkIiIiPRApqvFBDNmzLCrV68O9jBEREQkAIwxa6y1M5q6Tx1nRUREJCQpSBEREZGQpCBFREREQpKCFBEREQlJClJEREQkJClIERERkZDU5UqQjTEHgT0ePf0A4JBHzy1N03ve+fSeB4fe986n97zztec9H2GtbXLPmy4XpHjJGLO6uVpt8Ybe886n9zw49L53Pr3nnS/Q77mWe0RERCQkKUgRERGRkKQg5UT/CPYAeiC9551P73lw6H3vfHrPO19A33PlpIiIiEhI0kyKiIiIhCQFKYAxZoEx5lNjzA5jzH3BHk93ZYx5xBhzwBizscGxfsaYZcaY7b6ficEcY3djjEk2xrxjjNlijNlkjLnHd1zvu0eMMTHGmFXGmHW+9/zHvuN6zz1mjAk3xmQYY17x3dZ77iFjzG5jzAZjTKYxZrXvWEDf8x4fpBhjwoH7gYuAicANxpiJwR1Vt/UosKDRsfuAt621Y4G3fbclcGqAb1hrJwCzgS/5/n7rffdOJXCutXYakAYsMMbMRu95Z7gH2NLgtt5z751jrU1rUHYc0Pe8xwcpwExgh7V2l7W2CngauCLIY+qWrLXvA4cbHb4CeMz3+2PAlZ05pu7OWptnrV3r+70U9w/4cPS+e8Y6Zb6bkb4/Fr3nnjLGJAGXAA81OKz3vPMF9D1XkOL+wc5pcDvXd0w6x2BrbR64D1RgUJDH020ZY0YC6cBK9L57yrfskAkcAJZZa/Wee+8PwLeBugbH9J57ywJvGmPWGGPu9B0L6Hse0cEBdgemiWMqeZJuxRjTB3gB+Jq1tsSYpv7aS6BYa2uBNGNMAvCiMWZykIfUrRljLgUOWGvXGGPODvJwepIzrLX7jDGDgGXGmK2BvoBmUtzMSXKD20nAviCNpSfab4wZCuD7eSDI4+l2jDGRuABlibX2X77Det87gbW2CHgXl4ul99w7ZwCXG2N245bszzXGLEbvuaestft8Pw8AL+LSJwL6nitIgU+AscaYVGNMFHA9sDTIY+pJlgK3+H6/BXgpiGPpdoybMnkY2GKt/V2Du/S+e8QYM9A3g4IxJhY4H9iK3nPPWGu/Y61NstaOxP0b/l9r7U3oPfeMMaa3MSau/nfgAmAjAX7P1cwNMMZcjFvPDAcesdb+NLgj6p6MMU8BZ+N2ydwP/BD4N/AskAJkA9dYaxsn10o7GWPmAh8AGzi+Vv9dXF6K3ncPGGOm4hIGw3FfBJ+11v6vMaY/es8951vu+aa19lK9594xxozCzZ6ASx150lr700C/5wpSREREJCRpuUdERERCkoIUERERCUkKUkRERCQkKUgRERGRkKQgRUREREKSghQR8ZQxpta3S2r9n4Bt8maMGdlwV20R6V7UFl9EvHbUWpsW7EGISNejmRQRCQpjzG5jzC+NMat8f8b4jo8wxrxtjFnv+5niOz7YGPOiMWad788c31OFG2MeNMZsMsa86evyKiLdgIIUEfFabKPlnusa3FdirZ0J/AXX9Rnf749ba6cCS4A/+Y7/CXjPWjsNmA5s8h0fC9xvrZ0EFAGf9fTViEinUcdZEfGUMabMWtunieO7gXOttbt8myDmW2v7G2MOAUOttdW+43nW2gHGmINAkrW2ssFzjASWWWvH+m7fC0Raa/+vE16aiHhMMykiEky2md+bO6cplQ1+r0W5diLdhoIUEQmm6xr8/Nj3+0e4nWwBFgLLfb+/DdwNYIwJN8b07axBikhw6BuHiHgt1hiT2eD2G9ba+jLkaGPMStwXpht8x74KPGKM+RZwELjNd/we4B/GmEW4GZO7gTyvBy8iwaOcFBEJCl9Oygxr7aFgj0VEQpOWe0RERCQkaSZFREREQpJmUkRERCQkKUgRERGRkKQgRUREREKSghQREREJSQpSREREJCQpSBEREZGQ9P8BcDS/zihQprUAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.figure(figsize=(9,6))\n",
    "plt.plot(GRU_history.history['accuracy'])\n",
    "plt.plot(GRU_history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAikAAAGDCAYAAADu/IALAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABWGklEQVR4nO3dd3yV5f3/8deVkx1IAhlASAh7byIoOHBvwY111lW1rlrraL/9dWiHtnW1VqvWqrWKqKi4cCGCKELYe68wQyAJELKv3x/XAQKEkIRzcp8k7+fjkcfJuc997vPJcZz3uaax1iIiIiISasK8LkBERESkOgopIiIiEpIUUkRERCQkKaSIiIhISFJIERERkZCkkCIiIiIhSSFFRBqcMaajMcYaY8Jrce4Nxphvj/U6ItL4KKSISI2MMWuNMaXGmORDjs/1B4SOHpUmIk2cQoqI1MYa4Kp9d4wx/YAY78oRkeZAIUVEauO/wHVV7l8PvFb1BGNMgjHmNWNMrjFmnTHm/4wxYf7HfMaYvxpjthtjVgPnV/PcfxtjNhtjNhpjHjXG+OpapDEmzRgzwRizwxiz0hhzS5XHhhpjso0xhcaYrcaYJ/zHo40xrxtj8owx+caYmcaYNnV9bREJPIUUEamN6UC8MaaXPzxcCbx+yDl/BxKAzsApuFDzY/9jtwAXAIOALOCyQ577KlAOdPWfcxZwcz3qfBPIAdL8r/FHY8zp/seeBp621sYDXYBx/uPX++vOAJKA24C99XhtEQkwhRQRqa19rSlnAkuBjfseqBJcHrbW7rLWrgX+BlzrP+UK4Clr7QZr7Q7gT1We2wY4F7jXWrvHWrsNeBIYU5fijDEZwInAg9baYmvtXOClKjWUAV2NMcnW2t3W2ulVjicBXa21FdbaWdbawrq8togEh0KKiNTWf4EfATdwSFcPkAxEAuuqHFsHtPf/ngZsOOSxfTKBCGCzv7slH/gXkFrH+tKAHdbaXUeo4SagO7DU36VzQZW/6zNgrDFmkzHmcWNMRB1fW0SCQCFFRGrFWrsON4D2PGD8IQ9vx7VIZFY51oEDrS2bcd0pVR/bZwNQAiRbaxP9P/HW2j51LHET0NoY07K6Gqy1K6y1V+HCz2PAO8aYOGttmbX2d9ba3sBwXLfUdYiI5xRSRKQubgJOs9buqXrQWluBG+PxB2NMS2NMJnAfB8atjAPuNsakG2NaAQ9Vee5m4HPgb8aYeGNMmDGmizHmlLoUZq3dAHwH/Mk/GLa/v97/ARhjrjHGpFhrK4F8/9MqjDGnGmP6+busCnFhq6Iury0iwaGQIiK1Zq1dZa3NPsLDdwF7gNXAt8AbwMv+x17EdanMA2ZzeEvMdbjuosXATuAdoF09SrwK6IhrVXkP+I219gv/Y+cAi4wxu3GDaMdYa4uBtv7XKwSWAN9w+KBgEfGAsdZ6XYOIiIjIYdSSIiIiIiFJIUVERERCkkKKiIiIhCSFFBEREQlJCikiIiISksK9LqCukpOTbceOHb0uQ0RERAJg1qxZ2621KdU91uhCSseOHcnOPtIyDSIiItKYGGPWHekxdfeIiIhISFJIERERkZCkkCIiIiIhqdGNSalOWVkZOTk5FBcXe11K0EVHR5Oenk5EhHaSFxGRpq1JhJScnBxatmxJx44dMcZ4XU7QWGvJy8sjJyeHTp06eV2OiIhIUDWJ7p7i4mKSkpKadEABMMaQlJTULFqMREREmkRIAZp8QNmnufydIiIiTSakeCkvL4+BAwcycOBA2rZtS/v27fffLy0trfG52dnZ3H333Q1UqYiISOPRJMakeC0pKYm5c+cC8Nvf/pYWLVpw//3373+8vLyc8PDq3+qsrCyysrIaokwREZFGRS0pQXLDDTdw3333ceqpp/Lggw8yY8YMhg8fzqBBgxg+fDjLli0DYPLkyVxwwQWACzg33ngjI0eOpHPnzjzzzDNe/gkiIiKeanItKb/7cBGLNxUG9Jq90+L5zYV96vy85cuX8+WXX+Lz+SgsLGTKlCmEh4fz5Zdf8stf/pJ33333sOcsXbqUr7/+ml27dtGjRw9uv/12TTcWEZFmqcmFlPqqtBaAsAAOTL388svx+XwAFBQUcP3117NixQqMMZSVlVX7nPPPP5+oqCiioqJITU1l69atpKenB6wmERGRxqLJhZT6tHgArM7dTaW1dE1tGbBa4uLi9v/+61//mlNPPZX33nuPtWvXMnLkyGqfExUVtf93n89HeXl5wOoRERFpTDQmxS8qPIyS8sqgXb+goID27dsD8MorrwTtdURERJoKhRS/yPAwKiot5ZXBCSoPPPAADz/8MCNGjKCioiIoryEiItKUGOsfi9FYZGVl2ezs7IOOLVmyhF69eh3TdQv2lrEubw9dU1sQGxnavWCB+HtFRERCgTFmlrW22rU4gtaSYox52RizzRiz8AiPX22Mme//+c4YMyBYtdRGZLh7K0qD2OUjIiIitRfM7p5XgHNqeHwNcIq1tj/wCPBCEGs5qkifQoqIiEgoCVq/hrV2ijGmYw2Pf1fl7nTA03m2vjBDuC9MIUVERCREhMrA2ZuAT4/0oDHmVmNMtjEmOzc3N2hFRPnCKKlQSBEREQkFnocUY8ypuJDy4JHOsda+YK3NstZmpaSkBK2WyHC1pIiIiIQKT0OKMaY/8BIwylqb52Ut4EJKWUUllZWNa8aTiIhIU+TZXFtjTAdgPHCttXa5V3VUFbVvhk9FJdFhvlo/Ly8vj9NPPx2ALVu24PP52NfiM2PGDCIjI2t8/uTJk4mMjGT48OH1rFxERKTpCVpIMca8CYwEko0xOcBvgAgAa+3zwP8DkoB/GrdfTvmR5kk3lKozfKIjah9SkpKSmDt3LuB2Mm7RogX3339/rZ8/efJkWrRooZAiIiJSRdC6e6y1V1lr21lrI6y16dbaf1trn/cHFKy1N1trW1lrB/p/PA0ocGCtlEAsjz9r1ixOOeUUhgwZwtlnn83mzZsBeOaZZ+jduzf9+/dnzJgxrF27lueff54nn3ySgQMHMnXq1GN+bRERkaYgtJdWrY9PH4ItC+r1VB+WLqUVhIcZCK/SktK2H5z751pfx1rLXXfdxQcffEBKSgpvvfUWv/rVr3j55Zf585//zJo1a4iKiiI/P5/ExERuu+22Ore+iIiINHVNL6QcA4PBGDjWcbMlJSUsXLiQM888E4CKigratWsHQP/+/bn66qsZPXo0o0ePPsaKRUREmq6mF1Lq0OJRndy8PRSXVdKjbct6X8NaS58+ffj+++8Pe+zjjz9mypQpTJgwgUceeYRFixYdS7kiIiJNlufrpISayPAwSisqOZaNF6OiosjNzd0fUsrKyli0aBGVlZVs2LCBU089lccff5z8/Hx2795Ny5Yt2bVrV6D+BBERkSZBIeUQUeFhWGspO4aVZ8PCwnjnnXd48MEHGTBgAAMHDuS7776joqKCa665hn79+jFo0CB+9rOfkZiYyIUXXsh7772ngbMiIiJVNL3unmNUdRpyZHjtpyHv89vf/nb/71OmTDns8W+//fawY927d2f+/Pl1fi0REZGmTC0ph9gXTAIxDVlERETqTyHlEBE+gzGGUm00KCIi4imFlEMYY4j0aaNBERERrzWZkHIss3EOFRUeFrLdPYH8O0VEREJZkwgp0dHR5OXlBewDPDLctaSEWiCw1pKXl0d0dLTXpYiIiARdk5jdk56eTk5ODrm5uQG53u6ScvKLyiA/Gl+YCcg1AyU6Opr09HSvyxAREQm6JhFSIiIi6NSpU8CuN2npVm4Zm827t5/AkMzWAbuuiIiI1F6T6O4JtMykOADW5RV5XImIiEjzpZBSjfRWMRijkCIiIuIlhZRqRIX7SEuIYf0OhRQRERGvKKQcQYfWsazL2+N1GSIiIs2WQsoRZCbFqiVFRETEQwopR9AhKZbtu0vZXVLudSkiIiLNkkLKEXTcP8NHXT4iIiJeUEg5gg6tYwFYrxk+IiIinlBIOYLMJBdS1mlcioiIiCcUUo6gZXQEreMitVaKiIiIRxRSaqBpyCIiIt5RSKlBZlKsWlJEREQ8opBSg8ykODYX7KW0vNLrUkRERJodhZQaZLaOpdJCzk61poiIiDQ0hZQaaIaPiIgcVVkxvDEGNszwupImRyGlBh32hZTtGjwrIiJHsGoSLP8Uvn3S60qCo6IcJj8GhZsa/KUVUmqQ0iKK2EifWlJEROTIlkxwt8s/g11bva0lGBa/D5P/CBtnN/hLK6TUwBhDh9axWnVWRESqV1EGyz6BjOPBVsD8sV5XFFjWwrSnILk79DivwV9eIeUoMpNi1ZIiIiLVWzMFigtgxD2QMQzm/M99sDcVqybBlgUw/G4Ia/jIoJByFJlJcazfUURlZRP6l05ERAJjyYcQEQddToNB18D2ZZCT7XVVgfPtk9CyHfS/wpOXV0jZJ39Dtf9idWgdS2l5JVsKiz0oSkREQlZlBSz9CLqfBRHR0OdiiIiFOf/1urLA2DgL1k6FE34K4VGelKCQss+7N8OH9x52eP80ZI1LERGRqjb8AHtyoddF7n5US+g9GhaOh9Im8Jnx7VMQnQBDbvCsBIWUfXqPgq0LIG/VQYczW8cBsH6HpiGLiEgViyeALwq6nXng2KBroHTXgRk/jdX2la4r67ibXfjyiELKPr0udLeLPzjocFpiNOFhRi0pIiJygLXuQ7zr6Qd/iGcOh1adYM7r3tUWCN89A75IGHabp2UopOyTmAHtsw4LKeG+MNJbxWiGj4iIHLBpNhTmHPiCu48xMOhqN5Zjx5q6X9da2JsfkBLrbdcWmPem+ztapHpaikJKVb1Hwea5sHPtQYc7JMVprRQRETlgyYcQFg7dzzn8sQFXAQbmvlH36056BB7vBB/81E3o8ML0f0JlOQy/y5vXr0Ihpare/sFPiw/uS8xsHcvavD3YpjT3XURE6sda9znR8SSIbX344wnpbkry3DfcDKDaWv+Dm/Lbpg/MHwd/HwITfwl78gJX+9EUF0D2f9wA4NadG+51j0AhpapWHaHdwMO6fDKTYtlVXE5+UZknZYmISAjZtgR2rDrwxbY6g65x3UFrvqndNUuL4P3bXcD58adw12zodzn88Bw8PcDtnVOyKzD11yT7ZSgphBPvDf5r1ULQQoox5mVjzDZjzMIjPG6MMc8YY1YaY+YbYwYHq5Y66X0RbMyGgpz9hzKT3AwfjUsRERE3c8dAj/OPfE6P8yA6sfYDaL/6nQs+o551A3ETM2D0s3DHdOgy0u2d8/RAmP4clJcc+99QnbJid/3Op0K7AcF5jToKZkvKK0A1nXX7nQt08//cCjwXxFpqr9cod7vkw/2HDqyVomnIIiLN3pIPocMJ0LLNkc+JiHartC75CPburPl6a6bAD8+7mTSdTj74sZQecOXrcPMkaNMbJj7kuoHm/K9uXUm1Me9N2L01ZFpRIIghxVo7BdhRwymjgNesMx1INMa0C1Y9tZbcFdr0PajLp0NrF1I0eFZEpJnLWwVbFx4+q6c6A6+GihJY8M6RzynZBe//FFp3gdN/c+Tz0ofA9R/Cte9DXDJ8cAe8elHgBtdWVrhpx2mDoNMpgblmAHg5JqU9UPXdzfEfO4wx5lZjTLYxJjs3Nzf4lfUeBeunQ+FmAKIjfLSJj2KtQoqISPO2r5W9NiGl3QBo06/mLp/PfuXGrox+DiJjj37NLqfCLV+7bqHNc+G5ETWHoNpa8iHsWA0j7nXTqEOElyGluneh2ukz1toXrLVZ1tqslJSUIJeFCylYtyeDX2brOK06KyLS3C2Z4FobEjOOfq4xbgDt5rmwpZrhmSu+hNmvuqm+HYbVvoZ9171tqusOevcmePcWNzOnPqyFaU+51pzahK8G5GVIyQGq/lNOBzZ5VMvBUnpASs+Du3ySYrXqrIhIc1aQ4zbd61XDrJ5D9bscwiJg7v8OPr53J0y4C1J6wchf1q+e1p3dTKCRD8PCd12rytppdb/Omm9g0xwXlsJ89aslSLwMKROA6/yzfI4HCqy1mz2s52C9R8G6abB7GwAdk2LZtquEvaUBHqgkIiKNwxJ/63pdQkpcEvQ8D+a/BeWlB45/+hDs2QYXP+cG2daXLxxGPgQ3fuYWl3vlfPjydwe/1tF8+xTEpfoXoQstwZyC/CbwPdDDGJNjjLnJGHObMWbfRgCfAKuBlcCLwB3BqqVeeo8CW7m/y6dD0r6NBtWaIiLSLC35EFJ7uwkWdTHwGijKg+UT/df5COaPhZPud11HgZBxnOv+GXQ1fPsE/PtM2L7i8PPKS6FwE2yeByu/hB/+Bau/hhPuOLawFCThwbqwtbbGSGbd8q0/DdbrH7PU3pDU1XX5ZN1Ipn+Gz9q8PfRo692OkCIi4oHdubD+Ozj5F3V/bpfToGU7N4A2cwR8dC+07Q8n3x/YGqNaugG13c6GD++Gf50MnUdC0Q7Ykwt7tkNJNeNW4tMh68bA1hIgQQspjZ4xrjXl26egaAeZSS0ATUMWEWmWln3sWtfr0tWzjy/cdaVMe8oNci0ugOsmgC8i4GUCblHS9Cz45BeQtxLiUtxMo7gU/0/ywb/Hp0FETHBqOUYKKTXpdRFM/Rss/ZjEwdcSHx3OOs3wERFpfhZPgFad3L469THQ3w2z+ms447duYbZgik+DMf87+nkhTnv31KTdAEjM3D/LJzMpTjN8RESam735bgZM74vqv4ZIcle33HyH4TD87oCW15SpJaUm+7p8pj8He3eSmRTLgo31nIcuIiKN0/KJUFlev66eqq5+B7AhN803lKkl5Wh6j4bKMlg2kcykWDbu3EtZRaXXVYmISENZ8iHEt4e0Y9wH1xcevHEoTZRCytG0H+xGPi/+gK6pLSivtCzf2gDbZYuIiPdKdrupuj0vgDB9ZDY0dfcczb4un5kvcsIZkQB8vyqPPmkJHhcmIiLHpGQ3bFvs1jA59GeP/3bXFigvduNRpMEppNRG71Ew/VnabvmGzskpTFu5nZtP6ux1VSIiUl9bFsKbY6DgkF2EfVFuWm5sa4hNcoukDbwKOpzgTZ3NnEJKbaQf5xbiWfw+w7s+xHuzN1JWUUmET01/IiKNzrKJbr2SqJZw+auQ2MEFktgkiIwLqV2Amzt9ytZGWJgb1b3yS07OjGFPaQXzNuR7XZWIiNSFtfDdP1wLSlJXuGUS9Bntxh62yoSoFgooIUYhpbZ6j4LyYkbYORgD01bmeV2RiIjUVnmpWyr+819Brwvd7sHxaV5XJUehkFJbHY6HuFTiVn1Mn7R4pq3a7nVFIiJSG0U74PVLYPZrcNLPXRdPZKzXVUktKKTUVpgPel0Ayz9jZMdY5qzfSVFpuddViYhITbavhJfOgA0/wMX/gtP/n6YSNyL6J1UXA34EZUWMtpMoq7DMXLvT64pERORIVn8DL50OxfluQ78BY7yuSOpIIaUuMo6DDsPpvPI/xPgq+G6lunxERELSrFdcF0/LtnDzV5CpKcSNkUJKXZ14L2GFG/lp8jyNSxERCUXTn4cP74FOp8BNn0PrTl5XJPWkkFJX3c6C1N6MKRvP4k355BeVel2RiIjsM/PfMPFBt4z9j96CaK0O3pgppNSVMTDiXpKLVjPSzOX7VZqKLCISEmb/Fz6+D7qdDZf9R5v5NQEKKfXR9xJsQjp3RnyoLh8RkVAw7y2YcBd0OQ2ueA3CI72uSAJAIaU+fBGYE+5isFlG4bKpXlcjIl4pLYIdq72uQha+C+/fBp1OgjFvQES01xVJgCik1NfgaymOSOSi3ePYXLDX62pExAuTHoFnh8HWRV5X0nwtngDv3gIZx8NVYyEixuuKJIAUUuorMo7C/jdyhm8OC2dP97oaEWlolRWw4B2oKIXxP3HLrkvDWvYpvHMjtB8CV49zmwNKk6KQcgyST72TvUSROPc5r0sRkYa29lvYs80t8rh1AUx53OuKmpcVX8K466BtX7jmHbejsTQ54V4X0JiFtUji+8QLODn/fWz+ekxiB69LEpGGsvBdiIiD8//mZv1NfQK6nwvpQ7yurGHtzYclH7pultgkiEuGuBT3e02za8pLYPc22L3V/eza4u5XlrnnxiZD3L7bZHe7b6zJ6snw1tWQ0gOufU/TjJswhZRjVDDwVuzX71Mw6SkSL3nC63JEpCFUlMGSCdDzPLdR3Tl/ckuwv/cTuG1q8xkXsfwzt2jars3VPx6dUCVkJEHpHn8w2QJ7q9tWxIAJA1tR/fUiW7jr7N4KrbvAtR9ATKuA/TkSehRSjtGgvv2Y8NUJjFr0Pzjn/yC2tdcliUiwrZ7sPmT7XuruRyfA6GfhtVHw1e9daGnK9u6EiQ/DvDchtbdbkyS2NezZDkXbYU8u7Mnz/+4/tnOdGzOS1AU6joAWbQ78tPTfxqWA8bm9doryDjx3/+/+27BwOPP3rqVFmjSFlGOUmRTL/8VcxqWl38KMF2DkQ16XJCLBtvBdiEpwa3Ls03kkDL0Vpv8TepznpsM2RUs/gY9+5oLIyQ/AyfdDeJR7LKVHYF4jtrX7Se4WmOtJo6WBs8fIGEO7boP5hiHYH/7lmjNFpOkqK4alH0OvCw98OO9zxm+hdWd4/w4oLvSkvKAp2uGm+o69ynXf3DIJTvvV4e+BSAAppATAiK7J/L3kfMzeHTDnda/LEWlcyordSqEL3gFrva7m6FZ+CSWF0PeSwx+LjIOL/wWFOfD5rxq+tmBZ8pFbD2bReDjlIbjla0gb6HVV0gwopATA8C5JZNuebE4YCN/93Q2qE5HaWfoRzH4N3r0J/jsatq+s/7V2bYGNswJWWrUWvusGb3Y6pfrHM4bCiHvc37T8s9pft7wUKisDU2OgFO2Ad25yM2latnHh5NSHteS8NBiFlABIjY+mW2oL3oy4GAo2wMLxXpck0njMexPi0+G8v8LGOfDcCTDpD1BWh5Wct690rTFP9YMXT4fc5cGptXQPLJ8IvUeBr4YhfSMfhtQ+rqaiHUc+r7ISVn0N42+FxzLhnR+HTmvS3p3wyvmw+AM49VcuoLTr73VV0swopATIiK7JvLi1G5XJPWDaU6HzPxqRUFa4GVZNggFjYOgtcOdM6D3aLYz2zxPcgl01ycmGt66Bf2TB/HEw8EdujMR3Twen3uUToazowKyeIwmPgoufdwHlk/sPfzxvFXz1iAtV/x0NyyZC+nGw+H3I/ncwKq+bsr3wxhjIW+kWSjvlAe0oLJ5QSAmQ4V2S2FsGq3vcAtsWu/9hikjNFowDW+lCCrguhUtfhOsmuGmm/7vUrSpauOnAc6yF5Z/Df86Hl06HNVPdDJN7F8KFT8Oga9yOuFWfEygLx0OLttDhhKOf264/jHzQdQ8tHO8WPcv+D7x0Jvx9MHz7BKT2gstehvuXw7XvQ9czYOIvYcvC+tdoLeQuq/8XpYpyePvHsOEHN76m88j61yJyjBRSAmRY5yTCDHxUMRzSh8IHP3XfjiR0LHoPvvyt11XIPtbC3DddC8KhU007nwK3T4PT/s+N6/jHcfDdP1z4eG4EvHE57FwLZ/8JfrbIndcixT13+F0u+Hz/bGDrLS6AFV9An4shzFe754z4mdtX5oM74a/d4aN73aDbM38PP1vsWin6XupWUg0Lg9HPQ0yi6/apz0xBa+GLX8OzQ2HctXWfYWQtfHQPLP8UzvtL9YODRRqQQkqAJMRE0C89kalrCuDqt6FNH/c/iZVfeV2aAJQWwSe/gGlPQ8kur6sRgM1zIXcJDLiq+sfDo+DkX8Ad0yFzuJst896tLoCMfh7umQsn3AFRLQ5+XquOLkjMeuUIq5rW09JPoKLk6F09VfnCXWtEclcYfJ0b13HHdDewNr7d4ee3SIFLXoDtK+DTB+pe45S/usH7HU9y9b54GmxbWvvnT3rEzVA8+QHX/SbiMYWUABrRJYl5G/LZHdbC7SeR3APG/gjWTPG6NJn9qlt8ylYGf/aH1M7cN8EXdfRv6607wY/Guf+mrhkPd3wPA6+qeYzEiHugdDfMDOD4jkXjIaEDpGfV7XnJ3eAnU+D8v0L7wW6fn5p0Hgkn/dyFhQXv1P51pj8HXz/qQt91E+C6D9zKrS+e5rqcjvr852Hq32Dw9XDqL2v/uiJBpJASQCO6JlNeaZmxJs+tlnjd+9CqE7xxJaz73uvymq+yYvj2KUgbDBjYMMPriqS8FBa8DT3Ord3eK8a41V27nn70D3lw40G6nA4/PF+3WUJHUrTDDfDte3HtXv9YjXwYMobBh/fCjtVHP3/2f2HiQ26BuYv+4bqOOp3kwlHbvvDOjW4Z+yMtj7DgHZj4IPS8AM5/omH+RpFaUEgJoCGZrYgMD2Payjx3IC7ZfZuJT4P/Xe5mIkjDm/Nft6HZGb91+4ysn+51RbLic9i7w83GCZYT73WtZ3PfOPZrLZkAleV16+o5Fr5wuPQlFzbeudGFuiNZOB4+vNuFskv/ffDU6Pg0uP4jGPoTt1z/qxe6tWSqWjUJ3rsNMkcc/nwRjymkBFB0hI+szFZMW7n9wMGWbeD6D11g+e8lsGmOdwU2R+WlrhUlYxh0OtkttJUzM/QWzWpu5r0JcanugzVYOp7kWs+++ztUHmFX3dpaON7tutu2AdcJSezgWkU2zYGvflf9Ocs/h/G3QMbxcOXr1S9RHx4J5z0Ol7wEm+fBv06Gdd+5xzbOgrHXuD13xrzhBvCKhBCFlAAb0TWZpVt2sX13yYGD8WkuqEQnwH8vhi0LvCuwuZn3hlui/JQHXBN2xjA3uyK3DoMJJbD25LkZO/2vCO63dmPgxJ/BzjVuQbL62rUV1k51rSgN3Q3S+yI47mb4/h8ukFS19ls3OL9NX/jRWIiMrfla/S+Hm790S/e/cgFMetS18MYlwdXvuFlFIiFGISXAhndxW4cf1JoCkJgB10+AiFi3nfu2JR5U18xUlLmBgGmDD3xjzxjqbjf84F1dzd3Cd6Gy7MizegKp5/mQ1PXYFlhc/IEbcO3VdNyz/uCCyPu3ucXvAHJmubFurTq6wcTRCbW7Vps+cOtk6H4OTPmLO3bNe9XPNBIJAUENKcaYc4wxy4wxK40xD1XzeIIx5kNjzDxjzCJjzI+DWU9D6J+eSNv4aN6fs/HwB1t3ci0qYRHw6kXBW7pbnPnjIH89nPLggW/ArTtDbLIGz3pp3hvQtp8b0BlsYT4Yfrfr5lg9uX7XWDTejWVK7RXQ0motItot+Fa2103B3rIAXr/EdSFf+75rCamL6ATXNXTxC3DDJ256tEiIClpIMcb4gGeBc4HewFXGmN6HnPZTYLG1dgAwEvibMaZR71zlCzNcNiSdb5bnsim/mlkFSV1ciwoWnh/h1u7Y9+1IAqeiHKb+1Y0h6H72geP7unzUkuKNbUvdGIsBQRwwe6gBY9wqsdOeqvtzC3Jg/ffeL2qW0gPOfdwtZ/Diaa5F9roP6t8CEhYGA66E1J6BrVMkwILZkjIUWGmtXW2tLQXGAqMOOccCLY0xBmgB7ADKg1hTg7giK4NKC+/Myqn+hJQeblGnAWPcOg5PD4BPHzx81L3U36LxburmvrEoVWUMhR2rYM/26p/bkKx1rT3Nxbw3wPig3+UN95rhUXD87a4lpa4D1xe95277hMDKq4OucV1kMa1cQGnV0euKRIIumCGlPbChyv0c/7Gq/gH0AjYBC4B7rLWHTbswxtxqjMk2xmTn5uYGq96A6ZAUy4iuSYzL3kBl5RH6wRMz4KK/w12z3P+wZ7zowsrEX8LubYEtqHSP21V23tjAXjdUVVa4/vbUPtDj/MMfzxjmbkOhy2fhu/BU/+YxmLqywnXBdTvzwBL2DSXrRohKcDO96mLheGg30LWAes0YGP2c26MopbvX1Yg0iGCGlOqGwR/6iX02MBdIAwYC/zDGxB/2JGtfsNZmWWuzUlIa+H9u9XTlcR3I2bmX71bl1Xxi604w+lm3+2ufS+CH59yH1uf/B7sDEMhWT3a7yU553K2FsHjCsV8zUFZ9DZ/96sgLTNXX4g9g+3K36VxYNf+Kpw1044JCoctn9muAPbbZJ43F6q9h1+aGGTB7qOh4OO5Gt95J3qraPWfHatg0u+HWRqkNY9yUYpFmIpghJQfIqHI/HddiUtWPgfHWWQmsAZpEJ+lZvduQEBPB2Jm1bMpP6gIXPwd3ZkPvUW5ztKf9YaU+3QF7892mZq+NcrvJXvOuW857/C2h0YJQXADjb3VTKyfcVf+ZF4eqrHStKMk93PtYnYgYaDfA+/ehYOOBLROWfORtLQ1h7psQnehWmfXCsNtdOP3u77U7f+F4d9vn4uDVJCI1CmZImQl0M8Z08g+GHQMc+jV+PXA6gDGmDdADqMUa0KEvOsLHxYPa8/mirezcU8NqkYdK6gKX/At+OsNNn/z+WdcN9OaP3MqQtfkwX/IRPDvMrbQ54l63m2zXM+CqsdCynZu6WNtvk8Hy9Z/caqD9x7iFvSY9GpjrLvsYti32t6LUsFNtxjD3LbmmlTyDbcHbgIWht7qN9rz+Z1IXxYWuZe6dG906Ikc9vwCWfuRaJapbcKwhtGzj9vyZ+8aRa961xbVujb3aTV/PGOa6ZkXEE0ELKdbacuBO4DNgCTDOWrvIGHObMeY2/2mPAMONMQuAr4AHrbUhMJoxMK48LoPSikreq2468tEkd3PLYt8z3wWNDT+4heD+keU2EisuOPw5u7fBuOvhrashLgVu+QrO/J1rOQA3ZfEa/0Zj/7vMu4GjWxfBjBdgyA1w8fNuQ7Opfz32zeCshW8edyuDHm2gY8ZQKC/2biyItTD/LUg/Dobf5Y4tbSStKVsXwQsj3fiSJR/BP4e5vV9qCtCLP3DvdzCXwa+N4XdDRanb0wdcy1tOthuz9a+T4W89XMvepjlusbnRz3lbr0gzZ2ygmtkbSFZWls3Objx74Iz6x7cUl1Uy8d6TMMeyWmV5CSx6H2a+6JZ1j4hz/xMdeotbw2HeWLfBWFmRWxdkxD1H3iV2wwy3h0fbfm7dln0hpiFYC/85z7Uc3DXbbcRYUe6C1YrP3foNPasZ7FobyybCm1e6D5ajfRgWboYnesLZf4IT7qjf6x2LzfPhXyfBeX91/wz/dbLbEfjmLxq+lrqY+wZ8dJ9ba+Py/7g1Z96/HTZmu83tzn+y+kGxL5/rWs7unOn95nXjrnfjoXqe7/6dK9oOJswFxm5nuSnrbfp6X6dIM2GMmWWtrXZ7ca04G2RXHteBZVt3MS+nmpaPugiPcusa3PylWzGyz8Wum+S54W7syvu3uanNt01zXR01bWOfMRQuecF9gxx/y7Hva1IXC96B9d/B6b9xAQXc0uiXvQxpg1z3QX3GilgL3zwGiZm1m94a3w4SOng3eHb+W258xL5BmT0vcOEzVKehlxXDhLtdIEnPgtumQuZwN8vkxs/gjN+5pe7/OezAtN19dqxx/8wHXhUaH/wn/gxKd8GyT6DzSLjkRfjFKrjpc/ffTtt+oVGniCikBNuFA9oRE+HjrdoOoK2NtEFuRtB9S+DMRyAhwy309OOJtZ+a2HsUnP1HWPIhfP7rwNVWk+JCNxA4bRAMvu7gxyLj4Efj3D5Hb1wJ21fU7dqrvnJjTE76ec0BraqMoS6kNHRrYkW5G4/S7awDQa3nBYB1H5yhZsca+PeZMPtVOPE+t8ppi9QDj/vC3Y7DP5niNsV7+wbXWrGvO3HeWMC48UehIG0g3LfUBZPL/u1aJPf9cxCRkKKQEmQtoyM4v387JszdxJ6SAK9TF9saRtwNP/4Ehv2k+um2NTnhDhh2G0x/1o1zCbZvHoPdW+C8v1U/qHXfmBkT5pb9rs2AzPJSN95h4sMurNVlemuH492U2IIjLLoXLGsmw+6trmVsn9Rebsn+pR83bC1Hs/QTeOEUyF8HV70FZ/zmyJsCpvaCm76E037t/o5nh7l/NvPehM6nQMKhyyR5qGWb4G5uKCIBoZDSAMYcl8Ge0go+XhCCy9+f/Uf3LX7iw65VpTrFBbB2mgsy793udlBd+WXdXmfbUjdYcdC1kD7kyOe17gxXj3Pfwt+4HEp2VX/e5vluld6/9YBx10HJbjj/b3VbQ8KrzQbnveXGdHQ/58AxY9wYidXfVD8ouqFVlMMXv4GxV7mVTX8yBXqcc9Sn4Qt3XSY/+caFknHXuYDTkMvgi0iToa8SDWBIZiu6pMTx1swNXJEVYtMZw3yuT/7VC+Hdm93AVWthyzwXBLbMh51rD5wflwq+SLfF+1mPwvF3HL3/3lr45H7XpXPGb49eU/shcPmr8OYY123wo7dcF86ePNdNMvd1NyvHF+k+2AdeA11OrXnKcXVS+7gByBtmQL/L6vbc+irZ7Wbx9L/i8Km4PS90a3is+KLh6qlOWbELiGumwJAfwzl/dpvc1UWbPnDzV/Dtk7D2W+h1QXBqFZEmTSGlARhjuPK4DP74yVJWbttF19SWXpd0sMhYFwReOsNNTd6nVSe36Nmga91t237Qsq37oH3vJ/DZL2HrYrjgiZrXvlg0HtZOdTNZ4pJrV1P3s+DCp2HCnW6MgwmDZZ9CZZlbpvy8v7pBp8cylsAX7lp1GrIlZcmHbgZWdeMz0o9zIXDpR96GlEmPuIBy0d8PHztUF74It3fSKQ8ErjYRaVYUUhrIJYPTeXziMt6auYFfnX/oZtAhIC7ZjW1Z8TkkdYO2fV2XRHWiWsAV/4XJf3LL7eetcC0wVQdT7lOyGz77P7cbcdaNdatp8LVQuAkm/9FNdR16Kwy62n1LD5SMYTD1Cbe/UWRc4K57JPPHuhlIHY4//LGwMOh5npsBVVZc99aLQFgzxS0gmHXTsQUUEZEA0JiUBpLcIooze7fh3dkbKS0/bA/F0BCf5hZY6zjiyAFln7AwOO1XcNl/XLfQC6e620NNeRx2bXLjReraHQPuW/ht09xMpnP+GNiAAi6k2ArYODuw161O4SY35mTAmCN3kfW8EEp3H1guvyEVF7gxR607w1mPNPzri4gcQiGlAV1xXAY79pTy5ZJazFppLPpeAjd+Clh4+eyDN8rLXe6+lQ+8+sAg1boyxrXqBGtTtXT/+kEN0eWzbxn8/lce+ZxOJ0FkS1h6hEHMwfTJA2620yUvNEyrkojIUSikNKCTu6XQLiGat2Zu8LqUwEobBLd87Vo5xl0Hk//slhv/9BduYOoZv/O6wiOLaQUpPRtms8F5/mXwk7oc+ZzwKDceZ9mnDbvI3qL3XFfUyb84ENxERDymkNKAfGGGy7MymLIil435e70uJ7BatoHrP3LrlEz+E7x0Oqye7LqEqlsmPZRkDIWcGS5YBcuWBbBtUc2tKPv0PN8tId9QuzQXboaPfgZpg930YRGREKGQ0sAuH5IOwNvZTaw1BdxAz9HPuVVwN81x+59k3eR1VUeXMQz27oS8lcF7jXljD14GvyZdz3TTqxtiw0Fr4YOfuoG6l7xQ+9V6RUQagEJKA8toHcuJXZN5OzuHisrGtbljrRjjVsH9yTdw9TuNY1XPjGHuNljjUior3Iydqsvg1yQ63u0ps/Sj4C/ZP/Mlt6XAWY+4nbdFREKIQooHrjwug435e5m2crvXpQRPuwFuE7/GIKmrG5sSrJCyerLbDmBALbp69ul5vltEb+ui4NQEbn+kz38NXU6H424O3uuIiNSTQooHzuzdhlaxEYwN5KaDUn/GuNaUYI0BmV/NMvhH0+M8wARvL5+KMrcDdkQ0jHpWu/6KSEhSSPFAVLiPy7My+GzRVjYXNLEBtI1VxlDYvgyKdgT2uiW73SqzfS6ueVXeQ7VIdcEpWFORp/zFjRu64KnG0+IlIs2OQopHrj0+E2str09f53UpAgfGpeRkB/a6Sz868jL4R9PrAjcraGeA/x3ZMBOm/NXNxOozOrDXFhEJIIUUj2S0juWMXm1444f1FJc14HoYUr20wWB8gR+XMq+GZfCPpuf57jaQXT67t8F7t7rVhc99LHDXFREJAoUUD90woiM7i8qYMG+T16VIZCy06x/YkFK4yQ2a7X9l/cZ8tO7sdmo+1qnIe/Jg1ivw2ij4Ww83IHf0c0ff+kBExGONYH5o03VC5yR6tGnJK9PWcvmQdIwGL3orYxjMfs0NKq1pvRBrXfgo3AgVpe78ilIoLznwe0UpbFsCWLdXT331usCNH9mzvfY7SIMbW7P0Y7cD9epv3P5ErTvDife5HZZTe9W/JhGRBqKQ4iFjDNcP78gv31tA9rqdHNexFmtoSPBkDIUfnoetC91S/4ey1i1XP/lPsKWazRT3CYtwi7H5ItyA2ZqWwT+anufDN4+51x18bc3nFu1w5y16D1Z/DZXl0KojjLjH1dG2n2bxiEijopDisdGD0nhs4lJembZWIcVr+xd1m3FwSLEWln/mwsnmudCqk+su6XjSgTDiizzweyCDQNv+kNDBtYocGlIqyiBnJqya5H42zgYsJHaAE37qgkm7gQomItJoKaR4LDYynDHHZfDSt2vYlL+XtMQYr0tqvhLSIb69G5cy7CcunKz4woWTTbNdq8Sof7oxJg21kq4xrstn5r/ddObdWw+EkjVToXSXG/CbngUjH4JuZ/oHASuYiEjjp5ASAq45PpMXp67m9enreOCcnl6X07xlDIX1P8CKL1042ZjtWiYu+ocbW+LF3jY9z4fp/4Sn+0NRnjuWmAn9L4cup7kWnZjEhq9LRCTIFFJCwL7pyG/OWM/dp3cjOsLndUnNV8YwN6bjf5e6bpYLn4GBP/J2470OJ0DXM8AXBV1OdcGkdWe1lohIk6eQEiJuGNGRzxdvZcK8TVyRleF1Oc1Xzwtg+UToPRoGXg3hkV5XBGE+uOZdr6sQEWlwWiclRFSdjmyDvfOtHFliBlz3AWT9ODQCiohIM1arkGKMiTPGhPl/726MucgY42H7d9NjjOGGER1ZvLmQmWt3el2OiIiI52rbkjIFiDbGtAe+An4MvBKsopqr0QPbkxATwSvfrfG6FBEREc/VNqQYa20RcAnwd2vtxUDv4JXVPMVE+hhznNsdeVO+dkcWEZHmrdYhxRhzAnA1sG+3Mw26DYJrtDuyiIgIUPuQci/wMPCetXaRMaYz8HXQqmrGMlrHcmZvNx1ZuyOLiEhzVquQYq39xlp7kbX2Mf8A2u3W2ruDXFuzdcPwTm535LnaHVlERJqv2s7uecMYE2+MiQMWA8uMMb8IbmnN1/GdW9OjTUv+852mI4uISPNV2+6e3tbaQmA08AnQATjKlqxSX/umIy/ZXMiMNTu8LkdERMQTtQ0pEf51UUYDH1hrywB9xQ+iA9OR13pdioiIiCdqG1L+BawF4oApxphMoDBYRYl/OvLQDD5btIXZ67W4m4iIND+1HTj7jLW2vbX2POusA04Ncm3N3k9P7Uq7hBjuHTuX3SXlXpcjIiLSoGo7cDbBGPOEMSbb//M3XKuKBFF8dARPjxlIzs4ifvPBIq/LERERaVC17e55GdgFXOH/KQT+E6yi5ICsjq2587RuvDs7hw/naUqyiIg0H7UNKV2stb+x1q72//wO6BzMwuSAu0/ryqAOifzyvQVs1HL5IiLSTNQ2pOw1xpy4744xZgRw1E9LY8w5xphlxpiVxpiHjnDOSGPMXGPMImPMN7Wsp1kJ94Xx9JWDqKy0/OytuVRUamKViIg0fbUNKbcBzxpj1hpj1gL/AH5S0xOMMT7gWeBc3GaEVxljeh9yTiLwT+Aia20f4PI6Vd+MdEiK5fej+jJjzQ6e/2aV1+WIiIgEXW1n98yz1g4A+gP9rbWDgNOO8rShwEp/91ApMBYYdcg5PwLGW2vX+19nW52qb2YuGdyeC/q348kvljN3Q77X5YiIiARVbVtSALDWFvpXngW47yintwc2VLmf4z9WVXeglTFmsjFmljHmuuouZIy5dd/Motzc3LqU3KQYY/jDxf1oEx/NvWPnsEfTkkVEpAmrU0g5hKnH44cOpggHhgDnA2cDvzbGdD/sSda+YK3NstZmpaSk1KvYpiIhJoInrhjA+h1F/O5DTUsWEZGm61hCytFGb+YAGVXupwOHzqHNASZaa/dYa7cDU4ABx1BTszCscxJ3jOzKuOwcPlmw2etyREREgqLGkGKM2WWMKazmZxeQdpRrzwS6GWM6GWMigTHAhEPO+QA4yRgTboyJBYYBS+r5tzQr95zRjQEZiTz07nw2aVqyiIg0QTWGFGttS2ttfDU/La214Ud5bjlwJ/AZLniMs9YuMsbcZoy5zX/OEmAiMB+YAbxkrV0YiD+sqYvwhfH0lQMpr7TcN07TkkVEpOkx1jauD7esrCybnZ3tdRkhY1z2Bh54Zz4PntOT20d28bocERGROjHGzLLWZlX32LGMSZEQcPmQdM7r15YnvljGgpwCr8sREREJGIWURs4Ywx8v7kdSXBT3vDWHvaUVXpckIiISEAopTUBibCRPXDmANdv38OjHi70uR0REJCAUUpqI4V2SufWkzvzvh/V8sXir1+WIiIgcM4WUJuS+s7rTJy2eB9+dz7ZdxV6XIyIickwUUpqQqHAfT48ZyJ6Scu5/ez6VmpYsIiKNmEJKE9M1tSX/d0FvpizP5dXv13pdjoiISL0ppDRB1wzrwOk9U/nTp0tZtmWX1+WIiIjUi0JKE2SM4bHL+hMfHc49Y+dQXKZpySIi0vgopDRRyS2i+MvlA1i6ZRd/+WyZ1+WIiIjUmUJKE3Zqj1SuPyGTf3+7hinLc70uR0REpE4UUpq4h8/rRbfUFvz87Xns2FPqdTkiIiK1ppDSxEVH+Hh6zCAKisp4ePx8GtuGkiIi0nwppDQDvdPi+flZ3fls0VY+mLvJ63JERERqRSGlmbj5pM5kZbbi/32wkC0FWo1WRERCn0JKM+ELM/z18gGUVVgefFfdPiIiEvoUUpqRjslxPHxeT75ZnsvYmRu8LkdERKRGCinNzDXDMhnRNYlHP1rMhh1FXpcjIiJyRAopzUxYmOHxywZgjOH+t+dpE0IREQlZCinNUPvEGP7fhb35Yc0OXvlurdfliIiIVEshpZm6fEg6p/dM5bGJS1mVu9vrckRERA6jkNJMGWP40yX9iIn0cf/b8yivqPS6JBERkYMopDRjqfHRPDKqL3PW5/PC1NVelyMiInIQhZRm7sIBaZzfvx1PfrGcpVsKvS5HRERkP4UU4ZFRfUmIieS+t+ZRWq5uHxERCQ0KKULruEj+dEk/Fm8u5B+TVnhdjoiICKCQIn5n9m7DpYPTeXbyKs32ERGRkKCQIvs9fF5PosPDeHziUq9LERERUUiRA5JbRHHbKV34bNFWstfu8LocERFp5hRS5CA3n9SZNvFR/PGTJdopWUREPKWQIgeJifRx35ndmb0+n4kLt3hdjoiINGMKKXKYSwen071NCx6buFRTkkVExDMKKXKYcF8YD53bk7V5Rbw5Y73X5YiISDOlkCLVOrVHKid0TuLpr1awq7jM63JERKQZUkiRahljePi8nuzYU8rz36zyuhwREWmGFFLkiPqnJ3LRgDRemrqGzQV7vS5HRESaGYUUqdEvzu6BtfDkF8u9LkVERJoZhRSpUUbrWK47IZO3Z+Vol2QREWlQCilyVHee1pWWUeH8+VMtly8iIg1HIUWOKjE2kp+e2pXJy3KZtnK71+WIiEgzoZAitXL98I60T4zhj58sobJSy+WLiEjwBTWkGGPOMcYsM8asNMY8VMN5xxljKowxlwWzHqm/6Agf95/dnUWbCpkwb5PX5YiISDMQtJBijPEBzwLnAr2Bq4wxvY9w3mPAZ8GqRQJj1ID29EmL5y+fLaO4rMLrckREpIkLZkvKUGCltXa1tbYUGAuMqua8u4B3gW1BrEUCICzM8MvzerExfy+3vJatlWhFRCSoghlS2gMbqtzP8R/bzxjTHrgYeL6mCxljbjXGZBtjsnNzcwNeqNTeiK7JPHZpP75blcflz3/PloJir0sSEZEmKpghxVRz7NARl08BD1pra+w7sNa+YK3NstZmpaSkBKo+qacrj+vAyzccx4YdRVz8z2laP0VERIIimCElB8iocj8dOHTEZRYw1hizFrgM+KcxZnQQa5IAOaV7CuNuO4FKa7n8ue/5doWmJouISGAFM6TMBLoZYzoZYyKBMcCEqidYaztZaztaazsC7wB3WGvfD2JNEkB90hJ4744RtG8Vww3/mcHb2RuO/iQREZFaClpIsdaWA3fiZu0sAcZZaxcZY24zxtwWrNeVhpWWGMO4207g+M5J/OKd+Tz15XKs1ToqIiJy7Exj+0DJysqy2dnZXpchhygtr+Th8Qt4d3YOlw1J548X9yMyXGsFiohIzYwxs6y1WdU9Ft7QxUjTFBkexl8v709G6xie+nIFWwqK+ec1g4mPjvC6NBERaaT0VVcCxhjDvWd05y+X9Wf66jxufS2bCi2hLyIi9aSQIgF3eVYGf7ykH9NX7+C5ySu9LkdERBophRQJisuHpHPRgDSe/HIFs9bt8LocERFphBRSJCiMMTx6cV/SEqO5+825FBRpCX0REakbhRQJmvjoCP5+1WC2Fhbz0Pj5mposIiJ1opAiQTUwI5H7z+7Bpwu38OYMLfYmIiK1p5AiQXfrSZ05qVsyv/twEcu37vK6HBERaSQUUiTowsIMf7tiAC2jw7nzjdkUl9W4n6SIiAigkCINJLVlNH+7YiDLt+7mkY8We12OiIg0Agop0mBO6Z7CrSd35n8/rGfiws1elyMiIiFOIUUa1P1n9WBAegIPvDOfjfl7vS5HRERCmEKKNKjI8DCeuWoQlRbueXMO5RWVXpckIiIhSiFFGlxmUhx/uLgv2et28uSXy70uR0REQpRCinhi1MD2XD4knWe/XsU9Y+dQWKwVaUVE5GAKKeKZP1/an/vP6s5H8zdz7lNTmbFGe/yIiMgBCiniGV+Y4c7TuvHObScQ7jOMeeF7/vb5Mso0TkVERFBIkRAwqEMrPr77JC4bks7fJ63ksue/Z+32PV6XJSIiHlNIkZDQIiqcxy8bwD+vHsza7Xs475mpjMveoE0JRUSaMYUUCSnn9WvHxHtPYkB6Ig+8M587/jeb/KJSr8sSEREPKKRIyGmXEMPrNw/joXN78uWSrZzz1FRWaGNCEZFmRyFFQpIvzHDbKV14744RVFjLDf+ZydbCYq/LEhGRBqSQIiGtb/sE/nPDcewsKuXH/5nJ7pJyr0sSEZEGopAiIa9v+wT+efVglm3dxe2vz9IUZRGRZkIhRRqFkT1S+ePFfZm6Yju/HL9As35ERJqBcK8LEKmtK4/rwMade3lm0krat4rh3jO6e12SiIgEkUKKNCo/O7M7G/OLeerLFaQlxnBFVobXJYmISJAopEijYozhT5f0Y2thMb8cv4C28dGc3D2lVs8t2FuGMRAfHRHkKkVEJBA0JkUancjwMJ67ZjBdU1tw++uzWLSp4Ijn5u0uYeyM9Vz/8gyyHv2C4//4FVNX5DZgtSIiUl+msQ1AzMrKstnZ2V6XISFgS0ExF/9zGhWVlvd+OoL2iTEAbCss5rNFW/hkwRZ+WJNHpYUOrWM5t29bvlmey6rc3TxxxUAuHJDm8V8gIiLGmFnW2qxqH1NIkcZs2ZZdXPb8d7SNj+bK4zKYuHALs9bvxFrokhLHef3acU7ftvRuF48xhoK9ZdzyajYz1+3gdxf14boTOnr9J4iINGsKKdKkfbdqO9e/PIOyCkuvdvGc27ct5/ZtS7c2Las9v7isgrvenMMXi7dy9+nd+NkZ3TDGNHDVIiICCinSDCzdUkh0uI+OyXG1Or+8opJfvreAcdk5XD2sA78f1RdfmIKKiEhDqymkaHaPNAk928bX6fxwXxiPXdqfpBZRPDd5FTuLSnnyyoFEhfuCVKGIiNSVQoo0W8YYHjynJ0lxkTz68RLyi2bywnVZtIjSfxYiIqFAU5Cl2bv5pM48ccUAflizg6temM723SVelyQiIiikiABwyeB0XrxuCCu27eLy579nS0Gx1yWJiDR7Cikifqf1bMP/bh5G7q4Srn95BgVFZV6XJCLSrCmkiFQxJLM1/7p2CKu37+bm12ZSXFbhdUkiIs2WQorIIUZ0TebJKweSvW4nd74xh/KKSq9LEhFplhRSRKpxQf80fnthH75cspX/e38hjW09IRGRpiCoIcUYc44xZpkxZqUx5qFqHr/aGDPf//OdMWZAMOsRqYvrh3fkrtO6MnbmBp74YrnX5YiINDtBWxDCGOMDngXOBHKAmcaYCdbaxVVOWwOcYq3daYw5F3gBGBasmkTq6r4zu5O7q4S/T1pJcosorh/e0euSRESajWCuWjUUWGmtXQ1gjBkLjAL2hxRr7XdVzp8OpAexHpE6M8bw6Oi+5O0p5bcfLiKpRSQX9NfuySIiDSGY3T3tgQ1V7uf4jx3JTcCn1T1gjLnVGJNtjMnOzc0NYIkiRxfuC+PvVw0iK7MVP3trLtNWbve6JBGRZiGYIaW63dqqHX1ojDkVF1IerO5xa+0L1tosa21WSkpKAEsUqZ3oCB8vXXccnZNb8JP/zmLhxoIGff3S8koN3hWRZieY3T05QEaV++nApkNPMsb0B14CzrXW5gWxHpFjkhAbwas3DuXS577jhv/M4PaRXQGorLRUWkulxd1WWir89zNbxzJqYBrhvvp9Hygtr+Tf367hma9WcFyn1jx2aT/aJcQE8s8SEQlZJljfzowx4cBy4HRgIzAT+JG1dlGVczoAk4DrDhmfckRZWVk2Ozs7CBWL1M7Kbbu56sXp5O6q3R4/nVPieODsnpzdpw3GVNfAWL1pK7fz6w8Wsjp3D8O7JDFnfT7hPsNvLuzDpYPb1+laIiKhyhgzy1qbVe1jwWxCNsacBzwF+ICXrbV/MMbcBmCtfd4Y8xJwKbDO/5TyIxW6j0KKhIKS8gqKSioIM4awMAgzBl+YwRj/78b9/vnirTw+cSmrcvcwJLMVD5/bk6yOrWu89paCYh79eDEfzd9Mh9ax/Pai3pzWsw3r8vbwi7fnM2PtDs7olcofL+lHasvoBvqLRUSCw7OQEgwKKdLYlFdU8vasHJ78YjnbdpVwRq82PHhOD7q1aXnQeWUVlbwybS1PfbmcskrLHSO7cNspXYiO8O0/p7LS8vK0Nfzls2XERPr4/ai+XNi/nVpVRKTRUkgRCQFFpeW8/O0anv9mNUWl5VyRlcG9Z3SnbUI001fn8f8+WMjyrbs5tUcKv72oD5lJcUe81qrc3fx83DzmbsjnvH5teWRUX5JaRDXgXyMiEhgKKSIhZMeeUv4+aQWvT1+HL8yQldmab1dup31iDL+5sDdn9q7d2JXyikpemLqap75YQXxMOI+O7sc5fds2wF8gIhI4CikiIWjDjiL++vkyJi/L5drjM/npqV2JifQd/YmHWLZlF/eNm8uiTYWM7JHCuX3bcmrPVI1XEZFGQSFFpIkrq6jkX9+s4o0f1rOpoBiAARmJnN4zldN7pdK7XbzGrYhISFJIEWkmrLUs3bKLr5Zs5csl25iXk4+10C4hmtN6pnJGrzac0CXpoMG4IiJeUkgRaaZyd5Xw9bJtTFqyjSkrcikqraBlVDgPntuTHw3tQFiYWldExFsKKSJCSXkF01fv4IUpq5i2Mo/jO7fmsUv71ziLSEQk2GoKKcHcu0dEQkhUuI9Tuqfw+k3D+PMl/Vi0sZCzn5rCS1NXU1HZuL6siEjzoJAi0swYYxgztAOf33cyI7ok8+jHS7js+e9YuW2X16WJiBxEIUWkmWqXEMNL12fx1JUDWbN9D+c9/S3Pfr2SsopKr0sTEQEUUkSaNWMMowe154ufncIZvVP5y2fLGP3sNBZtKvC6NBERDZwVkQM+XbCZX3+wiPyiUk7qlsyIru6nR5uWmgkkIkFR08DZ8IYuRkRC17n92nFClyT+PmklXy/bxtcfLwEguUUkJ3RJ5sSuSQzvkkxG69haXa+0vJJKa5v9uiwl5RVE+sK0oJ5IHaklRUSOaHPBXqatzGPayu1MW7mdbbtKAMhMimV4l2TSW8VQsLeMgqIy8veWUrC3jPyiMgr3lpG/t4yiUvfhfNHANG46sRO92sUHvWZrbciEgY35e3nqi+W8OzuHqHAfaYnRpCXGkN4qhvaJMaQlutv2rWJoGx9NuE898NL8aJ0UETlm1lpWbtvNtJXb+XZlHj+szmNXSTnREWEkxESQGBNJQkwECbER/vvudkthMeNnb2RvWQUndk3m5pM6cUr3lIAEiZLyChZvKmTO+nzmbMhnzvqdFO4t46phHbhxRCfaxHuzf1He7hKe/XoVr09fBwauyEonOtzHxvy9bMrfy8b8vWzfXXrQc8IMnNO3Lb+7qC8pLbWjtTQfCikiEnAVlZayispadeXkF5Xyxoz1vPrdWrYWltAttQU3ndiJ0YPa17oryFrLpoJi5qzf6ULJ+p0s3FRIabmbjZSWEM2gDq2otJbPFm3BF2a4eFB7bj25M11TWx7T31pbu4rLeGnqGl6aupq9ZRVcPiSDe87oRlpizGHnFpdVsDF/Lxt3uuCyfOtuXp++jrgoH4+M7ssF/dMapGYRrymkiEhIKC2v5KP5m3hx6hqWbC4kKS6Sa47P5NoTMmkZHc6WgmI25RezuWAvmwuK2eRvedj3e2FxOQBR4WH0T09gUIdWDMpIZFCHVrRNONBqsj6viJe+Xc247A0Ul1VyRq823HZKZ7I6tg7K31VcVsHr09fx7Ncr2VlUxnn92nLfmT3omtqiTtdZsXUX9789j3k5BZzfrx2/H9WHpBZqVZGmTSFFREKKtZbvV+Xx0rdrmLR0G74wU+2qt61iI2iXEENaYjTtEmLomtqCwR1a0bNdSyJqMX4jb3cJr32/jle/X0t+URlDMlvxk5M7c0avNgGZrVRaXsn7czby1JfL2VRQzEndkvnF2T3on55Y72uWV1TyrymreerL5cRHR/Do6L6c26/dMdcqEqoUUkQkZK3ctpvx/oGl7RKjSUuI2X8bExmYWUFFpeW8nZ3Di1NXk7NzL51T4jijVxsGd2jF4MxEUlvWbuzKvnE5U1ds59uV25m+Oo+i0goGpCfwwDk9GdE1OSD1Aizb4lpVFmws4MIBafz+oj60iosM2PVFQoVCiogIrpXik4VbeP37dczdkE+pf3XdjNYxDOnQiiGZrRic2YoebVrun2mzfXcJ01Zud8FkxXa2FBYD0DEplhO7JXN6rzaMDNBA4EOVVVTy/ORVPDNpBQkxkfzh4r6c3adtwF9HxEsKKSIihygpr2DhxkLmrN/JrHU7yV63k1z/FOu4SB8DMhLZWVTGks2FACTGRjCiSzIndkvmxK61XysmEJZsLuTn4+axeHMhp/VM5aRuyQzMSKR3WjxR4c17DRpp/BRSRESOwlpLzs69zPaHljnr84mL8nFStxRO6pZMn7QEfB6uultWUck/v17F2Jnr2VzgWnMifWH0aR/PoIxWDOqQyKAOibRPjAmZdWJEakMhRUSkCdlSUMzcDfumYuczf2M+xWWu6yqlZRRDOrRi1MA0zujdplYDjEW8pGXxRUSakLYJ0ZyT0I5z+rpZP2UVlSzbsmv/GjLTVm1n4qItpLSM4oqsdMYc16FBu6dEAkUtKSIiTUxFpWXysm288cN6vl62DQuc3C2FHw3rwOk9U7X8voQUdfeIiDRTG/P38tbMDbw1cz1bC0toEx/FlVkZXDm0A2kJ0ewprWDnnlLyi8rYWVTqfvaUsrOojPyiUiLDwxiY4aZqt0s4fOVckWOlkCIi0syVV1Qyaek23pixnm+W5wIQHmYoqzjyZ0B8dDjF5ZX7tx5olxDN4MxWbn2ZDon0SUsgMvzgVpnKSsvWXcWs3V7E+h17WJtXxPq8InJ2FtGrXTxXHJfBoIxEDe6V/RRSRERkv5ydRbw3eyN7SitoFRtBq9hIEmMjaB0XSWJsJK38m0SG+8IoLa9kyeZCZq3byWz/mJeN+XsBiAwPo1/7BHq0bcm2whLW5e1h/Y4iSvyhBiDCZ0hvFUvb+Gjmbshnb1kFXVNbcEVWOhcPSg+pzRT3lJSzNm8P6/KKWLN9D+vy9rB2exGFxWUM6tCKE7smc0KXJFprUb2AUkgREZGA2VpYzOx1O/cHl1W5e2gbH01mUqz/J46OSXFkJsXSLiF6/xiY3SXlfDx/E2/N3MDs9fmEhxlO65nKlcdlcEr3lICMlSkuq2Dx5kIWbypkT0k5lRYqraWi0lJpLZWVlkoLFf7fd+wpdaEkb8/+dXL2SWkZRaekOGIifcxat5PdJW7vqN7t4hnRNYnhXZMZ2rE1cVGag3IsFFJERCSkrNy2i7ezc3h3dg7bd5eS2jKKS4ekc3rP1P0tOgkxETWuTVNcVsHSLbtYkJPPgo0FzM8pYMW23dXuA7WPMRBmDD5jCAuDltERdPIHqo7JcXRK9v+eFHdQ+CivqGT+xgKmrdjOtFXbmb3OrVgc4TMMymjF8K5JDO3UmoEZicRG1i20VFZaFmwsYNLSbXy9bBsbdhRxRq82jB7UnuM7J3m6Pk9DUEgREZGQVFZRyddLtzEuewNfL8s9KGAYA/HRESTGRuzvhkqMicAXFsaSzYUs37qLcv/5reMi6dc+gX7tE+jbPoG+7eNpFRuJL8xgDPiM8f8emA/8vaUVZK/bwbSVeUxbuZ2Fmwqw1o3z6ZMWz5DM1mR1bEVWZitS4w/fG6qwuIxvV2xn0tJtTF6Wy/bdJYQZGNShFe0TY5i0dBu7S8pJbRnFhQPSGD2wPX3bxzfJsTwKKSIiEvK27Spm0aZCCvwzjfL9M4zy95btn22UX1RGSXkF3du0pH+6CyX90hNJS4j29AO8oKiM2et3kr1uB9lrdzJ3Q/7+sTkdWseSldmKIR1bUVRSwaSl25i5dgfllZb46HBO6ZHK6T1TObl7yv7xLsVl7rz352xk8rJcSisq6ZwSx6gB7Rk1MI2OyXGe/a2BppAiIiLSgErLK1m0qYBZ63Yyc+0OZq3byfbdpQD0aNOSU3umclrPVAZ3SDzqWJyCojI+WbiZD+Zu5Ic1O7AWBqS7AcupLaNJjY+qchtFSsuoGvd0qqy0FJdXUFRawd7SCsorLZHhYUTt//ER4Qtcq9PRKKSIiIh4yFrL+h1FhPvCaJ9Y//VmNuXv5cN5m/hs0RZydu5l++4SqhuCkxgbQWrLKCLDwygqraC4tIK9ZS6YVJ19dSTGuL2hosLDiIrwERUexqOj+zKyR2q9az/ya2lZfBEREc8YY8hMOvYumrTEGH5yShd+ckoXwK0unLenhG2FJWzbVey/LWFrYTHbdpVQWWmJjvQRE+Ej1n8bHeEjxv97TKTPv15OJSXllZSUVVJSXkFpuf9+ubtfUl7pydRrhRQREZFGyhdmXFdPy2ggwetyAk4bOIiIiEhIUkgRERGRkKSQIiIiIiFJIUVERERCkkKKiIiIhKSghhRjzDnGmGXGmJXGmIeqedwYY57xPz7fGDM4mPWIiIhI4xG0kGKM8QHPAucCvYGrjDG9DzntXKCb/+dW4Llg1SMiIiKNSzBbUoYCK621q621pcBYYNQh54wCXrPOdCDRGNMuiDWJiIhIIxHMkNIe2FDlfo7/WF3PwRhzqzEm2xiTnZubG/BCRUREJPQEM6RUtzPRoTsM1OYcrLUvWGuzrLVZKSkpASlOREREQlswQ0oOkFHlfjqwqR7niIiISDMUzJAyE+hmjOlkjIkExgATDjlnAnCdf5bP8UCBtXZzEGsSERGRRiJoGwxaa8uNMXcCnwE+4GVr7SJjzG3+x58HPgHOA1YCRcCPg1WPiIiINC7G2sOGgIQ0Y0wusC5Il08Gtgfp2lI9vecNT++5N/S+Nzy95w2vPu95prW22gGnjS6kBJMxJttam+V1Hc2J3vOGp/fcG3rfG57e84YX6Pdcy+KLiIhISFJIERERkZCkkHKwF7wuoBnSe97w9J57Q+97w9N73vAC+p5rTIqIiIiEJLWkiIiISEhSSAGMMecYY5YZY1YaYx7yup6myhjzsjFmmzFmYZVjrY0xXxhjVvhvW3lZY1NjjMkwxnxtjFlijFlkjLnHf1zve5AYY6KNMTOMMfP87/nv/Mf1ngeZMcZnjJljjPnIf1/veRAZY9YaYxYYY+YaY7L9xwL6njf7kGKM8QHPAucCvYGrjDG9va2qyXoFOOeQYw8BX1lruwFf+e9L4JQDP7fW9gKOB37q//db73vwlACnWWsHAAOBc/wraus9D757gCVV7us9D75TrbUDq0w7Duh73uxDCjAUWGmtXW2tLQXGAqM8rqlJstZOAXYccngU8Kr/91eB0Q1ZU1Nnrd1srZ3t/30X7n/g7dH7HjTW2e2/G+H/seg9DypjTDpwPvBSlcN6zxteQN9zhRT3P+wNVe7n+I9Jw2izb78m/22qx/U0WcaYjsAg4Af0vgeVv9thLrAN+MJaq/c8+J4CHgAqqxzTex5cFvjcGDPLGHOr/1hA3/Og7d3TiJhqjmnKkzQpxpgWwLvAvdbaQmOq+9deAsVaWwEMNMYkAu8ZY/p6XFKTZoy5ANhmrZ1ljBnpcTnNyQhr7SZjTCrwhTFmaaBfQC0pruUko8r9dGCTR7U0R1uNMe0A/LfbPK6nyTHGROACyv+steP9h/W+NwBrbT4wGTcWS+958IwALjLGrMV12Z9mjHkdvedBZa3d5L/dBryHGz4R0PdcIQVmAt2MMZ2MMZHAGGCCxzU1JxOA6/2/Xw984GEtTY5xTSb/BpZYa5+o8pDe9yAxxqT4W1AwxsQAZwBL0XseNNbah6216dbajrj/h0+y1l6D3vOgMcbEGWNa7vsdOAtYSIDfcy3mBhhjzsP1Z/qAl621f/C2oqbJGPMmMBK3S+ZW4DfA+8A4oAOwHrjcWnvo4FqpJ2PMicBUYAEH+up/iRuXovc9CIwx/XEDBn24L4LjrLW/N8Ykofc86PzdPfdbay/Qex48xpjOuNYTcENH3rDW/iHQ77lCioiIiIQkdfeIiIhISFJIERERkZCkkCIiIiIhSSFFREREQpJCioiIiIQkhRQRCSpjTIV/l9R9PwHb5M0Y07Hqrtoi0rRoWXwRCba91tqBXhchIo2PWlJExBPGmLXGmMeMMTP8P139xzONMV8ZY+b7bzv4j7cxxrxnjJnn/xnuv5TPGPOiMWaRMeZz/yqvItIEKKSISLDFHNLdc2WVxwqttUOBf+BWfcb/+2vW2v7A/4Bn/MefAb6x1g4ABgOL/Me7Ac9aa/sA+cClQf1rRKTBaMVZEQkqY8xua22Lao6vBU6z1q72b4K4xVqbZIzZDrSz1pb5j2+21iYbY3KBdGttSZVrdAS+sNZ2899/EIiw1j7aAH+aiASZWlJExEv2CL8f6ZzqlFT5vQKNtRNpMhRSRMRLV1a5/d7/+3e4nWwBrga+9f/+FXA7gDHGZ4yJb6giRcQb+sYhIsEWY4yZW+X+RGvtvmnIUcaYH3BfmK7yH7sbeNkY8wsgF/ix//g9wAvGmJtwLSa3A5uDXbyIeEdjUkTEE/4xKVnW2u1e1yIioUndPSIiIhKS1JIiIiIiIUktKSIiIhKSFFJEREQkJCmkiIiISEhSSBEREZGQpJAiIiIiIUkhRURERELS/wfvOTTuaW7Y/AAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training & validation loss values\n",
    "plt.figure(figsize=(9,6))\n",
    "plt.plot(GRU_history.history['loss'])\n",
    "plt.plot(GRU_history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 2s 18ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_GRU = GRU_model.predict(feature_test)\n",
    "y_pred_GRU_class = np.argmax(y_pred_GRU, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8172043010752689\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.63      0.65        19\n",
      "           1       0.85      0.88      0.86        50\n",
      "           2       0.87      0.87      0.87        23\n",
      "           3       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.82        93\n",
      "   macro avg       0.60      0.60      0.60        93\n",
      "weighted avg       0.81      0.82      0.81        93\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/pjw22/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test_class, y_pred_GRU_class))\n",
    "print(classification_report(y_test_class, y_pred_GRU_class))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Only use 3 classes to do Classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>fund_name</th>\n",
       "      <th>Performance fee?</th>\n",
       "      <th>Ivestment Strategy</th>\n",
       "      <th>Leverage?</th>\n",
       "      <th>Portfolio composition</th>\n",
       "      <th>Concentration</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000051931-18-000151</td>\n",
       "      <td>American Funds College 2018 Fund</td>\n",
       "      <td>None</td>\n",
       "      <td>Balanced Fund (Low Risk)</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Investment grade securities</td>\n",
       "      <td>Diversified</td>\n",
       "      <td>American Funds College 2018 Fund\\n\\nInvestment...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000051931-18-000151</td>\n",
       "      <td>American Funds College 2021 Fund</td>\n",
       "      <td>None</td>\n",
       "      <td>Balanced Fund (Low Risk)</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Investment grade securities</td>\n",
       "      <td>Diversified</td>\n",
       "      <td>American Funds College 2021 Fund\\n\\nInvestment...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000051931-18-000151</td>\n",
       "      <td>American Funds College 2024 Fund</td>\n",
       "      <td>None</td>\n",
       "      <td>Balanced Fund (Low Risk)</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Investment grade securities</td>\n",
       "      <td>Diversified</td>\n",
       "      <td>American Funds College 2024 Fund\\n\\nInvestment...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000051931-18-000151</td>\n",
       "      <td>American Funds College 2027 Fund</td>\n",
       "      <td>None</td>\n",
       "      <td>Balanced Fund (Low Risk)</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Investment grade securities</td>\n",
       "      <td>Diversified</td>\n",
       "      <td>American Funds College 2027 Fund\\n\\nInvestment...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000051931-18-000151</td>\n",
       "      <td>American Funds College 2030 Fund</td>\n",
       "      <td>None</td>\n",
       "      <td>Balanced Fund (Low Risk)</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Investment grade securities</td>\n",
       "      <td>Diversified</td>\n",
       "      <td>American Funds College 2030 Fund\\n\\nInvestment...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id                         fund_name Performance fee?  \\\n",
       "0  0000051931-18-000151  American Funds College 2018 Fund             None   \n",
       "1  0000051931-18-000151  American Funds College 2021 Fund             None   \n",
       "2  0000051931-18-000151  American Funds College 2024 Fund             None   \n",
       "3  0000051931-18-000151  American Funds College 2027 Fund             None   \n",
       "4  0000051931-18-000151  American Funds College 2030 Fund             None   \n",
       "\n",
       "         Ivestment Strategy Leverage?        Portfolio composition  \\\n",
       "0  Balanced Fund (Low Risk)       Yes  Investment grade securities   \n",
       "1  Balanced Fund (Low Risk)       Yes  Investment grade securities   \n",
       "2  Balanced Fund (Low Risk)       Yes  Investment grade securities   \n",
       "3  Balanced Fund (Low Risk)       Yes  Investment grade securities   \n",
       "4  Balanced Fund (Low Risk)       Yes  Investment grade securities   \n",
       "\n",
       "   Concentration                                            summary  \n",
       "0    Diversified  American Funds College 2018 Fund\\n\\nInvestment...  \n",
       "1    Diversified  American Funds College 2021 Fund\\n\\nInvestment...  \n",
       "2    Diversified  American Funds College 2024 Fund\\n\\nInvestment...  \n",
       "3    Diversified  American Funds College 2027 Fund\\n\\nInvestment...  \n",
       "4    Diversified  American Funds College 2030 Fund\\n\\nInvestment...  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove the 4th class and do the same process again \n",
    "\n",
    "df_label = pd.read_csv('/Users/pjw22/Desktop/BU Course/815/NLP_app/MutualFundLabels.csv')\n",
    "\n",
    "df_label = df_label[df_label['Ivestment Strategy'] != 'Commodities Fund (Low Risk)']\n",
    "df_label = df_label[df_label['Ivestment Strategy'] != 'Long Short Funds (High Risk)']\n",
    "\n",
    "# We create here the dataframe that contains the summaries along with their labels\n",
    "df_extraction = pd.DataFrame({'fund_name' : fund_names, 'summary':summaries})\n",
    "df = df_label.merge(df_extraction, on='fund_name', how='left').dropna()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Equity Long Only (Low Risk)          247\n",
       "Fixed Income Long Only (Low Risk)    130\n",
       "Balanced Fund (Low Risk)              84\n",
       "Name: Ivestment Strategy, dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Ivestment Strategy'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test validation split\n",
    "\n",
    "df_train, df_test = train_test_split(df, test_size = 0.2, random_state=41)\n",
    "df_train, df_val = train_test_split(df_train, test_size=0.2, random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_summaries = list(df_train['summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_words = np.concatenate([tokenizer(summary) for summary in train_summaries])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the dictionary and replace rare words with UNK token\n",
    "count = [('UNK', -1)]\n",
    "# Retrieve the most common words\n",
    "count.extend(collections.Counter(text_words).most_common(max_vocabulary_size - 1))\n",
    "# Remove samples with less than 'min_occurrence' occurrences\n",
    "for i in range(len(count) - 1, -1, -1):\n",
    "    if count[i][1] < min_occurrence:\n",
    "        count.pop(i)\n",
    "    else:\n",
    "        # The collection is ordered, so stop when 'min_occurrence' is reached\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2id = dict()\n",
    "for i, (word, _)in enumerate(count):\n",
    "    word2id[word] = i\n",
    "id2word = dict(zip(word2id.values(), word2id.keys()))\n",
    "vocab_size = len(id2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data\n",
    "data = list()\n",
    "unk_count = 0\n",
    "for word in text_words:\n",
    "    # Retrieve a word id, or assign it index 0 ('UNK') if not in dictionary\n",
    "    index = word2id.get(word, 0)\n",
    "    if index == 0:\n",
    "        unk_count += 1\n",
    "    data.append(index)\n",
    "count[0] = ('UNK', unk_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder, autoencoder = creat_word2vec_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l_/7bxj1ry51hbcvpybp93hdq4w0000gn/T/ipykernel_42137/486976267.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  autoencoder.fit_generator(batch_generator(batch_size, num_skips, skip_window, vocab_size), steps_per_epoch=ceil(len(data) / batch_size), epochs=num_epochs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "4018/4018 [==============================] - 26s 6ms/step - loss: 6.4972\n",
      "Epoch 2/2\n",
      "4018/4018 [==============================] - 29s 7ms/step - loss: 5.9765\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17ff0fb80>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit_generator(batch_generator(batch_size, num_skips, skip_window, vocab_size), steps_per_epoch=ceil(len(data) / batch_size), epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 546ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 1s 532ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n"
     ]
    }
   ],
   "source": [
    "# Create the Vectorizer function (prediciton of the encoder)\n",
    "def vecotrize(word):\n",
    "    word_one_hot = to_one_hot(word2id[word], vocab_size)\n",
    "    return encoder.predict(np.array([word_one_hot]))[0]\n",
    "\n",
    "\n",
    "# Create the word2vec dictionary\n",
    "word2vec = {w : vecotrize(w) for w in word2id.keys()}\n",
    "\n",
    "# This dictionary gives for all words it's vectorial representation.\n",
    "\n",
    "\n",
    "our_word2vec = 'word2vec_perso.txt'\n",
    "\n",
    "# We can save the word2vec dictionary to reuse it later.\n",
    "save_word2vec(our_word2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keywords for “Balanced Fund (Low Risk)”\n",
    "key_words1 = ['portfolio', 'balanced', 'asset', 'diversification', 'risk', 'low', 'investment', 'strategy', 'fixed', 'income', 'equity', 'return', 'fund', 'conservative', 'market']\n",
    "\n",
    "# keywords for “Fixed Income Long Only (Low Risk)”\n",
    "key_words2 = ['portfolio', 'risk', 'low', 'investment', 'strategy', 'cash', 'fixed', 'income', 'bond', 'yield', 'credit', 'maturity', 'duration', 'treasury', 'interest', 'rate', 'corporate', 'inflation', 'economic']\n",
    "\n",
    "# keywords for “Equity Long Only (Low Risk)”\n",
    "key_words3 = ['equity', 'stocks', 'securities', 'earnings', 'dividend', 'financial', 'statement', 'revenue', 'price', 'volatility', 'fund', 'company', 'industry', 'economic', 'growth', 'sector', 'strategy', 'risk', 'portfolio', 'factor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <progress\n",
       "            value='14'\n",
       "            max='14',\n",
       "            style='width: 100%'\n",
       "        >\n",
       "            14\n",
       "        </progress>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <progress\n",
       "            value='18'\n",
       "            max='18',\n",
       "            style='width: 100%'\n",
       "        >\n",
       "            18\n",
       "        </progress>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <progress\n",
       "            value='19'\n",
       "            max='19',\n",
       "            style='width: 100%'\n",
       "        >\n",
       "            19\n",
       "        </progress>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#word2vec = load_word2vec(our_word2vec)\n",
    "knowledge_base1 = create_knowledge_base(5, word2vec, key_words1)\n",
    "knowledge_base2 = create_knowledge_base(5, word2vec, key_words2)\n",
    "knowledge_base3 = create_knowledge_base(5, word2vec, key_words3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "knowledge_base = knowledge_base1.union(knowledge_base2).union(knowledge_base3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It takes several minutes (5-10 minutes)\n",
    "df_train['sentences_distance'] = df_train.apply(lambda x : extract_sentence_distance(x['summary'], knowledge_base, n_closer=10, n_reject=5, num_sent=5), axis=1)\n",
    "\n",
    "df_val['sentences_distance'] = df_val.apply(lambda x : extract_sentence_distance(x['summary'], knowledge_base, n_closer=10, n_reject=5, num_sent=5), axis=1)\n",
    "\n",
    "df_test['sentences_distance'] = df_test.apply(lambda x : extract_sentence_distance(x['summary'], knowledge_base, n_closer=10, n_reject=5, num_sent=5), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'iico also consider effect commodity price trends certain holdings poor capital management whether co'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = df_train['sentences_distance'].values\n",
    "X_val = df_val['sentences_distance'].values\n",
    "X_test = df_test['sentences_distance'].values\n",
    "\n",
    "# X = df['deriv_sentences_distance'].values # uncomment to use the first sentence extraction method.\n",
    "# Clean the texts\n",
    "X_train = [' '.join(tokenizer(txt)) for txt in X_train]\n",
    "X_val = [' '.join(tokenizer(txt)) for txt in X_val]\n",
    "X_test = [' '.join(tokenizer(txt)) for txt in X_test]\n",
    "\n",
    "X_train[0][:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot for labels\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "\n",
    "y_train = encoder.fit_transform(np.array(df_train['Ivestment Strategy']).reshape(-1,1))\n",
    "y_val = encoder.fit_transform(np.array(df_val['Ivestment Strategy']).reshape(-1,1))\n",
    "y_test = encoder.fit_transform(np.array(df_test['Ivestment Strategy']).reshape(-1,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Tokenizer provided by the Keras library allows to perform such transformation.\n",
    "keras_tokenizer = Tokenizer(num_words=num_words)\n",
    "keras_tokenizer.fit_on_texts(X_train)\n",
    "# word_index is the dictionary that contains the index of each words in our 2500 long vocabulary.\n",
    "word_index = keras_tokenizer.word_index\n",
    "sequences_train = keras_tokenizer.texts_to_sequences(X_train)\n",
    "sequences_test = keras_tokenizer.texts_to_sequences(X_test)\n",
    "sequences_val = keras_tokenizer.texts_to_sequences(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_train = pad_sequences(sequences_train, maxlen=maxlen, dtype=float, padding='post', truncating='post')\n",
    "feature_test = pad_sequences(sequences_test, maxlen=maxlen, dtype=float, padding='post', truncating='post')\n",
    "feature_val = pad_sequences(sequences_val, maxlen=maxlen, dtype=float, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(word_index) + 1, word_dimension))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = word2vec_g.get(word)\n",
    "    #embedding_vector = word2vec.get(word)   # uncomment to use our own word2vec\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_CNN_model():\n",
    "    CNN = Sequential()\n",
    "    # The Embedding layer takes the embedding matrix as an argument and transform the inputed the sequences of index to sequences of vectors.\n",
    "    CNN.add(Embedding(len(word_index) + 1, word_dimension, weights=[embedding_matrix], input_length = maxlen, trainable=False))\n",
    "\n",
    "\n",
    "    CNN.add(Convolution1D(64, 5, activation = 'relu'))\n",
    "    CNN.add(MaxPooling1D(pool_size = 5))\n",
    "\n",
    "    CNN.add(Convolution1D(32, 5, activation = 'relu'))\n",
    "    CNN.add(MaxPooling1D(pool_size = 5))\n",
    "\n",
    "    CNN.add(Flatten())\n",
    "    CNN.add(Dense(units = 128 , activation = 'relu'))\n",
    "    CNN.add(Dropout(0.5))\n",
    "\n",
    "    #CNN.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "    CNN.add(Dense(units = 3, activation = 'sigmoid'))\n",
    "\n",
    "    CNN.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    return CNN\n",
    "\n",
    "CNN_model = create_CNN_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1.0336 - accuracy: 0.5340 - val_loss: 0.8594 - val_accuracy: 0.6081\n",
      "Epoch 2/50\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.7459 - accuracy: 0.7041 - val_loss: 0.8420 - val_accuracy: 0.6486\n",
      "Epoch 3/50\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.5770 - accuracy: 0.7823 - val_loss: 0.6827 - val_accuracy: 0.8108\n",
      "Epoch 4/50\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.3833 - accuracy: 0.8639 - val_loss: 0.6680 - val_accuracy: 0.8108\n",
      "Epoch 5/50\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.3591 - accuracy: 0.8605 - val_loss: 0.8670 - val_accuracy: 0.7162\n",
      "Epoch 6/50\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.2794 - accuracy: 0.9082 - val_loss: 0.5607 - val_accuracy: 0.7973\n",
      "Epoch 7/50\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.1411 - accuracy: 0.9626 - val_loss: 0.6286 - val_accuracy: 0.8649\n",
      "Epoch 8/50\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.1050 - accuracy: 0.9796 - val_loss: 0.5894 - val_accuracy: 0.8108\n",
      "Epoch 9/50\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.0719 - accuracy: 0.9898 - val_loss: 0.6783 - val_accuracy: 0.8378\n",
      "Epoch 10/50\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.0620 - accuracy: 0.9864 - val_loss: 0.5894 - val_accuracy: 0.8378\n",
      "Epoch 11/50\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.0438 - accuracy: 0.9864 - val_loss: 0.6962 - val_accuracy: 0.8649\n",
      "Epoch 12/50\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.0408 - accuracy: 0.9932 - val_loss: 0.6830 - val_accuracy: 0.8514\n",
      "Epoch 13/50\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.0396 - accuracy: 0.9898 - val_loss: 0.8696 - val_accuracy: 0.8378\n",
      "Epoch 14/50\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.0689 - accuracy: 0.9864 - val_loss: 0.7132 - val_accuracy: 0.7703\n",
      "Epoch 15/50\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.0539 - accuracy: 0.9898 - val_loss: 0.6172 - val_accuracy: 0.8514\n",
      "Epoch 16/50\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.0254 - accuracy: 0.9932 - val_loss: 0.6757 - val_accuracy: 0.8649\n",
      "Epoch 17/50\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.0243 - accuracy: 0.9932 - val_loss: 0.6844 - val_accuracy: 0.8649\n",
      "Epoch 18/50\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.0215 - accuracy: 0.9932 - val_loss: 0.7559 - val_accuracy: 0.8649\n",
      "Epoch 19/50\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.0197 - accuracy: 0.9966 - val_loss: 0.9426 - val_accuracy: 0.8378\n",
      "Epoch 20/50\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.0212 - accuracy: 0.9966 - val_loss: 0.6955 - val_accuracy: 0.8243\n",
      "Epoch 21/50\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.0248 - accuracy: 0.9966 - val_loss: 0.7137 - val_accuracy: 0.7838\n",
      "Epoch 22/50\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.0250 - accuracy: 0.9898 - val_loss: 0.7264 - val_accuracy: 0.8514\n",
      "Epoch 23/50\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.0166 - accuracy: 0.9966 - val_loss: 0.7299 - val_accuracy: 0.8649\n",
      "Epoch 24/50\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.0226 - accuracy: 0.9932 - val_loss: 0.8503 - val_accuracy: 0.8649\n",
      "Epoch 25/50\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.0163 - accuracy: 0.9932 - val_loss: 0.7925 - val_accuracy: 0.8649\n",
      "Epoch 26/50\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.0159 - accuracy: 0.9932 - val_loss: 0.7305 - val_accuracy: 0.8514\n",
      "Epoch 27/50\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.0177 - accuracy: 0.9932 - val_loss: 0.8338 - val_accuracy: 0.8649\n",
      "Epoch 28/50\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.0119 - accuracy: 0.9966 - val_loss: 0.8019 - val_accuracy: 0.8649\n",
      "Epoch 29/50\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.0101 - accuracy: 0.9966 - val_loss: 0.7449 - val_accuracy: 0.8784\n",
      "Epoch 30/50\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.0136 - accuracy: 0.9932 - val_loss: 0.8031 - val_accuracy: 0.8649\n",
      "Epoch 31/50\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.0214 - accuracy: 0.9932 - val_loss: 0.7547 - val_accuracy: 0.8378\n",
      "Epoch 32/50\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.0155 - accuracy: 0.9932 - val_loss: 0.8068 - val_accuracy: 0.8649\n",
      "Epoch 33/50\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.0125 - accuracy: 0.9966 - val_loss: 0.7835 - val_accuracy: 0.8649\n",
      "Epoch 34/50\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.0224 - accuracy: 0.9864 - val_loss: 1.1333 - val_accuracy: 0.8243\n",
      "Epoch 35/50\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.0210 - accuracy: 0.9966 - val_loss: 0.9205 - val_accuracy: 0.8649\n",
      "Epoch 36/50\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.0076 - accuracy: 0.9966 - val_loss: 0.8233 - val_accuracy: 0.8649\n",
      "Epoch 37/50\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.0182 - accuracy: 0.9966 - val_loss: 0.7909 - val_accuracy: 0.8649\n",
      "Epoch 38/50\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.0106 - accuracy: 0.9966 - val_loss: 0.8213 - val_accuracy: 0.8649\n",
      "Epoch 39/50\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.0155 - accuracy: 0.9932 - val_loss: 0.7988 - val_accuracy: 0.8649\n",
      "Epoch 40/50\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.0084 - accuracy: 0.9966 - val_loss: 0.7764 - val_accuracy: 0.8514\n",
      "Epoch 41/50\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.0110 - accuracy: 0.9932 - val_loss: 0.8582 - val_accuracy: 0.8649\n",
      "Epoch 42/50\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.0146 - accuracy: 0.9966 - val_loss: 0.8589 - val_accuracy: 0.8649\n",
      "Epoch 43/50\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.0083 - accuracy: 0.9966 - val_loss: 1.0482 - val_accuracy: 0.8243\n",
      "Epoch 44/50\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.0090 - accuracy: 0.9966 - val_loss: 0.8156 - val_accuracy: 0.8514\n",
      "Epoch 45/50\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.0196 - accuracy: 0.9932 - val_loss: 0.8513 - val_accuracy: 0.8649\n",
      "Epoch 46/50\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.0095 - accuracy: 0.9966 - val_loss: 0.8704 - val_accuracy: 0.8649\n",
      "Epoch 47/50\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.0099 - accuracy: 0.9966 - val_loss: 0.8108 - val_accuracy: 0.8378\n",
      "Epoch 48/50\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.0118 - accuracy: 0.9966 - val_loss: 0.7360 - val_accuracy: 0.8784\n",
      "Epoch 49/50\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.8534 - val_accuracy: 0.8649\n",
      "Epoch 50/50\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.0104 - accuracy: 0.9932 - val_loss: 0.8400 - val_accuracy: 0.8649\n"
     ]
    }
   ],
   "source": [
    "CNN_history = CNN_model.fit(feature_train, y_train, epochs=50, batch_size=16, validation_data=(feature_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 3ms/step\n",
      "0.8709677419354839\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.68      0.76        19\n",
      "           1       0.85      0.98      0.91        46\n",
      "           2       0.92      0.82      0.87        28\n",
      "\n",
      "    accuracy                           0.87        93\n",
      "   macro avg       0.88      0.83      0.85        93\n",
      "weighted avg       0.87      0.87      0.87        93\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_CNN = CNN_model.predict(feature_test)\n",
    "y_pred_CNN_class = np.argmax(y_pred_CNN, axis=1)\n",
    "y_test_class = np.argmax(y_test, axis=1)\n",
    "\n",
    "print(accuracy_score(y_test_class, y_pred_CNN_class))\n",
    "print(classification_report(y_test_class, y_pred_CNN_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training & validation accuracy\n",
    "plt.figure(figsize=(9,6))\n",
    "plt.plot(CNN_history.history['accuracy'])\n",
    "plt.plot(CNN_history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training & validation loss values\n",
    "plt.figure(figsize=(9,6))\n",
    "plt.plot(CNN_history.history['loss'])\n",
    "plt.plot(CNN_history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_RNN_model():\n",
    "    RNN = Sequential()\n",
    "    RNN.add(Embedding(len(word_index) + 1, word_dimension, weights=[embedding_matrix], input_length = maxlen, trainable=False))\n",
    "\n",
    "    RNN.add(Bidirectional(LSTM(word_dimension)))\n",
    "    RNN.add(Dense(word_dimension, activation='relu'))\n",
    "    RNN.add(Dense(3, activation='sigmoid'))\n",
    "    RNN.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "    #RNN.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "    \n",
    "    return RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "19/19 [==============================] - 5s 115ms/step - loss: 1.0662 - accuracy: 0.4456 - val_loss: 0.9603 - val_accuracy: 0.5541\n",
      "Epoch 2/50\n",
      "19/19 [==============================] - 1s 38ms/step - loss: 0.8304 - accuracy: 0.6429 - val_loss: 0.8713 - val_accuracy: 0.5946\n",
      "Epoch 3/50\n",
      "19/19 [==============================] - 1s 65ms/step - loss: 0.6492 - accuracy: 0.7483 - val_loss: 0.8075 - val_accuracy: 0.6622\n",
      "Epoch 4/50\n",
      "19/19 [==============================] - 1s 35ms/step - loss: 0.5263 - accuracy: 0.8197 - val_loss: 0.7569 - val_accuracy: 0.7297\n",
      "Epoch 5/50\n",
      "19/19 [==============================] - 1s 35ms/step - loss: 0.4661 - accuracy: 0.8605 - val_loss: 0.6191 - val_accuracy: 0.8243\n",
      "Epoch 6/50\n",
      "19/19 [==============================] - 1s 35ms/step - loss: 0.4666 - accuracy: 0.8469 - val_loss: 0.7052 - val_accuracy: 0.7297\n",
      "Epoch 7/50\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 0.3715 - accuracy: 0.8707 - val_loss: 0.6666 - val_accuracy: 0.7973\n",
      "Epoch 8/50\n",
      "19/19 [==============================] - 1s 35ms/step - loss: 0.2905 - accuracy: 0.8946 - val_loss: 0.6790 - val_accuracy: 0.8243\n",
      "Epoch 9/50\n",
      "19/19 [==============================] - 1s 37ms/step - loss: 0.2568 - accuracy: 0.9218 - val_loss: 0.7260 - val_accuracy: 0.8378\n",
      "Epoch 10/50\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 0.2437 - accuracy: 0.9218 - val_loss: 1.0015 - val_accuracy: 0.6351\n",
      "Epoch 11/50\n",
      "19/19 [==============================] - 1s 39ms/step - loss: 0.2636 - accuracy: 0.9082 - val_loss: 0.7781 - val_accuracy: 0.7838\n",
      "Epoch 12/50\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 0.1676 - accuracy: 0.9558 - val_loss: 0.8707 - val_accuracy: 0.7297\n",
      "Epoch 13/50\n",
      "19/19 [==============================] - 1s 49ms/step - loss: 0.1563 - accuracy: 0.9626 - val_loss: 0.7873 - val_accuracy: 0.7568\n",
      "Epoch 14/50\n",
      "19/19 [==============================] - 1s 47ms/step - loss: 0.1594 - accuracy: 0.9592 - val_loss: 0.7876 - val_accuracy: 0.8108\n",
      "Epoch 15/50\n",
      "19/19 [==============================] - 1s 42ms/step - loss: 0.1411 - accuracy: 0.9626 - val_loss: 0.7332 - val_accuracy: 0.7838\n",
      "Epoch 16/50\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 0.1167 - accuracy: 0.9762 - val_loss: 0.8928 - val_accuracy: 0.7703\n",
      "Epoch 17/50\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 0.1334 - accuracy: 0.9558 - val_loss: 0.8052 - val_accuracy: 0.7432\n",
      "Epoch 18/50\n",
      "19/19 [==============================] - 1s 39ms/step - loss: 0.1262 - accuracy: 0.9660 - val_loss: 0.7728 - val_accuracy: 0.7973\n",
      "Epoch 19/50\n",
      "19/19 [==============================] - 1s 44ms/step - loss: 0.1118 - accuracy: 0.9694 - val_loss: 0.9697 - val_accuracy: 0.7568\n",
      "Epoch 20/50\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 0.0812 - accuracy: 0.9796 - val_loss: 0.9052 - val_accuracy: 0.7703\n",
      "Epoch 21/50\n",
      "19/19 [==============================] - 1s 39ms/step - loss: 0.0683 - accuracy: 0.9830 - val_loss: 0.9868 - val_accuracy: 0.7568\n",
      "Epoch 22/50\n",
      "19/19 [==============================] - 1s 39ms/step - loss: 0.0574 - accuracy: 0.9864 - val_loss: 0.9696 - val_accuracy: 0.7838\n",
      "Epoch 23/50\n",
      "19/19 [==============================] - 1s 47ms/step - loss: 0.0541 - accuracy: 0.9864 - val_loss: 1.1659 - val_accuracy: 0.7297\n",
      "Epoch 24/50\n",
      "19/19 [==============================] - 1s 44ms/step - loss: 0.0483 - accuracy: 0.9898 - val_loss: 0.9913 - val_accuracy: 0.7568\n",
      "Epoch 25/50\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 0.0972 - accuracy: 0.9660 - val_loss: 1.0141 - val_accuracy: 0.7703\n",
      "Epoch 26/50\n",
      "19/19 [==============================] - 1s 39ms/step - loss: 0.0767 - accuracy: 0.9728 - val_loss: 1.0756 - val_accuracy: 0.7838\n",
      "Epoch 27/50\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 0.0690 - accuracy: 0.9796 - val_loss: 1.1425 - val_accuracy: 0.7703\n",
      "Epoch 28/50\n",
      "19/19 [==============================] - 1s 44ms/step - loss: 0.0396 - accuracy: 0.9864 - val_loss: 1.1065 - val_accuracy: 0.7838\n",
      "Epoch 29/50\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 0.0261 - accuracy: 0.9898 - val_loss: 1.1711 - val_accuracy: 0.7838\n",
      "Epoch 30/50\n",
      "19/19 [==============================] - 1s 47ms/step - loss: 0.0196 - accuracy: 0.9966 - val_loss: 1.2019 - val_accuracy: 0.7838\n",
      "Epoch 31/50\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 0.0196 - accuracy: 0.9966 - val_loss: 1.2104 - val_accuracy: 0.7703\n",
      "Epoch 32/50\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 0.0164 - accuracy: 0.9966 - val_loss: 1.2374 - val_accuracy: 0.7703\n",
      "Epoch 33/50\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 0.0160 - accuracy: 0.9966 - val_loss: 1.3143 - val_accuracy: 0.7703\n",
      "Epoch 34/50\n",
      "19/19 [==============================] - 1s 42ms/step - loss: 0.0127 - accuracy: 0.9966 - val_loss: 1.2784 - val_accuracy: 0.7703\n",
      "Epoch 35/50\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 0.0120 - accuracy: 0.9966 - val_loss: 1.2979 - val_accuracy: 0.7703\n",
      "Epoch 36/50\n",
      "19/19 [==============================] - 1s 50ms/step - loss: 0.0123 - accuracy: 0.9966 - val_loss: 1.2949 - val_accuracy: 0.7703\n",
      "Epoch 37/50\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 0.0102 - accuracy: 0.9966 - val_loss: 1.3242 - val_accuracy: 0.7703\n",
      "Epoch 38/50\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 0.0115 - accuracy: 0.9966 - val_loss: 1.3560 - val_accuracy: 0.7703\n",
      "Epoch 39/50\n",
      "19/19 [==============================] - 1s 43ms/step - loss: 0.0118 - accuracy: 0.9966 - val_loss: 1.4186 - val_accuracy: 0.7838\n",
      "Epoch 40/50\n",
      "19/19 [==============================] - 1s 42ms/step - loss: 0.0143 - accuracy: 0.9966 - val_loss: 1.3749 - val_accuracy: 0.7703\n",
      "Epoch 41/50\n",
      "19/19 [==============================] - 1s 45ms/step - loss: 0.0116 - accuracy: 0.9966 - val_loss: 1.4011 - val_accuracy: 0.7703\n",
      "Epoch 42/50\n",
      "19/19 [==============================] - 1s 39ms/step - loss: 0.0103 - accuracy: 0.9966 - val_loss: 1.4041 - val_accuracy: 0.7703\n",
      "Epoch 43/50\n",
      "19/19 [==============================] - 1s 42ms/step - loss: 0.0112 - accuracy: 0.9966 - val_loss: 1.4384 - val_accuracy: 0.7838\n",
      "Epoch 44/50\n",
      "19/19 [==============================] - 1s 42ms/step - loss: 0.0103 - accuracy: 0.9966 - val_loss: 1.4363 - val_accuracy: 0.7703\n",
      "Epoch 45/50\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 0.0095 - accuracy: 0.9966 - val_loss: 1.4282 - val_accuracy: 0.7703\n",
      "Epoch 46/50\n",
      "19/19 [==============================] - 1s 45ms/step - loss: 0.0117 - accuracy: 0.9966 - val_loss: 1.4430 - val_accuracy: 0.7703\n",
      "Epoch 47/50\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 0.0101 - accuracy: 0.9966 - val_loss: 1.4582 - val_accuracy: 0.7838\n",
      "Epoch 48/50\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 0.0102 - accuracy: 0.9966 - val_loss: 1.4301 - val_accuracy: 0.7703\n",
      "Epoch 49/50\n",
      "19/19 [==============================] - 1s 42ms/step - loss: 0.0097 - accuracy: 0.9966 - val_loss: 1.4606 - val_accuracy: 0.7703\n",
      "Epoch 50/50\n",
      "19/19 [==============================] - 1s 66ms/step - loss: 0.0114 - accuracy: 0.9932 - val_loss: 1.4751 - val_accuracy: 0.7838\n"
     ]
    }
   ],
   "source": [
    "RNN_model = create_RNN_model()\n",
    "RNN_history = RNN_model.fit(feature_train, y_train, epochs=50, batch_size=16, validation_data=(feature_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 15ms/step\n",
      "0.8494623655913979\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.68      0.74        19\n",
      "           1       0.83      0.93      0.88        46\n",
      "           2       0.92      0.82      0.87        28\n",
      "\n",
      "    accuracy                           0.85        93\n",
      "   macro avg       0.85      0.81      0.83        93\n",
      "weighted avg       0.85      0.85      0.85        93\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_RNN = RNN_model.predict(feature_test)\n",
    "y_pred_RNN_class = np.argmax(y_pred_RNN, axis=1)\n",
    "\n",
    "print(accuracy_score(y_test_class, y_pred_RNN_class))\n",
    "print(classification_report(y_test_class, y_pred_RNN_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.figure(figsize=(9,6))\n",
    "plt.plot(RNN_history.history['accuracy'])\n",
    "plt.plot(RNN_history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training & validation loss values\n",
    "plt.figure(figsize=(9,6))\n",
    "plt.plot(RNN_history.history['loss'])\n",
    "plt.plot(RNN_history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_GRU_model():\n",
    "    RNN = Sequential()\n",
    "    RNN.add(Embedding(len(word_index) + 1, word_dimension, weights=[embedding_matrix], input_length = maxlen, trainable=False))\n",
    "\n",
    "    RNN.add(Bidirectional(GRU(word_dimension)))\n",
    "    RNN.add(Dense(word_dimension, activation='relu'))\n",
    "    RNN.add(Dense(3, activation='sigmoid'))\n",
    "    RNN.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "    #RNN.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "    \n",
    "    return RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "19/19 [==============================] - 4s 103ms/step - loss: 0.9818 - accuracy: 0.5612 - val_loss: 0.9372 - val_accuracy: 0.5541\n",
      "Epoch 2/50\n",
      "19/19 [==============================] - 1s 50ms/step - loss: 0.8272 - accuracy: 0.5952 - val_loss: 0.8711 - val_accuracy: 0.6351\n",
      "Epoch 3/50\n",
      "19/19 [==============================] - 1s 43ms/step - loss: 0.7165 - accuracy: 0.7245 - val_loss: 0.8408 - val_accuracy: 0.6622\n",
      "Epoch 4/50\n",
      "19/19 [==============================] - 1s 50ms/step - loss: 0.6233 - accuracy: 0.7993 - val_loss: 0.8103 - val_accuracy: 0.6757\n",
      "Epoch 5/50\n",
      "19/19 [==============================] - 1s 58ms/step - loss: 0.5361 - accuracy: 0.8231 - val_loss: 0.8347 - val_accuracy: 0.7027\n",
      "Epoch 6/50\n",
      "19/19 [==============================] - 1s 51ms/step - loss: 0.4918 - accuracy: 0.8469 - val_loss: 0.7990 - val_accuracy: 0.6486\n",
      "Epoch 7/50\n",
      "19/19 [==============================] - 1s 44ms/step - loss: 0.4078 - accuracy: 0.8707 - val_loss: 0.8002 - val_accuracy: 0.6892\n",
      "Epoch 8/50\n",
      "19/19 [==============================] - 1s 52ms/step - loss: 0.3600 - accuracy: 0.8741 - val_loss: 0.7982 - val_accuracy: 0.7027\n",
      "Epoch 9/50\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 0.3012 - accuracy: 0.8980 - val_loss: 0.8162 - val_accuracy: 0.7027\n",
      "Epoch 10/50\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 0.2772 - accuracy: 0.9116 - val_loss: 0.8321 - val_accuracy: 0.6892\n",
      "Epoch 11/50\n",
      "19/19 [==============================] - 1s 43ms/step - loss: 0.2431 - accuracy: 0.9082 - val_loss: 0.8664 - val_accuracy: 0.7027\n",
      "Epoch 12/50\n",
      "19/19 [==============================] - 1s 62ms/step - loss: 0.2114 - accuracy: 0.9286 - val_loss: 0.8572 - val_accuracy: 0.6892\n",
      "Epoch 13/50\n",
      "19/19 [==============================] - 1s 51ms/step - loss: 0.1963 - accuracy: 0.9354 - val_loss: 0.8779 - val_accuracy: 0.7027\n",
      "Epoch 14/50\n",
      "19/19 [==============================] - 1s 44ms/step - loss: 0.1654 - accuracy: 0.9490 - val_loss: 0.9222 - val_accuracy: 0.7027\n",
      "Epoch 15/50\n",
      "19/19 [==============================] - 1s 46ms/step - loss: 0.1498 - accuracy: 0.9524 - val_loss: 0.9759 - val_accuracy: 0.7297\n",
      "Epoch 16/50\n",
      "19/19 [==============================] - 1s 45ms/step - loss: 0.1390 - accuracy: 0.9524 - val_loss: 0.9230 - val_accuracy: 0.7432\n",
      "Epoch 17/50\n",
      "19/19 [==============================] - 1s 49ms/step - loss: 0.1351 - accuracy: 0.9626 - val_loss: 0.9618 - val_accuracy: 0.7027\n",
      "Epoch 18/50\n",
      "19/19 [==============================] - 1s 61ms/step - loss: 0.1455 - accuracy: 0.9524 - val_loss: 1.0316 - val_accuracy: 0.7297\n",
      "Epoch 19/50\n",
      "19/19 [==============================] - 1s 50ms/step - loss: 0.1339 - accuracy: 0.9524 - val_loss: 0.9368 - val_accuracy: 0.7297\n",
      "Epoch 20/50\n",
      "19/19 [==============================] - 1s 52ms/step - loss: 0.1034 - accuracy: 0.9660 - val_loss: 0.9652 - val_accuracy: 0.7568\n",
      "Epoch 21/50\n",
      "19/19 [==============================] - 1s 43ms/step - loss: 0.1024 - accuracy: 0.9558 - val_loss: 1.0039 - val_accuracy: 0.7432\n",
      "Epoch 22/50\n",
      "19/19 [==============================] - 1s 42ms/step - loss: 0.1067 - accuracy: 0.9626 - val_loss: 1.0307 - val_accuracy: 0.7568\n",
      "Epoch 23/50\n",
      "19/19 [==============================] - 1s 43ms/step - loss: 0.1074 - accuracy: 0.9660 - val_loss: 1.0000 - val_accuracy: 0.7297\n",
      "Epoch 24/50\n",
      "19/19 [==============================] - 1s 44ms/step - loss: 0.0943 - accuracy: 0.9660 - val_loss: 1.0048 - val_accuracy: 0.7432\n",
      "Epoch 25/50\n",
      "19/19 [==============================] - 1s 44ms/step - loss: 0.0733 - accuracy: 0.9728 - val_loss: 0.9996 - val_accuracy: 0.7703\n",
      "Epoch 26/50\n",
      "19/19 [==============================] - 1s 42ms/step - loss: 0.0678 - accuracy: 0.9728 - val_loss: 1.1053 - val_accuracy: 0.7838\n",
      "Epoch 27/50\n",
      "19/19 [==============================] - 1s 42ms/step - loss: 0.0831 - accuracy: 0.9728 - val_loss: 1.0984 - val_accuracy: 0.7703\n",
      "Epoch 28/50\n",
      "19/19 [==============================] - 1s 43ms/step - loss: 0.0603 - accuracy: 0.9864 - val_loss: 1.0123 - val_accuracy: 0.7297\n",
      "Epoch 29/50\n",
      "19/19 [==============================] - 1s 44ms/step - loss: 0.0687 - accuracy: 0.9762 - val_loss: 1.0662 - val_accuracy: 0.7432\n",
      "Epoch 30/50\n",
      "19/19 [==============================] - 1s 44ms/step - loss: 0.0701 - accuracy: 0.9728 - val_loss: 1.0904 - val_accuracy: 0.7568\n",
      "Epoch 31/50\n",
      "19/19 [==============================] - 1s 46ms/step - loss: 0.0582 - accuracy: 0.9830 - val_loss: 1.1071 - val_accuracy: 0.7703\n",
      "Epoch 32/50\n",
      "19/19 [==============================] - 1s 42ms/step - loss: 0.0473 - accuracy: 0.9864 - val_loss: 1.1855 - val_accuracy: 0.7703\n",
      "Epoch 33/50\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 0.0449 - accuracy: 0.9864 - val_loss: 1.2585 - val_accuracy: 0.7838\n",
      "Epoch 34/50\n",
      "19/19 [==============================] - 1s 53ms/step - loss: 0.0404 - accuracy: 0.9796 - val_loss: 1.2693 - val_accuracy: 0.7568\n",
      "Epoch 35/50\n",
      "19/19 [==============================] - 1s 44ms/step - loss: 0.0334 - accuracy: 0.9932 - val_loss: 1.3237 - val_accuracy: 0.7432\n",
      "Epoch 36/50\n",
      "19/19 [==============================] - 1s 43ms/step - loss: 0.0396 - accuracy: 0.9898 - val_loss: 1.3287 - val_accuracy: 0.7703\n",
      "Epoch 37/50\n",
      "19/19 [==============================] - 1s 46ms/step - loss: 0.0628 - accuracy: 0.9864 - val_loss: 1.2740 - val_accuracy: 0.7568\n",
      "Epoch 38/50\n",
      "19/19 [==============================] - 1s 48ms/step - loss: 0.0441 - accuracy: 0.9830 - val_loss: 1.2240 - val_accuracy: 0.7703\n",
      "Epoch 39/50\n",
      "19/19 [==============================] - 1s 43ms/step - loss: 0.0370 - accuracy: 0.9796 - val_loss: 1.4750 - val_accuracy: 0.7297\n",
      "Epoch 40/50\n",
      "19/19 [==============================] - 1s 58ms/step - loss: 0.0419 - accuracy: 0.9830 - val_loss: 1.2365 - val_accuracy: 0.7838\n",
      "Epoch 41/50\n",
      "19/19 [==============================] - 1s 73ms/step - loss: 0.0371 - accuracy: 0.9898 - val_loss: 1.3524 - val_accuracy: 0.7432\n",
      "Epoch 42/50\n",
      "19/19 [==============================] - 1s 48ms/step - loss: 0.0377 - accuracy: 0.9898 - val_loss: 1.1714 - val_accuracy: 0.7973\n",
      "Epoch 43/50\n",
      "19/19 [==============================] - 1s 43ms/step - loss: 0.0361 - accuracy: 0.9830 - val_loss: 1.1775 - val_accuracy: 0.7838\n",
      "Epoch 44/50\n",
      "19/19 [==============================] - 1s 42ms/step - loss: 0.0333 - accuracy: 0.9830 - val_loss: 1.3541 - val_accuracy: 0.7568\n",
      "Epoch 45/50\n",
      "19/19 [==============================] - 1s 42ms/step - loss: 0.0251 - accuracy: 0.9966 - val_loss: 1.1906 - val_accuracy: 0.7838\n",
      "Epoch 46/50\n",
      "19/19 [==============================] - 1s 43ms/step - loss: 0.0219 - accuracy: 0.9966 - val_loss: 1.3212 - val_accuracy: 0.7568\n",
      "Epoch 47/50\n",
      "19/19 [==============================] - 1s 46ms/step - loss: 0.0206 - accuracy: 0.9966 - val_loss: 1.3540 - val_accuracy: 0.7432\n",
      "Epoch 48/50\n",
      "19/19 [==============================] - 1s 45ms/step - loss: 0.0217 - accuracy: 0.9898 - val_loss: 1.3054 - val_accuracy: 0.7703\n",
      "Epoch 49/50\n",
      "19/19 [==============================] - 1s 43ms/step - loss: 0.0627 - accuracy: 0.9796 - val_loss: 1.3261 - val_accuracy: 0.7973\n",
      "Epoch 50/50\n",
      "19/19 [==============================] - 1s 44ms/step - loss: 0.0592 - accuracy: 0.9694 - val_loss: 1.3290 - val_accuracy: 0.7838\n"
     ]
    }
   ],
   "source": [
    "GRU_model = create_GRU_model()\n",
    "GRU_history = GRU_model.fit(feature_train, y_train, epochs=50, batch_size=16, validation_data=(feature_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 11ms/step\n",
      "0.8387096774193549\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.63      0.75        19\n",
      "           1       0.79      0.98      0.87        46\n",
      "           2       0.91      0.75      0.82        28\n",
      "\n",
      "    accuracy                           0.84        93\n",
      "   macro avg       0.88      0.79      0.82        93\n",
      "weighted avg       0.85      0.84      0.83        93\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_GRU = GRU_model.predict(feature_test)\n",
    "y_pred_GRU_class = np.argmax(y_pred_GRU, axis=1)\n",
    "\n",
    "print(accuracy_score(y_test_class, y_pred_GRU_class))\n",
    "print(classification_report(y_test_class, y_pred_GRU_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.figure(figsize=(9,6))\n",
    "plt.plot(GRU_history.history['accuracy'])\n",
    "plt.plot(GRU_history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training & validation loss values\n",
    "plt.figure(figsize=(9,6))\n",
    "plt.plot(GRU_history.history['loss'])\n",
    "plt.plot(GRU_history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
